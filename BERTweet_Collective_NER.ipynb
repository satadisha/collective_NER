{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZKMubBHEgZM"
      },
      "source": [
        "## **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygYoSkp_Wq-j",
        "outputId": "85dab83f-593f-4b6d-9d29-e3fe442f3229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ],
      "source": [
        "!python3 --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LQiJy6bX52T",
        "outputId": "28f4fd0f-b2d9-47f7-ed5a-46b8dec9270f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/BERTweet-ner\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "%cd gdrive/My Drive/BERTweet-ner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba-jv0cUX9R2",
        "outputId": "6b138f31-52a4-47cb-f1ed-77d251ad5944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n",
            "\u001b[K     |████████████████████████████████| 362 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 78.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 12.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 56.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 79.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 75.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 50.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 80.2 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 68.3 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, responses, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.3.2 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.8.1 multidict-6.0.2 pyyaml-6.0 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 75.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.12.1 transformers-4.20.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.1.tar.gz (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.20.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 24.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.8.1->sentence-transformers) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.8.1->sentence-transformers) (3.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.8.1->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.8.1->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.8.1->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.8.1->sentence-transformers) (4.11.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.8.1->sentence-transformers) (3.0.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.8.1->sentence-transformers) (3.8.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.8.1->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.8.1->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.8.1->sentence-transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.8.1->sentence-transformers) (2022.6.15)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.1-py3-none-any.whl size=125774 sha256=e95e82ea6378929a411eed0bc51225e6748e444998eb5c543c7d490deb9335f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/27/2f/708b4f002c226e57b6243769da345c650633175c7634f93365\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.1 sentencepiece-0.1.96\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install datasets\n",
        "!pip3 install transformers\n",
        "!pip3 install -U sentence-transformers\n",
        "!pip3 install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w4J4mdnYD2o",
        "outputId": "dae243f8-4b8b-41b4-bd83-a6a1a2c0d0d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 4.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=2898d376ed080e7643acc0c6d4d3ba9065e22366075808b2d1a759322914a31a\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht5nhSRpgxn4"
      },
      "outputs": [],
      "source": [
        "# import nltk\n",
        "# nltk.download('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_D9peakfkT9",
        "outputId": "e2b0db3c-394c-4d55-b44b-e7348d7f3495"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.cuda.amp.autocast_mode.autocast at 0x7f43c39d4610>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "\n",
        "from datasets import load_dataset, load_metric, ClassLabel, Sequence\n",
        "import random\n",
        "import torch\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "import copy\n",
        "\n",
        "# import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "torch.cuda.amp.autocast(enabled=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usDw-ReUiklS"
      },
      "source": [
        "## **Setting some global stuff**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lZKZmPKizRT",
        "outputId": "885d187e-16ac-4b04-ab5d-519db6cf4428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# Set device\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-uyPRRBJmEe"
      },
      "outputs": [],
      "source": [
        "# example_2D_list = [[0.2423,-0.6679,0.8277],[0.2423,-0.6679,0.8277],[0.2423,-0.6679,0.8277]]\n",
        "# twodTensor = torch.tensor(example_2D_list)\n",
        "\n",
        "# example_1D_list = [0.2245,-2.2268,0.4577]\n",
        "# origTensor = torch.tensor(example_1D_list)\n",
        "\n",
        "# # modifiedTensor = origTensor.repeat(3, 1)\n",
        "\n",
        "# # print(twodTensor.size(),origTensor.size())\n",
        "# # print(modifiedTensor)\n",
        "\n",
        "# cosine_layer = torch.nn.CosineSimilarity(dim=1)\n",
        "# output = cosine_layer(origTensor, twodTensor)\n",
        "# print(output)\n",
        "# print(torch.mul(output, -1/100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1_FuBfIU9E5"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "\n",
        "class PhraseEmbeddingI(nn.Module):\n",
        "\n",
        "    def __init__(self,input_size,output_size,device,mentions_dict,index_candidate_dict):\n",
        "        super(PhraseEmbeddingI, self).__init__()\n",
        "        self.print_once=True\n",
        "        self.dense_layer = nn.Linear(input_size,output_size)\n",
        "        self.batchnorm = nn.BatchNorm1d(output_size)\n",
        "        self.non_linear_layer = nn.LeakyReLU() #nn.Tanh()\n",
        "        self.cosine_layer = nn.CosineSimilarity(dim=1)\n",
        "        self.device = device\n",
        "        self.mentions_dict_train = mentions_dict\n",
        "        self.mentions_embedding_dict_train = {}\n",
        "        self.index_candidate_dict_train = index_candidate_dict\n",
        "        self.temperature = 2\n",
        "        return\n",
        "\n",
        "    def encode(self, input_embedding):\n",
        "\n",
        "        # print(input_embedding.size())\n",
        "\n",
        "        #Average Pooling has already been done before\n",
        "        input_embedding = input_embedding.to(device=self.device)\n",
        "        x = self.dense_layer(input_embedding)\n",
        "        x = self.batchnorm(x)\n",
        "        out = self.non_linear_layer(x)\n",
        "        # print(out.size())\n",
        "        return out\n",
        "\n",
        "    def compute(self, input_tuple):\n",
        "        # Soft Nearest Neighbours\n",
        "        # print(input_tuple)\n",
        "        anchor_mention_index = input_tuple[0]\n",
        "        input_anchor = self.index_candidate_dict_train[input_tuple[1]]\n",
        "        input_negative1 = self.index_candidate_dict_train[input_tuple[2]]\n",
        "        input_negative2 = self.index_candidate_dict_train[input_tuple[3]]\n",
        "        input_negative3 = self.index_candidate_dict_train[input_tuple[4]]\n",
        "        input_negative4 = self.index_candidate_dict_train[input_tuple[5]]\n",
        "\n",
        "        # print(anchor_mention_index,input_anchor,input_negative1,input_negative2,input_negative3,input_negative4)\n",
        "\n",
        "        positive_embeddings_list = []\n",
        "        all_embeddings_list = []\n",
        "\n",
        "        anchor_embedding = self.encode(self.mentions_dict_train[input_anchor][anchor_mention_index])\n",
        "\n",
        "        positive_embeddings_list = [self.mentions_dict_train[input_anchor][ind] for ind in range(len(self.mentions_dict_train[input_anchor])) if ind != anchor_mention_index]\n",
        "        \n",
        "        all_embeddings_list += positive_embeddings_list\n",
        "        all_embeddings_list += self.mentions_dict_train[input_negative1] + self.mentions_dict_train[input_negative2] + self.mentions_dict_train[input_negative3] + self.mentions_dict_train[input_negative4]\n",
        "\n",
        "        pos_emb_tensors = self.encode(torch.stack(positive_embeddings_list).to(self.device)) #\n",
        "        all_emb_tensors = self.encode(torch.stack(all_embeddings_list).to(self.device)) #\n",
        "\n",
        "        # print(len(positive_embeddings_list),len(all_embeddings_list))\n",
        "        # print(pos_emb_tensors.size(),all_emb_tensors.size())\n",
        "\n",
        "        # #Cosine sims\n",
        "        pos_sim_tensor = torch.mul(1-self.cosine_layer(anchor_embedding, pos_emb_tensors), -1/self.temperature)\n",
        "        all_sim_tensor = torch.mul(1-self.cosine_layer(anchor_embedding, all_emb_tensors), -1/self.temperature)\n",
        "\n",
        "        ret = torch.sum(torch.exp(pos_sim_tensor))/torch.sum(torch.exp(all_sim_tensor)).to(self.device)\n",
        "        # print('==>',output_anchor.size(),output_positive.size(),output_negative.size())\n",
        "        return ret\n",
        "\n",
        "    def forward(self,batch_data):\n",
        "        output_arr = []\n",
        "        printn=0\n",
        "\n",
        "        # # print('start')\n",
        "        # for key in self.mentions_dict_train.keys():\n",
        "        #     mentions_embedding_list = []\n",
        "        #     for emb in self.mentions_dict_train[key]:\n",
        "        #         mentions_embedding_list.append(self.encode(emb))\n",
        "        #     self.mentions_embedding_dict_train[key] = mentions_embedding_list\n",
        "        # # print('end')\n",
        "\n",
        "        anchor_mention_indices = batch_data[0]\n",
        "        anchor_candidate_indices = batch_data[1]\n",
        "        neg_candidate1_indices = batch_data[2]\n",
        "        neg_candidate2_indices = batch_data[3]\n",
        "        neg_candidate3_indices = batch_data[4]\n",
        "        neg_candidate4_indices = batch_data[5]\n",
        "\n",
        "        for index in range(len(anchor_mention_indices)):\n",
        "            x_tup = (int(anchor_mention_indices[index].item()), int(anchor_candidate_indices[index].item()), int(neg_candidate1_indices[index].item()), int(neg_candidate2_indices[index].item()), int(neg_candidate3_indices[index].item()), int(neg_candidate4_indices[index].item()))\n",
        "            out = self.compute(x_tup)\n",
        "            # if(printn%10==0):\n",
        "            #     print(printn)\n",
        "            printn+=1\n",
        "            output_arr.append(out)\n",
        "        output_tensor = torch.stack(output_arr).to(self.device)\n",
        "        return output_tensor\n",
        "\n",
        "    def getEmbedding(self, input_embeddings):\n",
        "        with torch.no_grad():\n",
        "            return self.encode(input_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6thsaSRLjH0e"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "\n",
        "class PhraseEmbedding(nn.Module):\n",
        "\n",
        "    def __init__(self,input_size,output_size,device):\n",
        "        super(PhraseEmbedding, self).__init__()\n",
        "        self.print_once=True\n",
        "        self.dense_layer1 = nn.Linear(input_size,output_size)\n",
        "        # self.batchnorm1 = nn.BatchNorm1d(350)\n",
        "        # self.dense_layer2 = nn.Linear(350,output_size)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(output_size)\n",
        "        self.non_linear_layer = nn.Tanh()#nn.LeakyReLU() \n",
        "        self.cosine_layer = nn.CosineSimilarity(dim=1)\n",
        "        self.device = device\n",
        "        return\n",
        "\n",
        "    \n",
        "\n",
        "    def encode(self, input_embedding):\n",
        "\n",
        "        # print(input_embedding.size())\n",
        "\n",
        "        #Average Pooling has already been done before\n",
        "        input_embedding = input_embedding.to(device=self.device)\n",
        "        # print(average_pooled_embedding.size())\n",
        "        x = self.dense_layer1(input_embedding)\n",
        "        # x = self.batchnorm1(x)\n",
        "        # x = self.non_linear_layer(x)\n",
        "        # x = self.dense_layer2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        out = self.non_linear_layer(x)\n",
        "        # print(out.size())\n",
        "        return out\n",
        "\n",
        "    def forward(self, input_tuple):\n",
        "        # Triplet\n",
        "        input_anchor = input_tuple[0]\n",
        "        input_positive = input_tuple[1]\n",
        "        input_negative = input_tuple[2]\n",
        "\n",
        "        output_anchor = self.encode(input_anchor)\n",
        "        output_positive = self.encode(input_positive)\n",
        "        output_negative = self.encode(input_negative)\n",
        "\n",
        "        assert torch.isnan(output_anchor).any() == False\n",
        "        assert torch.isnan(output_positive).any() == False\n",
        "        assert torch.isnan(output_negative).any() == False\n",
        "\n",
        "        # #L2 distances\n",
        "        # positive_distance = torch.linalg.norm(output_anchor - output_positive)\n",
        "        # negative_distance = torch.linalg.norm(output_anchor - output_negative)\n",
        "\n",
        "        #Cosine distances\n",
        "        positive_distance = 1-self.cosine_layer(output_anchor, output_positive)\n",
        "        negative_distance = 1-self.cosine_layer(output_anchor, output_negative)\n",
        "\n",
        "        # print('==>',output_anchor.size(),output_positive.size(),output_negative.size())\n",
        "        return (positive_distance,negative_distance)\n",
        "\n",
        "    def getEmbedding(self, input_embeddings):\n",
        "        with torch.no_grad():\n",
        "            return self.encode(input_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oz6WlopQquia"
      },
      "outputs": [],
      "source": [
        "class TripletLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "    \n",
        "    def forward(self, input_tup):\n",
        "        distance_positive = input_tup[0]\n",
        "        distance_negative = input_tup[1]\n",
        "        losses = torch.relu(distance_positive - distance_negative + self.margin)\n",
        "        # print(distance_positive.size(),losses.size())\n",
        "        return losses.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgXNBca_AM7G"
      },
      "outputs": [],
      "source": [
        "class TupletLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TupletLoss, self).__init__()\n",
        "    \n",
        "    def forward(self, input_tup):\n",
        "        expdiff1 = input_tup[0]\n",
        "        expdiff2 = input_tup[1]\n",
        "        expdiff3 = input_tup[2]\n",
        "        expdiff4 = input_tup[3]\n",
        "        expdiffsum = expdiff1 + expdiff2 + expdiff3 + expdiff4\n",
        "        losses = torch.log(torch.add(expdiffsum,1))\n",
        "        \n",
        "        # print(expdiff1.size(),expdiffsum.size(),losses.size())\n",
        "        return losses.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQ9JZrFdpqyU"
      },
      "outputs": [],
      "source": [
        "class SoftKNNLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SoftKNNLoss, self).__init__()\n",
        "    \n",
        "    def forward(self, input):\n",
        "        losses = torch.mul(torch.log(input),-1)\n",
        "        # print(input.size(),losses.size())\n",
        "        # final_loss = Variable(final_loss, requires_grad = True)’\n",
        "        return losses.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328,
          "referenced_widgets": [
            "b1dc79a62aa4482bb258bbb610fe8801",
            "75551b8dfb724224a1c01ca18a468dbd",
            "e3faa268eb6c4ccca59b3088aaec4ab9",
            "32bd522a15c34ae8822a610e2605da76",
            "db66b7c836a6468194a7bad1dbfb4e52",
            "5d4e228b9b8745eebbb2cc7388c46041",
            "90097e15f993452ea7d428823eef398b",
            "bd8f266dc9074c7aa2d0b60a717d1107",
            "21ede9873eb044e6a1bf0759770f25d4",
            "5dff7e1c834b4296a82ae4b181f72a07",
            "80abe1a5fcfd428ab05f89b3467fac45",
            "f594642877e94e0c8424f67183cd393e",
            "4c4973cc228741279270e90a9a200fe4",
            "f60b055cced64c0c889c277c612a8ef5",
            "92152896c9ba41f6a4d2066ca54f4df7",
            "2c95d44de52b41289afc44a904c7dc9a",
            "fdc1bde71f0c4164b49560f78b789c59",
            "6d729dc7617a44658e9fc71a16c2bbf9",
            "ee8681564a50431dbb2eecafc815a9c7",
            "304e3fb6d8cd46b2beef916d7ec358c9",
            "c92d53a9d14f43b5b426988ad4226402",
            "5b6073439d3e44369c1afa80b86a12a8",
            "3487d34848214cf8bbd86159f0c4e44e",
            "682cf09564b84076ac88e3bf83468b43",
            "877b2dfec2224785b0362fb20e2bacdd",
            "36e78d6c798f4780b105ff2feed7fa70",
            "be0f742d1c88420ba704816164d26c91",
            "07f3bfd67fb9420dbd75e4dd5881c988",
            "a12795fcb64d4d9f9e716c0f1c19a69d",
            "9a460fdfc13445b0a15ee2c27478ae17",
            "cb7607908ab345828676cbe3b1b59878",
            "2c8363a885884e66ba1bd02ed0490d75",
            "5c943f3a65f644e18e8b935a1af92293",
            "11118b22ecef44acb95651080ed57889",
            "0bfaf01db444496fa1846d573d69544b",
            "9a3f2552057b434cae80ab5c9f54fd03",
            "b860f904f8f24c0fb17ea57cd8b65b93",
            "90b1f53888bb4d2ca9b77c5e6bc15c91",
            "7eb5e662063e4b4abf9c2b24bfb2ebdd",
            "99582dfa47804bbc828fc6deeb8f2e2b",
            "fdb8075f3d704dba990554ba0a3edd26",
            "d64b301362224593bd5dec17f2941dc9",
            "1534f65fe72c4d46acc6d36fb24fef8b",
            "5114996707fc44cf9668e4041f8fa23f",
            "6402077d1b214d6b93af404593317be8",
            "dca18745ecf7403283b9270311bfab81",
            "1f2e17ac40764137bf76a9ac05f588a3",
            "a6f7afc495b0453bbdfe98ed7c9308fc",
            "67a7649512d44261951ad4ceabd67fd9",
            "016dc1a71b8c49679a08b8c760938d1d",
            "438ea8398f8544cbbc2e06815857245b",
            "bcc4728d9aa041a8803797182027eb8a",
            "fd1860a1309a49159f4528b845e39a90",
            "5f7acf72e38d48ae86217d835c406746",
            "017a638533ce4a9c9c90654a45970864",
            "12e1acc660f4486d9ca030e0f8b4965f",
            "cb71e3aa19714a5faee990bbf5c36c78",
            "758f0079ec8d42988a39901623852455",
            "516af4dab11c49848cb37c3b87d3804e",
            "21a9f8259807499ca01cfbbb423fb7c2",
            "5bede4a6edbb4d53b0695c57dc8ee624",
            "34add080a81b41f1918a06f7bf8ae80d",
            "24dcd3f5a6754179b056afd81741776e",
            "a355142d418d4102b3f0db1c737318b7",
            "c21bec3a8d3d404da07db6a48ad2306b",
            "2cd342354af24677898d237f628214a6",
            "c0da11c0181a419a863cf86df151b130",
            "341ebdce16b942d2bd62e848d7928ad6",
            "d6fd0eaadd4a4fbfab2fc7518a8d703f",
            "60474ab9f1f94a1ea1bb149e6d9cb1e5",
            "cfffe63f35054281b63372950bd28402",
            "a14a041b6d1f4642894754b1656477e8",
            "ab525bd932fc4abdabf8f7438acff1a9",
            "4fda688506364321bdea7203cecf8ca2",
            "33adeeed0e12464db6ddb6b9e424bcf2",
            "9dc306ede0b747cab4908cfceb3e93e3",
            "0aff12944bc4477fbd1c8e50a55d2ca5",
            "6ae92aaf38054c5686254b54db2b9358",
            "983991292c114144bb00e7652ee26d27",
            "1d630bed2e9242b1b4c6af977f1d0d40",
            "67905dcd3dde4153b083ff740c720631",
            "64b6cf52ffbe46559ffd5e2b0f13f505",
            "dda3391cadf54674b11f5b55413e8a64",
            "47f04fb929644df49aa2d7a9cf4d8b29",
            "4744990b4dff49e682eb8fec87d3c913",
            "78dfd3449d4044c8876e1db237fbcaea",
            "42c68f1abc3f4f649405235fc2f09b81",
            "39b51ca1f7f3474d959af284ed1d3b7a",
            "e034861130ee4d318039554952aed21b",
            "6b9970ad33ed455a9468ca2be2d7d51e",
            "7e67a319203a4820aec374761c32279e",
            "911ec2b356f94117af483ff6f16aff38",
            "efb99f2c061f4692b0dd98e83cc4869e",
            "02f629323214444cb105883b56ba6dce",
            "5587442219ad4173a1067c2bb68f011c",
            "14df70a7b046465ab74998bfa20b44c2",
            "684ee0417cba480f81529058ba2fa209",
            "0decd33fc65b4992be382ea9b9b04022",
            "ced851cbf22b4ad0a22800ba6059fb78",
            "75835fca11ba455b85f78dd28876a8e3",
            "f63dfd4ee0934560a3796fbf8accf1c6",
            "fd47174d492d49a6bc17b211a6650bb7",
            "7e7ee8ba4b2c42d0b157cbf5890e9a29",
            "03a50289cf6e4e42af01454d78bf415d",
            "f0de2fbb52c940b6937945e098d0469e",
            "636636f5b0ab4a47bbef54d9875d31df",
            "4866c09cd447474fa5f4ecebd12d30e4",
            "05bc48434e634f64bec3bcc23e37862b",
            "afd610ff06e340059b7bf8c21b64ef5a",
            "39ee43655bcf44389350a1ae07d0f165",
            "9a7861554e624405b7f5db21dd38cccf",
            "87fbe3da467f43488c2394ee6c37b5d5",
            "857aecde3da14be5b4af41808c74483c",
            "9bb7095aaabc431da3960e1051ea6018",
            "57c062d610ae4521b25f5eca7ac1ce07",
            "cf8bbd7fa3224ec39a4093bac8594c87",
            "1ab7a9bc3e53418bbcfad8d80e7942cc",
            "879076ff6d184ad19d700189cbf3c222",
            "79a6045891cd4797a06f77ff1ee9200a",
            "77c0c07ce21a4e11836d3d36dca794e8",
            "6ff9dd7daaae4901a544605011df5fa1"
          ]
        },
        "id": "8ENBgHBFm9fb",
        "outputId": "ae99ce2c-147e-4048-ca18-afb7ff8f79d6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1dc79a62aa4482bb258bbb610fe8801"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/1.66k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f594642877e94e0c8424f67183cd393e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset wnut_17/wnut_17 (download: 782.18 KiB, generated: 1.66 MiB, post-processed: Unknown size, total: 2.43 MiB) to /root/.cache/huggingface/datasets/wnut_17/wnut_17/1.0.0/077c7f08b8dbc800692e8c9186cdf3606d5849ab0e7be662e6135bb10eba54f9...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3487d34848214cf8bbd86159f0c4e44e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/185k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11118b22ecef44acb95651080ed57889"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/39.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6402077d1b214d6b93af404593317be8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/66.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12e1acc660f4486d9ca030e0f8b4965f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0da11c0181a419a863cf86df151b130"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/3394 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ae92aaf38054c5686254b54db2b9358"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1009 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e034861130ee4d318039554952aed21b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1287 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75835fca11ba455b85f78dd28876a8e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset wnut_17 downloaded and prepared to /root/.cache/huggingface/datasets/wnut_17/wnut_17/1.0.0/077c7f08b8dbc800692e8c9186cdf3606d5849ab0e7be662e6135bb10eba54f9. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a7861554e624405b7f5db21dd38cccf"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
        "model_checkpoint = \"vinai/bertweet-base\"\n",
        "batch_size = 32\n",
        "datasets = load_dataset(\"wnut_17\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhnAJCnbjKIm"
      },
      "source": [
        "## **Initialization of some components**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "\n",
        "# from entityEmbedding import phraseEmbedding\n",
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    return model, optimizer, checkpoint['epoch']"
      ],
      "metadata": {
        "id": "Yq3wS_ptXd79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNnKiVrjjQ3J"
      },
      "outputs": [],
      "source": [
        "# Initialize network\n",
        "output_embedding_size = 300\n",
        "# output_embedding_size = 768\n",
        "learning_rate = 0.001\n",
        "\n",
        "phraseEmbeddingModel = PhraseEmbedding(768, output_embedding_size, device).to(device) #triplet\n",
        "# phraseEmbeddingModel = PhraseEmbeddingI(768, output_embedding_size, device).to(device) #soft-knn\n",
        "\n",
        "#Loss and Optimizer\n",
        "optimizer = optim.Adam(phraseEmbeddingModel.parameters(), lr=learning_rate, weight_decay=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOtV2RzzVgt2"
      },
      "outputs": [],
      "source": [
        "# define checkpoint saved path for entity phrase embedder\n",
        "\n",
        "# ckp_path = \"entityEmbedding/model_checkpoints_ner/checkpoint_model300.pt\" #300 triplet\n",
        "# # ckp_path = \"entityEmbedding/model_checkpoints_ner/checkpoint_model300_softknn.pt\" #300 tuplet\n",
        "\n",
        "# if(path.exists(ckp_path)):\n",
        "#     # load the saved checkpoint\n",
        "#     entityPhraseEmbedder, optimizer, start_epoch = load_ckp(ckp_path, phraseEmbeddingModel, optimizer)\n",
        "\n",
        "#     print(\"starting with model at epoch:\", start_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3e11xA_kKRa",
        "outputId": "128b23cf-b420-4f6c-915c-dcbc4d9edbb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('gutenberg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl7BOt4tkLA1"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import gutenberg\n",
        "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer\n",
        "\n",
        "gutenberg_text = \"\"\n",
        "for file_id in gutenberg.fileids():\n",
        "    gutenberg_text += gutenberg.raw(file_id)\n",
        "tokenizer_trainer = PunktTrainer()\n",
        "tokenizer_trainer.INCLUDE_ALL_COLLOCS = True\n",
        "tokenizer_trainer.train(gutenberg_text)\n",
        "\n",
        "sentence_tokenizer = PunktSentenceTokenizer(tokenizer_trainer.get_params())\n",
        "\n",
        "sentence_tokenizer._params.abbrev_types.add('dr')\n",
        "sentence_tokenizer._params.abbrev_types.add('c.j')\n",
        "sentence_tokenizer._params.abbrev_types.add('u.s')\n",
        "sentence_tokenizer._params.abbrev_types.add('u.s.a')\n",
        "sentence_tokenizer._params.abbrev_types.add('ret')\n",
        "sentence_tokenizer._params.abbrev_types.add('rep')\n",
        "sentence_tokenizer._params.abbrev_types.add('mr')\n",
        "sentence_tokenizer._params.abbrev_types.add('ms')\n",
        "sentence_tokenizer._params.abbrev_types.add('mrs')\n",
        "sentence_tokenizer._params.abbrev_types.add('v')\n",
        "sentence_tokenizer._params.abbrev_types.add('vs')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5qm2iIc8zzq"
      },
      "source": [
        "## **External fine-tuning of BERTweet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5PzYXA7YglU"
      },
      "outputs": [],
      "source": [
        "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
        "model_checkpoint = \"vinai/bertweet-base\"\n",
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "c55b682db6794c2ba68ffde709a2ae49",
            "e10f5ab75f024e57b7057d7172865a41",
            "e9e4844f0345464591cac1676511ae8a",
            "ab73c596820e4189846ad824f51db0e7",
            "0db4a224496a4f9bba8f7b537c1da0e9",
            "7e3f8d971715479c9db649966522e3b9",
            "fcb8b669e6e646df8c2b60410b4089ca",
            "aec35f6fadb04dc9bf05a9cf2e79d756",
            "e7174a5d08404d64b56467596b08f189",
            "f3628a3ff8624bbe894c76baa547a011",
            "dbe2a15f7e644090bb9a0be73fcba41a"
          ]
        },
        "id": "qIjXWgKNYp6x",
        "outputId": "585cc73e-eca8-456f-c155-f8ae8c70523b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset wnut_17 (/root/.cache/huggingface/datasets/wnut_17/wnut_17/1.0.0/077c7f08b8dbc800692e8c9186cdf3606d5849ab0e7be662e6135bb10eba54f9)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c55b682db6794c2ba68ffde709a2ae49"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "datasets = load_dataset(\"wnut_17\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM4XcV19Yt0l",
        "outputId": "8a620914-98a1-4507-d1ba-d51ee85e4dbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 3394\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 1009\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'ner_tags'],\n",
              "        num_rows: 1287\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "001a47f6a44f4f4781b792c29f510d5d",
            "bdfc07901bd04641bf98d73a951d9714",
            "5e19564359dc4c29a0d36d448a55ae8e",
            "2ee3a5b3a6744fbf8679e0ad285d3b4d",
            "dc854083c65449b8b948be940a55bf4a",
            "3a7209429f0f4d3ca57b090dafc5a07f",
            "f42be22a4c8844d18cbeeb967f921be4",
            "2bd42e413aa140388db8198725274c12",
            "c5436b51e3784addb57194608dff4961",
            "7d195df342704c738ace65708401ad45",
            "6dcba632ec6a44b5a29525e407ff63a6",
            "ac0e8aa8bc444c1ca9c10a20af732e39",
            "5560accc267c432096cee013ea4cbb73",
            "6dce300f9032420cab5f14ca67515f73",
            "a58a373671104e1f899d7f1aa4d9f145",
            "32d4baca23d9443599ed1b53edd247b0",
            "5f448e4bfa7145dd92a78c9877226403",
            "34618d5166be4e1b973a756ec633217b",
            "156e05ab87374e98abd19229fcae0025",
            "f83be78a5f814fd393d237e12a85f6a6",
            "e2b1953ed7a34c4eaaccde5630b1ef73",
            "e23a9dfec8014e999a07c7a669bd0655",
            "a016bea695644ef39f99eebd27c586c9",
            "59d8d3aee55d4b03964cfc0346be9dc8",
            "b860b0c2195c4ac093b9fb9b364ca3b9",
            "aef6b6efb0944dc580da07bab67fb7ce",
            "9b2b7f29d6ba47c4944cf7e46920622d",
            "b7e4cff77eb74dada3042a61321f1c50",
            "01ad3c8ff3a849289bd6e272c63da9fe",
            "21539e4e9a8e4e4c93bcfcd6ed6694b7",
            "62e53537522148b6919c54ca87da8f2f",
            "30e7ce61472a47b794a30b5feb7d9654",
            "317885226f9d402e932cdf4b8b05fd2a"
          ]
        },
        "id": "hNlRZ-enYyuq",
        "outputId": "abe9e9d6-69d3-489a-d915-f5a25e9f8e46"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/558 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "001a47f6a44f4f4781b792c29f510d5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/824k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac0e8aa8bc444c1ca9c10a20af732e39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a016bea695644ef39f99eebd27c586c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=True)\n",
        "label_all_tokens = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HofMbhhY3My"
      },
      "outputs": [],
      "source": [
        "expanded_label_dict={0:'O', 1:'B-corporation', 2:'I-corporation', 3:'B-creative-work', 4:'I-creative-work', 5:'B-group', 6:'I-group', 7:'B-location', 8:'I-location', 9:'B-person', 10:'I-person', 11:'B-product', 12:'I-product'}\n",
        "BIO_dict={'O':0,'B':1,'I':2}\n",
        "BIO_type_dict={'O':0, 'B-ORG':1, 'I-ORG':2, 'B-MISC':3, 'I-MISC':4, 'B-LOC':5, 'I-LOC':6, 'B-PER':7, 'I-PER':8}\n",
        "label_map_dict={'O':'O', 'B-corporation':'B-ORG', 'I-corporation':'I-ORG', 'B-creative-work':'B-MISC', 'I-creative-work':'I-MISC', 'B-group':'B-MISC', 'I-group':'I-MISC', 'B-location':'B-LOC', 'I-location':'I-LOC', 'B-person':'B-PER', 'I-person':'I-PER', 'B-product':'B-MISC', 'I-product':'I-MISC'}\n",
        "\n",
        "def tokenize_and_align_labels(example):\n",
        "        \n",
        "    tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
        "    inputId_to_token_dict={}\n",
        "    for index, token in enumerate(example[\"tokens\"]):\n",
        "        values=tokenizer.encode(token, add_special_tokens=False, truncation=True)\n",
        "        for value in values:\n",
        "            try:\n",
        "                inputId_to_token_dict[value].append(index)\n",
        "            except KeyError:\n",
        "                inputId_to_token_dict[value]=[index]\n",
        "    labels=[]\n",
        "    for inputID in tokenized_input['input_ids']:\n",
        "        try:\n",
        "            index_list=copy.deepcopy(inputId_to_token_dict[inputID])\n",
        "            index_to_address=index_list.pop(0)\n",
        "\n",
        "            # label=BIO_dict[expanded_label_dict[example['ner_tags'][index_to_address]][0]] #Just BIO\n",
        "            # label = example['ner_tags'][index_to_address]\n",
        "            label = BIO_type_dict[label_map_dict[expanded_label_dict[example['ner_tags'][index_to_address]]]]\n",
        "\n",
        "            labels.append(label)\n",
        "            inputId_to_token_dict[inputID]=index_list\n",
        "        except KeyError:\n",
        "            labels.append(-100)\n",
        "\n",
        "    assert (len(tokenized_input['input_ids']) == len(labels))\n",
        "    tokenized_input['labels']=labels\n",
        "    \n",
        "    return tokenized_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "b2aba4ab958146b08209e8477172c4f2",
            "7db12347aef44a20ac873519e5b9e271",
            "e7b2e6a804fb4980a082e47bbbca5ef2",
            "6a138311557946509ce7a899dd0184c7",
            "dde1fb9123094acaacf319367e9f8f36",
            "13c8b391e2504051ad4e9ae56fe5fea7",
            "6d75cbd13a404381aa4c331440aab769",
            "aeaca672735f4408b7af772bf2eec94a",
            "d5c4bfd36e634319bc0b8df3a21fb690",
            "f48697ac141742e9979ad4401c8307a7",
            "051ff8fc9f33434c9ce21b438faf2dc5",
            "70afe0c654ff4325a3c26301419eab13",
            "c8b333f021c44369964215231feafdf0",
            "501f1fbb3ba442ee957ac0959ad9f3c9",
            "e4dac02df09344c9a3a7f6009841c5ca",
            "7db6534be7fe4381adad2a3959674cf0",
            "2a6d01a888114fb7acf8ce29e4ca1300",
            "b4fc7614208c4a8291a3a556796209a1",
            "9d51ae2c200344478c8b69192cb20e52",
            "1800f59450f14bf18ff3408613cc3fc4",
            "5aba16676355445d94d85402ee01b30c",
            "66f5936b02e9485f9339201109a03d52",
            "cb3a8918d26745a4b06a52888cebaf3d",
            "63f90a215ac4483e9885f6595f39b8fd",
            "3b13c49be3b946debe6ba1f05cdbe6bc",
            "743bc0e178d1440f8ebf559178f26739",
            "9a1370d962954032a86366b037e2b7dd",
            "7002d3142d54435b9fcddf6112815143",
            "5a5bcf77d77a487db478b3ba3ff88dec",
            "fcf98d2121544e8d8cf82d755c5cfa86",
            "e5bdb0de0fb9477f994e436c0e0176be",
            "9eba193d7ffb41c48d8e2b016d9d1c77",
            "e5d0bb6789bf4219b3d4de3cabfad0b5"
          ]
        },
        "id": "0G81rx9xnaxr",
        "outputId": "52446ce6-eda8-4fcf-d278-b51676c3ba2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Parameter 'function'=<function tokenize_and_align_labels at 0x7f42499f1b00> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3394 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2aba4ab958146b08209e8477172c4f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1009 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70afe0c654ff4325a3c26301419eab13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1287 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb3a8918d26745a4b06a52888cebaf3d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# tokenize_and_align_labels(datasets['train'][2])\n",
        "tokenized_datasets = datasets.map(tokenize_and_align_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86M5oot7pnfz",
        "outputId": "46feb10a-5e25-483d-9e0f-3213a67de5a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 3394\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "tokenized_datasets['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50ZRrI4JqT3R",
        "outputId": "9d98f0a2-1d01-4e17-9d0e-167a25b13791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=b91e1e601946d476ca6a18d10abdd97922320deb017a103ea2961e244f696328\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip3 install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "751993f2713947bd9fc5609ade3a715e",
            "95cdababeab948a1971fd47a128a3d72",
            "c1ebe461a96b4c2091187dc38034d868",
            "9b1b48a6fcd24c37b70b58600e6d2bdf",
            "a6ee188762704779a0eafbe7375ca131",
            "d34f53bdb8d14e27bba0994550d2b55b",
            "41f38cf56e8642faac3fff2b33285a91",
            "be334e62079342a79621dc1a16b909c2",
            "17f809e03fb04dcc92dc24b452f00323",
            "2aea79f74e784e05b8c5834f18cd44da",
            "e685a34d99af42db8e8185195807b0e9"
          ]
        },
        "id": "UCeuNMxFqhqi",
        "outputId": "2498f532-3ca2-4eaf-8dbc-e5f6d853a334"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "751993f2713947bd9fc5609ade3a715e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "metric = load_metric(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAWz_QrzqlAU",
        "outputId": "10ef9b87-09ae-4868-b5e8-2ebba0fb22f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'B-ORG', 'I-ORG', 'B-MISC', 'I-MISC', 'B-LOC', 'I-LOC', 'B-PER', 'I-PER']\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "# label_list = datasets[\"train\"].features[f\"{task}_tags\"].feature.names\n",
        "\n",
        "# label_list = ['O','B','I']\n",
        "\n",
        "label_list = ['O','B-ORG','I-ORG','B-MISC','I-MISC','B-LOC','I-LOC','B-PER','I-PER']\n",
        "print(label_list)\n",
        "print(len(label_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MmRvoZrrfwH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(p):\n",
        "    # print(p.shape)\n",
        "    output, labels = p\n",
        "\n",
        "    # print(len(predictions))\n",
        "    # print(predictions[0].shape)\n",
        "    # for elem in predictions[1]:\n",
        "    #   print(elem.shape)\n",
        "\n",
        "    predictions, _ = output\n",
        "    \n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "b7f9192387ed47e5938c1db413f50db4",
            "28cc23a1d218414c826871979888e30c",
            "47331b4f621e4e0ca3c667aa9cb16e67",
            "0efca1f12bdb4a7697a2cb4549b0b787",
            "c41cdcf9ddce42e1860300b96c7300cb",
            "4c450dacebed414f89c36e49341dcf58",
            "597e2fcf39824fd791dac9c038b01f93",
            "7c9d32087b1f4ba18b5d8563ea968a52",
            "a8646b1a071d4e1983c38bc8545f2809",
            "17859754b95b4b23869d9d525cfcf6be",
            "aa8a6edf3df44000a29f0b2eda246ee8"
          ]
        },
        "id": "Xkcj6DSGrspe",
        "outputId": "bbef8062-220c-4df2-a991-025dd1bbe44d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/517M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7f9192387ed47e5938c1db413f50db4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaForTokenClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "alt_model = AutoModelForTokenClassification.from_pretrained(\"vinai/bertweet-base\", output_hidden_states=True, num_labels=len(label_list))\n",
        "# alt_model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RBOsjlvsBqY"
      },
      "outputs": [],
      "source": [
        "alt_training_args = TrainingArguments(\n",
        "    f\"test-{task}\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "# alt_training_args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03zFk8aEmAkW"
      },
      "outputs": [],
      "source": [
        "# alt_training_args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouXBNnSqsE7g"
      },
      "outputs": [],
      "source": [
        "alt_trainer = Trainer(\n",
        "    alt_model,\n",
        "    alt_training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJaSNPccsIis",
        "outputId": "375a1832-d739-4055-8d70-7e8d64067c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3394\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 639\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='639' max='639' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [639/639 06:48, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.275247</td>\n",
              "      <td>0.536797</td>\n",
              "      <td>0.412303</td>\n",
              "      <td>0.466385</td>\n",
              "      <td>0.934701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.227843</td>\n",
              "      <td>0.678075</td>\n",
              "      <td>0.527016</td>\n",
              "      <td>0.593078</td>\n",
              "      <td>0.946833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.210900</td>\n",
              "      <td>0.241026</td>\n",
              "      <td>0.683519</td>\n",
              "      <td>0.561929</td>\n",
              "      <td>0.616788</td>\n",
              "      <td>0.948677</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1009\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1009\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to test-ner/checkpoint-500\n",
            "Configuration saved in test-ner/checkpoint-500/config.json\n",
            "Model weights saved in test-ner/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in test-ner/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in test-ner/checkpoint-500/special_tokens_map.json\n",
            "added tokens file saved in test-ner/checkpoint-500/added_tokens.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1009\n",
            "  Batch size = 16\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=639, training_loss=0.1856081787969025, metrics={'train_runtime': 411.4005, 'train_samples_per_second': 24.75, 'train_steps_per_second': 1.553, 'total_flos': 196065609633108.0, 'train_loss': 0.1856081787969025, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "alt_trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDEYZT668rNp"
      },
      "source": [
        "## **Pre-processing on custom test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4GEp-qlzNGZ",
        "outputId": "7be9d69f-fe93-4de9-dd99-f4b8a72e8b45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yW6tkKJGIAEN"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import emoji\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import gutenberg\n",
        "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import string\n",
        "\n",
        "string.punctuation=string.punctuation+'…‘’'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HcqhLmMIVo8"
      },
      "outputs": [],
      "source": [
        "def collate_token_labels(tweetWordList, token_dict, prediction_labels):\n",
        "    #this function is also a valid alt implementation of the one in LocalNER module\n",
        "    counter=0\n",
        "    collated_labels=[]\n",
        "    for word in tweetWordList:\n",
        "    # for key in token_dict.keys():\n",
        "        \n",
        "        vals=token_dict[word]\n",
        "        if(counter<len(prediction_labels)):\n",
        "            labels=prediction_labels[counter:counter+len(vals)]\n",
        "            boundary_labels=[label[0] for label in labels]\n",
        "            if('I' in boundary_labels):\n",
        "                label=labels[boundary_labels.index('I')]\n",
        "                collated_labels.append(label)\n",
        "            elif('B' in boundary_labels):\n",
        "                label=labels[boundary_labels.index('B')]\n",
        "                collated_labels.append(label)\n",
        "            else:\n",
        "                collated_labels.append('O')\n",
        "            counter+=len(vals)\n",
        "        else:\n",
        "            collated_labels.append('O')\n",
        "    return collated_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnIqT-daIZK2"
      },
      "outputs": [],
      "source": [
        "def get_entities(word_tag_tuples):\n",
        "    \n",
        "    mentions=[]\n",
        "    candidateMention=''\n",
        "    type_tag=''\n",
        "    #emoji.get_emoji_regexp().sub(u'', candidateMention)\n",
        "    for tup in word_tag_tuples:\n",
        "        candidate=tup[0]\n",
        "        tag=tup[1]\n",
        "\n",
        "        if(tag=='O'):\n",
        "            if(candidateMention):\n",
        "                if((not candidateMention.strip().startswith('#'))&(not candidateMention.strip().startswith('@'))&(not candidateMention.strip().startswith('https:'))):\n",
        "                    mention_to_add=emoji.get_emoji_regexp().sub(u'', candidateMention).strip(string.punctuation).lower().strip()\n",
        "                    if mention_to_add.endswith(\"'s\"):\n",
        "                        li = mention_to_add.rsplit(\"'s\", 1)\n",
        "                        mention_to_add=''.join(li)\n",
        "                    elif mention_to_add.endswith(\"’s\"):\n",
        "                        li = mention_to_add.rsplit(\"’s\", 1)\n",
        "                        mention_to_add=''.join(li)\n",
        "                    else:\n",
        "                        mention_to_add=mention_to_add\n",
        "                    if(mention_to_add!=''):\n",
        "                        mentions.append((mention_to_add,type_tag))\n",
        "            candidateMention=''\n",
        "            type_tag=''\n",
        "        else:\n",
        "            boundary_tag = tag.split('-')[0]\n",
        "            type_tag = tag.split('-')[1]\n",
        "            if (boundary_tag=='B'):\n",
        "                if((not candidateMention.strip().startswith('#'))&(not candidateMention.strip().startswith('@'))&(not candidateMention.strip().startswith('https:'))):\n",
        "                    mention_to_add=emoji.get_emoji_regexp().sub(u'', candidateMention).strip(string.punctuation).lower().strip()\n",
        "                    if mention_to_add.endswith(\"'s\"):\n",
        "                        li = mention_to_add.rsplit(\"'s\", 1)\n",
        "                        mention_to_add=''.join(li)\n",
        "                    elif mention_to_add.endswith(\"’s\"):\n",
        "                        li = mention_to_add.rsplit(\"’s\", 1)\n",
        "                        mention_to_add=''.join(li)\n",
        "                    else:\n",
        "                        mention_to_add=mention_to_add\n",
        "                    if(mention_to_add!=''):\n",
        "                        mentions.append((mention_to_add,type_tag))\n",
        "                candidateMention=candidate\n",
        "            else:\n",
        "                candidateMention+=\" \"+candidate\n",
        "        # if (tag=='B'):\n",
        "        #     if((not candidateMention.strip().startswith('#'))&(not candidateMention.strip().startswith('@'))):\n",
        "        #         mention_to_add=emoji.get_emoji_regexp().sub(u'', candidateMention).strip(string.punctuation).lower().strip()\n",
        "        #         if(mention_to_add):\n",
        "        #             mentions.append(mention_to_add)\n",
        "        #     candidateMention=candidate\n",
        "        # else:\n",
        "        #     candidateMention+=\" \"+candidate\n",
        "    if(emoji.get_emoji_regexp().sub(u'', candidateMention).strip(string.punctuation).strip()):\n",
        "        if((not candidateMention.strip().startswith('#'))&(not candidateMention.strip().startswith('@'))&(not candidateMention.strip().startswith('https:'))):\n",
        "            mention_to_add=emoji.get_emoji_regexp().sub(u'', candidateMention).strip(string.punctuation).lower().strip()\n",
        "            if(mention_to_add!=''):\n",
        "                mentions.append((mention_to_add,type_tag))\n",
        "        # mentions.append(emoji.get_emoji_regexp().sub(u'', candidateMention).strip(string.punctuation).lower().strip())\n",
        "    # print('extracted mentions:', mentions)\n",
        "    return mentions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kp4wv0yIj7F"
      },
      "outputs": [],
      "source": [
        "# def get_encoding_seq(tweet_word_list, mentions):\n",
        "#     print(tweet_word_list)\n",
        "#     print(mentions)\n",
        "#     tweet_word_index=0\n",
        "#     encoded_tag_sequence=[]\n",
        "#     while(mentions):\n",
        "#         current_mention=[token.strip() for token in mentions.pop(0).split(' ')]\n",
        "#         while(normalize(current_mention[0])!=normalize(tweet_word_list[tweet_word_index])):\n",
        "#             encoded_tag_sequence.append('O')\n",
        "#             tweet_word_index+=1\n",
        "#         if(normalize(current_mention[0])==normalize(tweet_word_list[tweet_word_index])):\n",
        "#             for token_index, token in enumerate(current_mention):\n",
        "#                 if(token_index==0):\n",
        "#                     encoded_tag_sequence.append('B')\n",
        "#                 else:\n",
        "#                     encoded_tag_sequence.append('I')\n",
        "#                 tweet_word_index+=1\n",
        "#     while(tweet_word_index<len(tweet_word_list)):\n",
        "#         encoded_tag_sequence.append('O')\n",
        "#         tweet_word_index+=1\n",
        "        \n",
        "#     print(encoded_tag_sequence)\n",
        "#     return encoded_tag_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uHnEzVDJN2F"
      },
      "outputs": [],
      "source": [
        "gutenberg_text = \"\"\n",
        "for file_id in gutenberg.fileids():\n",
        "    gutenberg_text += gutenberg.raw(file_id)\n",
        "tokenizer_trainer = PunktTrainer()\n",
        "tokenizer_trainer.INCLUDE_ALL_COLLOCS = True\n",
        "tokenizer_trainer.train(gutenberg_text)\n",
        "\n",
        "my_sentence_tokenizer = PunktSentenceTokenizer(tokenizer_trainer.get_params())\n",
        "my_sentence_tokenizer._params.abbrev_types.add('dr')\n",
        "my_sentence_tokenizer._params.abbrev_types.add('c.j')\n",
        "my_sentence_tokenizer._params.abbrev_types.add('u.s')\n",
        "my_sentence_tokenizer._params.abbrev_types.add('u.s.a')\n",
        "my_sentence_tokenizer._params.abbrev_types.add('ret')\n",
        "my_sentence_tokenizer._params.abbrev_types.add('rep')\n",
        "my_sentence_tokenizer._params.abbrev_types.add('mr')\n",
        "my_sentence_tokenizer._params.abbrev_types.add('ms')\n",
        "my_sentence_tokenizer._params.abbrev_types.add('mrs')\n",
        "my_sentence_tokenizer._params.abbrev_types.add('v')\n",
        "my_sentence_tokenizer._params.abbrev_types.add('vs')\n",
        "\n",
        "\n",
        "def normalize_to_sentences(text):\n",
        "    tweetSentences=list(filter (lambda sentence: len(sentence)>1, text.split('\\n')))\n",
        "    tweetSentenceList_inter=custom_flatten(list(map(lambda sentText: my_sentence_tokenizer.tokenize(sentText.lstrip().rstrip()),tweetSentences)),[])\n",
        "    tweetSentenceList=list(filter (lambda sentence: len(sentence)>1, tweetSentenceList_inter))\n",
        "    return tweetSentenceList\n",
        "\n",
        "def custom_flatten(mylist, outlist,ignore_types=(str, bytes, int)):\n",
        "    \n",
        "    if (mylist !=[]):\n",
        "        for item in mylist:\n",
        "            #print not isinstance(item, ne.NE_candidate)\n",
        "            if isinstance(item, list) and not isinstance(item, ignore_types):\n",
        "                custom_flatten(item, outlist)\n",
        "            else:\n",
        "                item=item.strip(' \\t\\n\\r')\n",
        "                outlist.append(item)\n",
        "    return outlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iv4aARohiJm9"
      },
      "outputs": [],
      "source": [
        "def preprocess(filename):\n",
        "    \"\"\"save a file with token, label and prediction in each row\"\"\"\n",
        "    tweet_to_sentences_w_annotation={}\n",
        "    sentenceID=0\n",
        "    test=pd.read_csv(\"data/\"+filename,sep =',',keep_default_na=False)\n",
        "    # outputfilename=\"data/covid/covid_2K.txt\"\n",
        "    \n",
        "    all_annotated_ne=[]\n",
        "    tweetsentences=[]\n",
        "    tokenizedsentences=[]\n",
        "    \n",
        "    for row in test.itertuples():\n",
        "        tweetID=str(row.Index)\n",
        "        text=str(row.TweetText)\n",
        "        row_sentences = normalize_to_sentences(text)\n",
        "        tweetsentences += row_sentences\n",
        "        tokenizedsentences += [tokenizer(sentence, is_split_into_words=True) for sentence in row_sentences]\n",
        "        # print(tweetID,text)\n",
        "        \n",
        "        mentions=[]\n",
        "        # print(row.mentions_other)\n",
        "        for sentence_level in str(row.mentions_other).split(';'):\n",
        "            if(sentence_level):\n",
        "                for elem in sentence_level.split(','):\n",
        "                    if(elem):\n",
        "                        mention_record = elem.split('|')\n",
        "                        # print(mention_record)\n",
        "                        mention, entity_type =  mention_record[0], mention_record[1].lower()\n",
        "                        if(mention):\n",
        "                            if((mention !='')&(mention !='nan')):\n",
        "                                mention = mention.lower().strip(string.punctuation).strip()\n",
        "                                if(mention.startswith('the ')):\n",
        "                                    mention = mention[4:]\n",
        "                                mentions.append((mention, entity_type))\n",
        "        # mentions=list(filter(lambda element: ((element !='')&(element !='nan')), mentions))\n",
        "        # all_annotated_ne.extend(mentions)\n",
        "        \n",
        "        # if(row_sentences):\n",
        "        tweet_to_sentences_w_annotation[tweetID]=((sentenceID,sentenceID+len(row_sentences)),mentions)\n",
        "        sentenceID+=len(row_sentences)\n",
        "        # else:\n",
        "        #     tweet_to_sentences_w_annotation[tweetID]=((sentenceID,sentenceID+1),mentions)\n",
        "        #     sentenceID+=1\n",
        "        # print(sentenceID,len(row_sentences))\n",
        "    return tweetsentences, tokenizedsentences, tweet_to_sentences_w_annotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChZgr__bv3M9"
      },
      "outputs": [],
      "source": [
        "def calculate_f1_ner(tweet_to_sentences_w_annotation, tweetsentences, true_predictions):\n",
        "    \n",
        "    entity_types = ['org','misc', 'loc', 'per']\n",
        "    confusion_matrices = {entity_type: {'TP': 0, 'TN': 0, 'FP': 0, 'FN': 0} for entity_type in entity_types}\n",
        "    scores = {entity_type: {'p': 0, 'r': 0, 'f1': 0} for entity_type in entity_types}\n",
        "\n",
        "    ner_arrays=[]\n",
        "    for n, tweet in enumerate(tweetsentences):\n",
        "        # tweet_data = list(zip(tweet, true_labels[n], predictions[i:i + len(tweet)]))\n",
        "        # word_tag_tuples=zip(tweet,predictions[i:i + len(tweet)])\n",
        "        \n",
        "        assert (len(tweet)==len(true_predictions[n]))\n",
        "        word_tag_tuples=zip(tweet,true_predictions[n])\n",
        "        entities_from_sentence=get_entities(word_tag_tuples)\n",
        "        ner_arrays.append(entities_from_sentence)\n",
        "\n",
        "    print('tally:',len(tweetsentences),len(ner_arrays))\n",
        "\n",
        "    for tweetID in tweet_to_sentences_w_annotation.keys():\n",
        "        unrecovered_annotated_mention_list=[]\n",
        "        annotated_mention_list=tweet_to_sentences_w_annotation[tweetID][1]\n",
        "        output_mentions_list=[]\n",
        "        true_positive_list=[]\n",
        "        idRange=tweet_to_sentences_w_annotation[tweetID][0]\n",
        "\n",
        "        for sentID in range(idRange[0],idRange[1]):\n",
        "            output_mentions_list+=ner_arrays[sentID]\n",
        "        output_mentions_list=[(elem[0],elem[1].lower()) for elem in output_mentions_list]\n",
        "        print(tweetID,annotated_mention_list,output_mentions_list)\n",
        "\n",
        "        while(annotated_mention_list):\n",
        "            if(len(output_mentions_list)):\n",
        "                annotated_candidate= annotated_mention_list.pop()\n",
        "                if(annotated_candidate in output_mentions_list):\n",
        "                    output_mentions_list.pop(output_mentions_list.index(annotated_candidate))\n",
        "                    # tp_counter_inner+=1 # for emd\n",
        "                    true_positive_list.append(annotated_candidate)\n",
        "                    # #for ner\n",
        "                    # entity_type=annotated_candidate[1]\n",
        "                    # confusion_matrices[entity_type]['TP']+=1\n",
        "                else:\n",
        "                    unrecovered_annotated_mention_list.append(annotated_candidate)\n",
        "            else:\n",
        "                unrecovered_annotated_mention_list.extend(annotated_mention_list)\n",
        "                break\n",
        "        # unrecovered_annotated_mention_list_outer.extend(unrecovered_annotated_mention_list)\n",
        "\n",
        "        # fn_counter_inner=len(unrecovered_annotated_mention_list)\n",
        "        # fp_counter_inner=all_postitive_counter_inner - tp_counter_inner\n",
        "        # print(tp_counter_inner,fp_counter_inner,fn_counter_inner)\n",
        "\n",
        "        print('true positives:',true_positive_list)\n",
        "        print('false positives:',output_mentions_list)\n",
        "        print('false negatives:',unrecovered_annotated_mention_list)\n",
        "\n",
        "        for mention_tup in true_positive_list:\n",
        "            entity_type=mention_tup[1]\n",
        "            if(mention_tup[0]):\n",
        "                confusion_matrices[entity_type]['TP']+=1\n",
        "\n",
        "        for mention_tup in unrecovered_annotated_mention_list:\n",
        "            entity_type=mention_tup[1]\n",
        "            if(mention_tup[0]):\n",
        "                confusion_matrices[entity_type]['FN']+=1\n",
        "\n",
        "        for mention_tup in output_mentions_list:\n",
        "            entity_type=mention_tup[1]\n",
        "            if(mention_tup[0]):\n",
        "                confusion_matrices[entity_type]['FP']+=1\n",
        "    \n",
        "    print('========Named Entity Recognition========')\n",
        "    for entity_type in entity_types:\n",
        "        print(entity_type.upper())\n",
        "        precision = confusion_matrices[entity_type]['TP']/(confusion_matrices[entity_type]['TP']+confusion_matrices[entity_type]['FP'])\n",
        "        recall = confusion_matrices[entity_type]['TP']/(confusion_matrices[entity_type]['TP']+confusion_matrices[entity_type]['FN'])\n",
        "        f_measure = 2*precision*recall/(precision+recall)\n",
        "\n",
        "        scores[entity_type]['p'] = precision\n",
        "        scores[entity_type]['r'] = recall\n",
        "        scores[entity_type]['f1'] = f_measure\n",
        "\n",
        "        print('precision: ',precision)\n",
        "        print('recall: ',recall)\n",
        "        print('f_measure: ',f_measure)\n",
        "\n",
        "        print('------------------------')\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOsWhlXRJRVw"
      },
      "outputs": [],
      "source": [
        "def calculate_f1_emd(tweet_to_sentences_w_annotation, tweetsentences, true_predictions):\n",
        "    \n",
        "    # dataset, i = [], 0\n",
        "    ner_arrays=[]\n",
        "    file_write_text=''\n",
        "    all_detected_ne=[]\n",
        "    all_annotated_ne=[]\n",
        "    \n",
        "    for n, tweet in enumerate(tweetsentences):\n",
        "        # tweet_data = list(zip(tweet, true_labels[n], predictions[i:i + len(tweet)]))\n",
        "        # word_tag_tuples=zip(tweet,predictions[i:i + len(tweet)])\n",
        "        \n",
        "        assert (len(tweet)==len(true_predictions[n]))\n",
        "        word_tag_tuples=zip(tweet,true_predictions[n])\n",
        "        entities_from_sentence=get_entities(word_tag_tuples)\n",
        "        # line_text='\\t'.join(entities_from_sentence)\n",
        "        # file_write_text+=line_text+'\\n'\n",
        "        # print(entities_from_sentence)\n",
        "        all_detected_ne.extend(entities_from_sentence)\n",
        "        ner_arrays.append(entities_from_sentence)\n",
        "        # dataset += tweet_data + [()]\n",
        "    \n",
        "    print('tally:',len(tweetsentences),len(ner_arrays))\n",
        "    system_output_mention_list=list(set(all_detected_ne))\n",
        "    # file_write_text='\\n'.join(system_output_mention_list)\n",
        "    # f1= open(outputfilename, \"w\")\n",
        "    # f1.write(file_write_text)\n",
        "    # f1.close()\n",
        "    \n",
        "    true_positive_count=0\n",
        "    false_positive_count=0\n",
        "    false_negative_count=0\n",
        "    total_mentions=0\n",
        "    total_annotation=0\n",
        "    \n",
        "    \n",
        "    for tweetID in tweet_to_sentences_w_annotation.keys():\n",
        "        unrecovered_annotated_mention_list=[]\n",
        "        tp_counter_inner=0\n",
        "        fp_counter_inner=0\n",
        "        fn_counter_inner=0\n",
        "        \n",
        "        annotated_mention_list=tweet_to_sentences_w_annotation[tweetID][1]\n",
        "        all_annotated_ne.extend(annotated_mention_list)\n",
        "        output_mentions_list=[]\n",
        "        output_mentions_w_type_list=[]\n",
        "        idRange=tweet_to_sentences_w_annotation[tweetID][0]\n",
        "        for sentID in range(idRange[0],idRange[1]):\n",
        "            output_mentions_w_type_list+=ner_arrays[sentID]\n",
        "            \n",
        "        print(tweetID,annotated_mention_list,output_mentions_w_type_list)\n",
        "        output_mentions_list=[elem[0] for elem in output_mentions_w_type_list]\n",
        "        print(output_mentions_list)\n",
        "        all_postitive_counter_inner=len(output_mentions_list)\n",
        "        while(annotated_mention_list):\n",
        "            if(len(output_mentions_list)):\n",
        "                annotated_candidate= annotated_mention_list.pop()\n",
        "                if(annotated_candidate in output_mentions_list):\n",
        "                    output_mentions_list.pop(output_mentions_list.index(annotated_candidate))\n",
        "                    tp_counter_inner+=1\n",
        "                else:\n",
        "                    unrecovered_annotated_mention_list.append(annotated_candidate)\n",
        "            else:\n",
        "                unrecovered_annotated_mention_list.extend(annotated_mention_list)\n",
        "                break\n",
        "        # unrecovered_annotated_mention_list_outer.extend(unrecovered_annotated_mention_list)\n",
        "        fn_counter_inner=len(unrecovered_annotated_mention_list)\n",
        "        fp_counter_inner=all_postitive_counter_inner - tp_counter_inner\n",
        "        \n",
        "        print(tp_counter_inner,fp_counter_inner,fn_counter_inner)\n",
        "        \n",
        "        true_positive_count+=tp_counter_inner\n",
        "        false_positive_count+=fp_counter_inner\n",
        "        false_negative_count+=fn_counter_inner\n",
        "        \n",
        "    print('true_positive_count,false_positive_count,false_negative_count:')\n",
        "    print(true_positive_count,false_positive_count,false_negative_count)\n",
        "    \n",
        "    precision=(true_positive_count)/(true_positive_count+false_positive_count)\n",
        "    recall=(true_positive_count)/(true_positive_count+false_negative_count)\n",
        "    f_measure=2*(precision*recall)/(precision+recall)\n",
        "            \n",
        "    print('========Entity Mention Detection========')\n",
        "    print('precision: ',precision)\n",
        "    print('recall: ',recall)\n",
        "    print('f_measure: ',f_measure)\n",
        "\n",
        "    # print('========Entity Detection========')\n",
        "    # true_positive_entities =  len(list(set(all_detected_ne).intersection(set(all_annotated_ne))))\n",
        "    # false_positive_entities = len(list(set(all_annotated_ne)-set(all_detected_ne)))\n",
        "    # false_negative_entities = len(list(set(all_detected_ne)-set(all_annotated_ne)))\n",
        "\n",
        "    # precision= (true_positive_entities)/(true_positive_entities+false_positive_entities)\n",
        "    # recall= (true_positive_entities)/(true_positive_entities+false_negative_entities)\n",
        "    # f_measure = 2*(precision*recall)/(precision+recall)\n",
        "\n",
        "    # print('precision: ',precision)\n",
        "    # print('recall: ',recall)\n",
        "    # print('f_measure: ',f_measure)   \n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK4fkrxjLQZj"
      },
      "source": [
        "## **Entity Classifier Alt**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-44Vn9b5LVdZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHrCHHreLbla"
      },
      "outputs": [],
      "source": [
        "class CandidateDataset(Dataset):\n",
        "    def __init__(self, df, candidateEmbeddingDict):\n",
        "        self.samples= []\n",
        "        self.max_freq=-1\n",
        "        self.freq_arr = []\n",
        "        # self.embeddings_repo = []\n",
        "        self.output = []\n",
        "\n",
        "        for index, row in df.iterrows():\n",
        "            candidate_record = row['candidate'].split('||')\n",
        "            # print(candidate_record)\n",
        "            candidate, cluster_id = candidate_record[0], candidate_record[1]\n",
        "            normalized_length = row['normalized_length']\n",
        "            cumulative= row['cumulative']\n",
        "            if(cumulative>self.max_freq):\n",
        "                self.max_freq=cumulative\n",
        "\n",
        "            output_val= row['class']\n",
        "\n",
        "            local_embedding_list= candidateEmbeddingDict[(candidate,cluster_id)]\n",
        "            assert len(local_embedding_list) !=0\n",
        "            assert cumulative == len(local_embedding_list)\n",
        "\n",
        "            tup=(candidate,cluster_id,normalized_length,cumulative)\n",
        "\n",
        "            self.freq_arr.append(cumulative)\n",
        "            self.samples.append(tup)\n",
        "            self.output.append(output_val)\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tup2=(self.freq_arr[idx]/self.max_freq,)\n",
        "        tup=self.samples[idx]+tup2\n",
        "\n",
        "        return tup,self.output[idx]\n",
        "        # return self.len_arr[idx],self.cum_freq_arr[idx],self.output[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d3CEsOhLhU9"
      },
      "outputs": [],
      "source": [
        "# 2 output_classes: 'entity'/'non-entity'; so sigmoid transformation would suffice\n",
        "\n",
        "class NN(nn.Module):\n",
        "    def __init__(self,input_size,device):\n",
        "        super(NN, self).__init__()\n",
        "        self.device=device\n",
        "        self.input_size = input_size\n",
        "\n",
        "        #customized weighted pooling\n",
        "        self.pooling_layer1 = nn.Linear(input_size,50)\n",
        "        self.pooling_layer2 = nn.Linear(50,1)\n",
        "\n",
        "        self.linear1 = nn.Linear(input_size+1,500)\n",
        "        self.batchnorm = nn.BatchNorm1d(500)\n",
        "        self.linear2 = nn.Linear(500,200)\n",
        "        self.linear3 = nn.Linear(200,50)\n",
        "        self.output_layer = nn.Linear(50,5)\n",
        "      \n",
        "    def nxn_cos_sim(A, B, dim=1, eps=1e-8):\n",
        "      numerator = A @ B.T\n",
        "      A_l2 = torch.mul(A, A).sum(axis=dim)\n",
        "      B_l2 = torch.mul(B, B).sum(axis=dim)\n",
        "      denominator = torch.max(torch.sqrt(torch.outer(A_l2, B_l2)), torch.tensor(eps))\n",
        "      return torch.div(numerator, denominator)\n",
        "\n",
        "    \n",
        "    def compute(self, x_tup):\n",
        "\n",
        "        x_len=x_tup[0]\n",
        "        # x_List=x_tup[1]\n",
        "        local_embedding_list=x_tup[1]\n",
        "        x_cum_freq=x_tup[2]\n",
        "        x_normalized_freq=x_tup[3]\n",
        "        \n",
        "        # x_tensor = torch.FloatTensor(np.array([x_len,x_normalized_freq],dtype=float)).to(self.device)\n",
        "        x_tensor = torch.FloatTensor(np.array([x_len],dtype=float)).to(self.device)\n",
        "\n",
        "        \n",
        "        all_local_embedding = torch.stack(local_embedding_list).to(self.device)\n",
        "\n",
        "        pooling_output_1=F.relu(self.pooling_layer1(all_local_embedding))\n",
        "        pooling_output_2=self.pooling_layer2(pooling_output_1)\n",
        "        weights = pooling_output_2.reshape(-1)\n",
        "        # print(all_local_embedding.size(),len(weights))\n",
        "\n",
        "        # cos_sim_matrix = self.nxn_cos_sim(all_local_embedding,all_local_embedding)\n",
        "        exp_tensor = torch.exp(weights)\n",
        "        sum_tensor = torch.sum(exp_tensor)\n",
        "        weights = torch.div(exp_tensor,sum_tensor).tolist()\n",
        "\n",
        "\n",
        "        aggregated_input = torch.zeros(self.input_size, requires_grad=True).to(self.device)\n",
        "        for ind, local_embedding in enumerate(all_local_embedding):\n",
        "            aggregated_input=aggregated_input.add(torch.mul(local_embedding, weights[ind]))\n",
        "        \n",
        "        # aggregated_input=torch.mul(aggregated_input, float(1/x_cum_freq))\n",
        "        x = torch.cat((x_tensor,aggregated_input), 0).to(self.device)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, batch_data):\n",
        "        global_embeddings_arr=[]\n",
        "        for x_tup in batch_data:\n",
        "            global_embeddings_arr.append(self.compute(x_tup))\n",
        "        # global_embeddings_arr = np.array(global_embeddings_arr)\n",
        "        global_embeddings_batch = torch.stack(global_embeddings_arr).to(self.device)\n",
        "        # global_embeddings_batch.requires_grad = True\n",
        "        # print(global_embeddings_batch.size())\n",
        "        x = F.relu(self.linear1(global_embeddings_batch))\n",
        "        x = self.batchnorm(x)\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = F.relu(self.linear3(x))\n",
        "        out = self.output_layer(x)\n",
        "        return out\n",
        "\n",
        "class EntityClassifierAlt():\n",
        "\n",
        "    def __init__(self, to_train, device, candidateBase_train, candidateEmbeddingDict):\n",
        "\n",
        "\n",
        "        self.candidateEmbeddingDict_train = candidateEmbeddingDict\n",
        "        self.candidateBase_train = candidateBase_train\n",
        "        self.combined_feature_list=['length']\n",
        "\n",
        "        self.device=device\n",
        "\n",
        "        self.input_size = 300 #len(['normalized_cf_'+str(i) for i in range(300)])\n",
        "\n",
        "        self.entity_types = {0:'ne', 1:'org', 2:'misc', 3:'loc', 4:'per'}\n",
        "        # self.confusion_matrices = {entity_type: {'TP': 0, 'TN': 0, 'FP': 0, 'FN': 0} for entity_type in self.entity_types.keys()}\n",
        "        # self.scores = {entity_type: {'p': 0, 'r': 0, 'f1': 0} for entity_type in self.entity_types.keys()}\n",
        "\n",
        "        # self.relevant_columns = ['candidate','normalized_length','cumulative']\n",
        "        self.relevant_columns = ['candidate','normalized_length','cumulative','class']\n",
        "        # self.relevant_columns = ['normalized_cf_'+str(i) for i in range(768)]\n",
        "        \n",
        "        #initialize the classifier model\n",
        "        self.classifier = NN(self.input_size,device).to(device)\n",
        "        #Loss and Optimizer\n",
        "        self.ec_criterion = nn.CrossEntropyLoss()\n",
        "        self.ec_optimizer = optim.Adam(self.classifier.parameters(), lr = 0.01, weight_decay=1e-8)\n",
        "        self.ec_batch_size = 32\n",
        "        self.ec_num_epochs = 200\n",
        "        self.patience = 10\n",
        "\n",
        "\n",
        "        if(to_train):\n",
        "\n",
        "            # define checkpoint saved path\n",
        "            ckp_path = \"entityClassifierAlt/model_checkpoints_ner/classifierAlt_checkpoint_model300_wnut.pt\" #300\n",
        "\n",
        "            if(path.exists(ckp_path)):\n",
        "                # load the saved checkpoint\n",
        "                self.classifier, self.ec_optimizer, self.start_epoch = self.load_ckp(ckp_path, self.classifier, self.ec_optimizer)\n",
        "\n",
        "            max_candidate_length = self.candidateBase_train['length'].max()+1\n",
        "            # print(self.train['length'].tolist())\n",
        "            self.candidateBase_train['normalized_length'] = self.candidateBase_train['length']/max_candidate_length\n",
        "\n",
        "            print(self.candidateBase_train['normalized_length'].max())\n",
        "            \n",
        "            #Loading the data\n",
        "            # candidate_array = self.train['candidate'].tolist()\n",
        "            dataset_df = self.candidateBase_train[self.relevant_columns]\n",
        "\n",
        "            dataset = CandidateDataset(dataset_df, self.candidateEmbeddingDict_train)\n",
        "\n",
        "            print(dataset.__getitem__(0))\n",
        "\n",
        "            train_len=int(math.ceil(len(dataset_df)*0.85))\n",
        "            val_len=len(dataset_df)-train_len\n",
        "\n",
        "            print('train_len',train_len)\n",
        "            print('val_len',val_len)\n",
        "\n",
        "            train_ds, val_ds = random_split(dataset, [train_len, val_len])\n",
        "\n",
        "            self.train_loader = DataLoader(train_ds, self.ec_batch_size, shuffle=True)\n",
        "            self.val_loader = DataLoader(val_ds, val_len, shuffle=True) #will execute in 1 batch\n",
        "\n",
        "            #Training the model\n",
        "            end_epoch = self.fit()\n",
        "\n",
        "            checkpoint_dir = \"entityClassifierAlt/model_checkpoints_ner\"\n",
        "            self.save_ckp(self.checkpoint, True, checkpoint_dir)\n",
        "\n",
        "        else:\n",
        "            # define checkpoint saved path\n",
        "            ckp_path = \"entityClassifierAlt/model_checkpoints_ner/classifierAlt_checkpoint_model300.pt\" #300\n",
        "            # ckp_path = \"entityClassifierAlt/model_checkpoints_ner/classifierAlt_checkpoint_model300_wnut.pt\" #300\n",
        "            # load the saved checkpoint\n",
        "            self.classifier, self.ec_optimizer, self.start_epoch = self.load_ckp(ckp_path, self.classifier, self.ec_optimizer)\n",
        "\n",
        "    def load_ckp(self, checkpoint_fpath, model, optimizer):\n",
        "        checkpoint = torch.load(checkpoint_fpath)\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        return model, optimizer, checkpoint['epoch']\n",
        "\n",
        "    def save_ckp(self,state, is_best, checkpoint_dir):\n",
        "        # f_path = checkpoint_dir + '/classifierAlt_checkpoint768.pt' #768\n",
        "        f_path = checkpoint_dir + '/classifierAlt_checkpoint_model300.pt' #300\n",
        "        torch.save(state, f_path)\n",
        "\n",
        "    def custom_loss(self, out, targets, freq):\n",
        "        print('verifying shapes:')\n",
        "        print(out.shape, targets.shape)\n",
        "        softmaxloss_arr=[]\n",
        "        for i, out_i in enumerate(out):\n",
        "            print(out_i.shape, targets[i].shape)\n",
        "            loss_i = self.ec_criterion(out_i, targets[i])\n",
        "            softmaxloss_arr.append(loss_i)\n",
        "        # print(type(softmaxloss))\n",
        "        softmaxloss = torch.stack(softmaxloss_arr).to(self.device)\n",
        "        print(softmaxloss, freq)\n",
        "        print(softmaxloss.shape, freq.shape)\n",
        "        vec=softmaxloss*freq\n",
        "        print(vec)\n",
        "        final_loss = torch.sum(vec)/torch.sum(freq)\n",
        "        print(vec.shape, loss.shape)\n",
        "        return final_loss\n",
        "\n",
        "\n",
        "    def fit(self):\n",
        "        # Train Network\n",
        "        history_validation = []\n",
        "        history_training= []\n",
        "        no_improvement_counter=0\n",
        "        best_loss = np.float('inf')\n",
        "        best_f1 = np.float('-inf')\n",
        "        for epoch in range(self.ec_num_epochs):\n",
        "            training_batch_loss=[]\n",
        "            for batch_idx, (data_inter, targets) in enumerate(self.train_loader):\n",
        "                # Get data to cuda if possible\n",
        "                # data = data.to(device=device)\n",
        "\n",
        "                # print(len(data_inter),len(targets),type(data_inter))\n",
        "                # print(len(data_inter[0]),len(data_inter[1]),len(data_inter[2]))\n",
        "\n",
        "                #(candidate,cluster_id,normalized_length,cumulative,normalized_cumulative)\n",
        "                candidates = data_inter[0]\n",
        "                cluster_ids = data_inter[1]\n",
        "                length_arr = data_inter[2]\n",
        "                cumulative_arr = data_inter[3]\n",
        "                normalized_freq_arr = data_inter[4]\n",
        "\n",
        "                data = [(length_arr[index], self.candidateEmbeddingDict_train[(candidate,cluster_ids[index])], cumulative_arr[index], normalized_freq_arr[index]) for index, candidate in enumerate(candidates)]\n",
        "                # targets = targets.unsqueeze(1).to(device=self.device)\n",
        "                targets = targets.type(torch.LongTensor)\n",
        "                targets = targets.to(device=self.device)\n",
        "\n",
        "                self.ec_optimizer.zero_grad()\n",
        "\n",
        "                # forwards\n",
        "                out = self.classifier(data)\n",
        "                # out = out.to(torch.float32)\n",
        "                # targets = targets.to(torch.float32)\n",
        "\n",
        "                # #custom cross-entropy loss factoring in frequency\n",
        "                # loss = self.custom_loss(out, targets, torch.FloatTensor(np.array(cumulative_arr)).unsqueeze(1).to(device=self.device))\n",
        "\n",
        "                loss = self.ec_criterion(out, targets)\n",
        "\n",
        "                training_batch_loss.append(loss.item())\n",
        "                # print(loss.item())\n",
        "\n",
        "                # backward\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.classifier.parameters(), 1.0)\n",
        "                # gradient descent or adam step\n",
        "                self.ec_optimizer.step()\n",
        "            combined_training_loss = np.mean(training_batch_loss)\n",
        "            print('combined_training_loss:',combined_training_loss)\n",
        "            history_training.append(combined_training_loss)\n",
        "\n",
        "            #Validation: DO NOT BACKPROPAGATE HERE\n",
        "            validation_batch_loss = []\n",
        "            labels = []\n",
        "            all_candidates = []\n",
        "            predictions = []\n",
        "            self.confusion_matrices = {entity_type: {'TP': 0, 'TN': 0, 'FP': 0, 'FN': 0} for entity_type in self.entity_types.keys()}\n",
        "            self.scores = {entity_type: {'p': 0, 'r': 0, 'f1': 0} for entity_type in self.entity_types.keys()}\n",
        "            with torch.no_grad():\n",
        "                self.classifier.eval()\n",
        "                for batch_idx, (val_data_inter, val_targets) in enumerate(self.val_loader):\n",
        "                    # val_data = val_data.to(device=device)\n",
        "                    val_candidates = val_data_inter[0]\n",
        "                    val_cluster_ids = val_data_inter[1]\n",
        "                    val_length_arr = val_data_inter[2]\n",
        "                    val_cumulative_arr = val_data_inter[3]\n",
        "                    val_normalized_freq_arr = val_data_inter[4]\n",
        "\n",
        "                    val_data = [(val_length_arr[index], self.candidateEmbeddingDict_train[(val_candidate,val_cluster_ids[index])], val_cumulative_arr[index], val_normalized_freq_arr[index]) for index, val_candidate in enumerate(val_candidates)]\n",
        "                    # val_targets = val_targets.unsqueeze(1).to(device=device)\n",
        "                    val_targets = val_targets.type(torch.LongTensor)\n",
        "                    val_targets = val_targets.to(device=device)\n",
        "\n",
        "                    val_out = self.classifier(val_data)\n",
        "\n",
        "                    # y_pred = out.to(torch.float32)\n",
        "                    # val_targets = val_targets.to(torch.float32)\n",
        "\n",
        "                    # print('checking shapes:')\n",
        "                    # print(out.shape)\n",
        "                    # print(val_targets.shape)\n",
        "                    \n",
        "                    y_pred_softmax = torch.log_softmax(val_out, dim = 1)\n",
        "                    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
        "                    batch_predictions = y_pred_tags.reshape(-1)\n",
        "                    # print(y_pred_tags.shape)\n",
        "                    # print(batch_predictions.shape)\n",
        "\n",
        "                    predictions+=batch_predictions.tolist()\n",
        "\n",
        "                    labels+=val_targets.tolist()\n",
        "                    all_candidates+=candidates\n",
        "\n",
        "                    # loss = F.mse_loss(out, val_targets) round\n",
        "                    val_loss = self.ec_criterion(val_out, val_targets)\n",
        "                    # loss = self.custom_loss(out, val_targets, torch.FloatTensor(np.array(cumulative_arr)).unsqueeze(1).to(device=self.device)) #custom l1 loss factoring in frequency\n",
        "                    validation_batch_loss.append(val_loss.item())\n",
        "                    # print(validation_batch_loss)\n",
        "                combined_validation_loss= np.mean(validation_batch_loss)\n",
        "                assert len(predictions)==len(labels)\n",
        "                # print(len(predictions),len(labels),type(predictions[0]))\n",
        "                # print(predictions)\n",
        "                \n",
        "\n",
        "                #EMD training objective\n",
        "                for indx in range(len(predictions)):\n",
        "                    predicted_class = predictions[indx]\n",
        "                    true_class = labels[indx]\n",
        "\n",
        "                    if(predicted_class==true_class):\n",
        "                        self.confusion_matrices[true_class]['TP']+=1\n",
        "                    else:\n",
        "                        self.confusion_matrices[true_class]['FN']+=1\n",
        "                        self.confusion_matrices[true_class]['FP']+=1\n",
        "\n",
        "                macrof1=0\n",
        "                for entity_type in self.entity_types:\n",
        "                    # print(entity_type.upper())\n",
        "                    try:\n",
        "                        precision = self.confusion_matrices[entity_type]['TP']/(self.confusion_matrices[entity_type]['TP']+self.confusion_matrices[entity_type]['FP'])\n",
        "                    except ZeroDivisionError:\n",
        "                        precision = 0\n",
        "                    try:\n",
        "                        recall = self.confusion_matrices[entity_type]['TP']/(self.confusion_matrices[entity_type]['TP']+self.confusion_matrices[entity_type]['FN'])\n",
        "                    except ZeroDivisionError:\n",
        "                        recall = 0\n",
        "                    try:\n",
        "                        f_measure = 2*precision*recall/(precision+recall)\n",
        "                    except ZeroDivisionError:\n",
        "                        f_measure = 0\n",
        "\n",
        "                    self.scores[entity_type]['p'] = precision\n",
        "                    self.scores[entity_type]['r'] = recall\n",
        "                    self.scores[entity_type]['f1'] = f_measure\n",
        "                    macrof1+=f_measure\n",
        "                    print(self.entity_types[entity_type], 'precision: ',precision, 'recall: ',recall, 'f_measure: ',f_measure)\n",
        "                    \n",
        "                macrof1 = macrof1/len(self.entity_types)\n",
        "                print('macrof1:',str(macrof1))\n",
        "                history_validation.append(combined_validation_loss)\n",
        "                \n",
        "                print('Epoch',str(epoch+1),':',combined_validation_loss)\n",
        "                \n",
        "                \n",
        "                # if(combined_validation_loss<best_loss):\n",
        "                if(macrof1>best_f1):\n",
        "                    # best_loss = combined_validation_loss\n",
        "                    best_f1 = macrof1\n",
        "                    print('making this the checkpoint to save')\n",
        "                    #Saving the model\n",
        "                    self.checkpoint = {\n",
        "                                'epoch': epoch + 1,\n",
        "                                'state_dict': self.classifier.state_dict(),\n",
        "                                'optimizer': self.ec_optimizer.state_dict()\n",
        "                            }\n",
        "                    no_improvement_counter=0\n",
        "                else:\n",
        "                    no_improvement_counter+=1\n",
        "                    if(no_improvement_counter>self.patience):\n",
        "                        break\n",
        "                if(((epoch+1)%10==0)|(epoch == (self.ec_num_epochs-1))):\n",
        "                    print('=========')\n",
        "                print('------------------------')\n",
        "                print('\\n')\n",
        "\n",
        "        return epoch\n",
        "\n",
        "    def run(self,candidateBase,candidateEmbeddingDict):\n",
        "\n",
        "        candidateBase['class']=-1\n",
        "        max_length=candidateBase['length'].max()+1\n",
        "        candidateBase['normalized_length']= candidateBase['length']/max_length\n",
        "\n",
        "        test_dataset = CandidateDataset(candidateBase, candidateEmbeddingDict)\n",
        "        test_loader = DataLoader(test_dataset, len(test_dataset)) #will execute in 1 batch\n",
        "\n",
        "        #Testing\n",
        "        predictions=[]\n",
        "        with torch.no_grad():\n",
        "            self.classifier.eval()\n",
        "            for batch_idx, (data_inter, targets) in enumerate(test_loader):\n",
        "                # data = data.to(device=device)\n",
        "                candidates = data_inter[0]\n",
        "                cluster_ids = data_inter[1]\n",
        "                length_arr = data_inter[2]\n",
        "                cumulative_arr = data_inter[3]\n",
        "                normalized_freq_arr = data_inter[4]\n",
        "\n",
        "                data = [(length_arr[index], candidateEmbeddingDict[(candidate,cluster_ids[index])], cumulative_arr[index], normalized_freq_arr[index]) for index, candidate in enumerate(candidates)]\n",
        "                y_pred = self.classifier(data)\n",
        "                # print(out.shape)\n",
        "                y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "                _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
        "                predictions = y_pred_tags.reshape(-1)\n",
        "        print(predictions.shape,len(candidateBase))\n",
        "\n",
        "        candidateBase['class'] = predictions.tolist()\n",
        "        # print(candidateBase['probability'].min(), candidateBase['probability'].max())\n",
        "        return candidateBase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47Do-RR4nsYt"
      },
      "source": [
        "## **Extracting Embeddings to train the Phrase Embedder on Contrastive Loss and EntityClassifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3akU16hcnywM"
      },
      "outputs": [],
      "source": [
        "from emoji import demojize\n",
        "from collections import defaultdict\n",
        "from random import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATZ1u0R_IcpH",
        "outputId": "7a42e208-3d03-4d06-a8a0-86d403e81971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Set device\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "print(device)\n",
        "tweetTokenizer = TweetTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2a9q8a64LAV"
      },
      "outputs": [],
      "source": [
        "def normalizeToken(token):\n",
        "    lowercased_token = token.lower()\n",
        "    if token.startswith(\"@\"):\n",
        "        return \"@USER\"\n",
        "    elif lowercased_token.startswith(\"http\") or lowercased_token.startswith(\"www\"):\n",
        "        return \"HTTPURL\"\n",
        "    elif len(token) == 1:\n",
        "        return demojize(token)\n",
        "    else:\n",
        "        if token == \"’\":\n",
        "            return \"'\"\n",
        "        elif token == \"…\":\n",
        "            return \"...\"\n",
        "        else:\n",
        "            return token\n",
        "\n",
        "def normalizeTweet(tweet):\n",
        "    tokens = tweetTokenizer.tokenize(tweet.replace(\"’\", \"'\").replace(\"…\", \"...\"))\n",
        "    normTweet = \" \".join([normalizeToken(token) for token in tokens])\n",
        "\n",
        "    normTweet = normTweet.replace(\"cannot \", \"can not \").replace(\"n't \", \" n't \").replace(\"n 't \", \" n't \").replace(\"ca n't\", \"can't\").replace(\"ai n't\", \"ain't\")\n",
        "    normTweet = normTweet.replace(\"'m \", \" 'm \").replace(\"'re \", \" 're \").replace(\"'s \", \" 's \").replace(\"'ll \", \" 'll \").replace(\"'d \", \" 'd \").replace(\"'ve \", \" 've \")\n",
        "    normTweet = normTweet.replace(\" p . m .\", \"  p.m.\") .replace(\" p . m \", \" p.m \").replace(\" a . m .\", \" a.m.\").replace(\" a . m \", \" a.m \")\n",
        "\n",
        "    normTweet = re.sub(r\",([0-9]{2,4}) , ([0-9]{2,4})\", r\",\\1,\\2\", normTweet)\n",
        "    normTweet = re.sub(r\"([0-9]{1,3}) / ([0-9]{2,4})\", r\"\\1/\\2\", normTweet)\n",
        "    normTweet = re.sub(r\"([0-9]{1,3}) - ([0-9]{2,4})\", r\"\\1-\\2\", normTweet)\n",
        "    \n",
        "    return normTweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrotodBggktV"
      },
      "outputs": [],
      "source": [
        "def collate_token_label_embedding(tweetWordList, token_dict, prediction_labels, entity_embeddings):\n",
        "    counter=0\n",
        "    collated_labels=[]\n",
        "    collated_entity_embeddings=[]\n",
        "    for word in tweetWordList:\n",
        "        vals=token_dict[word]\n",
        "        # print(word,vals)\n",
        "        if(counter<len(prediction_labels)):\n",
        "            labels=prediction_labels[counter:counter+len(vals)]\n",
        "            token_entity_embeddings=entity_embeddings[counter:counter+len(vals)]\n",
        "    #         print(token_entity_embeddings.shape)\n",
        "            mean_tensor = torch.mean(token_entity_embeddings,dim=0)\n",
        "            mean_tensor[torch.isnan(mean_tensor)] = 0\n",
        "            collated_entity_embeddings.append(mean_tensor)\n",
        "    #         print(collated_entity_embeddings)\n",
        "            if('I-PER' in labels):\n",
        "                collated_labels.append('I-PER')\n",
        "            elif('I-LOC' in labels):\n",
        "                collated_labels.append('I-LOC')\n",
        "            elif('I-ORG' in labels):\n",
        "                collated_labels.append('I-ORG')\n",
        "            elif('I-MISC' in labels):\n",
        "                collated_labels.append('I-MISC')\n",
        "            elif('B-PER' in labels):\n",
        "                collated_labels.append('B-PER')\n",
        "            elif('B-LOC' in labels):\n",
        "                collated_labels.append('B-LOC')\n",
        "            elif('B-ORG' in labels):\n",
        "                collated_labels.append('B-ORG')\n",
        "            elif('B-MISC' in labels):\n",
        "                collated_labels.append('B-MISC')\n",
        "            else:\n",
        "                collated_labels.append('O')\n",
        "            counter+=len(vals)\n",
        "        else:\n",
        "            collated_labels.append('O')\n",
        "            collated_entity_embeddings.append(torch.zeros(768).to(device))\n",
        "    assert len(collated_labels)==len(collated_entity_embeddings)\n",
        "    return collated_labels,collated_entity_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTSrRtJbzNTt"
      },
      "outputs": [],
      "source": [
        "# trainset, tokenizedtrainset, tweet_to_sentences_w_annotation = preprocess('wnut17test_ner.csv')\n",
        "# trainset, tokenizedtestset, tweet_to_sentences_w_annotation = preprocess('wnut17train_ner.csv')\n",
        "trainset, tokenizedtestset, tweet_to_sentences_w_annotation = preprocess('deduplicated_test_WTypes.csv')\n",
        "\n",
        "candidateBaseHeaders_alt=['candidate', 'batch', 'length','cumulative','class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ86SLX8Idct",
        "outputId": "1e5b3d3c-2be5-434c-a858-e3d45ffdab54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 3 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 3 4 0 0]\n",
            "13\n",
            "dict_keys(['REPORT', ':', 'FBI', 'Obtained', 'FISA', 'Warrant', 'For', 'Trump', 'Aide', ',', 'Believed', 'He', 'Was', \"'\", 'Agent', 'Of', 'The', 'Russian', 'Government'])\n",
            "tensor([[    0, 24537,    22,  5029,  6152, 33859, 47367,  4001,  7850,   287,\n",
            "           394, 51322,     7, 15415, 28288,   162,  1050,    69, 12284,   490,\n",
            "            47,  2768,  3521,    69,     2]])\n",
            "tensor([[    0, 24537,    22,  5029,  6152, 33859, 47367,  4001,  7850,   287,\n",
            "           394, 51322,     7, 15415, 28288,   162,  1050,    69, 12284,   490,\n",
            "            47,  2768,  3521,    69,     2]], device='cuda:0')\n",
            "['O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O']\n",
            "===============\n",
            "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "13\n",
            "dict_keys(['Well', ',', 'this', 'made', 'My', 'Day', 'Thank', 'you', 'Apple', ':', ')', '#', 'RelationshipSongs', 'NoStupidHeadsAllowed', 'InMyFreeTime'])\n",
            "tensor([[    0,   506,     7,    33,   214,   122,   443,   396,    14,  1395,\n",
            "            22,    60,   465, 61868,  9727,  8856,   465,  1986, 32108,  1702,\n",
            "          9740,  6434, 43669,   465,   881,  2397,  9560,   711,     2]])\n",
            "tensor([[    0,   506,     7,    33,   214,   122,   443,   396,    14,  1395,\n",
            "            22,    60,   465, 61868,  9727,  8856,   465,  1986, 32108,  1702,\n",
            "          9740,  6434, 43669,   465,   881,  2397,  9560,   711,     2]],\n",
            "       device='cuda:0')\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "===============\n",
            "[0 7 8 0 0 0 0 0 0 0 0 0 0 0 0 0 8 0 0]\n",
            "13\n",
            "dict_keys(['Carter', 'Page', 'is', 'trending', 'but', '3', 'weeks', 'ago', 'there', 'were', 'no', 'FISA', 'warrant', 'on', 'team', 'Trump', '.'])\n",
            "tensor([[    0,  7476,  5810,    17,  4476,    42,   163,   825,   585,    99,\n",
            "           147,    80, 47367, 23197,    24,   346,   394,     4,     2]])\n",
            "tensor([[    0,  7476,  5810,    17,  4476,    42,   163,   825,   585,    99,\n",
            "           147,    80, 47367, 23197,    24,   346,   394,     4,     2]],\n",
            "       device='cuda:0')\n",
            "['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-PER', 'O']\n",
            "===============\n",
            "[0 0 0 0 0 0 0 0 0 0 0]\n",
            "13\n",
            "dict_keys(['I', 'love', 'how', 'liberals', 'have', 'a', '36', 'hour', 'memory'])\n",
            "tensor([[   0,    8,   71,   84, 9917,   36,   11, 2412,  692, 3499,    2]])\n",
            "tensor([[   0,    8,   71,   84, 9917,   36,   11, 2412,  692, 3499,    2]],\n",
            "       device='cuda:0')\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "===============\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "13\n",
            "dict_keys(['Looks', 'like', 'it', 'might', 'be', 'time', 'for', 'some', 'more', 'tomahawks', '...'])\n",
            "tensor([[    0,  2276,    43,    18,   403,    31,    78,    19,   109,    89,\n",
            "          4990,   527, 16084,    28,     2]])\n",
            "tensor([[    0,  2276,    43,    18,   403,    31,    78,    19,   109,    89,\n",
            "          4990,   527, 16084,    28,     2]], device='cuda:0')\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "===============\n",
            "[7 7 8 0 7 8 0 8]\n",
            "13\n",
            "dict_keys(['Sean', 'Spicer', 'on', 'Carter', 'Page', ':'])\n",
            "tensor([[    0,  5244, 45320,    24,  7476,  5810,    22,     2]])\n",
            "tensor([[    0,  5244, 45320,    24,  7476,  5810,    22,     2]],\n",
            "       device='cuda:0')\n",
            "['B-PER', 'I-PER', 'O', 'B-PER', 'I-PER', 'O']\n",
            "===============\n",
            "5622 5622\n"
          ]
        }
      ],
      "source": [
        "predictions=[]\n",
        "tokenized_sentences=[]\n",
        "count=0\n",
        "with torch.no_grad():\n",
        "    for train_record in trainset:\n",
        "        \n",
        "        sentence = normalizeTweet(train_record)\n",
        "        tweetWordList = sentence.split()\n",
        "        enumerated_tweetWordList=[(token,idx) for idx,token in enumerate(tweetWordList)]\n",
        "\n",
        "        tokenized_input=tokenizer(sentence)\n",
        "        initial_input_ids = torch.tensor([tokenizer.encode(sentence)])\n",
        "\n",
        "        initial_input_ids = initial_input_ids[:,:128]\n",
        "        token_dict = {x : tokenizer.encode(x, add_special_tokens=False) for x in sentence.split()}\n",
        "\n",
        "        input_ids = initial_input_ids.to(device)\n",
        "        tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
        "\n",
        "        output = alt_model(input_ids)\n",
        "        \n",
        "        token_embeddings=output.hidden_states[-1].squeeze()[1:-1] # we dont need embeddings for CLS and EOS\n",
        "\n",
        "        assert torch.isnan(token_embeddings).any() == False\n",
        "\n",
        "        prediction = (torch.argmax(output.logits, axis=2))\n",
        "        prediction = prediction.cpu().numpy().reshape(-1)\n",
        "        if(count<=5):\n",
        "            print(prediction)\n",
        "        # prediction_labels=[label_list[l].split('-')[0] for l in prediction]\n",
        "        prediction_labels=[label_list[l] for l in prediction]\n",
        "        # prediction_labels=collate_token_labels(token_dict, prediction_labels[1:-1])\n",
        "        prediction_labels, entity_aware_embeddings = collate_token_label_embedding(tweetWordList, token_dict, prediction_labels[1:-1], token_embeddings)\n",
        "\n",
        "        # print(len(enumerated_tweetWordList),len(token_dict.keys()),len(entity_aware_embeddings),len(prediction_labels))\n",
        "\n",
        "        assert len(enumerated_tweetWordList)==len(entity_aware_embeddings)\n",
        "        assert len(prediction_labels)==len(enumerated_tweetWordList)\n",
        "\n",
        "        predictions.append(prediction_labels)\n",
        "        tokenized_sentences.append((tweetWordList,entity_aware_embeddings))\n",
        "\n",
        "        if(count<=5):\n",
        "            print(len(output.hidden_states))\n",
        "            print(token_dict.keys())\n",
        "            print(initial_input_ids)\n",
        "            print(input_ids)\n",
        "            print(prediction_labels)\n",
        "            print('===============')\n",
        "        count+=1\n",
        "\n",
        "print(len(predictions),len(tokenized_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXTEOoQPHZYt",
        "outputId": "f1a9b1b1-19b3-4bc3-c553-4c5f51e82c34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
            "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
            "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
            "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
            "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tally: 5622 5622\n"
          ]
        }
      ],
      "source": [
        "local_ner_arrays=[]\n",
        "for n, sentence_tup in enumerate(tokenized_sentences):  \n",
        "    sentence = sentence_tup[0]\n",
        "    assert (len(sentence)==len(predictions[n]))\n",
        "    word_tag_tuples=zip(sentence,predictions[n])\n",
        "    entities_from_sentence=get_entities(word_tag_tuples)\n",
        "    local_ner_arrays.append(entities_from_sentence)\n",
        "print('tally:',len(tokenized_sentences),len(local_ner_arrays))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hc4iew2YzB0",
        "outputId": "3590d147-1fdd-4744-f7e8-89f9450c45e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tired', 'law', 'investigations', 'north', 'certainly', 'evil', 'blame', 'terror', 'neo', 'reputation', 'gone', 'getting', 'might want', 'spy', 'daughters', 'god', 'missile', 'public', 'mainstream', 'mouthpiece', 'called', 'ignorance', 'fms', 'ongoing', 'bet', 'day', 'aide carter', 'meets', 'mad', 'jab', 'find', 'inauguration', 'overwatch', 'beautiful', 'live', 'seeks', 'satan', 'launches', 'beyond', 'cable', 'knows', 'products', 'played', 'basket', 'cut', 're-accommodated', 'subject', 'staffers', 'platform', 'cabal', 'airstrikesγç', 'dad', 'admits', 'supporters', 'peace', 'win', 'repeated', 'pop', 'hired', 'falling', 'advisors', 'daughter', 'took', 'worse', 'mouth', 'morning', 'big', 'tweet', 'population', 'capital', 'comments', 'skittles', 'rise', 'clarify', 'back', 'pig', 'surveillance', 'gay', 'probe', 'lil', 'gif', 'club', 'butt', 'trump said', 'guy', 'ladies', 'sudden', 'pay', 'dummies', 'wanted', 'sean spicerγçös hitler', 'court jester', 'theory', 'lacks', 'daily', 'makes', 'world', 'ivanka influenced', 'state', 'fall', 'empire', 'gift', 'plan', 'probed', 'service', 'may', 'press briefing', 'deep state', 'co', 'socks', 'marketing', 'believes', 'admin', 'gets', 'take', 'better', 'cards', 'orange', 'reveals', 'ass', 'sale', 'claimed', 'scandal', 'comment', 'conference', 'slowly', 'though', 'compared', 'joke', 'stick', 'anti', 'claimed adolf', 'office', 'break', 'nerve', 'ordering', 'justice', 'pretty', 'night live', 'magazine', 'get', 'meme', 'holocaust denial', 'ties', 'stupid', 'research', 'bank', \"f'ing\", 'minister', 'say', 'save', 'finally', 'debate', 'questions', 'liked', 'said', 'independent', 'seen', 'gas', 'troops', 'reportedly', 'weapons', 'canγçöt', 'millions', 'cruise', 'spice', 'spicer really', 'show', 'put', 'neocons', 'hateful', 'tower', 'mafia', 'lies', 'boom', 'new', 'murdering', 'busy', 'watched', 'prez', 'ual', 'history', 'swayed', 'hiding', 'possible', 'trump-russia', 'planet', 'media', 'saying', 'last', 'tried', 'charter', 'fix', 'went', 'interview', 'trip', 'tie', 'golden', 'orders', 'shame', 'threatened', 'golfing', 'administration', 'downfall', 'sean spicer white house', 'talk', 'chief', 'spokesperson', 'shitting', 'flight', 'staff', 'barrel', 'professor', 'force', 'organization', 'stock', 'last summer', 'decides', 'exterminated', 'denial', 'warn', 'needs', 'move', 'soon', 'fucked', 'judge', 'ahead', 'doctor', 'suggested', 'toast', 'plane', 'unemployment', 'complex', 'sugar', 'right', 'first', 'keeping', 'market', 'entire', 'decisions', 'chump', 'woman', 'spin', 'hire', 'battlefield', 'target', 'lucky', 'article', 'designer', 'airfield', 'dot', 'children', 'tax', 'dirty', 'expects', 'claims', 'elected', 'stance', 'greatest', 'sean spicer holocaust centers', 'apologist', 'wall', 'meals', 'wag the dog', 'idiocy', 'hold', 'spies', 'cover', 'mayor', 'causes outrage', 'unrelated', 'set', 'complete', 'news', 'politicians', 'scumbags', 'fight', 'apologized', 'already', 'speaking', 'insensitive', 'middle', 'regime', 'beers', 'call', 'butthead', 'obtained', 'election', 'approves', 'bad day', 'turnip', 'replacement', 'killed', 'trending', 'order', 'project', 'financial', 'customer service', 'downplaying', 'punch', 'playing', 'rules', 'chamber', 'everywhere', 'help', 'faces', 'throwing', 'others', 'heard', 'lord', 'masters', 'voters', 'race', 'way', 'liberty', 'keeps', 'doomed', 'trump advisor', 'native', 'campaign', 'et', 'healthcare', 'prof', 'planes', 'reading', 'skit', 'passenger', 'breaking', 'fashion', 'voices', 'revised', 'land', 'idiot', 'fire', 'loves', 'bff', 'worker', 'thing', 'bad', 'pleasant', 'asked', 'chef', 'junior', 'ordered', 'pundits', 'feather', 'adviser', 'almost', 'zero', 'caused', 'roles', 'weird', 'falls', 'cronies', 'assistant', 'crimes', 'carter page fisa', 'power', 'writers', 'foundation', 'referred', 'rocks', 'vehicle', 'deal', 'gold', 'missles', 'ivanka told', 'spicer apologizes', 'innocent', 'mid', 'airport', 'pizza', 'shut', 'reports', 'funnier', 'trolls', 'dealings', 'senator', 'beer', 'video', 'seriously', 'along', 'business', 'airstrikes', 'demand', 'grizzly', 'taxpayers', 'board', 'list', 'reference', 'great', 'display', 'america great', 'department', 'er', 'food', 'ol', 'war', 'press', 'little', 'general', 'suffering', 'knew', 'lied', 'got', 'fans', 'st', 'money', 'starts', 'decision', 'rather', 'half', 'edge', 'resignation', 'eyes', 'means', 'lie', 'devil', 'arts', 'according', 'info', 'strike', 'fault', 'end', 'air', 'cult', 'center', 'tool', 'one', 'watches', 'gave', 'duck', 'tribe', 'con', 'sent', 'complaint', 'spokesman', 'clearly', 'influenced', 'earth', 'calls concentration', 'liar', 'hall', 'viva', 'brought', 'son', 'coach', 'fake', 'national', 'moron', 'fired', 'fits', 'leaking', 'lawn', 'comes', 'spicer said', 'references', 'denies', 'connection', 'bunny', 'ivanka swayed', 'ends', 'strikes', 'locked', 'hitler didnγçöt', 'tries', 'history book', 'provide', 'mess', 'reps', 'mean', 'mustard', 'gassing', 'moon', 'support', 'sounding', 'come', 'eric trump newcomerstown', 'men', 'turley', 'college', 'learn', 'edit', 'gov', 'anymore', 'things', 'transition', 'royal', 'statements', 'lead', 'backing', 'defense', 'impress', 'seat', 'incident', 'nationalist', 'personally', 'lmao', 'prison planet', 'reversal', 'lady', 'inside', 'version', 'daily news', 'really', 'district', 'demonstrate', 'textbooks', 'concentration', 'level', 'dictator', 'army', 'connections', 'russia-trump', 'latest', 'federal', 'analysis', 'bury', 'sink', 'ally', 'sean spicer barca', 'democracy', 'court', 'wait', 'line', 'team', 'talks', 'works', 'spicer needs', 'family', 'comparison', 'jokes', 'emails', 'assad-hitler', 'agent', 'conflict', 'wld', 'statement', 'fan', 'lifetime', 'post', 'told', 'aide', 'changed', 'triggered', 'drug', 'spying', 'face', 'correction', 'stranger', 'spicer makes', 'mercy', 'victims', 'holy', 'apprentice', 'mall', 'goes', 'theatre', 'pr', 'apparently', 'pol pot', 'claim', 'answer', 'drag', 'mini', 'dictators', 'protests', 'steps', 'immediately', 'spicer claims', 'press secretary', 'repeal', 'actor', 'nation', 'south', 'created', 'gonna', 'position', 'citizen', 'talking', 'chaos', 'presidents', 'gassed', 'labor', 'united pr', 'sean spicer dybala barca', 'syriaγçös assad', 'scene', 'vice', 'commits', 'refugees', 'values', 'among', 'suffers', 'sexual', 'going', 'trump russia', 'bout', 'party', 'meeting', 'movie', 'feels', 'centre', 'action', 'feed', 'costume', 'aid', 'trump adviser', 'bigly', 'think', 'rabbit', 'biggest', 'relations', 'felt', 'dragging', 'saidγçª', 'wrote', 'girl', 'fascist', 'fallout', 'sway', 'idiots', 'look', 'sparks', 'members', 'keep talking', 'lying', 'smokescreen', 'piece', 'times', 'low', 'tells', 'past', 'threaten', 'babs', 'suggests ivanka', 'ivanka encouraged', 'computer', 'kids', 'go', 'deer', 'forgot', 'says', 'bombed syria', 'brilliant', 'resort', 'hours', 'clan', 'dropping', 'sake', 'freaks', 'presidential', 'claiming', 'geils', 'thinks', 'planned', 'traitor', 'per', 'comparisonγç', 'shots', 'trump says', 'disproves', 'march', 'human', 'watching', 'editor', 'fair', 'pelosi says', 'wire', 'go visit', 'agree', 'use', 'angry', 'drew', 'amirite', 'operative', 'solves', 'controlled', 'role', 'leader', 'convince', 'govt', 'hammers sean', 'completely', 'kill', 'etc', 'um', 'wearing', 'due', 'father', 'option', 'man', 'tweeted', 'zones', 'brothers', 'days', 'vacation', 'least', 'eric says', 'member', 'vampire', 'added', 'juve', 'rep', 'airline', 'pops', 'mommy', 'reported', 'cried', 'pro', 'response', 'see', 'living', 'diary', 'ovens', 'deep', 'wont', 'prior', 'later', 'conducted', 'asshole', 'presidency', 'puppets', 'concentration camp', 'anyway', 'uses', 'loan', 'luck', 'videos', 'definitely', 'candidate', 'puppet', 'influenced decision', 'exists', 'camps', 'gaffe', 'poor', 'forced', 'water', 'didnγçöt', 'beforehand', 'dumb', 'confirms', 'alternative', 'corps', 'supposedly', 'daddy', 'engaged', 'camp', 'black ops 2', 'dept', 'agent orange', 'jackass', 'roll', 'work', 'comparisons', 'us', 'sean spicer carter page', 'five', 'email', 'secretly', 'blonde', 'total', 'pot', 'helped', 'repeat', \"gov't\", 'encouraged', 'death', 'official', 'ambassador', 'princess', 'surrounds', 'colluded', 'blaming', 'give', 'thinking', 'instead', 'lolol', 'years', 'loses', 'following', 'week', 'source', 'hitler-assad', 'gives', 'contract', 'sean spicer juve', 'direction', 'chemical', 'sound', 'embarrassing', 'gaslighting', 'made', 'universe', 'black', 'beating', 'sets', 'stated', 'case', 'governor', 'pre', 'raw', 'global', 'sean spicer holocaust', 'communications', 'school', 'hands', 'invasion', 'centres', 'train', 'trick', 'sean spicer hitler', 'controls', 'share', 'input', 'job', 'village', 'hard', 'stop', 'airstrike', 'analogy', 'claims hitler', 'united flight', 'dog', 'fed', 'animal', 'guys', 'blasts sean', 'officially', 'ear', 'rump', 'dug', 'actually', 'scary', 'advisor', 'rolling', 'time', 'smh', 'launch', 'weekly', 'short', 'driving', 'social', 'alike', 'mic', 'tillerson arrives', 'pres', 'street', 'nepotism', 'rest', 'passes', 'memes', 'chance', 'meant', 'putting', 'band', 'hack', 'good', 'aliens', 'left', 'respect', 'politics', 'trust', 'worked', 'carries', 'night', 'sea', 'stuff', 'staged', 'visit aushtwitz', 'analogies', 'distractions', 'snowflake', 'supporter', 'trump wants', 'used', 'away', 'base', 'foreign', 'master', 'assertion', 'convinced', 'karma', 'need', 'runs', 'proven', 'lost', 'rock', 'deflect', 'political', 'white house easter bunny', 'forces', 'toγçª', 'offers', 'came', 'branch', 'centers', 'press conference', 'self', 'blood', 'western', 'eric said', 'bombs', 'coup', 'bombing', 'next', 'airbase', 'committed', 'ceo', 'producers', 'remarks', 'reach', 'takes', 'sanctions', 'kid', 'gas chambers', 'officials', 'spicer says', 'heavily', 'headed', 'leave', 'trumprussia', 'investigation', 'controlling', 'kingdom', 'sycophants', 'mention', 'secretary', 'mentally', 'problem', 'charge', 'visiting', 'hitler reference', 'intelligence', 'rewriting', 'led', 'tho', 'allies', 'inc', 'continue', 'treason', 'spicer speaks', 'distraction', 'turns', 'using', 'attack', 'run', 'oil', 'busted', 'name', 'shows', 'girls', 'airlines', 'anti-trump', 'comrade', 'dump', 'longer', 'sean spicer dortmund', 'music', 'navy', 'message', 'warrant', 'people', 'thought', 'wants', 'demand sean', 'showed', 'friends', 'elementary school', 'government', 'citizens', 'intel', 'story', 'stream media', 'everyday', 'awful', 'association', 'wing', 'uncle', 'bomb', 'bozo', 'full', 'bombed', 'hill', 'baby hitler', 'imminent', 'collusion', 'gate'}\n",
            "989\n"
          ]
        }
      ],
      "source": [
        "canonical_candidate_df=pd.read_csv(\"data/candidate_train_records_altClassifier_new.csv\",sep =',', keep_default_na=False)\n",
        "canonical_ne_list = canonical_candidate_df[(canonical_candidate_df['class']==0)&(canonical_candidate_df['cumulative']>=5)].candidate.tolist()\n",
        "\n",
        "\n",
        "canonical_ne_list = set(canonical_ne_list)\n",
        "canonical_ne_list.remove('ex-trump')\n",
        "canonical_ne_list.remove('ex-trump adviser')\n",
        "canonical_ne_list.remove('jr')\n",
        "canonical_ne_list.remove('dt')\n",
        "canonical_ne_list.remove('ic')\n",
        "canonical_ne_list.remove('al')\n",
        "canonical_ne_list.remove('report')\n",
        "canonical_ne_list.remove('impeachment')\n",
        "canonical_ne_list.remove('missiles')\n",
        "canonical_ne_list.remove('america')\n",
        "canonical_ne_list.remove('military')\n",
        "canonical_ne_list.remove('congressional')\n",
        "canonical_ne_list.remove('secretary of state')\n",
        "canonical_ne_list.remove('america first')\n",
        "canonical_ne_list.remove('easter bunny')\n",
        "canonical_ne_list.remove('west')\n",
        "canonical_ne_list.remove('east')\n",
        "canonical_ne_list.remove('states')\n",
        "canonical_ne_list.remove('white')\n",
        "canonical_ne_list.remove('science')\n",
        "\n",
        "print(canonical_ne_list)\n",
        "print(len(canonical_ne_list))\n",
        "\n",
        "entity_types_dict = {'ne':0, 'org':1, 'misc':2, 'loc':3, 'per':4}\n",
        "type_candidate_dict = {entity_type:{} for entity_type in entity_types_dict}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSQL5lqsIqzo",
        "outputId": "b4506fc5-1920-45aa-941e-9509c07c2c09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "spotify\n",
            "2184 ['WHO', 'KNOWS', 'WHAT', 'HOTEL', 'Pinkfloyd', 'were', 'STAYING', 'AT', 'ON', 'SUNDAY', 'IN', 'Madrid', '?']\n",
            "annotated_mention_list: [('pinkfloyd', 'misc'), ('madrid', 'loc')]\n",
            "non_entity_list: ['knows']\n",
            "pinkfloyd\n",
            "madrid\n",
            "2185 ['Carter', 'Page', 'said', 'that', 'the', 'Steele', 'dossier', 'was', '\"', 'little', 'more', 'than', 'a', 'comedic', 'distraction', 'for', 'months', 'on', 'end', '\"']\n",
            "annotated_mention_list: [('carter page', 'per'), ('steele dossier', 'misc')]\n",
            "non_entity_list: ['distraction', 'said', 'little', 'end']\n",
            "carter page\n",
            "steele dossier\n",
            "2186 ['@USER', 'Carter', 'Page', 'tuning', 'up', 'for', 'his', 'big', 'number', '.']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "non_entity_list: ['big']\n",
            "carter page\n",
            "2187 ['A', 'FISA', 'warrant', 'for', 'the', 'guy', 'who', 'was', 'one', 'of', 'Trump', \"'s\", 'few', 'named', 'foreign', 'policy', 'advisers', '.', 'So', 'chew', 'on', 'that', '.']\n",
            "annotated_mention_list: [('fisa warrant', 'misc'), ('trump', 'per')]\n",
            "non_entity_list: ['one', 'guy', 'foreign', 'warrant']\n",
            "fisa warrant\n",
            "trump\n",
            "2188 ['Were', 'many', 'young', 'girls', 'queuing', 'outside', 'the', 'Brighton', 'Centre', 'for', 'Pinkfloyd', ':', '/']\n",
            "annotated_mention_list: [('brighton centre', 'loc'), ('pinkfloyd', 'misc')]\n",
            "non_entity_list: ['centre', 'girls']\n",
            "brighton centre\n",
            "pinkfloyd\n",
            "2189 ['FBI', 'obtained', 'FISA', 'warrant', 'to', 'monitor', 'former', 'Trump', 'adviser', 'Carter', 'Page', 'Deep', 'and', 'dark']\n",
            "annotated_mention_list: [('fbi', 'org'), ('fisa warrant', 'misc'), ('trump', 'per'), ('carter page', 'per')]\n",
            "non_entity_list: ['adviser', 'deep', 'obtained', 'warrant']\n",
            "fbi\n",
            "fisa warrant\n",
            "trump\n",
            "carter page\n",
            "2190 ['does', 'this', 'make', 'President', 'Bannon', 'or', 'that', 'guy', 'nervous', '?']\n",
            "annotated_mention_list: [('president bannon', 'per')]\n",
            "non_entity_list: ['guy']\n",
            "president bannon\n",
            "2191 ['@USER', 'A', 'little', 'too', 'much', 'time', 'on', 'Carter', 'Page', 'and', 'not', 'enough', 'time', 'on', 'Tamerlan', '.', 'Gotta', 'by', 'a', 'hardcover', 'copy', 'for', 'my', 'cruise', 'next', 'month', '!']\n",
            "annotated_mention_list: [('carter page', 'per'), ('tamerlan', 'per')]\n",
            "non_entity_list: ['cruise', 'little', 'time', 'next']\n",
            "carter page\n",
            "tamerlan\n",
            "2192 ['Page', ':', '\"', 'Thanks', 'a', 'lot', ',', 'dRump', '\"', '(', 'of', 'course', ')']\n",
            "annotated_mention_list: [('page', 'per'), ('drump', 'per')]\n",
            "page\n",
            "drump\n",
            "2193 ['Why', 'the', 'FBI', 'obtained', 'a', 'secret', 'court', 'order', 'to', 'monitor', 'Donald', 'Trump', \"'s\", 'ex-foreign', 'policy', 'adviser', 'Carter', 'Page']\n",
            "annotated_mention_list: [('fbi', 'org'), ('donald trump', 'per'), ('carter page', 'per')]\n",
            "non_entity_list: ['order', 'adviser', 'obtained', 'court']\n",
            "fbi\n",
            "donald trump\n",
            "carter page\n",
            "2194 ['Thanks', 'Obama', '!']\n",
            "annotated_mention_list: [('obama', 'per')]\n",
            "obama\n",
            "2195 ['Fernando', 'Torres', 'should', 'go', 'out', 'to', 'an', 'epic', 'song', 'like', 'Numb']\n",
            "annotated_mention_list: [('fernando torres', 'per'), ('numb', 'misc')]\n",
            "non_entity_list: ['go']\n",
            "fernando torres\n",
            "numb\n",
            "2196 ['Seems', 'appropriate', 'to', 'retweet', 'this', 'today', ',', 'given', 'Page', 'was', 'a', 'FISA', 'target', '...']\n",
            "annotated_mention_list: [('page', 'per'), ('fisa', 'misc')]\n",
            "non_entity_list: ['target']\n",
            "page\n",
            "fisa\n",
            "2197 ['\"', 'Carter', 'Page', 'confirmed', 'spy', '.', '\"', '\"', 'For', 'us', 'or', 'them', '?', '\"']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "non_entity_list: ['us', 'spy']\n",
            "carter page\n",
            "2198 ['@USER', 'drip', ',', 'drip', 'finally', 'the', 'real', 'story', 'starts', 'to', 'flow', 'and', 'soon', 'the', 'flood', 'will', 'come', ',', 'hopefully', 'before', 'he', 'gets', 'us', 'into', 'nuclear', 'war']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['war', 'us', 'starts', 'come', 'soon', 'story', 'finally', 'gets']\n",
            "2199 ['Another', 'SHOUTOUT', 'to', 'another', 'good', 'person', ',', 'KyleKulinski', 'for', 'giving', 'me', 'so', 'much', 'feedback', 'on', 'my', 'videos']\n",
            "annotated_mention_list: [('kylekulinski', 'per')]\n",
            "non_entity_list: ['videos', 'good']\n",
            "kylekulinski\n",
            "2200 ['This', 'is', 'insane', '.', 'This', '.', 'Is', '.', 'Insane', '.']\n",
            "annotated_mention_list: []\n",
            "2201 ['Eric', 'Trump', ',', 'Nunes', ',', 'Carter', 'Page', ',', 'Sean', 'Spicer', ',', 'Holocaust', 'Centers', ';', 'bout', 'time', 'we', 'heard', 'from', 'Kelly', 'Ann', 'Conway', 'I', 'think', '.']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('nunes', 'per'), ('carter page', 'per'), ('sean spicer', 'per'), ('holocaust centers', 'org'), ('kelly ann conway', 'per')]\n",
            "non_entity_list: ['time', 'heard', 'centers', 'bout', 'think']\n",
            "eric trump\n",
            "nunes\n",
            "carter page\n",
            "sean spicer\n",
            "holocaust centers\n",
            "kelly ann conway\n",
            "2202 ['Trump', 'threaten', 'war', 'w', '/', 'North', 'Korea', 'today', '..', 'He', 'knew', 'Carter', 'Page', 'story', 'was', 'coming', 'out', '..', 'what', 'will', 'he', 'do', 'when', 'his', 'tax', 'returns', 'r', 'leaked']\n",
            "annotated_mention_list: [('trump', 'per'), ('north korea', 'loc'), ('carter page', 'per')]\n",
            "non_entity_list: ['war', 'tax', 'north', 'knew', 'story', 'threaten']\n",
            "trump\n",
            "north korea\n",
            "carter page\n",
            "2203 ['Kislyak', 'and', 'Putin', 'workin', \"'\", 'all', 'the', 'Trump', 'bitches', '!', '\"', 'Carter', 'Page', '\"']\n",
            "annotated_mention_list: [('kislyak', 'per'), ('putin', 'per'), ('trump', 'per'), ('carter page', 'per')]\n",
            "kislyak\n",
            "putin\n",
            "trump\n",
            "carter page\n",
            "2204 ['\"', 'Carter', 'Page', ',', 'at', 'Center', 'of', 'Trump', 'Russian', 'Investigation', ',', 'Writes', 'Bizarre', 'Letter', 'to', 'DOJ', 'Blaming', 'Hillary', 'Clinton', '\"', '.']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "non_entity_list: ['investigation', 'center', 'blaming']\n",
            "carter page\n",
            "2205 ['Something', 'tells', 'me', 'Carter', 'Page', 'is', 'not', 'so', 'bright', '.']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "non_entity_list: ['tells']\n",
            "carter page\n",
            "2206 ['MORE', 'PROOF', 'OF', 'OBAMA', \"'s\", 'GESTAPO', 'TACTICS', '!']\n",
            "annotated_mention_list: [('obama', 'per'), ('gestapo', 'misc')]\n",
            "obama\n",
            "gestapo\n",
            "2207 ['@USER', 'breaking', 'alert', '@USER', 'associate', 'subject', 'of', 'warrant', '2016', 'as', 'per', '@USER', 'look', ':', 'more', 'leaks', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['warrant', 'breaking', 'look', 'subject', 'per']\n",
            "2208 ['Dems', 'were', 'in', 'the', 'dark', ':', 'did', \"n't\", 'know', 'Page', 'was', 'already', 'under', 'federal', 'investigation', '.', 'It', \"'s\", 'bullshit', 'to', 'say', 'HRC', 'campaign', 'made', 'up', 'Russia', 'theories']\n",
            "annotated_mention_list: [('dems', 'misc'), ('page', 'per'), ('hrc', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['campaign', 'made', 'already', 'investigation', 'federal', 'say']\n",
            "dems\n",
            "page\n",
            "hrc\n",
            "russia\n",
            "2209 ['This', 'is', 'the', 'story', 'you', 'need', 'to', 'be', 'paying', 'attention', 'to', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['need', 'story']\n",
            "2210 ['WaPost', ':', 'FBI', 'Had', 'FISA', 'Warrant', 'to', 'Monitor', 'Trump', 'Adviser', 'Page', 'via', '@USER', 'Newsmax']\n",
            "annotated_mention_list: [('wapost', 'org'), ('fbi', 'org'), ('fisa warrant', 'misc'), ('trump', 'per'), ('newsmax', 'org')]\n",
            "non_entity_list: ['adviser', 'warrant']\n",
            "wapost\n",
            "fbi\n",
            "fisa warrant\n",
            "trump\n",
            "newsmax\n",
            "2211 ['Because', 'of', 'we', 'must', 'DENAND', 'new', 'election', '.', 'Carter', 'Page', 'admittedly', 'colluded', '.', '@USER']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "non_entity_list: ['new', 'colluded', 'election']\n",
            "carter page\n",
            "2212 ['Carter', 'Page', 'most', 'certainly', 'should', 'make', 'a', 'deal', 'to', 'sing', 'like', 'a', 'bird', '.']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "non_entity_list: ['deal', 'certainly']\n",
            "carter page\n",
            "2213 ['REVEALED', ':', 'FBI', 'secured', 'FISA', 'warrant', 'against', 'Carter', 'Page', 'over', 'concerns', 'he', 'was', 'acting', 'as', 'an', 'agent', 'of', 'Russia']\n",
            "annotated_mention_list: [('fbi', 'org'), ('fisa warrant', 'misc'), ('carter page', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['agent', 'warrant']\n",
            "fbi\n",
            "fisa warrant\n",
            "carter page\n",
            "russia\n",
            "2214 ['Not', 'a', 'low', 'bar', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['low']\n",
            "2215 ['Distractions', 'from', 'his', 'treason', 'investigation', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['investigation', 'treason', 'distractions']\n",
            "2216 ['So', 'Comey', \"'s\", 'been', 'lying', 'that', 'he', 'knew', 'nothing', 'about', 'a', 'FISA', 'report', '?', 'Washington', 'Times', 'reported', 'FBI', 'monitored', 'Carter', 'Page', 'via', 'FISA', '..']\n",
            "annotated_mention_list: [('comey', 'per'), ('fisa report', 'misc'), ('washington times', 'org'), ('fbi', 'org'), ('carter page', 'per'), ('fisa', 'misc')]\n",
            "non_entity_list: ['lying', 'reported', 'times', 'knew']\n",
            "comey\n",
            "fisa report\n",
            "washington times\n",
            "fbi\n",
            "carter page\n",
            "fisa\n",
            "2217 ['Per', 'Rachel', 'Maddow', 'now', 'this', 'warrant', 'has', 'been', 'renewed', 'more', 'than', 'once', '.']\n",
            "annotated_mention_list: [('rachel maddow', 'per')]\n",
            "non_entity_list: ['warrant', 'per']\n",
            "rachel maddow\n",
            "2218 ['Per', '@USER', 'reporter', ':', 'FISA', 'warrant', 'was', 'renewed', 'by', 'judge', '-', 'at', 'least', 'once', '!']\n",
            "annotated_mention_list: [('fisa warrant', 'misc')]\n",
            "non_entity_list: ['warrant', 'least', 'judge', 'per']\n",
            "fisa warrant\n",
            "2219 ['When', 'will', 'POTUS', 'fire', 'Comey', '?', 'He', 'is', 'not', 'your', 'friend', '!', 'What', 'you', 'need', 'to', 'know', 'about', 'former', 'Trump', 'adviser', 'Carter', 'Page']\n",
            "annotated_mention_list: [('potus', 'per'), ('comey', 'per'), ('trump', 'per'), ('carter page', 'per')]\n",
            "non_entity_list: ['need', 'fire', 'adviser']\n",
            "potus\n",
            "comey\n",
            "trump\n",
            "carter page\n",
            "2220 ['@USER', '@USER', '45', 'surrounds', 'himself', 'with', '\"', 'QUALITY', 'PEOPLE', '\"', 'only', 'the', 'best', '!', 'or', 'is', 'that', 'the', 'bestest', '?', 'carter', 'page', 'is', 'the', 'kind', 'of', 'guy', 'who', 'impresses', '45', 'YIKES', '!']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "non_entity_list: ['people', 'surrounds', 'guy']\n",
            "carter page\n",
            "2221 ['Watch', 'Maddow', 'tonite', 'abt', 'Carter', 'Page', '/', 'FISA', 'warrant', 'and', 'his', 'being', 'agent', 'of', 'Russia', 'for', 'Trump', \"'s\", 'campaign', '.', 'Anothr', 'nail', 'in', 'the', 'coffin', '(', 'big', 'nail', '!', ')', '.']\n",
            "annotated_mention_list: [('maddow', 'per'), ('carter page', 'per'), ('fisa warrant', 'misc'), ('russia', 'loc'), ('trump', 'per')]\n",
            "non_entity_list: ['agent', 'campaign', 'big', 'warrant']\n",
            "maddow\n",
            "carter page\n",
            "fisa warrant\n",
            "russia\n",
            "trump\n",
            "2222 ['Troll', 'so', 'hard', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['hard']\n",
            "2223 ['I', 'do', \"n't\", 'think', 'Carter', 'Page', 'is', 'as', 'stupid', 'as', 'he', 'pretends', 'to', 'be', '.', 'I', 'think', 'he', 'was', 'fully', 'aware', 'of', 'what', 'he', 'was', 'doing', '.']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "non_entity_list: ['think', 'stupid']\n",
            "carter page\n",
            "2224 ['Carter', 'Page', '.', 'Come', 'in', 'from', 'the', 'cold', '.']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "non_entity_list: ['come']\n",
            "carter page\n",
            "2225 ['Yep', '...', 'Follow', 'the', 'connections', '...', 'Remember', 'the', 'Hacker', 'in', 'Spain', 'that', 'they', 'Holding', 'for', 'the', 'FBI', '...']\n",
            "annotated_mention_list: [('spain', 'loc'), ('fbi', 'org')]\n",
            "non_entity_list: ['connections']\n",
            "spain\n",
            "fbi\n",
            "2226 ['This', '!']\n",
            "annotated_mention_list: []\n",
            "2227 ['I', 'keep', 'telling', 'ya', 'Carter', 'Page', 'is', 'going', 'to', 'be', 'the', 'one', 'to', 'bring', 'the', 'Trump', 'crime', 'family', 'down', 'with', 'sheer', 'stupidity', '.', 'His', 'and', 'Trump', '.']\n",
            "annotated_mention_list: [('carter page', 'per'), ('trump', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['going', 'family', 'one']\n",
            "carter page\n",
            "trump\n",
            "trump\n",
            "2228 ['So', '.', 'FBI', 'Obtained', 'FISA', 'warrant', 'against', 'former', 'Trump', 'adviser', 'Carter', 'Page']\n",
            "annotated_mention_list: [('fbi', 'org'), ('fisa warrant', 'misc'), ('trump', 'per'), ('carter page', 'per')]\n",
            "non_entity_list: ['adviser', 'obtained', 'warrant']\n",
            "fbi\n",
            "fisa warrant\n",
            "trump\n",
            "carter page\n",
            "2229 ['8', 'Key', 'Facts', 'About', 'Carter', 'Page', \"'s\", 'Connections', 'to', 'Russia', 'Being', 'Probed', '-', 'Who', 'Is', 'Trump', \"'s\", 'Former', 'Adviser', 'Carter', 'Page', '.']\n",
            "annotated_mention_list: [('carter page', 'per'), ('russia', 'loc'), ('trump', 'per'), ('carter page', 'per')]\n",
            "non_entity_list: ['connections', 'adviser', 'probed']\n",
            "carter page\n",
            "russia\n",
            "trump\n",
            "carter page\n",
            "2230 ['Purchase', 'one', 'FISA', 'Warrant', 'for', 'Carter', 'Page', '.', 'Get', 'Donald', 'Trump', 'calls', 'for', 'FREE', '!']\n",
            "annotated_mention_list: [('fisa warrant', 'misc'), ('carter page', 'per'), ('donald trump', 'per')]\n",
            "non_entity_list: ['warrant', 'get', 'one']\n",
            "fisa warrant\n",
            "carter page\n",
            "donald trump\n",
            "2231 ['Oh', 'man', ',', 'FISA', 'warrant', 'for', 'Carter', 'Page', '?', 'Who', 'was', 'on', 'Trump', 'transition', 'team', '?', 'Not', 'suspicious', 'at', 'all', '...']\n",
            "annotated_mention_list: [('fisa warrant', 'misc'), ('carter page', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['warrant', 'team', 'transition', 'man']\n",
            "fisa warrant\n",
            "carter page\n",
            "trump\n",
            "2232 ['@USER', 'First', '.', 'Just', 'ask', 'Carter', 'Page', '.']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "non_entity_list: ['first']\n",
            "carter page\n",
            "2233 ['Full', 'circle', 'to', 'find', 'the', 'truth', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['full', 'find']\n",
            "2234 ['@USER', 'Bad', 'actor', 'that', 'Carter', 'Page', ',', 'definitely', 'not', 'playing', 'with', 'a', 'full', 'deck', '.']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "non_entity_list: ['bad', 'full', 'actor', 'playing', 'definitely']\n",
            "carter page\n",
            "2235 ['Is', 'this', 'connected', 'to', 'how', 'we', 'got', 'Flynn', 'or', 'is', 'there', 'so', 'many', 'goddamn', 'FISA', 'warrants', 'surround', 'Trump', 'Tower', ',', 'it', \"'s\", 'like', 'playing', 'A', 'Barrel', 'Full', 'of', 'shit', '?']\n",
            "annotated_mention_list: [('flynn', 'per'), ('fisa warrants', 'misc'), ('trump tower', 'loc')]\n",
            "non_entity_list: ['tower', 'full', 'playing', 'got', 'barrel']\n",
            "flynn\n",
            "fisa warrants\n",
            "trump tower\n",
            "2236 ['Carter', 'Page', 'on', 'Russia', ':', '\"', 'We', 'can', 'not', 'in', 'one', 'breath', 'speak', 'of', 'protecting', 'lives', 'and', 'in', 'the', 'next', 'close', 'the', 'prerequisite', 'pathways', 'of', 'negotiation', '\"']\n",
            "annotated_mention_list: [('carter page', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['next', 'one']\n",
            "carter page\n",
            "russia\n",
            "2237 ['\"', 'Carter', 'Page', '\"', 'OH', 'the', 'Incidental', 'contact', 'possibilities', '!', '!']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "carter page\n",
            "2238 ['Another', 'lie', 'from', 'a', 'CNN', 'anchor', '.', 'How', 'shocking', '!', '\"', 'Carter', 'Page', '\"']\n",
            "annotated_mention_list: [('cnn', 'org'), ('carter page', 'per')]\n",
            "non_entity_list: ['lie']\n",
            "cnn\n",
            "carter page\n",
            "2239 ['If', 'the', 'Republican', 'voters', 'must', 'ask', 'themselves', ':', 'Why', 'would', 'hire', 'so', 'many', 'Russians', ',', 'if', 'he', 'was', \"n't\", 'a', 'Russian', 'too', '?']\n",
            "annotated_mention_list: [('republican', 'misc'), ('russians', 'misc'), ('russian', 'misc')]\n",
            "non_entity_list: ['voters', 'hire']\n",
            "republican\n",
            "russians\n",
            "russian\n",
            "2240 ['Please', 'Carter', 'cut', 'a', 'deal', '.']\n",
            "annotated_mention_list: [('carter', 'per')]\n",
            "non_entity_list: ['deal', 'cut']\n",
            "carter\n",
            "2241 ['Carter', 'Page', 'Time', 'Line', 'Great', '@USER', 'Thread']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "non_entity_list: ['line', 'great', 'time']\n",
            "carter page\n",
            "2242 ['Flynn', 'and', 'Sessions', 'both', 'lied', 'about', 'meetings', 'with', 'Russians', 'after', 'the', 'FBI', 'started', 'watching', 'Carter', 'Page', 'for', 'espionage', '.', 'Must', 'be', 'a', 'coincidence', '.']\n",
            "annotated_mention_list: [('flynn', 'per'), ('sessions', 'per'), ('russians', 'misc'), ('fbi', 'org'), ('carter page', 'per')]\n",
            "non_entity_list: ['watching', 'lied']\n",
            "flynn\n",
            "sessions\n",
            "russians\n",
            "fbi\n",
            "carter page\n",
            "2243 ['Carter', 'Page', 'everyone', '.', 'Not', 'shocked', '.']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "carter page\n",
            "2244 ['He', 'gave', 'the', 'Russian', 'ambassador', 'his', 'card', '.', 'At', 'a', 'DNC', 'function', 'set', 'up', 'by', 'Obama', '.', 'That', 'is', 'probable', 'cause', 'for', 'Democrats', '?']\n",
            "annotated_mention_list: [('russian', 'misc'), ('dnc', 'org'), ('obama', 'per'), ('democrats', 'misc')]\n",
            "non_entity_list: ['gave', 'ambassador', 'set']\n",
            "russian\n",
            "dnc\n",
            "obama\n",
            "democrats\n",
            "2245 ['A', 'Shoe', 'Drops', ':', 'Obama', 'Administration', 'Spied', 'On', 'Carter', 'Page']\n",
            "annotated_mention_list: [('obama administration', 'org'), ('carter page', 'per')]\n",
            "non_entity_list: ['administration']\n",
            "obama administration\n",
            "carter page\n",
            "2246 ['The', 'trash', 'is', 'being', 'dumped', 'now', '.', 'Report', ':', 'FBI', 'obtained', 'FISA', 'warrant', 'to', 'monitor', 'Trump', \"'s\", 'advisor', 'Carter', 'Page']\n",
            "annotated_mention_list: [('fbi', 'org'), ('fisa warrant', 'misc'), ('trump', 'per'), ('carter page', 'per')]\n",
            "non_entity_list: ['advisor', 'obtained', 'warrant']\n",
            "fbi\n",
            "fisa warrant\n",
            "trump\n",
            "carter page\n",
            "2247 ['Breaking', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['breaking']\n",
            "2248 ['@USER', 'How', 'would', 'Carter', 'Page', 'know', 'that', '?']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "carter page\n",
            "2249 ['There', \"'s\", 'a', 'really', 'decent', 'chance', 'that', 'Carter', 'Page', \"'s\", 'payout', 'from', 'the', 'Rosneft', 'privatization', 'deal', 'is', 'right', 'here']\n",
            "annotated_mention_list: [('carter page', 'per'), ('rosneft', 'org')]\n",
            "non_entity_list: ['right', 'deal', 'really', 'chance']\n",
            "carter page\n",
            "rosneft\n",
            "2250 ['There', \"'s\", 'a', 'really', 'decent', 'chance', 'that', 'Carter', 'Page', \"'s\", 'payout', 'from', 'the', 'Rosneft', 'privatization', 'deal', 'is', 'right', 'here']\n",
            "annotated_mention_list: [('carter page', 'per'), ('rosneft', 'org')]\n",
            "non_entity_list: ['right', 'deal', 'really', 'chance']\n",
            "carter page\n",
            "rosneft\n",
            "2251 ['Carter', 'Page', 'is', 'also', 'probably', 'pretty', 'grateful', '.']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "non_entity_list: ['pretty']\n",
            "carter page\n",
            "2252 ['This', 'is', 'getting', 'good', 'folks', '!', 'FBI', 'reportedly', 'probed', 'ex', '-', 'trump', 'aide', 'Carter', 'Page', 'during', 'campaign']\n",
            "annotated_mention_list: [('fbi', 'org'), ('trump', 'per'), ('carter page', 'per')]\n",
            "non_entity_list: ['campaign', 'getting', 'probed', 'good', 'reportedly', 'aide']\n",
            "fbi\n",
            "trump\n",
            "carter page\n",
            "2253 ['Washington', 'Post', ':', 'FBI', 'warrant', 'targeting', 'Carter', 'Page', ',', 'Trump', \"'s\", 'guy', 'during', 'the', 'election', '...', 'Carter', 'Page', 'may', 'have', 'been', 'recruited', 'by', 'the', 'Russians', '...']\n",
            "annotated_mention_list: [('washington post', 'org'), ('fbi', 'org'), ('carter page', 'per'), ('trump', 'per'), ('carter page', 'per'), ('russians', 'misc')]\n",
            "non_entity_list: ['guy', 'may', 'warrant', 'post', 'election']\n",
            "washington post\n",
            "fbi\n",
            "carter page\n",
            "trump\n",
            "carter page\n",
            "russians\n",
            "2254 ['Report', ':', 'FBI', 'granted', 'FISA', 'warrant', 'to', 'surveil', 'ex', '-', 'trump', 'aide', 'Carter', 'Page', '-', 'The', 'Hill']\n",
            "annotated_mention_list: [('fbi', 'org'), ('fisa warrant', 'misc'), ('trump', 'per'), ('carter page', 'per'), ('hill', 'org')]\n",
            "non_entity_list: ['aide', 'warrant']\n",
            "fbi\n",
            "fisa warrant\n",
            "trump\n",
            "carter page\n",
            "hill\n",
            "2255 ['Hitler', 'Is', 'Pissed', 'About', 'Google']\n",
            "annotated_mention_list: [('hitler', 'per'), ('google', 'org')]\n",
            "hitler\n",
            "google\n",
            "2256 ['one', 'day', ',', 'if', 'we', 'live', 'that', 'long', ',', 'there', \"'s\", 'gonna', 'be', 'a', 'really', 'interesting', 'carter', 'page', 'biography']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "non_entity_list: ['live', 'really', 'day', 'gonna', 'one']\n",
            "carter page\n",
            "2257 ['Trump', 'foreign', 'policy', 'adviser', 'Carter', 'Page', 'was', 'the', 'subject', 'of', 'an', 'early', 'FISA', 'warrant', 'as', 'a', 'foreign', 'agent', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('carter page', 'per'), ('fisa warrant', 'misc')]\n",
            "non_entity_list: ['foreign', 'subject', 'agent', 'adviser', 'warrant']\n",
            "trump\n",
            "carter page\n",
            "fisa warrant\n",
            "2258 ['\"', '...', 'the', 'clearest', 'evidence', 'so', 'far', 'that', 'the', 'FBI', 'had', 'reason', 'to', 'believe', '...', 'a', 'Trump', 'campaign', 'adviser', 'was', 'in', 'touch', 'with']\n",
            "annotated_mention_list: [('fbi', 'org'), ('trump', 'per')]\n",
            "non_entity_list: ['campaign', 'adviser']\n",
            "fbi\n",
            "trump\n",
            "2259 ['@USER', 'Check', 'with', 'Carter', 'Page', '...', 'ET', ',', 'it', \"ain't\", 'ova', ',', 'son', 'just', 'wait', '!', '!', '!']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "non_entity_list: ['wait', 'son', 'et']\n",
            "carter page\n",
            "2260 ['TODAY', ':', 'Tillerson', 'doesnt', 'know', 'why', 'US', 'should', 'care', 'abt', 'Ukraine', 'Spicer', \"'s\", 'Hitler', 'comments', 'Carter', 'Page', 'spied', 'Devin', 'Nunes', 'lied', 'Its', 'only', 'Tuesday']\n",
            "annotated_mention_list: [('tillerson', 'per'), ('us', 'loc'), ('ukraine', 'loc'), ('spicer', 'per'), ('hitler', 'per'), ('carter page', 'per'), ('devin nunes', 'per')]\n",
            "non_entity_list: ['comments', 'lied']\n",
            "tillerson\n",
            "us\n",
            "ukraine\n",
            "spicer\n",
            "hitler\n",
            "carter page\n",
            "devin nunes\n",
            "2261 ['linuxnewbie', 'on', 'Tweeted', 'Times', '-', 'top', 'stories', 'by', 'malcolmcoles', ',', 'neave', 'in', 'nbc']\n",
            "annotated_mention_list: [('malcolmcoles', 'per'), ('neave', 'per'), ('nbc', 'org')]\n",
            "non_entity_list: ['tweeted', 'times']\n",
            "malcolmcoles\n",
            "neave\n",
            "nbc\n",
            "2262 ['@USER', '@USER', 'Especially', 'when', 'it', 'was', 'the', 'FBI', 'not', 'Obama', 'and', 'it', 'was', 'Carter', 'Page', 'not', 'Trump', 'Tower', '..', 'Their', 'interpretation', 'takes', 'so', 'many', 'liberties', 'it', \"'s\", 'absurd']\n",
            "annotated_mention_list: [('fbi', 'org'), ('obama', 'per'), ('carter page', 'per'), ('trump tower', 'loc')]\n",
            "non_entity_list: ['tower', 'takes']\n",
            "fbi\n",
            "obama\n",
            "carter page\n",
            "trump tower\n",
            "2263 ['@USER', 'They', 'got', 'him', 'already', 'thanks', 'to', 'carter', 'Page', 'and', 'fisa', 'all', 'legal', 'arrest', 'around', 'corner', 'and', 'yes', 'u', 'need', 'to', 'b']\n",
            "annotated_mention_list: [('carter page', 'per'), ('fisa', 'misc')]\n",
            "non_entity_list: ['already', 'need', 'got']\n",
            "carter page\n",
            "fisa\n",
            "2264 ['Google', 'To', 'Join', 'Anti', '-', 'SOPA', \"'\", '\"', \"'\", 'Blackout', 'Day', \"'\", '\"', \"'\", 'With', 'Home', 'Page', 'Protest', 'via', 'sengineland']\n",
            "annotated_mention_list: [('google', 'org'), ('sopa', 'misc')]\n",
            "non_entity_list: ['day', 'anti']\n",
            "google\n",
            "sopa\n",
            "2265 ['Carter', 'Page', 'is', 'a', 'self', 'serving', 'weasel', ',', 'sure', 'he', 'knows', 'much', 'bout', 'Trump', 'and', 'Russia', '.', 'But', 'he', 'wo', \"n't\", 'sing', ',', 'Trump', 'will', 'offer', 'him', 'money', 'and', 'a', 'pardon']\n",
            "annotated_mention_list: [('carter page', 'per'), ('trump', 'per'), ('russia', 'loc'), ('trump', 'per')]\n",
            "non_entity_list: ['knows', 'self', 'money', 'bout']\n",
            "carter page\n",
            "trump\n",
            "russia\n",
            "trump\n",
            "2266 ['Breaking', '!', '!', 'FBI', 'obtained', 'FISA', 'WARRANT', 'on', 'Trump', 'advisor', 'Carter', 'Page', 'more', 'than', 'once', '!', '!', 'Russian', 'Spy', '!']\n",
            "annotated_mention_list: [('fbi', 'org'), ('fisa warrant', 'misc'), ('trump', 'per'), ('carter page', 'per'), ('russian', 'misc')]\n",
            "non_entity_list: ['advisor', 'spy', 'breaking', 'warrant', 'obtained']\n",
            "fbi\n",
            "fisa warrant\n",
            "trump\n",
            "carter page\n",
            "russian\n",
            "2267 ['Neymar', 'used', 'to', 'grab', 'games', 'by', 'the', 'scruff', '.', 'Nowadays', 'I', 'do', \"n't\", 'think', 'he', 'could', 'grab', 'a', 'kitten', 'by', 'the', 'scruff', 'of', 'the', 'neck', '.']\n",
            "annotated_mention_list: [('neymar', 'per')]\n",
            "non_entity_list: ['think', 'used']\n",
            "neymar\n",
            "2268 ['@USER', 'is', '3-0', '.', 'Say', 'what', 'you', 'will', 'about', 'her', ',', 'the', 'woman', 'has', 'been', 'on', 'point', 'about', 'Russia', '/', 'Trump', '/', 'FISA', '.']\n",
            "annotated_mention_list: [('russia', 'loc'), ('trump', 'per'), ('fisa', 'misc')]\n",
            "non_entity_list: ['woman', 'say']\n",
            "russia\n",
            "trump\n",
            "fisa\n",
            "2269 ['So', 'much', 'love', 'for', 'the', 'US', 'imperialist', 'wolves', 'in', 'nbc', 'at', '30rock', ',', 'but', 'redundant', 'torso', 'fabric', 'ftw']\n",
            "annotated_mention_list: [('us', 'loc'), ('nbc', 'org')]\n",
            "us\n",
            "nbc\n",
            "2270 ['BBC', 'News', '-', 'Symantec', 'advises', 'disabling', 'pcAnywhere', 'software']\n",
            "annotated_mention_list: [('bbc', 'org'), ('symantec', 'org'), ('pcanywhere', 'misc')]\n",
            "non_entity_list: ['news']\n",
            "bbc\n",
            "symantec\n",
            "pcanywhere\n",
            "2271 ['I', 'did', 'not', 'collude', 'with', 'any', 'country', 'that', 'is', 'not', 'Russia', '-', 'Carter', 'Page', '.', '@USER', '@USER', 'at', 'msnbc']\n",
            "annotated_mention_list: [('russia', 'loc'), ('carter page', 'per'), ('msnbc', 'org')]\n",
            "russia\n",
            "carter page\n",
            "msnbc\n",
            "2272 ['Breaking', 'news', '!', 'FBI', 'obtained', 'a', 'FISA', 'warrant', 'targeting', 'Carter', 'Page', 'last', 'summer', '.']\n",
            "annotated_mention_list: [('fbi', 'org'), ('fisa warrant', 'misc'), ('carter page', 'per')]\n",
            "non_entity_list: ['last', 'breaking', 'warrant', 'obtained', 'news']\n",
            "fbi\n",
            "fisa warrant\n",
            "carter page\n",
            "2273 ['@USER', 'when', 'anyone', 'asks', 'Carter', 'Page', 'a', 'question', '...']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "carter page\n",
            "2274 ['FISA', 'warrant', 'to', 'monitor', 'Carter', 'Page', 'as', 'an', 'agent', 'of', 'Russian', 'government', ',', 'who', 'happened', 'to', 'be', 'a', 'DT', 'advisor', '?']\n",
            "annotated_mention_list: [('fisa warrant', 'misc'), ('carter page', 'per'), ('russian', 'misc'), ('dt', 'per')]\n",
            "non_entity_list: ['agent', 'government', 'advisor', 'warrant']\n",
            "fisa warrant\n",
            "carter page\n",
            "russian\n",
            "dt\n",
            "2275 ['Carter', 'Page', 'thread']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "carter page\n",
            "2276 ['Carter', 'Page', 'like', '@USER', 'is', 'a', '.', 'should', 'result', 'in', 'trials', 'for', '.']\n",
            "annotated_mention_list: [('carter page', 'per')]\n",
            "carter page\n",
            "2277 ['HackneyCouncil', 'Labour', 'councillors', 'making', 'a', 'meal', 'of', 'Ken', \"'\", 's', 'fares', 'policy', '-', 'despite', 'everyone', 'knowing', 'it', 'does', \"n't\", 'add', 'up', '.', 'Get', 'real', ',', 'guys', '!']\n",
            "annotated_mention_list: [('hackneycouncil labour', 'org'), ('ken', 'per')]\n",
            "non_entity_list: ['guys', 'get']\n",
            "hackneycouncil labour\n",
            "ken\n",
            "2278 ['Amazing', \"'\", 'tops', '2012', 'words', 'that', 'should', 'be', 'banned', 'list', '.', 'It', \"'\", 's', 'obviously', 'a', 'US', 'poll', 'because', \"'\", 'banter', \"'\", 'gets', 'no', 'mention', 'at', 'all', '.']\n",
            "annotated_mention_list: [('us', 'loc')]\n",
            "non_entity_list: ['mention', 'list', 'gets']\n",
            "us\n",
            "2279 ['Exxon', 'Acquires', 'New', 'Gold', 'Project', 'in', 'Nevada']\n",
            "annotated_mention_list: [('exxon', 'org'), ('nevada', 'loc')]\n",
            "non_entity_list: ['project', 'new', 'gold']\n",
            "exxon\n",
            "nevada\n",
            "2280 ['Even', 'if', 'we', 'sent', 'them', 'a', 'bill', ',', 'they', 'would', 'not', 'pay', 'it', '.', 'Bankruptcy', 'the', 'and', 'eric', 'et', 'al', '.', '@USER']\n",
            "annotated_mention_list: [('eric', 'per')]\n",
            "non_entity_list: ['sent', 'et', 'pay']\n",
            "eric\n",
            "2281 ['Did', 'replacing', 'your', 'BT', 'Infinity', 'Homehub', 'improve', '#', 'broadband', '?', 'Swap', 'out', 'of', 'these', 'Apple', 'devices', 'underway', 'for', 'new', 'model']\n",
            "annotated_mention_list: [('bt infinity homehub', 'misc'), ('apple', 'org')]\n",
            "non_entity_list: ['new']\n",
            "bt infinity homehub\n",
            "apple\n",
            "2282 ['really', 'hoping', 'sid', 'picks', 'a', 'john', 'mayer', 'song', '!']\n",
            "annotated_mention_list: [('sid', 'per'), ('john mayer', 'per')]\n",
            "non_entity_list: ['really']\n",
            "sid\n",
            "john mayer\n",
            "2283 ['Read', 'The', 'Charles', 'Simmons', 'Daily', 'today', \"'s\", 'top', 'stories', 'via', '@USER', '@USER', '@USER']\n",
            "annotated_mention_list: [('charles simmons daily', 'org')]\n",
            "non_entity_list: ['daily']\n",
            "charles simmons daily\n",
            "2284 ['Some', '1', 'needs', '2', 'monitor', 'this', 'new', 'Tinkle', 'biz', 'location', '!', 'U', 'c', 'this', '?', '@USER', '@USER', '@USER']\n",
            "annotated_mention_list: [('tinkle', 'misc')]\n",
            "non_entity_list: ['needs', 'new']\n",
            "tinkle\n",
            "2285 ['Many', 'Trump', 'supporters', 'are', 'having', 'a', 'hard', 'time', 'believing', 'they', 'were', 'fooled', 'so', 'badly', 'by', 'failing', 'POTUS', 'Trump', '.', 'He', 'lies', 'very', 'well', '!']\n",
            "annotated_mention_list: [('trump', 'per'), ('potus trump', 'per')]\n",
            "non_entity_list: ['time', 'hard', 'lies', 'supporters']\n",
            "trump\n",
            "potus trump\n",
            "2286 ['@USER', 'has', 'found', 'a', 'way', 'to', 'avoid', 'news', 'cycle', '.', 'His', 'arrogant', 'ignorance', 'will', 'lead', 'to', 'a', 'nuclear', 'holocaust', '@USER']\n",
            "annotated_mention_list: [('holocaust', 'misc')]\n",
            "non_entity_list: ['lead', 'way', 'ignorance', 'news']\n",
            "holocaust\n",
            "2287 ['Lowongan', 'PT', 'Citilink', 'Indonesia', '-', 'Recruitment', 'ForFresh', 'Graduate', 'Management', 'Trainee', 'Citilink', 'January', '2017', '.', '.', '.', '@USER']\n",
            "annotated_mention_list: [('pt citilink indonesia', 'org'), ('citilink', 'org')]\n",
            "pt citilink indonesia\n",
            "citilink\n",
            "2288 ['More', 'than', '3', 'out', 'of', '4', 'UK', 'based', 'credit', 'websites', 'checked', 'in', 'an', 'EU', 'sweep', 'failed', 'to', 'meet', 'consumer', 'law', 'requirements', ',', 'a', 'survey', 'revealed', 'today', '.']\n",
            "annotated_mention_list: [('uk', 'loc'), ('eu', 'org')]\n",
            "non_entity_list: ['law']\n",
            "uk\n",
            "eu\n",
            "2289 ['Ouch', '!', 'Apparently', 'Eric', 'does', \"n't\", 'want', 'to', 'hear', 'about', 'the', 'Trump', 'family', \"'s\", 'draining', 'America', 'of', 'OUR', 'money', '...', 'not', 'theirs', '.', 'Corruption', 'and', 'Collusion', '.']\n",
            "annotated_mention_list: [('eric', 'per'), ('trump', 'per'), ('america', 'loc')]\n",
            "non_entity_list: ['family', 'collusion', 'money', 'apparently']\n",
            "eric\n",
            "trump\n",
            "america\n",
            "2290 ['#', 'ThankYouGOP', 'For', 'fucking', 'up', 'the', 'economy', 'and', 'then', 'tryin', 'to', 'blame', 'it', 'on', '#', 'Dem']\n",
            "annotated_mention_list: [('dem', 'org')]\n",
            "non_entity_list: ['blame']\n",
            "dem\n",
            "2291 ['Video', ':', 'Eric', 'Trump', 'says', 'Trump', 'Org', 'plans', 'to', 'do', 'more', 'business', 'in', 'Shanghai', ',', 'Hong', 'Kong', 'and', 'Beijing']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('trump org', 'org'), ('shanghai', 'loc'), ('hong kong', 'loc'), ('beijing', 'loc')]\n",
            "non_entity_list: ['video', 'business', 'says']\n",
            "eric trump\n",
            "trump org\n",
            "shanghai\n",
            "hong kong\n",
            "beijing\n",
            "2292 ['@USER', '@USER', '@USER', '@USER', '@USER', 'Dark', 'Money', 'is', 'connected', 'to', 'Putin', '.', 'NRA', 'connected', 'to', 'Putin', ',', 'Moscow', '2015', ',', 'met']\n",
            "annotated_mention_list: [('putin', 'per'), ('nra', 'org'), ('putin', 'per'), ('moscow', 'loc')]\n",
            "non_entity_list: ['money']\n",
            "putin\n",
            "nra\n",
            "putin\n",
            "moscow\n",
            "2293 ['Video', ':', 'Eric', 'Trump', 'in', 'the', 'Philippines', 'saying', 'their', 'best', 'biz', 'project', 'ever', 'will', 'be', 'in', 'Manila']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('philippines', 'loc'), ('manila', 'loc')]\n",
            "non_entity_list: ['project', 'saying', 'video']\n",
            "eric trump\n",
            "philippines\n",
            "manila\n",
            "2294 ['Photo', ':', 'Eric', 'Trump', 'and', 'Don', 'Jr', 'w', '/', 'mob', 'related', 'felon', 'Joey', \"'\", 'No', 'Socks', \"'\", 'Cinque', 'at', 'Tsar-a-Lago', 'on', 'New', 'Years', '-', '3', 'yrs', 'ago']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('don jr', 'per'), (\"joey ' no socks ' cinque\", 'per'), ('tsar-a-lago', 'loc')]\n",
            "non_entity_list: ['socks', 'new', 'years']\n",
            "eric trump\n",
            "don jr\n",
            "joey ' no socks ' cinque\n",
            "tsar-a-lago\n",
            "2295 ['RT', '@USER', 'briankoppelman', ':', 'Yeah', ',', 'man', '.', '@USER', 'jaketapper', 'is', 'handling', 'this', 'as', 'well', 'and', 'professionally', 'and', 'even', 'heroically', 'as', 'one', 'can', '.', 'Good', 'on', 'you', ',', 'Jak', '...']\n",
            "annotated_mention_list: [('briankoppelman', 'per'), ('jaketapper', 'per'), ('jak', 'per')]\n",
            "non_entity_list: ['one', 'good', 'man']\n",
            "briankoppelman\n",
            "jaketapper\n",
            "jak\n",
            "2296 ['@USER', 'The', 'Trumps', 'are', 'egotistical', ',', 'money', 'hungry', 'assholes', '!']\n",
            "annotated_mention_list: [('trumps', 'misc')]\n",
            "non_entity_list: ['money']\n",
            "trumps\n",
            "2297 ['Ffs', 'will', 'everyone', 'seriously', 'just', 'stop', 'tweeting', 'about', 'chaz', 'and', 'justin', ',', 'and', 'selena', 'and', 'zayn', '.', 'Jeezz']\n",
            "annotated_mention_list: [('chaz', 'per'), ('justin', 'per'), ('selena', 'per'), ('zayn', 'per')]\n",
            "non_entity_list: ['stop', 'seriously']\n",
            "chaz\n",
            "justin\n",
            "selena\n",
            "zayn\n",
            "2298 ['Theory', ':', 'Putin', 'would', 'rather', 'have', 'an', 'ally', 'he', 'helped', 'install', 'in', 'America', 'over', 'an', 'ally', 'he', 'loses', 'face', 'to', 'save', 'in', 'Syria', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('america', 'loc'), ('syria', 'loc')]\n",
            "non_entity_list: ['face', 'rather', 'theory', 'loses', 'helped', 'ally', 'save']\n",
            "putin\n",
            "america\n",
            "syria\n",
            "2299 ['The', 'River', 'Rom', ',', 'also', 'in', 'places', 'known', 'as', 'the', 'River', 'Beam', ',', 'is', 'a', 'river', 'in', 'Essex', 'which', 'becomes', 'a', 'tributary', 'of', 'the', 'River', '...', '@USER']\n",
            "annotated_mention_list: [('river rom', 'misc'), ('river beam', 'misc'), ('essex', 'loc')]\n",
            "river rom\n",
            "river beam\n",
            "essex\n",
            "2300 ['Wow', 'eric', 'you', 'are', 'so', 'obvious', '!']\n",
            "annotated_mention_list: [('eric', 'per')]\n",
            "eric\n",
            "2301 ['The', 'River', 'Rom', ',', 'also', 'in', 'places', 'known', 'as', 'the', 'River', 'Beam', 'is', 'a', 'river', 'in', 'Essex']\n",
            "annotated_mention_list: [('river rom', 'misc'), ('river beam', 'misc'), ('essex', 'loc')]\n",
            "river rom\n",
            "river beam\n",
            "essex\n",
            "2302 ['@USER', 'Did', 'you', 'wake', 'up', 'and', 'see', 'bad', 'bad', 'pictures', 'Donnie', '?']\n",
            "annotated_mention_list: [('donnie', 'per')]\n",
            "non_entity_list: ['see', 'bad']\n",
            "donnie\n",
            "2303 ['So', 'to', 'even', 'further', 'move', 'away', 'from', '@USER', 'wants', 'a', 'war', 'with', 'North', 'Korea', '?', 'When', 'will', 'this', 'man', 'be', 'stopped', '?']\n",
            "annotated_mention_list: [('north korea', 'loc')]\n",
            "non_entity_list: ['war', 'wants', 'north', 'move', 'man', 'away']\n",
            "north korea\n",
            "2304 ['Many', 'Trump', 'supporters', 'are', 'having', 'a', 'hard', 'time', 'believing', 'they', 'were', 'fooled', 'so', 'badly', 'by', 'failing', 'POTUS', 'Trump', '.', 'He', 'lies', 'very', 'well', '!']\n",
            "annotated_mention_list: [('trump', 'per'), ('potus trump', 'per')]\n",
            "non_entity_list: ['time', 'hard', 'lies', 'supporters']\n",
            "trump\n",
            "potus trump\n",
            "2305 ['gross', '...', 'even', 'if', 'trump', 'was', \"n't\", 'president', '...', 'gross']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "trump\n",
            "2306 ['RT', '@USER', 'TheLeadCNN', ':', '.', '@USER', 'jaketapper', ':', 'There', 'is', 'a', 'reason', 'White', 'House', 'is', 'providing', 'no', 'evidence', 'about', 'voter', 'fraud', 'claim', '–', 'there', 'is', 'no', 'evidence', '...']\n",
            "annotated_mention_list: [('jaketapper', 'per'), ('white house', 'org')]\n",
            "non_entity_list: ['claim']\n",
            "jaketapper\n",
            "white house\n",
            "2307 ['Eric', 'Trump', 'is', 'such', 'a', 'dumbass']\n",
            "annotated_mention_list: [('eric trump', 'per')]\n",
            "eric trump\n",
            "2308 ['Show', 'HN', ':', 'Hib', '—', 'a', 'bionic', 'cycadales', ',', 'precociously', 'incanted', 'in', 'Umple', '.']\n",
            "annotated_mention_list: [('umple', 'loc')]\n",
            "non_entity_list: ['show']\n",
            "umple\n",
            "2309 ['Daily', 'Audio', 'Bible', 'Program', 'is', 'starting', 'now', '!', 'Listen', 'live', 'here', ':', '@USER']\n",
            "annotated_mention_list: [('daily audio bible program', 'misc')]\n",
            "non_entity_list: ['live', 'daily']\n",
            "daily audio bible program\n",
            "2310 ['Venezuela', 'used', 'to', 'be', 'the', 'jewel', 'of', 'Latin', 'America', '.']\n",
            "annotated_mention_list: [('venezuela', 'loc'), ('latin america', 'loc')]\n",
            "non_entity_list: ['used']\n",
            "venezuela\n",
            "latin america\n",
            "2311 ['Anyone', 'got', 'any', 'idea', 'how', 'to', 'stop', 'your', 'tweets', 'going', 'to', 'Facebook', '?']\n",
            "annotated_mention_list: [('facebook', 'org')]\n",
            "non_entity_list: ['going', 'got', 'stop']\n",
            "facebook\n",
            "2312 ['@USER', 'Starting', 'multiple', 'wars', 'will', 'not', 'save', 'you', 'donald', '.', 'There', 'will', 'be', 'justice', 'even', 'with', 'your', 'shill', 'on', 'the', 'Supreme', 'Court', '.']\n",
            "annotated_mention_list: [('donald', 'per'), ('supreme court', 'org')]\n",
            "non_entity_list: ['justice', 'save', 'court']\n",
            "donald\n",
            "supreme court\n",
            "2313 ['Why', 'a', 'Big', 'Mac', 'is', 'the', 'perfect', 'snack', 'in', 'sub-zero', 'Russia', '.', 'Love', 'this', '!', 'RT', '@USER', 'GlutenFreeMrsD', ':', 'Gluten', 'Free', 'McDonalds']\n",
            "annotated_mention_list: [('big mac', 'misc'), ('russia', 'loc'), ('mcdonalds', 'org')]\n",
            "non_entity_list: ['big']\n",
            "big mac\n",
            "russia\n",
            "mcdonalds\n",
            "2314 ['@USER', 'Lawrence', '23', ':', 'great', 'job']\n",
            "annotated_mention_list: [('lawrence 23', 'per')]\n",
            "non_entity_list: ['great', 'job']\n",
            "lawrence 23\n",
            "2315 ['@USER', '@USER', 'Impeachment', ',', 'is', 'the', 'only', 'answer', '.']\n",
            "annotated_mention_list: [('impeachment', 'misc')]\n",
            "non_entity_list: ['answer']\n",
            "impeachment\n",
            "2316 ['Republicans', 'do', \"n't\", 'want', 'to', 'stop', 'him', '...', 'he', 'is', 'signing', 'everything', 'they', 'put', 'in', 'front', 'of', 'him', '.', 'He', \"'s\", 'a', 'puppet', '...', 'for', 'Vlad', 'and', 'the', 'ReThugs', '.']\n",
            "annotated_mention_list: [('republicans', 'misc'), ('vlad', 'per')]\n",
            "non_entity_list: ['puppet', 'stop', 'put']\n",
            "republicans\n",
            "vlad\n",
            "2317 ['Trump', 'to', 'rank', 'US', 'counties', 'by', 'coronavirus', 'risk', ',', 'may', \"'\", 'relax', \"'\", 'social', 'distancing', 'via', '@USER']\n",
            "annotated_mention_list: [('trump', 'per'), ('us', 'loc')]\n",
            "non_entity_list: ['may', 'social']\n",
            "trump\n",
            "us\n",
            "2318 ['US', 'Deaths', 'May', 'Exceed', '80,000', ',', 'Even', 'With', 'Social', 'Distancing', ',', 'Study', 'Finds']\n",
            "annotated_mention_list: [('us', 'loc')]\n",
            "non_entity_list: ['may', 'social']\n",
            "us\n",
            "2319 ['This', 'is', 'about', 'oil', '.', 'North', 'Dakota', 'is', 'ground', 'zero', 'and', 'corrupt', 'AF', '.']\n",
            "annotated_mention_list: [('north dakota', 'loc')]\n",
            "non_entity_list: ['north', 'oil', 'zero']\n",
            "north dakota\n",
            "2320 ['PUTIN', 'SUX']\n",
            "annotated_mention_list: [('putin', 'per')]\n",
            "putin\n",
            "2321 ['@USER', 'I', 'think', 'Easter', 'at', 'NY', ',', 'NJ', ',', 'PA', ',', 'MI', ',', 'LA', ',', 'WA', ',', 'CA', ',', 'MA', ',', 'FL', 'and', 'IL', 'are', 'likely', 'to', 'still', 'be', 'on', 'line', '.', 'The', 'rest', 'of', 'the', '...']\n",
            "annotated_mention_list: [('ny', 'loc'), ('nj', 'loc'), ('pa', 'loc'), ('mi', 'loc'), ('la', 'loc'), ('wa', 'loc'), ('ca', 'loc'), ('ma', 'loc'), ('fl', 'loc'), ('il', 'loc')]\n",
            "non_entity_list: ['line', 'think', 'rest']\n",
            "ny\n",
            "nj\n",
            "pa\n",
            "mi\n",
            "la\n",
            "wa\n",
            "ca\n",
            "ma\n",
            "fl\n",
            "il\n",
            "2322 ['Tiffany', 'has', 'no', 'idea', 'how', 'lucky', 'she', 'is', 'to', 'be', 'the', 'black', 'sheep']\n",
            "annotated_mention_list: [('tiffany', 'per')]\n",
            "non_entity_list: ['black', 'lucky']\n",
            "tiffany\n",
            "2323 ['@USER', '@USER', 'THREAD', ':', 'E', 'is', 'Trump', \"'s\", 'EPSHTEYN']\n",
            "annotated_mention_list: [('trump', 'per'), ('epshteyn', 'per')]\n",
            "trump\n",
            "epshteyn\n",
            "2324 ['Russia', 'now', 'threatening', 'U', '.', 'S', '.', 'of', 'consequences', 'if', 'military', 'operation', 'in', 'Venezuela', 'launched']\n",
            "annotated_mention_list: [('russia', 'loc'), ('u . s', 'loc'), ('venezuela', 'loc')]\n",
            "russia\n",
            "u . s\n",
            "venezuela\n",
            "2325 ['@USER', '@USER', 'The', 'SCAM', 'was', 'simply', 'to', 'cover', 'up', 'for', 'Obama', 'using', 'to', 'criminally', 'gather', 'information', 'on', 'the', '@USER', 'team', '.', 'Nothing', 'more', '.']\n",
            "annotated_mention_list: [('obama', 'per')]\n",
            "non_entity_list: ['team', 'using', 'cover']\n",
            "obama\n",
            "2326 ['There', 'is', 'a', 'massive', 'FBI', 'and', 'CIA', 'Investigation', 'going', 'on', 'right', 'now', 'for', 'possible', 'TREASON', '.', 'Do', \"n't\", 'be', 'distracted', '.']\n",
            "annotated_mention_list: [('fbi', 'org'), ('cia', 'org')]\n",
            "non_entity_list: ['right', 'investigation', 'going', 'treason', 'possible']\n",
            "fbi\n",
            "cia\n",
            "2327 ['@USER', '@USER', 'Oops', '!', 'You', 'must', 'have', 'already', 'gotten', 'into', 'the', 'vodka', '.', 'Caviar', 'and', 'vodka', 'for', 'everyone', '!']\n",
            "annotated_mention_list: [('vodka', 'misc'), ('caviar', 'misc'), ('vodka', 'misc')]\n",
            "non_entity_list: ['already']\n",
            "vodka\n",
            "caviar\n",
            "vodka\n",
            "2328 ['support', 'the', 'revolution', 'in', 'Venezuela', 'from', 'start']\n",
            "annotated_mention_list: [('venezuela', 'loc')]\n",
            "non_entity_list: ['support']\n",
            "venezuela\n",
            "2329 ['Remarkable', 'statement', 'from', 'Trump', \"'s\", 'son', 'Eric', '.', 'He', \"'s\", 'basically', 'claiming', '@USER', \"'\", 's', 'Syria', 'strike', 'debunks', 'entire', 'scandal', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('eric', 'per'), ('syria', 'loc')]\n",
            "non_entity_list: ['entire', 'scandal', 'strike', 'claiming', 'statement', 'son']\n",
            "trump\n",
            "eric\n",
            "syria\n",
            "2330 ['Dear', '@USER', '@USER', '@USER', '@USER', '@USER', ':', 'PLEASE', 'GET', 'ALL', 'TRUMP', 'CRIMINALS', 'OUT', 'OF', '*', 'OUR', '*', 'WHITE', 'HOUSE', '!', '!', '!', 'THIS', 'is', 'BEYOND', 'CRAZY', '!']\n",
            "annotated_mention_list: [('trump', 'per'), ('white house', 'loc')]\n",
            "non_entity_list: ['beyond', 'get']\n",
            "trump\n",
            "white house\n",
            "2331 ['I', \"'m\", 'deeply', 'concerned', 'by', 'the', 'actions', 'of', 'the', 'criminal', 'US', 'government', 'as', 'it', 'relates', 'to', 'Venezuela']\n",
            "annotated_mention_list: [('us government', 'org'), ('venezuela', 'loc')]\n",
            "non_entity_list: ['government', 'us']\n",
            "us government\n",
            "venezuela\n",
            "2332 ['China', 'is', 'Venezuela', \"'s\", 'single', 'largest', 'state', 'creditor']\n",
            "annotated_mention_list: [('china', 'loc'), ('venezuela', 'loc')]\n",
            "non_entity_list: ['state']\n",
            "china\n",
            "venezuela\n",
            "2333 ['I', 'hope', '/', 'pray', '@USER', 'said', 'Ivanka', 'is', 'the', 'reason', 'for', 'the', 'just', 'to', 'create', 'another', 'distraction', 'from']\n",
            "annotated_mention_list: [('ivanka', 'per')]\n",
            "non_entity_list: ['distraction', 'said']\n",
            "ivanka\n",
            "2334 ['Photo', ':', 'small', 'changes', 'make', 'big', 'differences', '-', 'by', '@USER', 'wendyquent', '(', 'Taken', 'with', 'instagram', ')']\n",
            "annotated_mention_list: [('wendyquent', 'per'), ('instagram', 'org')]\n",
            "non_entity_list: ['big']\n",
            "wendyquent\n",
            "instagram\n",
            "2335 ['Here', 'is', 'a', 'great', 'shot', 'of', 'trumps', 'racehorses', 'Dumb', 'and', 'Dumber', 'socializing', 'with', 'criminals', 'at', 'Dads', 'place', 'love', 'current', 'admin', 'has', 'such', 'legit', 'ties']\n",
            "annotated_mention_list: [('trumps', 'misc')]\n",
            "non_entity_list: ['great', 'dumb', 'admin', 'ties']\n",
            "trumps\n",
            "2336 ['Both', 'US', 'strikes', 'were', 'for', 'show', '!', 'Russia', 'and', 'Syria', 'both', 'knew', 'in', 'advance', 'we', 'were', 'coming', 'and', 'what', 'was', 'happening', '!', 'It', 'was', 'merely', 'a', 'diversion', '!']\n",
            "annotated_mention_list: [('us', 'loc'), ('russia', 'loc'), ('syria', 'loc')]\n",
            "non_entity_list: ['strikes', 'show', 'knew']\n",
            "us\n",
            "russia\n",
            "syria\n",
            "2337 ['The', 'idea', 'of', 'a', 'transition', 'wherein', 'chavismo', 'takes', 'a', 'seat', 'is', 'a', 'guarantee', 'Venezuela', 'will', 'not', 'be', 'considered', 'a', 'trustworthy', 'partner', 'by', 'international', 'investors', '.']\n",
            "annotated_mention_list: [('chavismo', 'per'), ('venezuela', 'loc')]\n",
            "non_entity_list: ['takes', 'transition', 'seat']\n",
            "chavismo\n",
            "venezuela\n",
            "2338 ['\"', 'Mommy', ',', 'why', 'did', 'they', 'arrest', 'the', 'easter', 'bunny', '?', '\"', '\"', 'I', 'guess', 'it', \"'s\", 'time', 'to', 'have', 'that', \"'\", 'propaganda', \"'\", 'talk', '...', '\"']\n",
            "annotated_mention_list: [('easter bunny', 'misc')]\n",
            "non_entity_list: ['mommy', 'talk', 'time', 'bunny']\n",
            "easter bunny\n",
            "2339 ['Village', 'idiot', '.', 'Thank', 'u', 'Eric']\n",
            "annotated_mention_list: [('eric', 'per')]\n",
            "non_entity_list: ['village', 'idiot']\n",
            "eric\n",
            "2340 ['You', 'know', 'well', 'the', 'role', 'you', 'played', 'in', 'planning', 'today', \"'s\", 'move', 'for', 'democracy', 'in', 'Venezuela', '.']\n",
            "annotated_mention_list: [('democracy', 'misc'), ('venezuela', 'loc')]\n",
            "non_entity_list: ['move', 'played', 'role']\n",
            "democracy\n",
            "venezuela\n",
            "2341 ['CONFIRMED', ':', 'Malaysia', 'Airlines', 'has', 'lost', 'contact', 'of', '#MH17', 'from', '#Amsterdam', '@USER', 'MAS']\n",
            "annotated_mention_list: [('malaysia airlines', 'org'), ('mas', 'org')]\n",
            "non_entity_list: ['airlines', 'lost']\n",
            "malaysia airlines\n",
            "mas\n",
            "2342 ['Join', 'the', 'Tax', 'March', 'on', 'April', '15', 'at', '11', 'am', 'Where', ':', 'North', 'Carolina', 'State', 'Capitol', 'at', '1', '...']\n",
            "annotated_mention_list: [('north carolina state capitol', 'loc')]\n",
            "non_entity_list: ['north', 'state', 'march', 'tax']\n",
            "north carolina state capitol\n",
            "2343 ['\"', 'You', 'Liar', '.', '\"', 'as', 'Joe', 'would', 'say', '.', 'I', 'say', 'that', 'it', 'indeed', 'proves', 'the', \"'\", 'connect', \"'\", 'to', 'a', 'whole', 'new', 'level', '.', 'Oh', 'yeah', '.']\n",
            "annotated_mention_list: [('joe', 'per')]\n",
            "non_entity_list: ['liar', 'level', 'say', 'new']\n",
            "joe\n",
            "2344 ['Put', 'humans', 'above', 'anything', 'and', 'just', 'help', 'the', 'situation', 'in', 'Venezuela', '.']\n",
            "annotated_mention_list: [('venezuela', 'loc')]\n",
            "non_entity_list: ['help', 'put']\n",
            "venezuela\n",
            "2345 ['TRUMPS', 'ARE', 'FRAUDS', '!']\n",
            "annotated_mention_list: [('trumps', 'misc')]\n",
            "trumps\n",
            "2346 ['@USER', '@USER', '@USER', '@USER', 'Lol', 'meanwhile', 'there', 'is', 'a', 'flood', 'of', 'at', 'Trump', \"'s\", 'door']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "trump\n",
            "2347 ['Here', 'we', 'see', 'Putin', 'showing', 'off', 'his', 'favorite', 'pet', '.']\n",
            "annotated_mention_list: [('putin', 'per')]\n",
            "non_entity_list: ['see']\n",
            "putin\n",
            "2348 ['Vendors', 'rush', 'to', 'patch', 'apple', 'flaw', '-', 'Gives', 'hackers', 'root', 'access', '#', 'security']\n",
            "annotated_mention_list: [('apple', 'org')]\n",
            "non_entity_list: ['gives']\n",
            "apple\n",
            "2349 ['ZDNet', ':', 'Apple', 'denied', 'Samsung', 'Galaxy', 'sales', 'ban', 'in', 'Dutch', 'court', 'by', '@USER', 'zackwhittaker']\n",
            "annotated_mention_list: [('zdnet', 'org'), ('apple', 'org'), ('samsung galaxy', 'misc'), ('dutch court', 'org'), ('zackwhittaker', 'per')]\n",
            "non_entity_list: ['court']\n",
            "zdnet\n",
            "apple\n",
            "samsung galaxy\n",
            "dutch court\n",
            "zackwhittaker\n",
            "2350 ['We', 'could', 'do', 'with', 'something', 'like', 'this', 'in', 'the', 'UK', '.', '@USER', 'RonCharles', ':', 'Yes', ',', 'reviewers', ',', 'do', 'join', '#', 'NBC', '.', 'The', 'annual', 'mtg', 'is', 'gr8', 'way', 'to', 'meet', 'other', 'critics', '.']\n",
            "annotated_mention_list: [('uk', 'loc'), ('roncharles', 'per'), ('nbc', 'org')]\n",
            "non_entity_list: ['way']\n",
            "uk\n",
            "roncharles\n",
            "nbc\n",
            "2351 ['Press', 'needs', 'to', 'keep', 'up', 'the', 'pressure', 'during', 'Congressional', 'recess', '.']\n",
            "annotated_mention_list: [('congressional', 'misc')]\n",
            "non_entity_list: ['press', 'needs']\n",
            "congressional\n",
            "2352 ['feel', 'sorry', 'for', '@USER', 'jessicalowndes', 'in', '90210', '.']\n",
            "annotated_mention_list: [('jessicalowndes', 'per')]\n",
            "jessicalowndes\n",
            "2353 ['How', 'To', 'Turn', 'Off', 'Google', \"'s\", 'Personal', 'Search', 'Results', '&', 'Get', 'Back', 'To', 'Enjoying', 'Life']\n",
            "annotated_mention_list: [('google', 'org')]\n",
            "non_entity_list: ['get', 'back']\n",
            "google\n",
            "2354 ['And', 'who', 'is', 'Sally', 'Hemings', '?']\n",
            "annotated_mention_list: [('sally hemings', 'per')]\n",
            "sally hemings\n",
            "2355 ['HA', 'my', 'Cat', 'wrestling', 'a', 'Chanel', 'bag', '..', 'Right', '.']\n",
            "annotated_mention_list: [('chanel', 'org')]\n",
            "non_entity_list: ['right']\n",
            "chanel\n",
            "2356 ['Shocking', 'scenes', 'in', 'Venezuela', 'as', 'defected', 'soldiers', 'fire', 'back', 'to', 'protect', 'protesters']\n",
            "annotated_mention_list: [('venezuela', 'loc')]\n",
            "non_entity_list: ['back', 'fire']\n",
            "venezuela\n",
            "2357 ['The', 'Cannes', \"'\", 's', 'International', 'Film', 'Season', '2012', 'kicks', 'off', 'on', 'February', '14th', '-', '-']\n",
            "annotated_mention_list: [('cannes', 'org')]\n",
            "cannes\n",
            "2358 ['State', 'Farm', 'Legal', 'Observers', 'Needed', '-', 'Training', 'Coming', 'Soon']\n",
            "annotated_mention_list: [('state farm', 'org')]\n",
            "non_entity_list: ['soon', 'state']\n",
            "state farm\n",
            "2359 ['she', 'need', 'to', 'be', 'heartbroken', 'about', 'fact', 'that', 'entire', 'trump', 'base', 'is', 'turning', 'on', 'her', 'father', 'and', 'damn', 'near', 'all', 'of', 'them', 'are', 'strapped', 'af', '/', 'bearing', 'arms']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['need', 'base', 'father', 'entire']\n",
            "trump\n",
            "2360 ['You', 'must', 'now', 'stand', 'and', 'do', 'what', 'is', 'right', 'for', 'Venezuela']\n",
            "annotated_mention_list: [('venezuela', 'loc')]\n",
            "non_entity_list: ['right']\n",
            "venezuela\n",
            "2361 ['@USER', 'of', 'course', 'he', 'does', ',', 'he', 'sends', 'he', 'controls', 'Trump', '.']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['controls']\n",
            "trump\n",
            "2362 [\"Y'all\", 'let', 'a', 'Russian', 'Stooge', 'put', 'a', 'man', 'on', 'the', 'Supreme', 'Court', '!']\n",
            "annotated_mention_list: [('russian', 'misc'), ('supreme court', 'org')]\n",
            "non_entity_list: ['put', 'court', 'man']\n",
            "russian\n",
            "supreme court\n",
            "2363 ['Two', 'MAS', 'planes', 'catastrophe', 'in', 'a', 'period', 'of', 'half', 'a', 'year', '.', 'This', 'time', 'it', \"'\", 's', '#MH17', 'though', 'sources', 'are', 'yet', 'to', 'be', 'confirmed']\n",
            "annotated_mention_list: [('mas', 'org')]\n",
            "non_entity_list: ['though', 'planes', 'time', 'half']\n",
            "mas\n",
            "2364 ['Malaysian', 'Airlines', '#MH17', 'shot', 'down', 'by', 'russian', 'missiles', '.', 'How', 'do', 'you', 'mistake', 'an', 'airliner', 'for', 'a', 'fighter', 'jet', '?', '#PrayForMH17']\n",
            "annotated_mention_list: [('malaysian airlines', 'org'), ('russian', 'misc')]\n",
            "non_entity_list: ['airlines']\n",
            "malaysian airlines\n",
            "russian\n",
            "2365 ['Update', 'from', '@USER', ':', 'Ukrainian', 'minister', 'says', 'rebels', 'shot', 'down', '#MH17', 'Malaysia', 'Airlines']\n",
            "annotated_mention_list: [('ukrainian', 'misc'), ('malaysia airlines', 'org')]\n",
            "non_entity_list: ['airlines', 'minister', 'says']\n",
            "ukrainian\n",
            "malaysia airlines\n",
            "2366 ['@USER', '@USER', 'knows', '@USER', 'called', 'before', 'striking', 'SMELLS', 'like', 'coordinating', 'w', '/', 'Russia', 'on']\n",
            "annotated_mention_list: [('russia', 'loc')]\n",
            "non_entity_list: ['called', 'knows']\n",
            "russia\n",
            "2367 ['Good', 'work', ',', 'Scott', '!']\n",
            "annotated_mention_list: [('scott', 'per')]\n",
            "non_entity_list: ['work', 'good']\n",
            "scott\n",
            "2368 ['US', 'pilots', 'previously', 'told', 'not', 'to', 'fly', 'over', 'Ukraine']\n",
            "annotated_mention_list: [('us', 'loc'), ('ukraine', 'loc')]\n",
            "non_entity_list: ['told']\n",
            "us\n",
            "ukraine\n",
            "2369 ['And', 'this', 'is', 'how', 'the', 'world', 'ends', '.', 'Not', 'with', 'a', 'bang', 'but', 'a', 'tweet', '.', 'War', 'started', 'via', 'twitter']\n",
            "annotated_mention_list: [('twitter', 'org')]\n",
            "non_entity_list: ['war', 'ends', 'world', 'tweet']\n",
            "twitter\n",
            "2370 ['i', 'have', 'no', 'words', '.', '\"', '@USER', 'BhasChat', ':', 'How', 'is', 'it', 'Malaysian', 'Airlines', 'fault', 'that', 'the', 'plane', 'was', 'shot', 'down', '?', '#MH17']\n",
            "annotated_mention_list: [('bhaschat', 'per'), ('malaysian airlines', 'org')]\n",
            "non_entity_list: ['airlines', 'fault', 'plane']\n",
            "bhaschat\n",
            "malaysian airlines\n",
            "2371 ['Malaysia', 'Airlines', 'flight', '#MH17', 'crash', 'site', 'in', 'Ukraine', '.', 'Plane', 'was', 'carrying', '295', 'people', '.', '(', 'Photo', 'via', 'Reuters', ')']\n",
            "annotated_mention_list: [('malaysia airlines', 'org'), ('ukraine', 'loc'), ('reuters', 'org')]\n",
            "non_entity_list: ['airlines', 'plane', 'people', 'flight']\n",
            "malaysia airlines\n",
            "ukraine\n",
            "reuters\n",
            "2372 ['@USER', 'Three', 'words', ':', 'Conflict', '.', 'Of', '.', 'Interest', '.', 'What', 'can', 'be', 'done', 'about', 'this', 'nonsense', '?', 'When', 'did', 'America', 'turn', 'into', 'a', 'Kingdom', ',', 'monarchy', '?']\n",
            "annotated_mention_list: [('america', 'loc')]\n",
            "non_entity_list: ['kingdom', 'conflict']\n",
            "america\n",
            "2373 ['Putin', 'mercenary', 'boasted', 'about', 'downing', 'a', 'plane']\n",
            "annotated_mention_list: [('putin', 'per')]\n",
            "non_entity_list: ['plane']\n",
            "putin\n",
            "2374 ['@USER', '@USER', 'I', \"'ll\", 'be', '\"', 'Putin', '\"', 'money', 'on', 'Trump', \"'s\", 'imminent', 'impeachment', '.', 'He', 'and', 'his', 'treasonous', 'cabal', 'will', 'be', 'wearing', 'orange', 'jumpsuits', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per'), ('impeachment', 'misc')]\n",
            "non_entity_list: ['money', 'orange', 'wearing', 'cabal', 'imminent']\n",
            "putin\n",
            "trump\n",
            "impeachment\n",
            "2375 ['@USER', 'Wonder', 'if', 'trump', 'supporters', 'knew', 'this', 'is', 'what', 'they', 'were', 'electing', '.', 'Not', 'like', 'voting', 'for', 'a', 'loud', 'mouth', 'pathological', 'liar', 'was', 'enough']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['liar', 'mouth', 'knew', 'supporters']\n",
            "trump\n",
            "2376 ['I', 'do', \"n't\", 'understand', 'why', 'some', 'ppl', 'are', 'blaming', 'MAS', 'for', 'this', 'incident', '.', 'The', 'plane', 'was', 'shot', 'down', 'by', 'a', 'freaking', 'missile', '!', 'How', 'stupid', 'can', 'u', 'be', '?', '#mh17']\n",
            "annotated_mention_list: [('mas', 'org')]\n",
            "non_entity_list: ['blaming', 'incident', 'stupid', 'missile', 'plane']\n",
            "mas\n",
            "2377 ['I', 'posted', 'a', 'new', 'status', 'to', 'Facebook']\n",
            "annotated_mention_list: [('facebook', 'org')]\n",
            "non_entity_list: ['new']\n",
            "facebook\n",
            "2378 ['I', 'feel', 'like', 'Celtics', 'fans', 'are', 'the', 'best', 'with', 'following', 'their', 'team', ',', 'maybe', 'im', 'a', 'lil', 'bias', 'tho', 'lol']\n",
            "annotated_mention_list: [('celtics', 'misc')]\n",
            "non_entity_list: ['team', 'tho', 'lil', 'following', 'fans']\n",
            "celtics\n",
            "2379 ['What', 'if', '...', 'Russia', 'did', 'the', 'chem', 'attacks', 'Knowing', 'trump', 'would', 'blame', 'Assad', 'Putin', \"'s\", 'comments', 'support', 'it']\n",
            "annotated_mention_list: [('russia', 'loc'), ('trump', 'per'), ('assad', 'per'), ('putin', 'per')]\n",
            "non_entity_list: ['comments', 'blame', 'support']\n",
            "russia\n",
            "trump\n",
            "assad\n",
            "putin\n",
            "2380 ['I', 'bet', 'Turkey', 'is', 'feeling', 'left', 'out']\n",
            "annotated_mention_list: [('turkey', 'loc')]\n",
            "non_entity_list: ['bet', 'left']\n",
            "turkey\n",
            "2381 ['Tweedledum', 'and', 'Tweedledee', 'hanging', 'out', 'with', 'Joey', \"'\", 'Mo', 'Socks', \"'\", 'Cinque', '.']\n",
            "annotated_mention_list: [(\"joey ' mo socks ' cinque\", 'per')]\n",
            "non_entity_list: ['socks']\n",
            "joey ' mo socks ' cinque\n",
            "2382 ['Celtics', 'fans', 'are', 'the', 'best', 'with', 'following', 'their', 'team']\n",
            "annotated_mention_list: [('celtics', 'misc')]\n",
            "non_entity_list: ['following', 'team', 'fans']\n",
            "celtics\n",
            "2383 ['@USER', 'and', 'congrats', 'to', 'the', 'for', 'colluding', 'with', 'Putin', 'to', 'steal', 'the', 'Presidency', '.']\n",
            "annotated_mention_list: [('putin', 'per')]\n",
            "non_entity_list: ['presidency']\n",
            "putin\n",
            "2384 ['@USER', '@USER', '@USER', 'Yes', '.', 'We', 'wo', \"n't\", 'know', 'about', 'it', 'unless', 'a', 'Russian', 'with', 'a', 'death', 'wish', 'chooses', 'to', 'speak', 'anonymously', '.', 'But', 'yes', '.']\n",
            "annotated_mention_list: [('russian', 'misc')]\n",
            "non_entity_list: ['death']\n",
            "russian\n",
            "2385 ['@USER', '@USER', '@USER', 'He', 'is', 'a', 'joke', 'of', 'a', 'public', 'servant', ',', 'and', 'a', 'complete', 'and', 'utter', 'joke', 'of', 'a', '\"', 'man', '.', '\"']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['complete', 'joke', 'public', 'man']\n",
            "2386 ['And', 'scene']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['scene']\n",
            "2387 ['Crew', 'hanging', 'at', 'TSAR-A-LAGO', '(', 'great', 'phrase', '!', ')', ',', '@USER', 'is', 'the', 'only', 'story', 'that', 'matters', '!']\n",
            "annotated_mention_list: [('tsar-a-lago', 'loc')]\n",
            "non_entity_list: ['great', 'story']\n",
            "tsar-a-lago\n",
            "2388 ['The', 'missile', 'strike', 'did', 'nothing', 'except', 'teach', 'Trump', 'how', 'to', 'generate', 'applause']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['strike', 'missile']\n",
            "trump\n",
            "2389 ['Cheeto', 'worried', 'he', 'might', 'b', 'Teflon', 'Don', '2', '?']\n",
            "annotated_mention_list: [('cheeto', 'misc'), ('teflon don 2', 'per')]\n",
            "cheeto\n",
            "teflon don 2\n",
            "2390 ['Wonder', 'if', 'GOP', '/', 'RNC', 'still', 'cheating', 'to', 'win', '?', 'resorted', 'to', 'cheating', ',', 'lying', ',', 'collusion', ',', 'hacking', ',', 'propaganda', 'and', 'treason', 'to', 'get', 'office', '.']\n",
            "annotated_mention_list: [('gop', 'org'), ('rnc', 'org')]\n",
            "non_entity_list: ['win', 'office', 'treason', 'get', 'lying', 'collusion']\n",
            "gop\n",
            "rnc\n",
            "2391 ['FIXED', 'ELECTION', '!', 'trumps']\n",
            "annotated_mention_list: [('trumps', 'misc')]\n",
            "non_entity_list: ['election']\n",
            "trumps\n",
            "2392 ['And', 'according', 'the', 'the', '@USER', 'he', 'has', 'stock', 'in', 'the', 'company', 'that', 'makes', 'the', 'missiles', '.', 'If', 'its', 'true', 'its', 'another', 'conflict', 'of', 'interest', ',', 'BIGLY']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['conflict', 'makes', 'stock', 'according', 'bigly']\n",
            "2393 ['APR', '11', ':', 'Issue', '55', 'Opposition', 'Watch', '-', 'Daily', 'Intelligence', 'Briefing']\n",
            "annotated_mention_list: [('intelligence briefing', 'misc')]\n",
            "non_entity_list: ['intelligence', 'daily']\n",
            "intelligence briefing\n",
            "2394 ['Trump', 'notified', 'the', 'Russians', 'but', 'not', 'Congress', 'or', 'the', 'State', 'Dept', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('russians', 'misc'), ('congress', 'org'), ('state dept', 'org')]\n",
            "non_entity_list: ['dept', 'state']\n",
            "trump\n",
            "russians\n",
            "congress\n",
            "state dept\n",
            "2395 ['Normalizing', 'this', 'is', 'part', 'of', 'the', 'insanity', '.', 'No', '-', 'this', 'is', 'not', 'right', 'and', 'we', 'must', 'put', 'a', 'stop', 'to', 'this', 'completely', 'unreasonable', 'form', 'of', 'nepotism', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['right', 'nepotism', 'stop', 'put', 'completely']\n",
            "2396 ['@USER', '@USER', 'good', 'boy', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['good']\n",
            "2397 ['/', '.', 'Trump', 'administration', 'rolls', 'back', 'protections', 'for', 'people', 'in', 'default', 'on', 'student', 'loans', '@USER']\n",
            "annotated_mention_list: [('trump administration', 'org')]\n",
            "non_entity_list: ['administration', 'people', 'back']\n",
            "trump administration\n",
            "2398 ['@USER', '@USER', 'love', 'love', 'love', 'how', 'she', 'signs', 'off', 'with']\n",
            "annotated_mention_list: []\n",
            "2399 ['@USER', 'is', 'not', 'as', 'clever', 'as', 'you', 'think', 'he', 'is', '.', 'We', \"'re\", 'on', 'to', 'you', 'both', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['think']\n",
            "2400 ['@USER', 'help', 'flip', 'these', 'seats', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['help']\n",
            "2401 ['Fuckin', 'outrageous', '!', '!']\n",
            "annotated_mention_list: []\n",
            "2402 ['carries', 'stance', 'to', 'as', 'Trump', 'administration', 'speaks', 'for', 'West', 'via', '@USER']\n",
            "annotated_mention_list: [('trump administration', 'org'), ('west', 'loc')]\n",
            "non_entity_list: ['administration', 'carries', 'stance']\n",
            "trump administration\n",
            "west\n",
            "2403 ['The', 'Idiot', 'Trump', 'brothers', 'and', 'some', 'dude', 'named', '\"', 'no', 'socks', '\"', ',', 'are', 'you', 'fucking', 'kidding', 'me', '?']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['socks', 'idiot', 'brothers']\n",
            "trump\n",
            "2404 ['Winning', 'for', 'the', 'Trump', 'family', 'Entire', 'USA', 'LOSERS']\n",
            "annotated_mention_list: [('trump family', 'misc'), ('usa', 'loc')]\n",
            "non_entity_list: ['family', 'entire']\n",
            "trump family\n",
            "usa\n",
            "2405 ['Holy', 'crap', '!', 'what', 'was', 'in', 'that', 'mini', 'bar', '?', 'A', 'kilo', 'of', 'blow', 'and', '88', 'hookers', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['mini', 'holy']\n",
            "2406 ['from', 'Palestine', 'to', 'Malaysia', ',', 'Be', 'Strong', 'as', 'you', 'always', 'are', '.', '#MH17', '#PrayForMH17', 'Malaysian', 'Airlines', 'All', '295']\n",
            "annotated_mention_list: [('palestine', 'loc'), ('malaysia', 'loc'), ('malaysian airlines', 'org')]\n",
            "non_entity_list: ['airlines']\n",
            "palestine\n",
            "malaysia\n",
            "malaysian airlines\n",
            "2407 ['A', 'passenger', 'posted', 'before', 'boarding', 'Malaysian', 'Airlines', '#MH17', '.', 'It', 'says', '\"', 'If', 'it', 'disappears', ',', 'this', 'is', 'what', 'it', 'looks', 'like', '.', '\"']\n",
            "annotated_mention_list: [('malaysian airlines', 'org')]\n",
            "non_entity_list: ['airlines', 'passenger', 'says']\n",
            "malaysian airlines\n",
            "2408 ['GOP', 'is', 'racist', 'to', 'the', 'core', '!', 'They', 'have', 'to', 'be', 'broken', '.', '(', 'In', 'the', 'meantime', ',', 'keeping', 'our', 'on', ')']\n",
            "annotated_mention_list: [('gop', 'org')]\n",
            "non_entity_list: ['keeping']\n",
            "gop\n",
            "2409 ['Going', 'to', 'cheer', 'on', 'the', 'runners', 'of', 'the', 'Boston', 'marathon', '!', 'Anyone', 'watching', '?']\n",
            "annotated_mention_list: [('boston marathon', 'misc')]\n",
            "non_entity_list: ['going', 'watching']\n",
            "boston marathon\n",
            "2410 ['@USER', '@USER', 'Who', 'says', 'the', 'Russians', 'do', \"n't\", 'have', 'a', 'sense', 'of', 'humor', '?']\n",
            "annotated_mention_list: [('russians', 'misc')]\n",
            "non_entity_list: ['says']\n",
            "russians\n",
            "2411 ['Russian', 'military', 'laid', 'out', 'its', 'data', 'on', '#MH17', 'which', 'BBC', 'chose', 'to', 'report', 'on', 'in', 'Russian', 'but', 'not', 'in', 'English', '.', 'Impartiality', '?']\n",
            "annotated_mention_list: [('russian military', 'org'), ('bbc', 'org'), ('russian', 'misc'), ('english', 'misc')]\n",
            "russian military\n",
            "bbc\n",
            "russian\n",
            "english\n",
            "2412 ['@USER', 'How', 'many', 'support', 'nuking', 'North', 'Korea', '?', 'This', 'seems', 'eminent', 'with', 'Trump', 'in', 'office', '.']\n",
            "annotated_mention_list: [('north korea', 'loc'), ('trump', 'per')]\n",
            "non_entity_list: ['north', 'office', 'support']\n",
            "north korea\n",
            "trump\n",
            "2413 ['Is', 'Beavis', 'or', 'Butthead', '...', 'I', 'get', 'them', 'confused', 'ALL', 'THE', 'TIME', '.']\n",
            "annotated_mention_list: [('beavis', 'per')]\n",
            "non_entity_list: ['get', 'butthead', 'time']\n",
            "beavis\n",
            "2414 ['Ca', \"n't\", 'be', 'a', 'man', 'since', 'he', \"'s\", 'a', 'proven', 'man-baby', 'per', '@USER', 'TheRickWilson', '.', 'He', \"'s\", 'also', '.']\n",
            "annotated_mention_list: [('therickwilson', 'per')]\n",
            "non_entity_list: ['proven', 'man', 'per']\n",
            "therickwilson\n",
            "2415 ['Ukraine', \"'\", 's', 'pro', '-', 'Russia', 'rebels', 'hand', 'over', 'Malaysia', 'Airlines', '#MH17', \"'s\", 'black', 'boxes']\n",
            "annotated_mention_list: [('ukraine', 'loc'), ('russia', 'loc'), ('malaysia airlines', 'org')]\n",
            "non_entity_list: ['airlines', 'black', 'pro']\n",
            "ukraine\n",
            "russia\n",
            "malaysia airlines\n",
            "2416 [',', 'Our', 'Dishonest', 'President', 'and', 'thought', 'yup', ',', 'Obama', 'be', 'spying', 'and', 'hiding', 'overseas', 'cause', 'his', 'ass', 'busted', '.']\n",
            "annotated_mention_list: [('obama', 'per')]\n",
            "non_entity_list: ['spying', 'hiding', 'ass', 'busted', 'thought']\n",
            "obama\n",
            "2417 ['Despite', '#MH17', 'and', '#MH370', 'disasters', ',', 'Malaysia', 'Airlines', 'reports', 'no', 'surge', 'in', 'ticket', 'cancellations']\n",
            "annotated_mention_list: [('malaysia airlines', 'org')]\n",
            "non_entity_list: ['airlines', 'reports']\n",
            "malaysia airlines\n",
            "2418 ['@USER', 'Stay', 'Focused', '!', 'Demand', 'Independent', 'Investigation', 'Congressional', 'Switchboard', '(202)', '224-3121', 'This', 'is', 'not', 'normal', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['investigation', 'demand', 'independent']\n",
            "2419 ['It', \"'s\", 'like', 'a', 'black-tie', 'RICO', 'indictment']\n",
            "annotated_mention_list: [('rico', 'misc')]\n",
            "rico\n",
            "2420 ['We', \"can't\", 'let', 'the', 'media', \"'s\", 'distraction', 'with', 'Syria', 'let', 'us', 'be', 'distracted', '.']\n",
            "annotated_mention_list: [('syria', 'loc')]\n",
            "non_entity_list: ['distraction', 'media', 'us']\n",
            "syria\n",
            "2421 ['@USER', 'Rayelle', '73', 'just', 'had', 'a', 'mtg', 'abt', 'that', '.', 'Look', 'for', 'change', 'soon']\n",
            "annotated_mention_list: [('rayelle 73', 'per')]\n",
            "non_entity_list: ['soon', 'look']\n",
            "rayelle 73\n",
            "2422 ['@USER', '@USER', '@USER', 'MERRICK', 'GARLAND']\n",
            "annotated_mention_list: [('merrick garland', 'per')]\n",
            "merrick garland\n",
            "2423 ['President', 'Carter', \"'s\", 'rating', 'did', \"n't\", 'drop', 'until', 'August', 'of', '1977', 'when', 'Bert', 'Lance', 'was', 'accused', 'of', 'wrongdoing', 'at', 'a', 'bank', 'in', 'Georgia', 'and', 'later', 'cleared', '.']\n",
            "annotated_mention_list: [('president carter', 'per'), ('bert lance', 'per'), ('georgia', 'loc')]\n",
            "non_entity_list: ['bank', 'later']\n",
            "president carter\n",
            "bert lance\n",
            "georgia\n",
            "2424 ['Kremlin', 'says', 'arrested', 'Russian', 'hacker', 'has', 'admitted', 'to', 'hacking', 'election', 'in', 'Donald', 'Trump', \"'s\", 'favor']\n",
            "annotated_mention_list: [('kremlin', 'loc'), ('russian', 'misc'), ('donald trump', 'per')]\n",
            "non_entity_list: ['says', 'election']\n",
            "kremlin\n",
            "russian\n",
            "donald trump\n",
            "2425 ['Just', 'got', 'word', 'of', 'the', 'explosion', 'near', 'the', 'finish', 'line', 'of', 'the', 'Boston', 'marathon', '.', 'This', 'is', 'terrible', ':(', 'hope', 'all', 'are', 'ok', '.', '.', '.']\n",
            "annotated_mention_list: [('boston marathon', 'misc')]\n",
            "non_entity_list: ['line', 'got']\n",
            "boston marathon\n",
            "2426 ['Bowie', \"'\", 's', 'last', 'day', '-', 'we', 'had', 'permission', 'for', 'a', 'year', ',', 'so', 'our', 'Space', 'Oddity', 'video', 'comes', 'down', 'today', '.', 'One', 'last', 'look', ':']\n",
            "annotated_mention_list: [('bowie', 'per'), ('space oddity', 'misc')]\n",
            "non_entity_list: ['comes', 'look', 'last', 'video', 'day', 'one']\n",
            "bowie\n",
            "space oddity\n",
            "2427 ['Can', 'someone', 'explain', '?']\n",
            "annotated_mention_list: []\n",
            "2428 ['is', 'serious', 'business', 'and', 'Rep', 'Swalwell', 'KNOWS', 'it', '!']\n",
            "annotated_mention_list: [('rep swalwell', 'per')]\n",
            "non_entity_list: ['business', 'knows', 'rep']\n",
            "rep swalwell\n",
            "2429 ['Again', ',', 'a', 'declaration', 'that', 'turns', 'out', 'to', 'be', 'false', '.', 'How', 'often', 'until', 'we', 'have', 'enough', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['turns']\n",
            "2430 ['Fun', 'Fact', ':', 'I', 'reported', 'Eric', 'Trump', 'to', 'the', 'NY', 'Board', 'of', 'Elections', 'when', 'he', 'illegally', 'took', 'a', 'pic', 'of', 'his', 'ballot']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('ny board of elections', 'org')]\n",
            "non_entity_list: ['took', 'reported', 'board']\n",
            "eric trump\n",
            "ny board of elections\n",
            "2431 ['PLEASE']\n",
            "annotated_mention_list: []\n",
            "2432 ['No', ',', 'it', 'just', 'proves', 'Trump', 'is', 'trying', 'to', 'distract', 'the', 'public', '.', 'It', \"'s\", 'not', 'working', '.', 'Get', 'Trump', 'and', 'family', 'out', 'of', 'the', 'WH', '.', 'Now', '!']\n",
            "annotated_mention_list: [('trump', 'per'), ('trump', 'per'), ('wh', 'loc')]\n",
            "non_entity_list: ['family', 'get', 'public']\n",
            "trump\n",
            "trump\n",
            "wh\n",
            "2433 ['This', 'just', 'makes', 'it', 'seem', 'like', 'you', \"'re\", 'trying', 'so', 'hard', 'to', 'deny']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['makes', 'hard']\n",
            "2434 ['Has', 'anyone', 'else', 'heard', 'that', 'little', 'Donnie', 'Jr', '.', 'is', 'thinking', 'of', 'running', 'for', 'Mayor', 'of', 'NYC', '?', 'Will', 'Pooty', 'help', 'him', 'win', 'that', 'election', '?']\n",
            "annotated_mention_list: [('donnie jr', 'per'), ('mayor of nyc', 'per'), ('pooty', 'per')]\n",
            "non_entity_list: ['win', 'help', 'little', 'thinking', 'heard', 'mayor', 'election']\n",
            "donnie jr\n",
            "mayor of nyc\n",
            "pooty\n",
            "2435 ['Laughable', '.', 'Our', 'Syria', 'strike', 'was', 'part', 'of', 'the', 'script', 'laid', 'out', 'by', 'Putin', 'to', 'divert', 'attention', 'from']\n",
            "annotated_mention_list: [('syria', 'loc'), ('putin', 'per')]\n",
            "non_entity_list: ['strike']\n",
            "syria\n",
            "putin\n",
            "2436 ['@USER', 'Come', 'on', ',', 'people', '.', 'Let', \"'s\", 'start', 'rocking', 'the', 'twitter', 'boat', '.', 'Little', 'drops', 'of', 'water', ',', 'together', 'make', 'BIG', 'WAVES', '!', 'TREND', 'THIS', 'SUCKER']\n",
            "annotated_mention_list: [('twitter', 'org')]\n",
            "non_entity_list: ['little', 'water', 'big', 'come', 'people']\n",
            "twitter\n",
            "2437 ['REMINDER', 'trump', '/', 'admin', '/', 'campaign', 'effing', 'INVESTIGATED', 'BY', 'FBI', 'for', 'ATTACK', 'ON', 'OUR', 'DEMOCRACY', '!']\n",
            "annotated_mention_list: [('trump', 'per'), ('fbi', 'org'), ('democracy', 'misc')]\n",
            "non_entity_list: ['admin', 'attack', 'campaign']\n",
            "trump\n",
            "fbi\n",
            "democracy\n",
            "2438 ['trump', 'warned', 'Russia', 'who', 'warned', 'Syria', '.', 'Useless', 'air', 'strike', 'seemed', 'all', 'SHOW']\n",
            "annotated_mention_list: [('trump', 'per'), ('russia', 'loc'), ('syria', 'loc')]\n",
            "non_entity_list: ['strike', 'show', 'air']\n",
            "trump\n",
            "russia\n",
            "syria\n",
            "2439 ['Please', 'vote', ',', 'Kansas', '!', '!', '!', '!', '!', 'Be', 'trendsetters', '!']\n",
            "annotated_mention_list: [('kansas', 'loc')]\n",
            "kansas\n",
            "2440 ['@USER', '@USER', 'Stay', 'Focused', '!', 'Demand', 'Independent', 'Investigation', 'Congressional', 'Switchboard', '(202)', '224-3121', 'This', 'is', 'not', 'normal', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['investigation', 'demand', 'independent']\n",
            "2441 ['No', ',', 'is', 'not', 'a', 'thing', 'and', 'it', 'has', 'no', 'place', 'in', 'our', 'country', 'and', 'our', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['thing']\n",
            "2442 ['@USER', 'Been', 'wondering', 'if', 'anyone', 'checking', 'into', 'Pamela', 'Anderson', 'being', 'flown', 'in', 'to', '*', 'see', '*', 'Assange', '?', 'Have', \"n't\", 'seen', 'anything', 'on', 'this', '.']\n",
            "annotated_mention_list: [('pamela anderson', 'per'), ('assange', 'per')]\n",
            "non_entity_list: ['see', 'seen']\n",
            "pamela anderson\n",
            "assange\n",
            "2443 ['I', 'do', \"n't\", 'believe', 'ordered', 'the', 'jakarta', 'chemical', 'attack', '.', 'But', 'I', 'DO', 'believe', 'checked', 'with', 'his', 'blackmailer', 'prior', 'to', 'responding', '.']\n",
            "annotated_mention_list: [('jakarta chemical attack', 'misc')]\n",
            "non_entity_list: ['chemical', 'attack', 'prior', 'ordered']\n",
            "jakarta chemical attack\n",
            "2444 ['When', 'will', 'it', 'end', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['end']\n",
            "2445 ['they', 'say', 'a', 'poodle', 'understands', '100-200', 'words', 'so', '@USER', 'my', 'dog', 'is', 'as', 'smart', 'if', 'not', 'smarter', 'than', 'u']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['dog', 'say']\n",
            "2446 ['Apr', '11', '19:00', 'Temperature', '10C', 'light', 'showers', 'Wind', 'W', '18', 'km', '/', 'h', 'Humidity', '85', '%', 'Russia', '..']\n",
            "annotated_mention_list: [('russia', 'loc')]\n",
            "russia\n",
            "2447 ['@USER', \"can't\", 'take', 'it', 'can', 'you', 'How', 'is', 'nepotism', 'working', 'for', 'ya', '!', 'Daddy', 'passed', 'law', 'so', 'you', 'can', 'shoot', 'Grizzly', 'when', 'sleeping', '.', 'Easier', '4', 'U']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['take', 'nepotism', 'daddy', 'law', 'grizzly']\n",
            "2448 ['Good', 'point', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['good']\n",
            "2449 ['@USER', 'He', 'is', 'hoping', 'for', 'a', 'truck', ',', 'but', 'he', 'has', '2', 'learn', 'how', '2', 'ride', 'a', 'bike', 'first', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['first', 'learn']\n",
            "2450 ['@USER', 'Can', 'you', 'please', 'use', 'diplomacy', 'and', 'not', 'start', 'WWIII', 'just', 'for', 'a', 'distraction', '.']\n",
            "annotated_mention_list: [('wwiii', 'misc')]\n",
            "non_entity_list: ['distraction', 'use']\n",
            "wwiii\n",
            "2451 ['Ivanks', 'is', 'only', 'worried', 'about', 'filling', 'Ivanks', 'bank', 'accounts', '.', 'Worse', 'than', 'her', \"'\", 'Dad', \"'\", '.']\n",
            "annotated_mention_list: [('ivanks', 'per')]\n",
            "non_entity_list: ['worse', 'bank', 'dad']\n",
            "ivanks\n",
            "2452 ['So', 'now', 'tRump', 'is', 'at', 'war', 'with', 'freedom', 'of', 'the', 'press', '.', 'This', 'surely', 'is', 'a', 'breach', 'of', 'the', 'constitution', '!']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['war', 'press']\n",
            "trump\n",
            "2453 ['Sessions', 'the', 'AG', 'and', 'highest', 'law', 'enforcement', 'officer', 'in', 'the', 'land', 'committed', 'perjury', 'under', 'oath', 'and', 'should', 'resign', '.']\n",
            "annotated_mention_list: [('sessions', 'per'), ('ag', 'misc')]\n",
            "non_entity_list: ['law', 'committed', 'land']\n",
            "sessions\n",
            "ag\n",
            "2454 ['@USER', '@USER', 'Rachel', 'definitely', 'has', 'her', 'eye', 'on', 'the', 'prize', '.', 'Do', \"n't\", 'let', 'the', 'batshit', 'crazy', 'people', 'in', 'power', 'distract', 'us', 'from']\n",
            "annotated_mention_list: [('rachel', 'per')]\n",
            "non_entity_list: ['people', 'definitely', 'power', 'us']\n",
            "rachel\n",
            "2455 ['MUST', 'SEE', 'AMERICA', '.']\n",
            "annotated_mention_list: [('america', 'loc')]\n",
            "non_entity_list: ['see']\n",
            "america\n",
            "2456 ['To', 'Charm', 'Trump', ',', 'Paul', 'Manafort', 'Sold', 'Himself', 'as', 'an', 'Affordable', 'Outsider']\n",
            "annotated_mention_list: [('trump', 'per'), ('paul manafort', 'per')]\n",
            "trump\n",
            "paul manafort\n",
            "2457 ['@USER', 'Those', 'who', 'struggle', 'financially', 'are', 'paying', 'for', '@USER', 'and', 'family', \"'s\", 'lavish', 'lifestyle', 'yet', 'no', 'criticizing', '.', 'Why', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['family']\n",
            "2458 ['@USER', '@USER', 'Lets', 'not', 'forget', '!', 'warned', '!', 'No', 'one', 'listens', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['one']\n",
            "2459 ['@USER', '@USER', '@USER', 'THE', 'NERD', 'AND', 'THE', 'OTHER', 'SIBLINGS', 'THE', 'MOST', 'HATED', 'IN', 'AMERICA', '.', 'HAPPY', 'SIBLING', 'DAY', '!', '@USER', '@USER']\n",
            "annotated_mention_list: [('america', 'loc')]\n",
            "non_entity_list: ['day']\n",
            "america\n",
            "2460 ['@USER', 'He', 'clearly', 'got', 'his', 'smarts', 'from', 'his', 'father', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['got', 'father', 'clearly']\n",
            "2461 ['.', '@USER', '.', '@USER', '.', '@USER', '.', '@USER', '.', '@USER', '.', '@USER', '.', '@USER', '.', '@USER', '.', '@USER', '.', '@USER', '.', 'No', 'Distractions', 'from', 'corruption', 'in', 'Washington']\n",
            "annotated_mention_list: [('washington', 'loc')]\n",
            "non_entity_list: ['distractions']\n",
            "washington\n",
            "2462 ['@USER', '@USER', '@USER', 'He', 'did', \"n't\", 'really', 'care', 'about', 'that', 'attack', 'either', ',', 'Was', 'set', 'up']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['set', 'attack', 'really']\n",
            "2463 ['@USER', '@USER', '@USER', 'So', 'does', 'a', 'turkey', 'but', 'you', 'do', \"n't\", 'see', 'them', 'pretending', 'to', 'be', 'something', 'they', \"'re\", 'not', '.']\n",
            "annotated_mention_list: [('turkey', 'misc')]\n",
            "non_entity_list: ['see']\n",
            "turkey\n",
            "2464 ['@USER', 'This', 'is', 'so', 'exciting', '.', 'I', \"can't\", 'wait', 'to', 'watch', '@USER', 'tonight', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['wait']\n",
            "2465 ['Odds', 'that', 'the', 'eggs', 'at', 'the', 'Easter', 'Egg', 'Roll', 'are', 'of', 'Russian', 'Pysanky', 'design', 'this', 'year', '?']\n",
            "annotated_mention_list: [('easter egg roll', 'misc'), ('russian pysanky', 'misc')]\n",
            "non_entity_list: ['roll']\n",
            "easter egg roll\n",
            "russian pysanky\n",
            "2466 ['Dear', 'Congress', ',', 'On', 'behalf', 'of', 'myself', 'and', 'my', 'family', ',', 'can', 'you', 'please', 'cut', 'your', 'vacation', 'short', 'to', 'prevent', 'a', 'Nuclear', 'War', '?', 'Thank', 'You']\n",
            "annotated_mention_list: [('congress', 'org'), ('nuclear war', 'misc')]\n",
            "non_entity_list: ['war', 'vacation', 'cut', 'family', 'short']\n",
            "congress\n",
            "nuclear war\n",
            "2467 ['@USER', 'And', 'there', 'are', 'MANY', 'to', '\"', 'I', \"'s\", '\"', 'and', '\"', 'T', \"'s\", '\"', 'to', 'dot', 'and', 'cross', 'in', 'this', 'treacherous', 'WH', '.']\n",
            "annotated_mention_list: [('wh', 'loc')]\n",
            "non_entity_list: ['dot']\n",
            "wh\n",
            "2468 ['Alas', 'yes', ':']\n",
            "annotated_mention_list: []\n",
            "2469 ['JUST', 'HIT', '420', 'FOLLOWERS', 'FAM', '.', 'HIGHLY', 'CONSIDERING', 'STOPPING', 'AT', 'THAT', 'FOR', 'RELIGIOUS', 'PURPOSES', '.', 'GET', 'LIT', 'FAMMO', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['get']\n",
            "2470 ['Only', 'the', 'cult', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['cult']\n",
            "2471 ['ABSOLUTELY', 'AGREE', '!', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['agree']\n",
            "2472 ['NEW', 'Doc', '/', 'Photo', ':', 'Eric', 'Trump', 'in', 'Panama', 'talking', 'about', 'his', 'Canadian', 'biz', 'deals']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('panama', 'loc'), ('canadian', 'misc')]\n",
            "non_entity_list: ['new', 'talking']\n",
            "eric trump\n",
            "panama\n",
            "canadian\n",
            "2473 ['Stop', 'using', '.', 'You', 'have', 'yet', 'to', 'leak', 'a', 'single', 'shred', 'of', 'anything', ',', 'you', 'fraud', '.', 'You', 'discredit', 'those', 'who', 'are', 'actually', 'looking', 'for', 'leaks', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['using', 'stop', 'actually']\n",
            "2474 ['And', 'I', 'compare', '@USER', 'to', 'George', 'Hamilton', '.', 'Vacuous', 'Self', 'aggrandizing', 'Untalented', 'Entitled']\n",
            "annotated_mention_list: [('george hamilton', 'per')]\n",
            "non_entity_list: ['self']\n",
            "george hamilton\n",
            "2475 ['@USER', 'That', \"'s\", 'probably', 'not', 'the', 'truth', '.', 'If', 'indeed', 'the', 'actual', 'purpose', 'was', 'to', 'distract', 'from', '.', 'After', 'all', 'no', 'major', 'damage', 'was', 'done', '.']\n",
            "annotated_mention_list: []\n",
            "2476 ['@USER', 'I', 'think', 'you', \"'re\", 'the', 'one', 'looking', 'for', 'trouble', '.', 'Shooting', 'off', 'missiles', ',', 'so', 'much', 'more', 'fun', 'than', 'tax', 'reform', 'or', 'health', 'care', 'or', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['think', 'tax', 'one']\n",
            "2477 ['@USER', '@USER', '@USER', 'What', 'are', 'we', 'waiting', '4', '?']\n",
            "annotated_mention_list: []\n",
            "2478 ['Great', 'skits', ',', 'thanks']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['great']\n",
            "2479 ['@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', 'is', 'Under', 'FBI', 'Inve']\n",
            "annotated_mention_list: [('fbi', 'org')]\n",
            "fbi\n",
            "2480 ['@USER', 'Trump', 'notifies', 'Russians', 'but', 'not', 'Congress', 'or', 'State', 'Dept', '.', 'That', 'is', 'treason', 'and', 'collusion', 'with', 'the', 'enemy', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('russians', 'misc'), ('congress', 'org'), ('state dept', 'org')]\n",
            "non_entity_list: ['treason', 'collusion', 'state', 'dept']\n",
            "trump\n",
            "russians\n",
            "congress\n",
            "state dept\n",
            "2481 ['FBI', 'is', 'creating', 'a', 'Special', 'Unit']\n",
            "annotated_mention_list: [('fbi', 'org')]\n",
            "fbi\n",
            "2482 ['Nobody', 'will', 'be', 'with', 'us', 'as', 'long', 'as', 'we', 'have', 'Trump']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['us']\n",
            "trump\n",
            "2483 ['Err', ':', '509']\n",
            "annotated_mention_list: []\n",
            "2484 ['Thanks', 'for', 'the', 'follow', ',', '@USER', '!', 'And', 'for', 'working', 'to', 'expose', 'We', 'need', 'a', 'leader', 'like', 'you', 'in', 'the', 'WH', '.']\n",
            "annotated_mention_list: [('wh', 'loc')]\n",
            "non_entity_list: ['need', 'leader']\n",
            "wh\n",
            "2485 ['@USER', 'bahahaha', 'Trump', 'supporters', 'are', 'crying', '.', 'no', 'more', 'deep', 'state', 'excuse', '.', 'hawk', 'Trump', 'keeps', 'rubbing', 'in', 'supporters', 'eyes', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['eyes', 'deep', 'keeps', 'state', 'supporters']\n",
            "trump\n",
            "trump\n",
            "2486 ['Trump', \"'s\", 'presidency', 'has', 'never', 'been', 'about', 'anything', 'other', 'than', 'increasing', 'his', 'wealth', '.', 'Blatant', 'disregard', 'for', 'ethics', '.', 'Surprised', '?']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['presidency']\n",
            "trump\n",
            "2487 ['@USER', 'You', \"can't\", 'hide', '!']\n",
            "annotated_mention_list: []\n",
            "2488 ['NEW', 'Doc', '/', 'Photo', ':', 'Eric', 'Trump', 'in', 'Panama', 'talking', 'about', 'his', 'Canadian', 'biz', 'deals']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('panama', 'loc'), ('canadian', 'misc')]\n",
            "non_entity_list: ['new', 'talking']\n",
            "eric trump\n",
            "panama\n",
            "canadian\n",
            "2489 ['This', 'is', 'beyond', 'dangerous', '.', 'POTUS', 'is', 'taking', 'military', 'advise', 'from', 'his', 'children', 'instead', 'of', 'experts', '.', 'This', 'family', 'has', 'to', 'be', 'removed', 'from', 'office', '.']\n",
            "annotated_mention_list: [('potus', 'per')]\n",
            "non_entity_list: ['office', 'children', 'family', 'instead', 'beyond']\n",
            "potus\n",
            "2490 ['@USER', 'he', 'is', 'really', 'really', 'really', 'dull', '.', 'jesu', 'kristi', '.']\n",
            "annotated_mention_list: [('jesu kristi', 'per')]\n",
            "non_entity_list: ['really']\n",
            "jesu kristi\n",
            "2491 ['Everyone', 'do', 'not', 'forget', 'where', 'we', 'are', '!']\n",
            "annotated_mention_list: []\n",
            "2492 ['3rd', 'conspiracy', 'putins', 'girlfriend', 'told', 'ivanka', 'the', 'plans', 'so', 'no', 'contact', 'needed', 'with', 'sad']\n",
            "annotated_mention_list: [('ivanka', 'per')]\n",
            "non_entity_list: ['told']\n",
            "ivanka\n",
            "2493 ['More', 'Reason', 'to', 'on', '!', 'Putin', 'Never', 'had', 'USA', 'interests', '.', 'collaborated', 'w', '/', 'Enemy', '!']\n",
            "annotated_mention_list: [('putin', 'per'), ('usa', 'loc')]\n",
            "putin\n",
            "usa\n",
            "2494 ['@USER', 'Do', 'you', 'even', 'know', 'the', 'guy', '?', '?', '?', 'I', 'bet', 'not', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['guy', 'bet']\n",
            "2495 ['No', 'one', 'is', 'forgetting', 'about', 'or', 'or', 'your', 'ineffective', 'assault', 'on', 'Assad']\n",
            "annotated_mention_list: [('assad', 'per')]\n",
            "non_entity_list: ['one']\n",
            "assad\n",
            "2496 ['When', 'I', \"'m\", 'a', 'piece', 'of', 'fucking', 'shit', 'Trump', 'starts', 'a', 'war', 'with', 'N', '.', 'Korea', 'we', 'the', 'people', 'will', 'remove', 'hiss', 'fucking', 'ass', 'from', 'the', 'whitehouse', 'i', 'promise']\n",
            "annotated_mention_list: [('trump', 'per'), ('n . korea', 'loc'), ('whitehouse', 'loc')]\n",
            "non_entity_list: ['war', 'starts', 'ass', 'piece', 'people']\n",
            "trump\n",
            "n . korea\n",
            "whitehouse\n",
            "2497 ['An', 'old', 'TV', 'show', 'with', 'a', 'man', 'driving', 'around', 'in', 'his', 'cadillac', 'solving', 'problems']\n",
            "annotated_mention_list: [('cadillac', 'misc')]\n",
            "non_entity_list: ['driving', 'show', 'man']\n",
            "cadillac\n",
            "2498 ['Wilbur', 'Ross', 'is', 'not', 'a', 'crook', '.', 'Peloponnesian', 'forces', 'on', 'shore', ',', 'when', 'the', 'offenders', 'are', 'known', ',', 'of', 'pursuit', '.', 'folks', '.']\n",
            "annotated_mention_list: [('wilbur ross', 'per'), ('peloponnesian', 'misc')]\n",
            "non_entity_list: ['forces']\n",
            "wilbur ross\n",
            "peloponnesian\n",
            "2499 ['I', 'am', 'unable', 'to', 'get', 'rid', 'of', 'extra', 'charecters', 'with', 'comments', 'in', 'SQL', 'injection', 'payload']\n",
            "annotated_mention_list: [('sql', 'misc')]\n",
            "non_entity_list: ['comments', 'get']\n",
            "sql\n",
            "2500 ['Trump', '/', 'Putin', '/', 'Assad', 'STAGED', 'this', 'atrocity', 'as', 'a', 'RED', 'HERRING', '.', 'Try', 'to', 'look', 'like', 'Trump', '/', 'Putin', 'NOT', 'in', 'BED', 'together', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('putin', 'per'), ('assad', 'per'), ('trump', 'per'), ('putin', 'per')]\n",
            "non_entity_list: ['staged', 'look']\n",
            "trump\n",
            "putin\n",
            "assad\n",
            "trump\n",
            "putin\n",
            "2501 ['If', 'it', 'is', 'called', 'Mandalorian', ',', 'I', 'would', 'think', 'that', 'the', 'Mandalorians', 'designed', 'it', '.']\n",
            "annotated_mention_list: [('mandalorian', 'misc'), ('mandalorians', 'misc')]\n",
            "non_entity_list: ['think', 'called']\n",
            "mandalorian\n",
            "mandalorians\n",
            "2502 ['@USER', 'defalt', 'I', 'do', 'n', \"'\", 't', 'think', 'OP', 'was', 'asking', 'about', 'the', 'VPN', 'server', \"'\", 's', 'port', '(', 'which', 'I', 'addressed', ',', 'too', ')', '.']\n",
            "annotated_mention_list: [('defalt', 'per'), ('op', 'per'), ('vpn', 'misc')]\n",
            "non_entity_list: ['think']\n",
            "defalt\n",
            "op\n",
            "vpn\n",
            "2503 ['@USER', '@USER', 'It', \"'s\", 'not', 'that', 'they', \"can't\", ';', 'it', \"'s\", 'that', 'they', 'do', \"n't\", 'care']\n",
            "annotated_mention_list: []\n",
            "2504 ['@USER', '@USER', 'Eric', \"can't\", 'handle', 'the', 'truth', '.', 'The', 'Trump', 'family', 'will', 'have', 'a', 'hard', 'time', 'in', 'jail', 'unless', 'they', 'toughen', 'up', '.']\n",
            "annotated_mention_list: [('eric', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['family', 'time', 'hard']\n",
            "eric\n",
            "trump\n",
            "2505 ['OMB', 'nominee', 'Mick', 'Mulvaney', 'wants', 'changes', 'to', 'Social', 'Security', ',', 'Medicare', '@USER', 'via', '@USER', 'WSJ']\n",
            "annotated_mention_list: [('omb', 'org'), ('mick mulvaney', 'per'), ('social security', 'misc'), ('medicare', 'misc'), ('wsj', 'org')]\n",
            "non_entity_list: ['wants', 'social']\n",
            "omb\n",
            "mick mulvaney\n",
            "social security\n",
            "medicare\n",
            "wsj\n",
            "2506 ['Party', 'should', 'focus', 'on', 'its', 'own', 'Rot', 'and', 'not', ';', 'look', 'how', 'they', 'cheated', 'Bernie']\n",
            "annotated_mention_list: [('bernie', 'per')]\n",
            "non_entity_list: ['party', 'look']\n",
            "bernie\n",
            "2507 ['Store', 'SQL', 'database', 'credentials', 'in', 'a', 'webserver']\n",
            "annotated_mention_list: [('sql', 'misc')]\n",
            "sql\n",
            "2508 ['NEW', 'Photo', ':', 'Eric', 'Trump', 'and', 'Don', 'Jr', 'breaking', 'ground', 'in', 'the', 'Philippines']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('don jr', 'per'), ('philippines', 'loc')]\n",
            "non_entity_list: ['new', 'breaking']\n",
            "eric trump\n",
            "don jr\n",
            "philippines\n",
            "2509 ['Localizing', 'sql', 'payload', 'was', 'about', 'balancing', 'clarity', 'and', 'authenticity', ':', '@USER']\n",
            "annotated_mention_list: [('sql', 'misc')]\n",
            "sql\n",
            "2510 ['@USER', '@USER', 'He', 'did', 'it', 'to', 'try', 'to', 'divert', 'from', ',', 'not', 'because', 'he', 'cares', 'about', 'Syria', 'and', 'its', 'citizens', '.', 'If', 'he', 'did', '...']\n",
            "annotated_mention_list: [('syria', 'loc')]\n",
            "non_entity_list: ['citizens']\n",
            "syria\n",
            "2511 ['I', 'would', 'like', 'to', 'thank', 'the', \"gov't\", 'for', 'their', 'ceremonial', 'that', 'greeted', 'Sec', '.', 'of', 'State', 'at', 'the', 'airport', 'in', '.']\n",
            "annotated_mention_list: [('sec . of state', 'per')]\n",
            "non_entity_list: [\"gov't\", 'airport', 'state']\n",
            "sec . of state\n",
            "2512 ['The', 'Trumpino', 'Family']\n",
            "annotated_mention_list: [('trumpino', 'per')]\n",
            "non_entity_list: ['family']\n",
            "trumpino\n",
            "2513 ['Eric', 'Trump', 'is', 'a', 'chunk', 'off', 'the', 'delusional', 'Don', 'the', 'Con', 'Block', '.', 'He', 'lies', 'just', 'like', 'dumbo', '.', 'We', 'all', 'know', 'its', 'about', 'your', 'father', ',', 'Russia', 'and', 'bigly', 'bucks', '!']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('don the con block', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['con', 'lies', 'father', 'bigly']\n",
            "eric trump\n",
            "don the con block\n",
            "russia\n",
            "2514 ['Does', 'the', 'x-files', 'break', 'an', 'official', 'record', '?']\n",
            "annotated_mention_list: [('x-files', 'misc')]\n",
            "non_entity_list: ['break', 'official']\n",
            "x-files\n",
            "2515 ['Schumer', ':', 'Trump', 'doesnt', 'release', 'taxs', ',', 'will', 'make', 'tax', 'reform', 'harder']\n",
            "annotated_mention_list: [('schumer', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['tax']\n",
            "schumer\n",
            "trump\n",
            "2516 ['Syria', 'was', 'a', 'BS', 'game', 'to', 'distract', 'from', 'NK', 'game', 'will', 'be', 'BIG', 'distraction', 'that', 'is', 'lethal', 'for', 'all', 'babies', ',', 'children', 'and', 'mankind']\n",
            "annotated_mention_list: [('syria', 'loc'), ('nk', 'loc')]\n",
            "non_entity_list: ['distraction', 'big', 'children']\n",
            "syria\n",
            "nk\n",
            "2517 ['plot', 'is', 'more', 'bonkers', 'than', 'the', 'x-files']\n",
            "annotated_mention_list: [('x-files', 'misc')]\n",
            "x-files\n",
            "2518 ['@USER', 'is', 'trying', 'to', 'undermine', 'the', 'FBI', \"'s\", 'investigation', 'even', 'though', 'he', \"'s\", '\"', 'recused', '\"']\n",
            "annotated_mention_list: [('fbi', 'org')]\n",
            "non_entity_list: ['investigation', 'though']\n",
            "fbi\n",
            "2519 ['Komrade', 'Kushners', 'go', 'into', 'to', 'Gitmo', '.', 'Treason', '.', 'High', 'crimes', 'and', 'Oops', '!']\n",
            "annotated_mention_list: [('komrade kushners', 'misc'), ('gitmo', 'loc')]\n",
            "non_entity_list: ['crimes', 'go', 'treason']\n",
            "komrade kushners\n",
            "gitmo\n",
            "2520 ['We', 'do', \"n't\", 'buy', 'this', 'bullcrap', '@USER', 'All', 'that', 'you', 'Trumps', 'are', 'doing', 'is', 'trying', 'for', 'a', 'cash', 'grab', 'and', 'destructing', 'of', 'our', 'Country', 'before', 'jailtime']\n",
            "annotated_mention_list: [('trumps', 'misc')]\n",
            "trumps\n",
            "2521 ['This', 'is', 'all', 'a', 'smoke', 'screen', '.', 'Putin', 'wants', 'us', 'to', 'believe', 'they', 'are', \"n't\", 'in', 'cahoots', 'w', '/', 'trump', '.', 'Dangerous', 'things', 'could', 'happen', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['wants', 'things', 'us']\n",
            "putin\n",
            "trump\n",
            "2522 ['It', \"'s\", 'genetic', '.']\n",
            "annotated_mention_list: []\n",
            "2523 ['Only', '33121', 'hours', 'until', 'the', 'end', 'of', 'President', 'Trump', \"'s\", 'first', 'term', '!']\n",
            "annotated_mention_list: [('president trump', 'per')]\n",
            "non_entity_list: ['first', 'hours', 'end']\n",
            "president trump\n",
            "2524 ['Tillerson', 'in', 'Moscow', ',', 'getting', 'in', 'line', 'with', 'Haley', 'on', 'tough', 'Syria', 'talk']\n",
            "annotated_mention_list: [('tillerson', 'per'), ('moscow', 'loc'), ('haley', 'per'), ('syria', 'loc')]\n",
            "non_entity_list: ['line', 'talk', 'getting']\n",
            "tillerson\n",
            "moscow\n",
            "haley\n",
            "syria\n",
            "2525 ['What', 'is', 'everyone', 'watching', 'this', 'weekend', '?', 'Twins', '?', 'Vikings', '?', 'Or', 'an', 'oldie', 'like', 'x-files', '?']\n",
            "annotated_mention_list: [('twins', 'misc'), ('vikings', 'misc'), ('x-files', 'misc')]\n",
            "non_entity_list: ['watching']\n",
            "twins\n",
            "vikings\n",
            "x-files\n",
            "2526 ['Suggestions', 'on', 'how', 'I', 'would', 'detect', 'that', ',', 'or', 'rather', ';', 'or', 'whether', 'there', 'would', 'be', 'a', 'sql', 'Event', 'log', 'confirming', 'this', '?']\n",
            "annotated_mention_list: [('sql event log', 'misc')]\n",
            "non_entity_list: ['rather']\n",
            "sql event log\n",
            "2527 ['Eric', 'F', '*', 'CK', 'YOURSELF', 'U', 'LOW', 'LIFE', 'CO', '\"', 'KSUCKER', '!', '!', 'GOD', '\"', 'WILL', '\"', 'GET', 'YOU', '!', '!', '!', 'RETWEET', 'RETWEET', 'RETWEET', 'RETWEET', 'RETWEET', 'RETWEET', 'RETWEET', 'RETWEET', 'RETWEET']\n",
            "annotated_mention_list: [('eric', 'per')]\n",
            "non_entity_list: ['co', 'god', 'get', 'low']\n",
            "eric\n",
            "2528 ['did', \"n't\", 'stop', 'Assad', 'from', 'bombing', ',', 'or', 'stop', 'the', 'investigation', ',', 'or', 'change', 'the', 'bad', ',', 'or', 'improve', 'his', 'ratings', '.']\n",
            "annotated_mention_list: [('assad', 'per')]\n",
            "non_entity_list: ['investigation', 'bad', 'bombing', 'stop']\n",
            "assad\n",
            "2529 ['What', 'encryption', 'type', 'does', 'Windows', 'Hello', 'use', 'for', 'fingerprint', 'information', 'on', 'sql', '10', 'latest', 'build', '?']\n",
            "annotated_mention_list: [('windows hello', 'misc'), ('sql 10', 'misc')]\n",
            "non_entity_list: ['use', 'latest']\n",
            "windows hello\n",
            "sql 10\n",
            "2530 ['Good', 'evening', '!', 'Sun', 'will', 'set', 'in', '30', 'minutes', '(', 'local', 'time', '19:28', ')', '[', '11.04', '.', '2017', ']']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['set', 'time', 'good']\n",
            "2531 ['Hey', 'Trump', 'Kids', '-', 'shut', 'the', 'fuck', 'up', '.', 'You', \"'re\", 'ignorant', 'and', 'privileged', 'and', 'do', \"n't\", 'know', 'what', 'you', \"'re\", 'doing', '!', '@USER', '@USER']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['shut', 'kids']\n",
            "trump\n",
            "2532 ['@USER', 'We', 'see', 'you', ',', 'U', 'little', 'U', '!', 'U', 'trickster', 'U', 'So', 'well', 'matched', 'w', '/', 'both', 'of', 'U', 'LIARS', 'EXTRAORDINAIRE']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['see', 'little']\n",
            "2533 ['I', 'like', 'liberals', 'who', 'can', 'do', 'more', 'than', 'one', 'thing', '.', 'But', 'flipping', 'Congress', 'is', ',', 'right', 'now', ',', 'the', 'most', 'important', 'thing', '.']\n",
            "annotated_mention_list: [('liberals', 'misc'), ('congress', 'org')]\n",
            "non_entity_list: ['right', 'thing', 'one']\n",
            "liberals\n",
            "congress\n",
            "2534 ['@USER', 'When', 'are', 'American', 'people', 'going', 'to', 'learn', 'more', 'about', 'investigation', '?', 'Smokescreens', 'abound', ',', 'but', 'we', 'have', \"n't\", 'forgotten', '.']\n",
            "annotated_mention_list: [('american', 'misc')]\n",
            "non_entity_list: ['going', 'people', 'investigation', 'learn']\n",
            "american\n",
            "2535 ['Why', 'would', 'the', 'Mafia', 'waste', 'time', 'on', 'some', 'pasty', 'little', 'girly', 'man', '.', 'It', 'would', 'give', 'them', 'a', 'bad', 'name', '!']\n",
            "annotated_mention_list: [('mafia', 'misc')]\n",
            "non_entity_list: ['little', 'bad', 'give', 'time', 'man', 'name']\n",
            "mafia\n",
            "2536 ['@USER', '@USER', '@USER', 'Great', 'day', 'for', 'me', 'would', 'b', 'liar', '/', 'cheat', 'and', 'his', 'greedy', 'nazi', 'fascist', 'selfish', 'kleptocrats', 'out', 'of', 'WH', 'n', 'handcuffs', 'and', '1', 'way', 'tickt', '2', 'Gitmo', '.']\n",
            "annotated_mention_list: [('nazi', 'misc')]\n",
            "non_entity_list: ['great', 'liar', 'way', 'day', 'fascist']\n",
            "nazi\n",
            "2537 ['New', 'military', 'adviser', 'Ivanka', 'Trump', ':']\n",
            "annotated_mention_list: [('ivanka trump', 'per')]\n",
            "non_entity_list: ['new', 'adviser']\n",
            "ivanka trump\n",
            "2538 ['they', 'are', 'playing', 'einar', 'selvik', 'with', 'KISS', 'tomorrow', '-', '-', 'vikings', '!']\n",
            "annotated_mention_list: [('einar selvik', 'misc'), ('kiss', 'misc'), ('vikings', 'misc')]\n",
            "non_entity_list: ['playing']\n",
            "einar selvik\n",
            "kiss\n",
            "vikings\n",
            "2539 ['From', 'the', 'people', 'who', 'brought', 'you', 'Rubio', \"'s\", 'speedboat', '.']\n",
            "annotated_mention_list: [('rubio', 'per')]\n",
            "non_entity_list: ['brought', 'people']\n",
            "rubio\n",
            "2540 ['Hey', 'Sean', 'Spicer', 'OTD', '1945', 'the', 'US', 'Army', 'reached', 'the', '\"', 'Holocaust', 'Centers', '\"', 'of', 'Buchenwald', 'and', 'Dora', '.', '(', 'Buchenwald', 'were', 'mostly', 'political', 'prisoners', ')']\n",
            "annotated_mention_list: [('sean spicer', 'per'), ('us army', 'org'), ('holocaust centers', 'org'), ('buchenwald', 'loc'), ('dora', 'loc'), ('buchenwald', 'loc')]\n",
            "non_entity_list: ['political', 'army', 'us', 'centers']\n",
            "sean spicer\n",
            "us army\n",
            "holocaust centers\n",
            "buchenwald\n",
            "dora\n",
            "buchenwald\n",
            "2541 ['Could', 'we', 'pause', 'on', 'the', 'Syria', 'stuff', 'for', 'a', 'bit', '.', 'It', \"'s\", 'not', 'like', 'Trump', 'has', 'a', 'strategy', 'anyway', '.', 'And', 'get', 'back', 'to', 'the', 'FBI', 'investig', 'into']\n",
            "annotated_mention_list: [('syria', 'loc'), ('trump', 'per'), ('fbi', 'org')]\n",
            "non_entity_list: ['stuff', 'get', 'back', 'anyway']\n",
            "syria\n",
            "trump\n",
            "fbi\n",
            "2542 ['@USER', '@USER', 'This', 'is', 'the', 'culmination', 'of', 'the', \"'\", 's', 'long', 'game', 'domestic', 'holocaust', '.', 'This', 'is', 'it', '-', '-', 'we', 'either', 'live', 'or', 'die', 'now', '.', '@USER']\n",
            "annotated_mention_list: [('holocaust', 'misc')]\n",
            "non_entity_list: ['live']\n",
            "holocaust\n",
            "2543 ['Israeli', 'missile', 'brings', 'down', 'Syrian', 'jet', 'fighter', 'over', 'Golan', 'Heights']\n",
            "annotated_mention_list: [('israeli', 'loc'), ('syrian', 'misc'), ('golan heights', 'loc')]\n",
            "non_entity_list: ['missile']\n",
            "israeli\n",
            "syrian\n",
            "golan heights\n",
            "2544 ['What', 'to', 'do', 'about', 'Donnie', '?']\n",
            "annotated_mention_list: [('donnie', 'per')]\n",
            "donnie\n",
            "2545 ['All', 'I', 'can', 'say', 'is', '\"', 'thanks', 'Eric', 'for', 'reminding', 'our', 'MSM', 'media', 'to', 'get', 'back', 'to', 'covering', '\"']\n",
            "annotated_mention_list: [('eric', 'per')]\n",
            "non_entity_list: ['media', 'get', 'back', 'say']\n",
            "eric\n",
            "2546 ['Coroner', 'will', 'examine', 'roles', 'played', 'by', 'vic', 'dept', 'of', 'human', 'services', ',', '@USER', 'VictoriaPolice', 'and', 'Rosie', 'Batty', 'in', 'protecting', '#lukebatty', '(', '@USER', 'SimoLove', ')']\n",
            "annotated_mention_list: [('vic dept of human services', 'org'), ('victoriapolice', 'org'), ('rosie batty', 'per'), ('simolove', 'per')]\n",
            "non_entity_list: ['played', 'human', 'roles', 'dept']\n",
            "vic dept of human services\n",
            "victoriapolice\n",
            "rosie batty\n",
            "simolove\n",
            "2547 ['Security', 'is', 'tight', 'at', 'Indonesia', 'Parliament', 'for', 'the', 'inauguration', 'of', 'Joko', 'Widodo']\n",
            "annotated_mention_list: [('indonesia parliament', 'org'), ('joko widodo', 'per'), ('dan_bourchier', 'per')]\n",
            "non_entity_list: ['inauguration']\n",
            "indonesia parliament\n",
            "joko widodo\n",
            "2548 ['#ghpromises', 'Today', '#Takoradi', 'Govt', 'Assurance', 'Committee', 'and', 'GhanaParliament', 'launch', 'Rules', '&', 'digital', 'platform', '@USER', 'STARGhana', '@USER', 'kinnareads', '@USER', 'BBCWorld']\n",
            "annotated_mention_list: [('govt assurance committee', 'org'), ('ghanaparliament', 'org'), ('starghana', 'org'), ('kinnareads', 'org'), ('bbcworld', 'org')]\n",
            "non_entity_list: ['govt', 'platform', 'launch', 'rules']\n",
            "govt assurance committee\n",
            "ghanaparliament\n",
            "starghana\n",
            "kinnareads\n",
            "bbcworld\n",
            "2549 ['Well', ',', '15', 'lives', 'is', 'a', 'small', 'price', 'to', 'pay', 'for', 'a', 'momentary', 'public', 'relations', 'boost', '!', 'Well', 'played', ',', 'Herr', 'Trump', '!']\n",
            "annotated_mention_list: [('herr trump', 'per')]\n",
            "non_entity_list: ['played', 'relations', 'public', 'pay']\n",
            "herr trump\n",
            "2550 ['And', 'there', 'you', 'go', ',', 'the', 'whole', 'reason', 'for', 'the', 'is', 'very', 'real', 'or', 'Eric', 'never', 'would', 'have', 'said', 'that', '!']\n",
            "annotated_mention_list: [('eric', 'per')]\n",
            "non_entity_list: ['said', 'go']\n",
            "eric\n",
            "2551 ['Govt', 'Assurance', 'Committee', 'and', 'GhanaParliament', 'say', 'their', 'figures', \"'\", 'over', 'estimated', 'by', 'significant', 'amount', \"'\"]\n",
            "annotated_mention_list: [('govt assurance committee', 'org'), ('ghanaparliament', 'org')]\n",
            "non_entity_list: ['govt', 'say']\n",
            "govt assurance committee\n",
            "ghanaparliament\n",
            "2552 ['A', 'new', 'era', 'in', 'Trump', '-', 'Duterte', 'relations', '...']\n",
            "annotated_mention_list: [('trump', 'per'), ('duterte', 'per')]\n",
            "non_entity_list: ['new', 'relations']\n",
            "trump\n",
            "duterte\n",
            "2553 ['Watch', 'my', 'speech', 'in', 'the', 'House', 'Judiciary', 'Committee', 'debate', 'on', 'the', 'Colbert', 'Report', 'here', ':']\n",
            "annotated_mention_list: [('house judiciary committee', 'org'), ('colbert report', 'misc')]\n",
            "non_entity_list: ['debate']\n",
            "house judiciary committee\n",
            "colbert report\n",
            "2554 ['@USER', 'It', 'will', 'all', 'fall', 'apart', 'eventually']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['fall']\n",
            "2555 ['@USER', '@USER', 'OMG', '!', 'Someone', 'take', 'his', 'phone', 'away', '!', 'Stop', 'looking', 'for', 'a', 'fight', 'you', 'narcissistic', 'moron', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['take', 'moron', 'fight', 'stop', 'away']\n",
            "2556 ['And', 'probably', 'did', '.', 'There', 'was', 'some', 'evidence', 'In', 'WI', 'that', 'seals', 'were', 'broken', 'on', 'machines', 'in', 'one', 'county', '.', 'That', 'could', 'be', 'a', 'lie', '.', 'Will', 'check', 'further']\n",
            "annotated_mention_list: [('wi', 'loc')]\n",
            "non_entity_list: ['lie', 'one']\n",
            "wi\n",
            "2557 ['The', 'FBI', 'keeps', 'rounding', 'up', 'hackers', 'linked', 'to']\n",
            "annotated_mention_list: [('fbi', 'org')]\n",
            "non_entity_list: ['keeps']\n",
            "fbi\n",
            "2558 ['BUSINESS', 'AS', 'USUAL', 'BETTER', 'CONNECTIONS', 'AND', 'WHO', 'PAID', 'FOR', 'THAT', 'TRIP', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['trip', 'better', 'connections', 'business']\n",
            "2559 ['@USER', '@USER', 'SO', 'weird', '.', 'Tools', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['weird']\n",
            "2560 ['Trump', 'simply', 'turnin', \"'\", 'over', 'his', 'taxes', 'would', 'have', 'been', '84', 'million', 'dollars', 'cheaper', '.']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "trump\n",
            "2561 ['Ya', ',', 'right']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['right']\n",
            "2562 ['That', \"'s\", 'the', 'Kabuki', 'Theater', 'that', 'Spicer', 'is', 'performing', 'in', '.', 'He', \"'s\", 'an', 'Incoherent', 'clown', '!']\n",
            "annotated_mention_list: [('kabuki theater', 'misc'), ('spicer', 'per')]\n",
            "kabuki theater\n",
            "spicer\n",
            "2563 ['jesus', ',', 'you', 'are', 'an', 'imbecile', '@USER', '.', 'so', 'embarrassing', 'that', 'a', 'tweet', 'like', 'this', 'was', 'authored', 'by', 'an', 'adult', ',', 'not', 'a', '4th', 'grader', '.']\n",
            "annotated_mention_list: [('jesus', 'per')]\n",
            "non_entity_list: ['embarrassing', 'tweet']\n",
            "jesus\n",
            "2564 ['@USER', 'To', 'the', 'potential', 'donors', ':', 'BEWARE']\n",
            "annotated_mention_list: []\n",
            "2565 ['But', 'it', 'makes', 'a', 'good', 'media', 'soundbite']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['makes', 'media', 'good']\n",
            "2566 ['Nothing', 'to', 'do', 'with', 'the', 'NRA', 'funding', 'her', 'father', \"'s\", '/', 'Russian', 'campaign', 'for', 'POTUS', 'I', 'do', \"n't\", 'suppose', '?']\n",
            "annotated_mention_list: [('nra', 'org'), ('russian', 'misc'), ('potus', 'per')]\n",
            "non_entity_list: ['campaign', 'father']\n",
            "nra\n",
            "russian\n",
            "potus\n",
            "2567 ['Trying', 'to', 'silence', '@USER', 'with', 'account', 'termination', '?', 'I', 'smell', 'fear', 'in']\n",
            "annotated_mention_list: []\n",
            "2568 ['Bot', 'Oligarch', '@USER', '@USER', '@USER', '@USER', '@USER']\n",
            "annotated_mention_list: []\n",
            "2569 ['CORRUPTION', '@USER', 'WALK', 'THE', 'PLANK', 'WALK', 'THE', 'PLANK', 'WALK', 'THE', 'PLANK']\n",
            "annotated_mention_list: []\n",
            "2570 ['Breaking', ':', 'Panicked', 'White', 'House', 'forbids', 'reporting', 'on', 'Russia', 'briefing', 'via', '@USER']\n",
            "annotated_mention_list: [('white house', 'loc'), ('russia', 'loc')]\n",
            "non_entity_list: ['breaking']\n",
            "white house\n",
            "russia\n",
            "2571 ['There', 'is', 'some', 'genetic', 'mutation', 'in', 'that', 'gene', 'pool', '.']\n",
            "annotated_mention_list: []\n",
            "2572 ['This', 'guy', 'has', 'the', 'great', 'power', 'of', 'the', 'majority', 'in', 'Washington', '.', 'Doing', 'nothing', 'to', 'dig', 'into', 'elections', 'corruption', 'and', 'securing', 'our', 'nation', '.', 'Villain', '.']\n",
            "annotated_mention_list: [('washington', 'loc')]\n",
            "non_entity_list: ['great', 'guy', 'nation', 'power']\n",
            "washington\n",
            "2573 ['I', 'knew', 'and', 'said', 'this', 'air', 'strike', 'was', 'BS', 'when', 'it', 'was', 'announced', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['strike', 'said', 'knew', 'air']\n",
            "2574 ['@USER', 'Wake', 'Up', '!', '!', 'For', 'FREEDOM', ',', 'RIGHTS', ',', 'pride', ',', 'Honor', ',', 'Morality', '!']\n",
            "annotated_mention_list: []\n",
            "2575 ['B', '.', 'S', '.', 'that', 'does', 'not', 'prove', 'theres', 'no', 'trump', '-', 'russia', 'connection', '.', 'We', 'r', 'brighter', 'than', 'that', '..', 'Ur', 'FAM', 'must', 'have', 'thought', 'it', 'be', 'the', 'outcome', 'from', 'strike']\n",
            "annotated_mention_list: [('trump', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['strike', 'connection', 'thought']\n",
            "trump\n",
            "russia\n",
            "2576 ['With', 'lots', 'of', 'help', 'from', 'Russia', '.']\n",
            "annotated_mention_list: [('russia', 'loc')]\n",
            "non_entity_list: ['help']\n",
            "russia\n",
            "2577 ['They', 'want', 'to', 'build', 'in', 'Seattle', 'too', '.', 'Watch', 'the', 'backlash', 'on', 'that', 'one', '.', 'Truly', 'a', 'NIMBY', 'situation', '.']\n",
            "annotated_mention_list: [('seattle', 'loc'), ('nimby', 'misc')]\n",
            "non_entity_list: ['one']\n",
            "seattle\n",
            "nimby\n",
            "2578 ['@USER', 'do', 'you', 'know', 'anything', 'about', 'the', 'membership', 'of', 'mar', 'a', 'lago', '?', 'Who', 'are', 'these', 'people', 'that', 'have', 'so', 'much', 'access', 'to', 'Trump', 'on', 'weekends', '?']\n",
            "annotated_mention_list: [('mar a lago', 'loc'), ('trump', 'per')]\n",
            "non_entity_list: ['people']\n",
            "mar a lago\n",
            "trump\n",
            "2579 ['THIS', 'IS', 'The', 'Apprentice', '-', 'White', 'House', 'version', '.']\n",
            "annotated_mention_list: [('apprentice', 'misc'), ('white house', 'org')]\n",
            "non_entity_list: ['version']\n",
            "apprentice\n",
            "white house\n",
            "2580 ['We', 'are', 'under', 'authoritarian', 'rule', '.']\n",
            "annotated_mention_list: []\n",
            "2581 ['Obama', ':', 'The', 'U', '.', 'S', '.', 'will', 'meet', 'ISIL', \"'\", 'with', 'strength', 'and', 'resolve', '.', \"'\"]\n",
            "annotated_mention_list: [('obama', 'per'), ('u . s', 'loc'), ('isil', 'org')]\n",
            "obama\n",
            "u . s\n",
            "isil\n",
            "2582 ['President', 'Obama', 'is', 'addressing', 'the', 'nation', 'now', 'about', 'his', 'ISIL', 'strategy', '.', 'Watch', 'on', 'CNN']\n",
            "annotated_mention_list: [('president obama', 'per'), ('isil', 'org'), ('cnn', 'org')]\n",
            "non_entity_list: ['nation']\n",
            "president obama\n",
            "isil\n",
            "cnn\n",
            "2583 ['What', \"'\", 's', 'the', 'plan', ',', 'Mr', '.', 'President', '?', 'Here', 'are', '5', 'questions', 'he', 'must', 'answer', 'about', 'the', 'ISIL', 'strategy']\n",
            "annotated_mention_list: [('isil', 'org')]\n",
            "non_entity_list: ['answer', 'questions', 'plan']\n",
            "isil\n",
            "2584 ['He', \"'s\", 'right']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['right']\n",
            "2585 ['Eric', 'Trump', 'Syria', \"'s\", 'deployment', 'of', 'chemical', 'weapons', 'against', 'its', 'own', 'people', ',', 'and', 'the', 'U', '.', 'S', '.', 'missile', '...']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('syria', 'loc'), ('u . s', 'loc')]\n",
            "non_entity_list: ['chemical', 'people', 'missile', 'weapons']\n",
            "eric trump\n",
            "syria\n",
            "u . s\n",
            "2586 ['Too', 'Many']\n",
            "annotated_mention_list: []\n",
            "2587 ['Oh', 'look', 'a', 'masked', 'liberal', 'w', '/', 'a', 'no', 'fear', 'banner', 'and', 'a', 'bunch', 'of', '\"', 'ists', '\"', 'in', 'his', 'bio', 'Yawn', '...']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['look']\n",
            "2588 ['So', 'Mass', 'Media', '...', 'or', 'w', '/', 'CIA', 'secret', 'briefings', 'on', 'Trump', 'Campaign', 'communicating', 'w', '/', 'Russian', 'Agents', ',', 'to', 'Congress', 'year', 'ago', '!']\n",
            "annotated_mention_list: [('cia', 'org'), ('trump campaign', 'misc'), ('russian', 'misc'), ('congress', 'org')]\n",
            "non_entity_list: ['media', 'campaign']\n",
            "cia\n",
            "trump campaign\n",
            "russian\n",
            "congress\n",
            "2589 ['How', 'do', 'mass', 'protests', 'work', '?', '@USER', 'explains']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['work', 'protests']\n",
            "2590 ['They', 'should', 'fit', 'right', 'in', 'with', 'Duterte', '.']\n",
            "annotated_mention_list: [('duterte', 'per')]\n",
            "non_entity_list: ['right']\n",
            "duterte\n",
            "2591 ['Thats', 'not', 'so', 'surprising', '.', 'Putin', 'is', 'ex', '-', 'KGB', 'and', 'Russia', 'is', 'not', 'known', 'for', 'human', 'rights', '..']\n",
            "annotated_mention_list: [('putin', 'per'), ('kgb', 'org'), ('russia', 'loc')]\n",
            "non_entity_list: ['human']\n",
            "putin\n",
            "kgb\n",
            "russia\n",
            "2592 ['I', 'also', 'heard', 'grandpa', 'was', 'a', 'youth', 'nazi', '.', 'Can', 'anyone', 'confirm', 'that', '?']\n",
            "annotated_mention_list: [('nazi', 'misc')]\n",
            "non_entity_list: ['heard']\n",
            "nazi\n",
            "2593 ['Trump', ',', 'govt', ',', 'oil', '...', 'This', 'is', 'subtle', 'Russian', 'imperialism', ',', 'slow', 'take', 'over', 'without', 'firing', 'a', 'shot', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('russian', 'misc')]\n",
            "non_entity_list: ['oil', 'take', 'govt']\n",
            "trump\n",
            "russian\n",
            "2594 ['@USER', 'Do', \"n't\", 'know', 'who', 'does', 'these', 'satirical', 'cartoons', ',', 'beautiful', 'and', 'funny', 'and', 'cuts', 'to', 'the', 'bone', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['beautiful']\n",
            "2595 ['RT', '@USER', ':', 'Spawn', 'confirmed', 'Daddy', \"'s\", 'Syria', '\"', 'raid', '\"', 'was', 'a', 'cynical', 'stunt', '.', '@USER', '...']\n",
            "annotated_mention_list: [('syria', 'loc')]\n",
            "non_entity_list: ['daddy']\n",
            "syria\n",
            "2596 ['Hey', 'KS', ':', 'Get', 'te', 'fuck', 'up', 'and', 'vote', '.', 'Turn', 'your', 'state', 'BLUE', '!', '!']\n",
            "annotated_mention_list: [('ks', 'loc')]\n",
            "non_entity_list: ['get', 'state']\n",
            "ks\n",
            "2597 ['@USER', 'will', 'probably', 'have', 'all', 'of', 'the', 'info', 'on', 'this', 'tonight', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['info']\n",
            "2598 ['@USER', 'Breaking', 'ground', 'or', 'digging', 'where', 'the', 'caskets', 'will', 'be', 'placed', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['breaking']\n",
            "2599 ['Are', \"n't\", 'they', 'the', 'most', 'precious', 'little', 'silver', 'spooned', 'punks', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['little']\n",
            "2600 ['MOSCOW', ',', 'April', '11', '.', '/', 'TASS', '/', '.', 'The', 'delegation', 'will', 'arrive', 'at', 'the', '6th', 'Conference', '...']\n",
            "annotated_mention_list: [('moscow', 'loc')]\n",
            "non_entity_list: ['conference']\n",
            "moscow\n",
            "2601 ['I', 'am', 'a', 'huge', 'Omar', 'Sharif', 'fan', '.', 'This', 'is', 'another', 'Omar', 'whose', 'work', 'never', 'fails', 'impress', '...', '{', 'Thread', '}']\n",
            "annotated_mention_list: [('omar sharif', 'per'), ('omar', 'per')]\n",
            "non_entity_list: ['work', 'impress', 'fan']\n",
            "omar sharif\n",
            "omar\n",
            "2602 ['@USER', '@USER', 'Every', 'day', 'plays', 'roulette', 'w', '/', 'our', 'lives', '.', 'Our', 'country', 'and', 'world', \"can't\", 'wait', 'much', 'longer', 'to', 'the', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['wait', 'world', 'day', 'longer']\n",
            "2603 ['@USER', '@USER', 'The', 'name', 'is', 'synonymous', 'with', 'liar', '.', 'Bad', 'source', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['liar', 'source', 'bad', 'name']\n",
            "2604 ['Impeach', 'Trump', 'like', 'it', 'never', 'happened', 'They', 'are', \"n't\", 'talking', 'about', 'it', 'It', \"'s\", 'up', 'to', 'us', 'to', 'pressure', 'the', 'media', 'to', 'do', 'the', 'right', 'thing', 'and', 'keep', 'Headline']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['right', 'thing', 'us', 'media', 'talking']\n",
            "trump\n",
            "2605 ['Protected', 'by', 'secret', 'service', 'using', 'the', 'Trumps', 'r', 'enriching', 'themselves', 'and', 'do', \"n't\", 'care', 'about', 'the', 'average', 'American']\n",
            "annotated_mention_list: [('trumps', 'misc'), ('american', 'misc')]\n",
            "non_entity_list: ['service', 'using']\n",
            "trumps\n",
            "american\n",
            "2606 ['@USER', 'Maybe', 'this', 'is', 'a', 'good', 'time', 'for', 'Congress', 'to', 'cut', 'their', 'vacation', 'short', '?']\n",
            "annotated_mention_list: [('congress', 'org')]\n",
            "non_entity_list: ['vacation', 'cut', 'time', 'good', 'short']\n",
            "congress\n",
            "2607 ['@USER', '@USER', 'Hey', '!', '@USER', 'is', 'buying', 'it', '.']\n",
            "annotated_mention_list: []\n",
            "2608 ['@USER', '@USER', '@USER', 'Did', '45', 'have', 'hacking', 'help', 'in', 'that', '27', 'point', 'win', '?', 'Hope', 'the', 'hacking', 'is', 'done', 'and', 'is', \"n't\", 'going', 'to', '\"', 'help', '\"', 'Estes', '.']\n",
            "annotated_mention_list: [('estes', 'org')]\n",
            "non_entity_list: ['going', 'win', 'help']\n",
            "estes\n",
            "2609 ['@USER', '@USER', '@USER', '@USER', 'Huh', '?', 'Someone', 'has', 'less', 'IQ', 'than', '?', '?', '!', '!']\n",
            "annotated_mention_list: []\n",
            "2610 ['@USER', 'The', 'people', 'are', 'coming', 'after', 'the', 'traitor', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['people', 'traitor']\n",
            "2611 ['Thank', 'you', '!']\n",
            "annotated_mention_list: []\n",
            "2612 ['Town', 'hall', 'crowd', 'chants', '\"', 'you', 'lie', '\"', 'at', 'GOP', 'who', 'yelled', '\"', 'you', 'lie', '\"', 'at', 'Obama', 'in', '2009']\n",
            "annotated_mention_list: [('gop', 'org'), ('obama', 'per')]\n",
            "non_entity_list: ['lie', 'hall']\n",
            "gop\n",
            "obama\n",
            "2613 ['Doc', ':', 'Eric', 'Trump', 'said', 'that', 'the', 'Trump', 'Hotel', 'Collection', 'is', 'looking', 'for', 'markets', 'in', 'Russia']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('trump hotel collection', 'misc'), ('russia', 'loc')]\n",
            "non_entity_list: ['said']\n",
            "eric trump\n",
            "trump hotel collection\n",
            "russia\n",
            "2614 ['@USER', 'Your', 'tweet', 'has', 'been', 'liked', 'by', '250', 'people', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['people', 'liked', 'tweet']\n",
            "2615 ['@USER', 'Congrats', 'on', 'your', 'tweet', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['tweet']\n",
            "2616 ['Feels', 'like', 'we', \"'re\", 'in', 'some', 'James', 'Bond', 'movie', '!', 'We', 'must', 'and', 'PERSIST', 'until', 'the', 'TRUTH', 'is', 'REVEALED', '!']\n",
            "annotated_mention_list: [('james bond', 'per')]\n",
            "non_entity_list: ['movie', 'feels']\n",
            "james bond\n",
            "2617 ['We', 'up', 'shits', 'creek', 'without', 'a', 'paddle', 'with', 'this', 'man', 'at', 'helm', '.', 'We', 'are', 'doomed', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['doomed', 'man']\n",
            "2618 ['Great', '.', 'Now', 'Trump', 'will', 'know', 'what', 'to', 'do', 'to', 'increase', 'his', 'assets', 'overseas', '.', 'Worst', 'conflict', 'of', 'interest', 'in', 'US', 'history', '.', 'Where', 'does', 'it', 'end', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('us', 'loc')]\n",
            "non_entity_list: ['great', 'history', 'conflict', 'end']\n",
            "trump\n",
            "us\n",
            "2619 ['2018', 'it', \"'s\", 'around', 'the', 'corner', '/', 'wake', 'up', 'dems', '!']\n",
            "annotated_mention_list: [('dems', 'misc')]\n",
            "dems\n",
            "2620 ['These', 'feckers', 'are', 'bleeding', 'the', 'country', 'dry', 'with', 'their', 'golf', ',', 'graft', ',', 'vacations', ',', 'and', 'multiple', 'homes', 'requiring', 'huge', 'secret', 'service', 'protection', '.']\n",
            "annotated_mention_list: [('golf', 'misc')]\n",
            "non_entity_list: ['service']\n",
            "golf\n",
            "2621 ['@USER', 'Not', 'w', 'as', 'commander-in-chief', '.', 'No', 'trust', '.', 'Impeach', '@USER', 'then', 'US', 'can', 'get', 'serious', 'about', 'US', 'direction', '.']\n",
            "annotated_mention_list: [('us', 'loc'), ('us', 'loc')]\n",
            "non_entity_list: ['get', 'direction', 'trust']\n",
            "us\n",
            "us\n",
            "2622 ['@USER', 'Hypocrite', '!', 'You', 'are', 'ruining', 'the', 'country', '.', 'Step', 'down', 'before', 'you', 'bankrupt', 'us', '.', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['us']\n",
            "2623 ['Here', 'is', 'more', 'proof', '..', 'how', 'much', 'do', 'u', 'need', '2', 'arrest', 'or', 'tear', 'down', 'this', 'Empire', '..', 'so', 'much', 'damage', 'is', 'going', 'on', 'here', '..', 'not', 'what', 'the', 'majority', 'voices', 'want']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['going', 'need', 'voices', 'empire']\n",
            "2624 ['@USER', 'No', ',', 'no', 'it', 'does', \"n't\", '.', 'In', 'fact', '@USER', 'basically', 'confirms', 'the', 'collusion', 'exists', '.', 'Release', ',', 'complete', 'probe', '.', 'Now', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['confirms', 'probe', 'exists', 'collusion', 'complete']\n",
            "2625 ['Which', 'we', 'knew', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['knew']\n",
            "2626 ['Mazeltov', 'on', 'being', 'blocked', 'by', 'Eric', 'Trump', '!']\n",
            "annotated_mention_list: [('eric trump', 'per')]\n",
            "eric trump\n",
            "2627 ['There', \"'s\", 'a', 'reason', 'for', 'that', '.']\n",
            "annotated_mention_list: []\n",
            "2628 ['@USER', 'Thanks', 'for', 'the', 'follow', 'honey']\n",
            "annotated_mention_list: []\n",
            "2629 ['@USER', 'You', 'are', 'in', 'the', 'majority']\n",
            "annotated_mention_list: []\n",
            "2630 ['What', 'are', 'we', 'trying', 'to', 'accomplish', 'and', 'how', 'can', 'we', 'get', 'to', 'NORMAL', '?', 'ever', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['get']\n",
            "2631 ['@USER', 'We', 'should', 'have', 'waited', 'for', 'the', 'investigation', 'of', 'before', 'nomination', 'was', 'considered', '.', 'Hmm', ',', 'just', 'like', 'GOP', 'waited', 'a', 'year', 'for', 'an', 'election']\n",
            "annotated_mention_list: [('gop', 'org')]\n",
            "non_entity_list: ['investigation', 'election']\n",
            "gop\n",
            "2632 ['vid', 'RAW', 'Aftermath', 'of', 'trains', 'head-on', 'collision', 'in', 'dozens', 'hospitalized']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['raw']\n",
            "2633 ['Not', 'moving', 'to', 'Canada', '.', 'Still', 'do', \"n't\", 'like', 'you', '.', '@USER']\n",
            "annotated_mention_list: [('canada', 'loc')]\n",
            "canada\n",
            "2634 ['No', 'you', \"'re\", 'looking', 'for', 'a', 'distraction', 'from', 'all', 'your', 'treasonous', 'bullshit', '.', 'You', 'could', \"n't\", 'even', 'shut', 'down', 'an', 'airbase', 'dumbass', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['distraction', 'airbase', 'shut']\n",
            "2635 ['Tax', 'day', 'cometh']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['day', 'tax']\n",
            "2636 ['...', 'why', 'Russia', '?', '@USER', '@USER', '@USER']\n",
            "annotated_mention_list: [('russia', 'loc')]\n",
            "russia\n",
            "2637 ['Do', \"n't\", 'let', 'the', 'bombs', 'distract', 'you', ',', 'people', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['people', 'bombs']\n",
            "2638 ['Transition']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['transition']\n",
            "2639 ['Russia', ',', 'The', 'Place', 'Where', 'U', '.', 'S', '.', 'Presidents', 'Get', 'Their', 'Hopes', 'Dashed']\n",
            "annotated_mention_list: [('russia', 'loc'), ('u . s', 'loc')]\n",
            "non_entity_list: ['presidents', 'get']\n",
            "russia\n",
            "u . s\n",
            "2640 ['That', 'is', 'indeed', 'what', 'Eric', 'Trump', 'said', ',', 'to', '\"', 'The', 'Telegraph', '\"', '.']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('telegraph', 'org')]\n",
            "non_entity_list: ['said']\n",
            "eric trump\n",
            "telegraph\n",
            "2641 ['Doc', ':', 'Donald', 'Trump', \"'s\", 'Foundation', 'gave', '$', '100,000', 'to', 'the', 'Eric', 'Trump', 'Foundation', 'in', '2010']\n",
            "annotated_mention_list: [('donald trump', 'per'), ('eric trump foundation', 'org')]\n",
            "non_entity_list: ['gave', 'foundation']\n",
            "donald trump\n",
            "eric trump foundation\n",
            "2642 ['Just', 'Blowing', 'SMOKE', 'MEANS', 'NOTHING', ',']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['means']\n",
            "2643 ['Hopefully', 'Bevis', 'and', 'Butthead', 'are', 'digging', 'their', 'own', 'graves', 'here', '.', 'We', \"'ll\", 'kno', 'for', 'sure', 'when', 'Daddy', \"'s\", 'private', 'FBI', 'investigation', 'is', 'over', '!']\n",
            "annotated_mention_list: [('bevis', 'per'), ('fbi', 'org')]\n",
            "non_entity_list: ['investigation', 'butthead', 'daddy']\n",
            "bevis\n",
            "fbi\n",
            "2644 ['Stay', 'on', 'it', '...']\n",
            "annotated_mention_list: []\n",
            "2645 ['Unday', '?', 'Fredo', '?']\n",
            "annotated_mention_list: [('fredo', 'per')]\n",
            "fredo\n",
            "2646 ['@USER', '@USER', 'True', '.', 'I', 'think', 'they', 'decided', 'to', 'focus', 'on', 'Trump', '.', 'When', 'you', 'add', 'remarks', 'of', 'Giuliani', 'and', 'others', ',', 'observable', 'collusion', 'is', 'overwhelming', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('giuliani', 'per')]\n",
            "non_entity_list: ['think', 'remarks', 'collusion', 'others']\n",
            "trump\n",
            "giuliani\n",
            "2647 ['Theory', ':', 'trump', 'believes', 'if', 'he', 'starts', 'a', 'war', 'all', 'will', 'be', 'forgiven', 'and', 'forgotten']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['war', 'believes', 'starts', 'theory']\n",
            "trump\n",
            "2648 ['hey', '@USER', 'We', 'care', '!', '@USER']\n",
            "annotated_mention_list: []\n",
            "2649 ['What', \"'s\", 'this', 'CLOWN', '.', 'Doing', 'at', 'the', 'min', '.', ',', 'does', \"n't\", 'know', '*', '*', '*', ',', 'look', 'out', 'Spicer', ',', 'your', 'job', 'is', 'doomed', '.', 'Trump', ',', 'Keep', 'the', 'bucket', 'pups', 'out', 'of', 'site']\n",
            "annotated_mention_list: [('spicer', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['doomed', 'job', 'look']\n",
            "spicer\n",
            "trump\n",
            "2650 ['It', 'was', 'brilliant', '!', 'Say', 'words', 'that', 'gaslight', 'Dad', \"'s\", 'problems', 'and', 'it', 'will', 'all', 'go', 'away', '...', 'NOT', '!', 'Which', 'one', 'is', 'Eric', '?', 'Beavis', 'or', 'Butthead', '?']\n",
            "annotated_mention_list: [('eric', 'per'), ('beavis', 'per')]\n",
            "non_entity_list: ['go', 'brilliant', 'say', 'dad', 'butthead', 'away', 'one']\n",
            "eric\n",
            "beavis\n",
            "2651 ['@USER', '@USER', 'hey', 'Eric', '!', 'We', 'do', 't', 'believe', 'you', 'any', 'more', 'than', 'we', 'believe', 'your', 'dad', '.']\n",
            "annotated_mention_list: [('eric', 'per')]\n",
            "non_entity_list: ['dad']\n",
            "eric\n",
            "2652 ['Distraction', '.', 'Somebody', 'remind', 'him', 'that', 'bombing', 'does', \"n't\", 'raise', 'his', \"'\", 'ratings', \"'\", ',', 'please', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['distraction', 'bombing']\n",
            "2653 ['Ca', \"n't\", 'buy', ',', 'slink', 'and', 'use', 'smoking', 'mirrors', 'to', 'get', 'out', 'of', 'this', 'one', 'AND', 'YOU', \"CAN'T\", 'BLAME', 'OBAMA', 'you', 'are', 'goind', 'down', 'son', '!']\n",
            "annotated_mention_list: [('obama', 'per')]\n",
            "non_entity_list: ['get', 'use', 'blame', 'son', 'one']\n",
            "obama\n",
            "2654 ['Trump', \"'s\", 'Russia', 'connection', '!']\n",
            "annotated_mention_list: [('trump', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['connection']\n",
            "trump\n",
            "russia\n",
            "2655 ['We', 'met', 'with', '@USER', \"'\", 's', 'staff', 'to', 'discuss', 'ties', ',', ',', 'and', 'support', 'for', 'the', '.', 'Take', 'a', 'stand', ',', 'Vern', '!', '@USER']\n",
            "annotated_mention_list: [('vern', 'per')]\n",
            "non_entity_list: ['ties', 'take', 'support', 'staff']\n",
            "vern\n",
            "2656 ['Already', 'been', 'broke', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['already']\n",
            "2657 ['As', 'everyone', 'suspected', '.']\n",
            "annotated_mention_list: []\n",
            "2658 ['@USER', '@USER', 'If', 'one', 'had', 'been', 'undocumented', 'or', 'Muslim', 'he', 'would', 'have', 'commented', '.']\n",
            "annotated_mention_list: [('muslim', 'misc')]\n",
            "non_entity_list: ['one']\n",
            "muslim\n",
            "2659 ['@USER', 'No', ',', 'Eric', '\"', 'Qusay', '\"', 'Trump', '.', 'There', 'is', 'still']\n",
            "annotated_mention_list: [('eric \" qusay \" trump', 'per')]\n",
            "eric \" qusay \" trump\n",
            "2660 ['Never', 'about', '@USER']\n",
            "annotated_mention_list: []\n",
            "2661 ['@USER', '@USER', 'DumbassEric', 'keeps', 'letting', 'bits', 'of', 'truth', 'slip', 'out', '-', 'time', 'to', 'send', 'him', 'out', 'of', 'town', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['keeps', 'time']\n",
            "2662 ['I', \"'m\", 'jealous', '.', '@USER']\n",
            "annotated_mention_list: []\n",
            "2663 ['2018', 'California', '.', 'Let', \"'s\", 'get', 'rid', 'of', 'this', 'rotten']\n",
            "annotated_mention_list: [('california', 'loc')]\n",
            "non_entity_list: ['get']\n",
            "california\n",
            "2664 ['Thanks', ',', 'the', 'truth', 'will', 'out', '.', 'Inept', 'trolls', 'like', 'Jamali', 'can', 'only', 'help', 'Trump', 'so', 'much', '.']\n",
            "annotated_mention_list: [('jamali', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['help', 'trolls']\n",
            "jamali\n",
            "trump\n",
            "2665 ['Of', 'course', 'they', 'are']\n",
            "annotated_mention_list: []\n",
            "2666 ['Hey', 'Eric', 'Trump', ',', 'was', 'done', 'by', 'Russia', 'for', 'Trump', '.', 'now', '!']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('russia', 'loc'), ('trump', 'per')]\n",
            "eric trump\n",
            "russia\n",
            "trump\n",
            "2667 ['Marmel', '250s', '!', 'Your', 'tweet', 'has', 'been', 'liked', 'by', '250', 'people', '.']\n",
            "annotated_mention_list: [('marmel', 'per')]\n",
            "non_entity_list: ['people', 'liked', 'tweet']\n",
            "marmel\n",
            "2668 ['Marmel', 'Congrats', 'on', 'your', '250', 'tweet', '!']\n",
            "annotated_mention_list: [('marmel', 'per')]\n",
            "non_entity_list: ['tweet']\n",
            "marmel\n",
            "2669 ['This', 'is', 'for', '@USER', 'and', 'GOP', ',', 'if', 'any', 'of', 'you', 'can', 'read', '.']\n",
            "annotated_mention_list: [('gop', 'org')]\n",
            "gop\n",
            "2670 ['Thank', 'You', ',', 'Karma', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['karma']\n",
            "2671 ['Tax', 'dodging', 'is', 'fun', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['tax']\n",
            "2672 ['@USER', 'Also', ',', 'forensic', 'evidence', 'is', 'the', 'enemy', 'of', 'every', 'criminal', '.', 'Just', 'sayin', \"'\", '.']\n",
            "annotated_mention_list: []\n",
            "2673 ['@USER', '@USER', '@USER', 'will', 'hold', 'U', 'and', 'Your', 'Party', 'Responsible', 'for', 'this', 'EGREGIOUS', 'KLEPTOCRACY', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['party', 'hold']\n",
            "2674 ['@USER', 'ever', 'heard', 'of', 'freedom', 'of', 'speech', '?', 'If', 'you', 'did', \"n't\", 'do', 'anything', 'you', 'have', 'nothing', 'to', 'hide']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['heard']\n",
            "2675 ['Testified', 'at', 'what', '?', 'I', 'do', \"n't\", 'know', 'if', 'America', 'can', 'take', 'another', 'dumbo', 'Trump', 'running', 'his', 'lying', 'mouth', '.']\n",
            "annotated_mention_list: [('america', 'loc'), ('trump', 'per')]\n",
            "non_entity_list: ['take', 'mouth', 'lying']\n",
            "america\n",
            "trump\n",
            "2676 ['I', \"'m\", 'trying', '.', 'But', 'I', 'took', 'the', 'under', 'on', 'First', '100', 'Days', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['first', 'days', 'took']\n",
            "2677 ['@USER', 'So', 'in', 'other', 'words', 'it', 'moved', 'nowhere', '.', 'They', 'say', 'charity', 'begins', 'at', 'home', 'but', '@USER', 'and', 'family', 'take', 'it', 'too', 'literally', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['family', 'say', 'take']\n",
            "2678 ['The', 'entire', 'Trump', 'family', 'is', 'a', 'family', 'of', 'business', 'whores', 'on', 'taxpayer', 'monies', '!', 'It', \"'s\", 'appalling', '!']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['entire', 'family', 'business']\n",
            "trump\n",
            "2679 ['This', 'is', 'news', '?', 'I', 'remember', 'reading', 'that', 'many', 'were', 'foreign', 'buyers', 'and', 'that', 'some', 'were', 'Russian', 'before', 'now', '.', 'Recall', 'something', 'about', 'mob', 'ties', 'too', '.']\n",
            "annotated_mention_list: [('russian', 'misc')]\n",
            "non_entity_list: ['reading', 'foreign', 'ties', 'news']\n",
            "russian\n",
            "2680 ['Toronto', 'hotel', 'failed', ',', 'think', 'charges', 'of', 'fraud', '.', 'Just', 'before', 'election', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['think', 'election']\n",
            "2681 ['@USER', 'Mr', '.', 'Booker', ',', 'you', 'are', 'my', 'Representative', '.', 'Can', 'you', 'please', 'forward', 'my', 'concern', 'to', 'Congress', 'about', 'Trump', \"'s\", 'actions', '?']\n",
            "annotated_mention_list: [('mr . booker', 'per'), ('congress', 'org'), ('trump', 'per')]\n",
            "mr . booker\n",
            "congress\n",
            "trump\n",
            "2682 ['Hell', 'Yeah', '!']\n",
            "annotated_mention_list: []\n",
            "2683 ['@USER', 'Is', 'this', 'some', 'of', 'Eric', \"'s\", 'idiot', 'behavior', 'being', 'used', 'by', '45', 'as', 'an', 'attempt', 'to', 'create', 'a', 'distraction', 'from', '45s', 'major', 'prob', '?']\n",
            "annotated_mention_list: [('eric', 'per')]\n",
            "non_entity_list: ['distraction', 'idiot', 'used']\n",
            "eric\n",
            "2684 ['Evidently', 'you', 'THINK', 'you', 'knew', 'something', 'you', 'absolutely', 'know', 'nothing', 'about', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['think', 'knew']\n",
            "2685 ['Now', 'Playing', 'Disco', 'at', 'Apple', 'and', 'Google']\n",
            "annotated_mention_list: [('apple', 'org'), ('google', 'org')]\n",
            "non_entity_list: ['playing']\n",
            "apple\n",
            "google\n",
            "2686 ['Is', 'this', 'some', 'of', 'Eric', \"'s\", 'idiot', 'behavior', 'being', 'used', 'by', '45', 'as', 'an', 'attempt', 'to', 'create', 'a', 'distraction', 'from', '45s', 'major', 'prob', '?']\n",
            "annotated_mention_list: [('eric', 'per')]\n",
            "non_entity_list: ['distraction', 'idiot', 'used']\n",
            "eric\n",
            "2687 ['@USER', 'That', \"'s\", 'exactly', 'the', 'bait', 'and', 'switch', 'they', 'hoped', 'to', 'convince', 'the', 'world', 'of', '...', 'However', 'it', 'was', 'painfully', 'obvious', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['world', 'convince']\n",
            "2688 ['Trump', 'launches', 'misses', 'to', 'avoid', 'coverage', 'about', 'CIA', 'briefings', 'to', 'Congress', 're', ':', 'his', 'collusion', 'w', 'Russia', 'Watch']\n",
            "annotated_mention_list: [('trump', 'per'), ('cia', 'org'), ('congress', 'org'), ('russia', 'loc')]\n",
            "non_entity_list: ['launches', 'collusion']\n",
            "trump\n",
            "cia\n",
            "congress\n",
            "russia\n",
            "2689 ['Founding', 'father', 'Washington', 'is', 'ashamed']\n",
            "annotated_mention_list: [('washington', 'per')]\n",
            "non_entity_list: ['father']\n",
            "washington\n",
            "2690 ['@USER', '@USER', '@USER', 'I', 'meant', ',', 'the', 'possible', 'ramifications', 'of', 'could', 'include', 'reversal', 'of', 'some', 'actions', 'from', 'a', 'not', 'legitimate', 'presidency', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['meant', 'presidency', 'possible', 'reversal']\n",
            "2691 ['@USER', 'This', 'should', 'confirm', 'the', 'entire', 'episode', 'was', 'scripted', 'jointly', 'by', '@USER', 'and', 'collaborators']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['entire']\n",
            "2692 ['@USER', '@USER', '@USER', 'u', 'are', 'all', 'guilty', 'of', '@USER', 'Wake', 'up', 'America', '!']\n",
            "annotated_mention_list: [('america', 'loc')]\n",
            "america\n",
            "2693 ['NEW', 'Photo', ':', 'Eric', 'Trump', 'and', 'Don', 'Jr', 'breaking', 'ground', 'in', 'the', 'Philippines', 'Scott', 'Dworkin']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('don jr', 'per'), ('philippines', 'loc'), ('scott dworkin', 'per')]\n",
            "non_entity_list: ['new', 'breaking']\n",
            "eric trump\n",
            "don jr\n",
            "philippines\n",
            "scott dworkin\n",
            "2694 ['Doc', ':', 'Eric', 'Trump', 'said', 'the', 'Trump', 'Hotel', 'Collection', 'is', 'looking', 'for', 'markets', 'in', 'Russia']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('trump hotel collection', 'misc'), ('russia', 'loc')]\n",
            "non_entity_list: ['said']\n",
            "eric trump\n",
            "trump hotel collection\n",
            "russia\n",
            "2695 ['Doc', ':', 'Donald', 'Trump', \"'s\", 'foundation', 'gave', '$', '100,000', 'to', 'the', 'Eric', 'Trump', 'Foundation', 'in', '2010']\n",
            "annotated_mention_list: [('donald trump', 'per'), ('eric trump foundation', 'org')]\n",
            "non_entity_list: ['gave', 'foundation']\n",
            "donald trump\n",
            "eric trump foundation\n",
            "2696 ['that', '(', 'prison', 'name', ')', 'will', 'be', 'deeply', 'involved', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['name']\n",
            "2697 ['Meanwhile', 'back', 'at', 'RT', \"'s\", 'THIS', '.', 'It', 'would', 'be', 'hysterically', 'funny', ',', 'if', 'it', 'were', \"n't\", 'so', 'tragic']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['back']\n",
            "2698 ['Earlier', 'today', 'he', 'was', 'asked', 'a', 'question', '/', 'could', \"'ve\", 'condemned', 'Russia', 'but', 'refused', 'to', 'answer', '.', 'Hard', 'headed', 'SOB-what', 'is', 'he', 'hiding', '?', '!', '?', '@USER']\n",
            "annotated_mention_list: [('russia', 'loc')]\n",
            "non_entity_list: ['answer', 'headed', 'asked', 'hard', 'hiding']\n",
            "russia\n",
            "2699 ['Great', 'job', '@USER', '@USER', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['great', 'job']\n",
            "2700 ['@USER', '@USER', '@USER', '@USER', '@USER', '@USER', 'Wait', '...', 'Putin', 'gave', 'him', 'a', 'warning', '?', 'But', ',', 'but', ',', 'but', '.']\n",
            "annotated_mention_list: [('putin', 'per')]\n",
            "non_entity_list: ['gave', 'wait']\n",
            "putin\n",
            "2701 ['I', 'am', 'lying', 'right', 'now', '.', 'On', 'my', 'plane', '.', 'Lacedaemon', ',', 'have', 'no', 'existence', 'at', 'all', '.', 'folks', '.']\n",
            "annotated_mention_list: [('lacedaemon', 'misc')]\n",
            "non_entity_list: ['right', 'lying', 'plane']\n",
            "lacedaemon\n",
            "2702 ['@USER', '@USER', 'Is', 'the', 'red', 'tie', 'and', 'dress', 'a', 'silent', 'nod', 'to', 'uncle', 'Puttie', '?']\n",
            "annotated_mention_list: [('uncle puttie', 'per')]\n",
            "non_entity_list: ['tie', 'uncle']\n",
            "uncle puttie\n",
            "2703 ['American', 'voters', 'should', 'be', 'concerned', 'this', 'man', 'is', 'asking', 'questions', 'in', 'their', 'name', '.']\n",
            "annotated_mention_list: [('american', 'misc')]\n",
            "non_entity_list: ['voters', 'name', 'questions', 'man']\n",
            "american\n",
            "2704 ['\"', 'Pants', 'on', 'Fire', '\"', 'is', 'the', 'only', 'strategy', 'GOP', 'has', 'left', '.']\n",
            "annotated_mention_list: [('gop', 'org')]\n",
            "non_entity_list: ['left', 'fire']\n",
            "gop\n",
            "2705 ['Russian', 'arrested', 'for', \"'\", 'hacking', \"'\", 'US', 'election']\n",
            "annotated_mention_list: [('russian', 'misc'), ('us', 'loc')]\n",
            "non_entity_list: ['election']\n",
            "russian\n",
            "us\n",
            "2706 ['Not', 'much', 'of', 'a', 'choice', 'when', 'they', 'already', 'have', 'BOTH', '.', 'DEMAND', 'a', 'special', 'prosecutor', 'w', '/']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['already', 'demand']\n",
            "2707 ['Nuclear', 'fallout', '.', 'Flowing', 'from', 'Korea', 'to', 'Japan', ',', 'across', 'the', 'Pacific', 'to', 'west', 'coast', 'of', 'USA', 'and', 'Canada', '.']\n",
            "annotated_mention_list: [('korea', 'loc'), ('japan', 'loc'), ('pacific', 'loc'), ('west coast', 'loc'), ('usa', 'loc'), ('canada', 'loc')]\n",
            "non_entity_list: ['fallout']\n",
            "korea\n",
            "japan\n",
            "pacific\n",
            "west coast\n",
            "usa\n",
            "canada\n",
            "2708 ['Hey', '@USER', 'do', 'know', 'what', 'an', 'asshole', 'is', '?', 'Tag', '-', '-', 'you', \"'re\", 'it', '.', 'Nepotism', 'means', 'not', 'have', 'a', 'fucking', 'brain']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['nepotism', 'means', 'asshole']\n",
            "2709 ['3', 'YEARS', '9', 'MONTHS', '8', 'DAYS', '19', 'HOURS', '24', 'MINUTES']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['days', 'hours', 'years']\n",
            "2710 ['@USER', 'sheep', 'have', 'been', 'trumpeting', 'this', 'since', 'last', 'wk', 'They', 'want', 'to', 'go', 'away', 'Soooo', 'bad', '.', 'Tillerson', 'tough', 'talk', 'is', 'attempt']\n",
            "annotated_mention_list: [('tillerson', 'per')]\n",
            "non_entity_list: ['go', 'bad', 'talk', 'last', 'away']\n",
            "tillerson\n",
            "2711 ['@USER', 'Sign', 'Making', 'Party', 'for', 'Rubio', 'Protest', ':', 'Join', 'Us', '!']\n",
            "annotated_mention_list: [('rubio', 'per')]\n",
            "non_entity_list: ['party', 'us']\n",
            "rubio\n",
            "2712 ['It', 'looks', 'like', 'someone', 'learned', 'how', 'to', 'from', 'daddy', '!', '@USER', '@USER', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['daddy']\n",
            "2713 ['Hey', 'Kids', ',', 'Read', 'this', '.', 'I', 'mean', 'REALLY', 'read', 'this', '.', 'Then', 'remember']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['really', 'kids', 'mean']\n",
            "2714 ['How', 'convenient', '.']\n",
            "annotated_mention_list: []\n",
            "2715 ['This', 'bothers', 'me', 'every', 'day', '.', 'Most', 'MSM', 'do', 'not', 'lead', 'or', 'even', 'cover', 'this', 'danger', 'to', 'our', 'country', '.', 'Most', 'MSM', 'are', 'still', 'being', 'bedazzled', 'by', 'DJT', '.']\n",
            "annotated_mention_list: [('djt', 'per')]\n",
            "non_entity_list: ['lead', 'day', 'cover']\n",
            "djt\n",
            "2716 ['@USER', 'bombing', 'Syria', 'was', 'a', 'squirrel', 'meant', 'to', 'distract', 'from', 'plummeting', 'approval', 'rating', 'and']\n",
            "annotated_mention_list: [('syria', 'loc')]\n",
            "non_entity_list: ['bombing', 'meant']\n",
            "syria\n",
            "2717 ['yeah', ',', 'really', 'does', \"n't\", 'prove', 'a', 'thing', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['thing', 'really']\n",
            "2718 ['@USER', '@USER', 'So', 'help', 'me', 'God', ',', 'If', 'this', 'Syrian', 'bombing', 'was', 'orchestrated', 'by', 'your', 'pops', 'to', '\"', 'prove', '\"', 'no', 'connection', ',', \"'\", 'yall', 'belong', 'in', 'jail', '.']\n",
            "annotated_mention_list: [('syrian', 'misc')]\n",
            "non_entity_list: ['help', 'god', 'connection', 'pops', 'bombing']\n",
            "syrian\n",
            "2719 ['Is', 'this', 'the', '@USER', 'investigation', 'that', 'has', 'slowed', 'down', '@USER', 'on', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['investigation']\n",
            "2720 ['2', ')', 'to', 'make', 'Trump', 'look', 'good', '.', 'Remember', 'lifting', 'of', 'sanctions', 'is', 'the', 'goal', 'for', 'all', 'of', 'them', '.', 'Need', 'show', 'Russia', 'cooperating', 'with', 'US', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('russia', 'loc'), ('us', 'loc')]\n",
            "non_entity_list: ['show', 'look', 'need', 'good', 'sanctions']\n",
            "trump\n",
            "russia\n",
            "us\n",
            "2721 ['What', 'in', 'the', 'actual', 'Eff', 'is', 'this', '?', '?', '?', 'Ivanka', \"'s\", 'sad', 'so', 'we', 'bomb', 'Syria', ',', 'oh', 'that', 'makes', 'sense', '.']\n",
            "annotated_mention_list: [('ivanka', 'per'), ('syria', 'loc')]\n",
            "non_entity_list: ['makes', 'bomb']\n",
            "ivanka\n",
            "syria\n",
            "2722 ['Not', 'for', 'me', '...', 'Just', 'hate', 'when', 'MSM', 'falls', 'for', 'the', \"'\", 'shiny', 'object', \"'\", 'trick', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['trick', 'falls']\n",
            "2723 ['@USER', 'Nothing', 'wrong', 'with', 'whites', 'loving', 'and', 'supporting', 'our', 'own', 'race', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['race']\n",
            "2724 ['Stand', 'up', 'by', 'joining', 'a', 'Tax', 'March', 'in', 'your', 'area', '.', 'Details', 'here', ':']\n",
            "annotated_mention_list: [('tax march', 'misc')]\n",
            "non_entity_list: ['march', 'tax']\n",
            "tax march\n",
            "2725 ['God', ',', 'Eric', 'Trump', 'is', 'dumb', '.', 'Does', 'he', 'think', 'telling', 'the', 'world', 'will', 'bomb', 'places', '2', 'turn', 'Ivanka', 'on', 'is', 'going', 'to', 'make', 'anyone', 'comfortable', '?']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('ivanka', 'per')]\n",
            "non_entity_list: ['going', 'bomb', 'god', 'think', 'dumb', 'world']\n",
            "eric trump\n",
            "ivanka\n",
            "2726 ['@USER', 'The', 'rubes', 'have', 'been', 'duped', '.', '@USER']\n",
            "annotated_mention_list: []\n",
            "2727 ['OUR', 'ALLIES', 'and', 'THE', 'REST', 'OF', 'THE', 'WORLD', \"DON'T\", 'HAVE', 'TIME', 'TO', 'BABYSIT', 'DT', \"'s\", 'RECKLESS', 'and', 'INCOMPETENT', 'PRESIDENCY', '!', 'THIS', 'INEXPERIENCED']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['allies', 'rest', 'presidency', 'world', 'time']\n",
            "2728 ['@USER', '@USER', 'It', \"'s\", 'all', 'about', 'polling', 'his', 'number', 'up']\n",
            "annotated_mention_list: []\n",
            "2729 ['Move', 'Trump', 'ethics', 'violations', 'Please', 'RT']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['move']\n",
            "trump\n",
            "2730 ['Trump', 'using', 'Syria', 'strikes', 'to', 'claim', 'there', \"'s\", 'no', 'trump', '-', 'russia', 'connection', 'via', '@USER']\n",
            "annotated_mention_list: [('trump', 'per'), ('syria', 'loc'), ('trump', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['claim', 'strikes', 'using', 'connection']\n",
            "trump\n",
            "syria\n",
            "trump\n",
            "russia\n",
            "2731 ['This', 'needs', 'to', 'stop', '@USER', '@USER', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['needs', 'stop']\n",
            "2732 ['Another', 'way', 'Comrade', 'Trump', 'is', 'enriching', 'himself', 'and', 'his', 'family', '.']\n",
            "annotated_mention_list: [('comrade trump', 'per')]\n",
            "non_entity_list: ['family', 'comrade', 'way']\n",
            "comrade trump\n",
            "2733 ['Since', 'the', 'investigation', 'began', 'in', 'July', ',', 'think', 'about', 'all', 'the', 'treasonous', 'phone', 'calls', 'they', 'might', 'have', 'on', 'Trump', '.', '.', '.']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['investigation', 'think']\n",
            "trump\n",
            "2734 ['@USER', 'I', 'do', \"n't\", 'care', 'if', 'they', 'prop', \"'m\", 'up', 'on', 'the', 'bench', 'in', 'their', 'caskets', ',', 'they', \"'re\", 'NOT', 'ALLOWED', 'TO', 'RETIRE', '!', 'We', \"can't\", 'allow', 'Rump', 'another', 'pick', '.']\n",
            "annotated_mention_list: [('rump', 'per')]\n",
            "rump\n",
            "2735 ['@USER', 'the', 'walls', 'come', 'tumbling', 'down', '.', 'Maybe', 'John', 'Mellencamp', 'will', 'let', 'you', 'play', 'his', 'song', 'on', 'the', 'way', 'to', 'prison', '.']\n",
            "annotated_mention_list: [('john mellencamp', 'per')]\n",
            "non_entity_list: ['way', 'come']\n",
            "john mellencamp\n",
            "2736 ['LOOK', 'AT', 'THESE', 'THINGS', '!', '!', 'Walking', 'around', 'POSING', 'AS', 'HUMANS', '!', 'Nothing', 'Normal', 'about', 'this', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['things', 'look']\n",
            "2737 ['@USER', '@USER', 'too', 'funny', '.', 'not', 'much', 'of', 'a', 'loss', 'there', '.', 'sonny', 'seems', 'to', 'have', 'some', 'issues', 'and', 'they', 'are', 'starting', 'to', 'show', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['show']\n",
            "2738 ['He', \"'s\", 'a', 'moron', 'like', 'his', 'father', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['moron', 'father']\n",
            "2739 ['What', 'would', 'Chaffetz', 'be', 'doing', 'right', 'now', 'if', 'this', 'was', 'Hillary', \"'s\", 'daughter', '?']\n",
            "annotated_mention_list: [('chaffetz', 'per'), ('hillary', 'per')]\n",
            "non_entity_list: ['right', 'daughter']\n",
            "chaffetz\n",
            "hillary\n",
            "2740 ['@USER', '@USER', 'Love', 'the', 'idea', 'but', 'I', \"'m\", 'guessing', 'he', 'would', \"n't\", 'sign', 'and', '@USER', 'is', 'complicit', 'in', 'his', 'terrorizing', 'US']\n",
            "annotated_mention_list: [('us', 'loc')]\n",
            "us\n",
            "2741 ['OF', 'COURSE', 'THEY', 'DID', '!', 'They', \"'ve\", 'gotten', 'away', 'with', 'so', 'much', ',', 'that', 'I', \"'m\", 'sure', 'they', 'believe', 'that', 'LAWS', 'do', 'NOT', 'APPLY', 'to', 'them', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['away']\n",
            "2742 ['@USER', '@USER', '@USER', '@USER', 'This', 'is', 'on', 'you', '!', 'We', 'will', 'hold', 'U', 'accountable', 'for', 'voting', 'against', 'seeing', 'Trump', \"'s\", 'taxes']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['hold']\n",
            "trump\n",
            "2743 ['Something', 'is', 'mentally', 'wrong', 'with', 'him', '...', 'We', 'need', 'doctor', 'diagnosis', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['need', 'mentally', 'doctor']\n",
            "2744 ['trump', '/', 'admin', '/', 'campaign', 'INVESTIGATED', 'BY', 'FBI', '4', 'ATTACK', 'ON', 'OUR', 'DEMOCRACY']\n",
            "annotated_mention_list: [('fbi', 'org'), ('democracy', 'misc')]\n",
            "non_entity_list: ['admin', 'attack', 'campaign']\n",
            "fbi\n",
            "democracy\n",
            "2745 ['Nothing', 'to', 'see', 'here', 'People']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['see', 'people']\n",
            "2746 ['Playing', 'Devils', 'advocate', ':', 'What', 'if', 'Russia', 'is', 'telling', 'wife', '2', 'say', 'this', '-', 'trying', '2', 'break', 'those', 'that', 'still', 'support', 'Trump', '-', 'like', 'Syria', '-', 'way', 'rites', 'freakd']\n",
            "annotated_mention_list: [('russia', 'loc'), ('trump', 'per'), ('syria', 'loc')]\n",
            "non_entity_list: ['break', 'support', 'way', 'say', 'playing']\n",
            "russia\n",
            "trump\n",
            "syria\n",
            "2747 ['@USER', '@USER', '@USER', '@USER', 'Makes', 'no', 'sense', ',', 'both', 'are', 'fake', 'news', '.', 'Get', 'them', 'out', '.', 'Independent', 'investigation', 'of', '.', 'America', 'demands', 'answers']\n",
            "annotated_mention_list: [('america', 'loc')]\n",
            "non_entity_list: ['investigation', 'get', 'independent', 'makes', 'fake', 'news']\n",
            "america\n",
            "2748 ['Trump', \"'s\", 'arrogance', 'they', 'actually', 'believe', 'they', 'are', 'better', 'than', 'everyone', '!']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['better', 'actually']\n",
            "trump\n",
            "2749 ['The', 'latest', 'The', 'James', 'Barraford', 'Daily', '!', 'Thanks', 'to', '@USER', '@USER', '@USER']\n",
            "annotated_mention_list: [('james barraford daily', 'org')]\n",
            "non_entity_list: ['latest', 'daily']\n",
            "james barraford daily\n",
            "2750 ['@USER', 'Wow', ',', 'does', \"n't\", 'that', 'seem', 'now', 'along', 'with', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['along']\n",
            "2751 ['Why', 'not', '?', 'They', 'already', 'bombed', 'the', 'hospital', 'where', 'proof', 'would', 'have', 'been', 'found', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['already', 'bombed']\n",
            "2752 ['@USER', 'That', 'was', 'a', 'classic', 'change', 'the', 'subject', 'distraction', '!', 'Now', 'that', \"'s\", 'over']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['distraction', 'subject']\n",
            "2753 ['@USER', '@USER', '@USER', 'Spicey', '..', 'it', \"'s\", 'showtime', '!', 'SAD']\n",
            "annotated_mention_list: []\n",
            "2754 ['Absolutely', ',', 'he', 'should', '.']\n",
            "annotated_mention_list: []\n",
            "2755 ['Shut', 'down', 'the', 'and', 'EcoTerror', '!', 'Share', 'and', 'Tweet', '!', 'via', '@USER']\n",
            "annotated_mention_list: [('ecoterror', 'misc')]\n",
            "non_entity_list: ['shut', 'share', 'tweet']\n",
            "ecoterror\n",
            "2756 ['Is', 'this', 'SNL', 'or', 'South', 'Park', '?']\n",
            "annotated_mention_list: [('snl', 'misc'), ('south park', 'misc')]\n",
            "non_entity_list: ['south']\n",
            "snl\n",
            "south park\n",
            "2757 ['No', '\"', 'tie', '\"', '?', 'Yeah', ',', 'because', 'we', 'were', 'all', 'thinking', \"'\", 'noose', \"'\", 'is', 'a', 'more', 'descriptive', 'word', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['tie', 'thinking']\n",
            "2758 ['@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', 'Yep', 'you', 'will', 'continue', 'to', 'see', 'us', 'resistance', '\"', 'loons', '\"', 'until', 'the', 'trump', 'trash', 'is', 'gone', '.', 'mo']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['see', 'gone', 'continue', 'us']\n",
            "2759 ['Neocons', 'Have', 'Trump', 'on', 'His', 'Knees', 'His', 'Syria', 'strike', 'killed', 'beautiful', 'children', 'is', 'dangerous', 'MIC', 'con']\n",
            "annotated_mention_list: [('neocons', 'misc'), ('trump', 'per'), ('syria', 'loc')]\n",
            "non_entity_list: ['con', 'children', 'killed', 'beautiful', 'strike', 'mic']\n",
            "neocons\n",
            "trump\n",
            "syria\n",
            "2760 ['and', 'likely', 'billing', 'the', 'US', 'taxpayers', 'for', 'the', 'trip', 'as', 'always-fuckin', 'freeloading', 'hillbillies', '@USER']\n",
            "annotated_mention_list: [('us', 'loc')]\n",
            "non_entity_list: ['trip', 'taxpayers']\n",
            "us\n",
            "2761 ['To', 'Send', 'Clear', 'Message', 'To', 'At', 'Talks']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['message', 'talks']\n",
            "2762 ['Just', 'like', 'their', 'sperm', 'donor', '...', 'trying', 'to', 'be', 'MORE', 'than', 'they', 'Actually', 'ARE', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['actually']\n",
            "2763 ['Follow', 'the', 'money', 'Follow', 'the', 'Data', 'Russian', 'connection', '/', 'Taxes', 'Oil', ',', 'Politics', ',', 'GREED', ',', 'and', 'Lies', 'illegitimately', 'elected', ',']\n",
            "annotated_mention_list: [('russian', 'misc')]\n",
            "non_entity_list: ['politics', 'money', 'connection', 'lies', 'elected', 'oil']\n",
            "russian\n",
            "2764 ['This', 'might', 'be', 'the', 'most', 'mentally', 'ill', 'thing', 'yet', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['thing', 'mentally']\n",
            "2765 ['@USER', 'Doing', 'US', 'disservice', '2', 'threaten', 'NK', ',', 'Syria', 'w', '/', 'NO', 'strategy', '/', 'policy', '4', 'long', 'term', '.', 'BTW', 'we', 'will', 'NOT', 'drop', '@USER', '@USER']\n",
            "annotated_mention_list: [('nk', 'loc'), ('syria', 'loc')]\n",
            "non_entity_list: ['us', 'threaten']\n",
            "nk\n",
            "syria\n",
            "2766 ['I', \"'m\", 'calling', 'bs', 'on', 'this', '.', '1', ')', 'It', 'was', 'a', 'Putin', '/', 'Trump', 'stunt', 'to', 'distract', 'from', '2', ')', 'They', 'got', 'caught', 'so', 'they', \"'re\", 'pinning', 'it', 'on', 'her']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['got']\n",
            "putin\n",
            "trump\n",
            "2767 ['Yes', ',', '@USER', 'is', '!', '!']\n",
            "annotated_mention_list: []\n",
            "2768 ['@USER', '@USER', 'Yes', ',', 'let', \"'s\", 'get', 'back', 'to', 'the', 'real', 'story', 'Stop', 'falling', 'for', 'the', 'con', 'man', \"'s\", 'lobs', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['falling', 'back', 'stop', 'con', 'story', 'get', 'man']\n",
            "2769 ['@USER', 'Would', 'you', 'please', 'have', 'Ivugnka', 'give', 'you', 'your', 'medication', '?', 'Maybe', 'she', 'could', 'put', 'it', 'in', 'a', 'nice', 'jello', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['give', 'put']\n",
            "2770 ['He', 'will', 'make', 'a', 'great', 'wife', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['great']\n",
            "2771 ['Meanwhile', 'back', 'at', 'RT', \"'s\", 'THIS', '.', 'It', 'does', \"n't\", 'get', 'more', 'cyncially', 'opportunistic', 'than', 'this', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['get', 'back']\n",
            "2772 ['Avoids', 'Escalation', 'on', 'Eve', 'of', 'his', 'Visit']\n",
            "annotated_mention_list: []\n",
            "2773 ['I', 'just', 'sent', 'some', '$', 'to', 'support', 'Billboards', 'Shaming', '@USER', 'via', '@USER', '.', 'Must', 'invesitgate', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['support', 'sent']\n",
            "2774 ['Hey', '@USER', '!', 'Tax', 'cuts', 'for', 'who', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['tax']\n",
            "2775 ['@USER', '@USER', 'hope', 'so', ',', 'but', 'GOP', 'seems', 'determined', 'to', 'prevent', 'it', 'anyway', 'possible']\n",
            "annotated_mention_list: [('gop', 'org')]\n",
            "non_entity_list: ['possible', 'anyway']\n",
            "gop\n",
            "2776 ['\"', 'Let', 'them', 'eat', 'baloney', '!', '\"', 'is', 'apparently', 'the', 'new', 'Trump', 'strategy', '/', 'distraction', '?']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['distraction', 'new', 'apparently']\n",
            "trump\n",
            "2777 ['@USER', 'Please', 'expedite', '@USER', 'FBI', 'possible', 'coordination', 'between', 'Trump', 'Campaign', 'and', 'Russia', \"'s\", 'influence', 'with', 'our', 'democracy', '/', 'election', '≡', 'ƒç', '║', '≡', 'ƒç', '╕']\n",
            "annotated_mention_list: [('fbi', 'org'), ('trump campaign', 'misc'), ('russia', 'loc'), ('democracy', 'misc')]\n",
            "non_entity_list: ['campaign', 'possible', 'election']\n",
            "fbi\n",
            "trump campaign\n",
            "russia\n",
            "democracy\n",
            "2778 ['you', 'own', 'this']\n",
            "annotated_mention_list: []\n",
            "2779 ['Ca', \"n't\", 'we', 'stop', 'this', 'ride', '?', 'This', '(', 'not', 'so', ')', 'merry-go-round', '?', 'Strangers', 'on', 'a', 'train', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['train', 'stop']\n",
            "2780 ['@USER', '@USER', 'Keep', 'up', 'the', 'pressure', 'Scott', '!', 'I', 'love', 'it', 'when', 'they', 'prove', 'they', 'are', 'all', \"'\", 'Trumplethinskins', \"'\", '.']\n",
            "annotated_mention_list: [('scott', 'per'), ('trumplethinskins', 'per')]\n",
            "scott\n",
            "trumplethinskins\n",
            "2781 ['2', 'unhinged', 'leaders', 'holding', 'US', 'hostages', 'in', 'their', 'crazy', 'amusement', 'park']\n",
            "annotated_mention_list: [('us', 'loc')]\n",
            "us\n",
            "2782 ['Trump', 'simply', 'turnin', \"'\", 'over', 'his', 'would', 'have', 'been', '84', 'million', 'dollars', 'cheaper', '.']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "trump\n",
            "2783 ['@USER', 'who', 'approved', 'that', 'photo', '?', '?', '?', 'omg', '.', ':(']\n",
            "annotated_mention_list: []\n",
            "2784 ['-', 'and', 'Putin', \"'s\", 'puppet', 'hoax', 'unravels', '.']\n",
            "annotated_mention_list: [('putin', 'per')]\n",
            "non_entity_list: ['puppet']\n",
            "putin\n",
            "2785 ['@USER', '@USER', 'Stay', 'Focused', '!', 'Demand', 'Independent', 'Investigation', 'Congressional', 'Switchboard', '(202)', '224-3121', 'This', 'is', 'not', 'normal', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['investigation', 'demand', 'independent']\n",
            "2786 ['Well', 'this', 'explains', 'A', 'LOT', '!', '@USER', '@USER']\n",
            "annotated_mention_list: []\n",
            "2787 ['So', 'funny', 'and', 'ultimately', 'so', 'scary', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['scary']\n",
            "2788 ['Official', ':', 'Russia', 'knew', 'Syrian', 'chemical', 'attack', 'was', 'coming']\n",
            "annotated_mention_list: [('russia', 'loc'), ('syrian chemical attack', 'misc')]\n",
            "non_entity_list: ['chemical', 'official', 'attack', 'knew']\n",
            "russia\n",
            "syrian chemical attack\n",
            "2789 ['@USER', '@USER', '@USER', 'Like', 'in', 'a', 'padded', 'cell', 'w', 'no', 'phone', '?']\n",
            "annotated_mention_list: []\n",
            "2790 ['oh', 'Putin']\n",
            "annotated_mention_list: [('putin', 'per')]\n",
            "putin\n",
            "2791 ['Stolen', 'SCOTUS', 'seat', 'just', 'like', 'stolen', 'election', '(', 'with', 'the', 'help', 'of', 'Russia', '.', ')']\n",
            "annotated_mention_list: [('scotus', 'org'), ('russia', 'loc')]\n",
            "non_entity_list: ['help', 'seat', 'election']\n",
            "scotus\n",
            "russia\n",
            "2792 ['@USER', '@USER', 'I', 'think', 'it', 'was', 'a', 'calculated', ',', 'choreographed', 'move', 'to', 'distract', 'from', ',', 'but', 'if', 'it', 'made', 'sister', 'happy', '...']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['think', 'move', 'made']\n",
            "2793 ['Wow', '!', 'Going', 'off', 'to', 'war', 'the', 'other', 'day', 'must', 'have', 'really', 'done', 'a', 'lot', 'for', 'Jared', \"'s\", 'qualifications', '.', 'So', 'glad', 'to', 'have', 'such', 'a', 'strong', 'leader', '.']\n",
            "annotated_mention_list: [('jared', 'per')]\n",
            "non_entity_list: ['war', 'leader', 'going', 'day', 'really']\n",
            "jared\n",
            "2794 ['Wait', '.', 'Did', 'he', 'run', 'for', 'office', 'and', 'I', 'missed', 'it', '?', 'Why', 'is', 'the', 'media', 'covering', 'his', 'pronouncements', '?', 'What', 'is', 'his', 'expertise', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['office', 'media', 'run', 'wait']\n",
            "2795 ['Rachel', 'is', 'a', 'bull', 'dog', '.', 'She', 'will', 'bring', 'down', 'this', 'WH', '.']\n",
            "annotated_mention_list: [('rachel', 'per'), ('wh', 'loc')]\n",
            "non_entity_list: ['dog']\n",
            "rachel\n",
            "wh\n",
            "2796 ['Dude', ';', 'enough']\n",
            "annotated_mention_list: []\n",
            "2797 ['In', 'fact', ',', 'lock', 'the', 'whole', 'damn', 'family', 'up', 'and', 'throw', 'away', 'the', 'key', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['family', 'away']\n",
            "2798 ['@USER', '@USER', 'they', \"'re\", 'repulsive', '.', 'i', 'have', 'a', 'visceral', 'grossed-out', 'reaction', 'when', 'i', 'look', 'at', 'them', '.', ':(']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['look']\n",
            "2799 ['We', 'aready', 'knew', 'that', 'lol', 'We', 'did', \"n't\", 'need', 'proof', '.', 'The', 'proof', 'was', 'in', 'the', 'pudding', 'SMH', 'so', 'much', 'horrible', 'thigs', 'going', 'on', 'with', 'our', 'government']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['need', 'government', 'going', 'knew', 'smh']\n",
            "2800 ['@USER', '@USER', 'trumps', 'are', 'greedy', 'dishonest', 'fools', 'looting', 'the', 'American', 'public', '.', 'Lock', 'Them', 'Up']\n",
            "annotated_mention_list: [('trumps', 'misc'), ('american', 'misc')]\n",
            "non_entity_list: ['public']\n",
            "trumps\n",
            "american\n",
            "2801 ['@USER', '@USER', '@USER', 'I', 'never', 'thought', 'like', 'this', 'until', '.', 'Now', 'i', \"'m\", 'going', 'back', 'to', 'review', '9/11', 'conspiracies', 'and', 'JFK', 'assignation', '.', 'Trump', 'is', 'making', 'me', '.']\n",
            "annotated_mention_list: [('jfk', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['going', 'back', 'thought']\n",
            "jfk\n",
            "trump\n",
            "2802 ['@USER', 'Most', 'likely', 'negative', 'spin', 'on', 'doctor', 'put', 'out', 'by', '@USER', 'kinda', 'like', '@USER', 'bombing', 'Syria', 'do', 'deflect', 'from']\n",
            "annotated_mention_list: [('syria', 'loc')]\n",
            "non_entity_list: ['deflect', 'put', 'spin', 'doctor', 'bombing']\n",
            "syria\n",
            "2803 ['@USER', 'And', 'he', 'explained', 'to', 'you', ',', 'via', 'world', 'media', ',', 'he', 'knows', 'you', 'are', 'a', 'weakened', 'politician', 'trying', 'to', 'distract', 'from']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['world', 'knows', 'media']\n",
            "2804 ['@USER', '\"', 'Also', ',', 'Syrian', 'rebels', 'are', 'to', 'blame', '4', 'stealing', 'US', 'election', ',', 'Muslim', 'ban', 'rollout', ',', 'AHCA', 'and', '3M', 'illegal', 'votes', 'cast', 'in', 'NH', '.', '\"']\n",
            "annotated_mention_list: [('syrian', 'misc'), ('us', 'loc'), ('muslim', 'misc'), ('ahca', 'org'), ('nh', 'loc')]\n",
            "non_entity_list: ['blame', 'election']\n",
            "syrian\n",
            "us\n",
            "muslim\n",
            "ahca\n",
            "nh\n",
            "2805 ['andrew', 'mccabe', 'fuck', 'flynn', 'then', 'we', 'fuck', 'trump', '-', 'Google', 'Search', '@USER', 'StefanMolyneux', '@USER', 'realDonaldTrump', '@USER', 'DonaldJTrumpJr', '@USER', ':']\n",
            "annotated_mention_list: [('andrew mccabe', 'per'), ('flynn', 'per'), ('trump', 'per'), ('google', 'org'), ('stefanmolyneux', 'per'), ('realdonaldtrump', 'per'), ('donaldjtrumpjr', 'per')]\n",
            "andrew mccabe\n",
            "flynn\n",
            "trump\n",
            "google\n",
            "stefanmolyneux\n",
            "realdonaldtrump\n",
            "donaldjtrumpjr\n",
            "2806 ['Just', 'cause', 'you', 'bombed', 'another', 'country', 'does', \"n't\", 'mean', 'we', 'forgot', 'about']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['bombed', 'forgot', 'mean']\n",
            "2807 ['So', 'is', 'she', 'saying', 'she', 'loves', 'China', 'and', 'Eric', 'trump', '?', 'But', 'does', 'it', 'really', 'matter', 'anyway', '?']\n",
            "annotated_mention_list: [('china', 'loc'), ('eric trump', 'per')]\n",
            "non_entity_list: ['saying', 'really', 'loves', 'anyway']\n",
            "china\n",
            "eric trump\n",
            "2808 ['Harry', 'Potter', 'Humour', '-', 'Writers', 'Write', 'Creative', 'Blog', '@USER']\n",
            "annotated_mention_list: [('harry potter', 'per')]\n",
            "non_entity_list: ['writers']\n",
            "harry potter\n",
            "2809 ['Seriously', '?', 'Maybe', 'Secretary', 'Potemkin', 'should', 'consult', 'with', '@USER']\n",
            "annotated_mention_list: [('secretary potemkin', 'per')]\n",
            "non_entity_list: ['secretary', 'seriously']\n",
            "secretary potemkin\n",
            "2810 ['@USER', 'Do', \"n't\", 'discourage', 'Eric', 'from', 'talking', '.', 'He', \"'s\", 'states', 'evidence', 'and', 'he', 'does', \"n't\", 'even', 'know', 'it', '.', 'Shhhhhh', '...']\n",
            "annotated_mention_list: [('eric', 'per')]\n",
            "non_entity_list: ['talking']\n",
            "eric\n",
            "2811 ['Ok', 'just', 'moving', 'money', 'around', 'and', 'deduct', 'it', 'on', 'income', 'tax', '?', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['money', 'tax']\n",
            "2812 ['@USER', 'Yoshkumar', 'Happens', ':frowning_face:', 'that', \"'\", 's', 'Esports', 'for', 'ya']\n",
            "annotated_mention_list: [('yoshkumar', 'per'), ('esports', 'misc')]\n",
            "yoshkumar\n",
            "esports\n",
            "2813 ['Ahem', '...', 'shocker']\n",
            "annotated_mention_list: []\n",
            "2814 ['@USER', 'He', 'does', 'seem', 'to', 'lie', 'a', 'lot', '...']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['lie']\n",
            "2815 ['Great', 'job', '@USER', '!', 'Keep', 'us', 'on', 'track', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['great', 'job', 'us']\n",
            "2816 ['U', '.', 'S', '.', ',', 'jab', 'over', 'before', 'diplomatic', 'talks', 'in', '|', 'Star', 'Tribune']\n",
            "annotated_mention_list: [('u . s', 'loc'), ('star tribune', 'org')]\n",
            "non_entity_list: ['jab', 'talks']\n",
            "u . s\n",
            "star tribune\n",
            "2817 ['Whoa', '!', 'Well', 'looked', 'here', '...']\n",
            "annotated_mention_list: []\n",
            "2818 ['but', 'one', 'thing', 'I', 'm', 'dead', 'sure', 'of', 'it', 'Mccain', 'is', 'evil', 'Whether', 'trump', 'is', 'puppet', 'or', 'not']\n",
            "annotated_mention_list: [('mccain', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['thing', 'evil', 'puppet', 'one']\n",
            "mccain\n",
            "trump\n",
            "2819 ['You', 'need', 'to', 'stop', 'these', 'idiots', 'from', 'getting', 'in', 'trouble', ',', '@USER', ',', '@USER', ',', '@USER', ',', '@USER', ',', '@USER', ',', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['need', 'getting', 'stop', 'idiots']\n",
            "2820 ['This', 'is', 'what', 'THEY', 'want', 'us', 'to', 'believe', '...', 'Trump', \"'s\", 'Syrian', 'airstrike', 'was', 'an', 'ineffective', ',', 'yet', 'expensive', 'deflection', 'of', 'collusion', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('syrian airstrike', 'misc')]\n",
            "non_entity_list: ['collusion', 'us', 'airstrike']\n",
            "trump\n",
            "syrian airstrike\n",
            "2821 ['@USER', 'Actually', 'disgusting', 'that', 'anyone', 'did', \"n't\", 'seen', 'deflection', 'in', 'this', 'act', '!', 'Why', 'call', 'Putin', 'before', '?', 'Is', 'that', 'collusion', '?']\n",
            "annotated_mention_list: [('putin', 'per')]\n",
            "non_entity_list: ['call', 'collusion', 'seen', 'actually']\n",
            "putin\n",
            "2822 ['And', 'this', 'is', 'the', ',', '@USER', 'who', 'does', \"n't\", 'give', 'up', 'military', 'plans', '!', 'for', 'and', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['give']\n",
            "2823 ['Did', 'they', 'build', 'it', 'or', 'did', 'they', 'simply', 'slap', 'the', 'Trump', 'name', 'on', 'it', '?']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['name']\n",
            "trump\n",
            "2824 ['@USER', 'You', 'sure', 'do', 'so', 'you', 'can', 'cut', 'taxes', '650', 'billion', 'for', 'top', '2', '%', 'in', 'this', 'country', 'while', 'middle', 'class', 'and', 'poor', 'pay', 'for', 'your']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['poor', 'cut', 'middle', 'pay']\n",
            "2825 ['@USER', 'thank', 'you', 'for', 'clarifying', '.', 'Now', 'we', 'can', 'blame', '@USER', 'along', 'w', '/', '@USER', 'for', 'that', 'stunt', '.', 'Your', 'family', 'is', 'crazy', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['along', 'family', 'blame']\n",
            "2826 ['@USER', \"'\", 'shocked', \"'\", 'by', 'tough', 'language', 'ahead', 'of', 'visit', '.', \"'\", 'Radical', 'reversal', \"'\", 'from', 'earlier', 'tone', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['ahead', 'reversal']\n",
            "2827 ['We', 'Have', 'NOT', 'forgotten', '@USER']\n",
            "annotated_mention_list: []\n",
            "2828 ['@USER', '@USER', 'Read', 'this', '@USER', 'or', 'read', '@USER', 'report', 'on', 'trump', 'towers', 'servers.Ties', 'trump', '/', 'Russia', 'collusion', 'into', '2016', 'election']\n",
            "annotated_mention_list: [('trump towers', 'loc'), ('trump', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['collusion', 'election']\n",
            "trump towers\n",
            "trump\n",
            "russia\n",
            "2829 ['Forget', 'missiles', ',', 'tillerson', \"'s\", 'lies', ',', 'etc', '.', 'they', 'are', 'a', 'distraction', '.', 'This', 'should', 'have', 'been', 'over', 'before', 'gorsuch', '.']\n",
            "annotated_mention_list: [('tillerson', 'per'), ('gorsuch', 'per')]\n",
            "non_entity_list: ['distraction', 'etc', 'lies']\n",
            "tillerson\n",
            "gorsuch\n",
            "2830 ['4/11', 'Headlines', 'Tell', 'US', 'How', 'Bad', 'It', 'Is', 'Going', 'to', 'Get', '...', '@USER']\n",
            "annotated_mention_list: [('us', 'loc')]\n",
            "non_entity_list: ['going', 'get', 'bad']\n",
            "us\n",
            "2831 ['Of', 'course', 'we', \"'re\", 'being', 'fleeced', '.', 'Never', 'steal', 'anything', 'small']\n",
            "annotated_mention_list: []\n",
            "2832 ['@USER', 'She', 'can', 'read', 'the', 'intel', 'briefings', 'to', 'her', 'dad', '.', 'Remember', ',', 'only', 'one', 'page', 'nine', 'bullets', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['one', 'intel', 'dad']\n",
            "2833 ['@USER', '@USER', '@USER', 'Nope', ',', 'sugar', 'gives', 'more', 'energy', 'to', 'research', 'more', 'ties', '!', '≡', 'ƒÿé']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['ties', 'gives', 'sugar', 'research']\n",
            "2834 ['@USER', '@USER', '@USER', '@USER', '@USER', 'How', 'bout', 'protecting', 'US', ':']\n",
            "annotated_mention_list: [('us', 'loc')]\n",
            "non_entity_list: ['bout']\n",
            "us\n",
            "2835 ['@USER', 'you', \"'re\", '\"', 'bigley', '\"', 'in', 'trouble', 'if', 'you', 'do', \"n't\", 'understand', 'NK', ':', 'now', 'let', \"'s\", 'get', 'back', 'to', 'and', 'the', 'illegitimate', 'Orange']\n",
            "annotated_mention_list: [('nk', 'loc')]\n",
            "non_entity_list: ['get', 'back', 'orange']\n",
            "nk\n",
            "2836 ['Freedom', 'of', 'Information', 'Act', ':', 'how', 'about', 'the', 'rest', 'of', '@USER', 'income', 'tax', 'docs', '?', '@USER']\n",
            "annotated_mention_list: [('freedom of information act', 'misc')]\n",
            "non_entity_list: ['rest', 'tax']\n",
            "freedom of information act\n",
            "2837 ['The', 'latest', 'The', 'Mash-Ups', 'Daily', '!', 'Thanks', 'to', '@USER', '@USER', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['latest', 'daily']\n",
            "2838 ['Trump', \"'s\", 'to', 'do', 'list', ':', '1', '.', 'Distract', 'from', '2', '.', 'Distract', 'from', '3', '.', 'Distract', 'from', '=', 'not', 'distracted']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['list']\n",
            "trump\n",
            "2839 ['Good', 'job', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['job', 'good']\n",
            "2840 ['@USER', 'remember', 'when', 'you', 'stood', 'up', 'against', 'Trump', '?', 'Regrow', 'that', 'spine', '.']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "trump\n",
            "2841 ['This', 'man', 'is', 'under', 'criminal', 'investigation', 'he', 'should', 'not', 'be', 'making', 'decisions', 'for', 'our', 'country', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['investigation', 'decisions', 'man']\n",
            "2842 ['It', \"'s\", 'like', 'SNL', 'coming', 'to', 'life', '.', 'He', \"'s\", 'just', 'as', 'corrupt', 'as', 'the', 'others', ',', 'and', 'just', 'as', 'damned', 'stupid', '.']\n",
            "annotated_mention_list: [('snl', 'misc')]\n",
            "non_entity_list: ['others', 'stupid']\n",
            "snl\n",
            "2843 ['Really', '?', 'Are', 'we', 'going', 'to', 'pretend', 'the', 'WH', 'does', \"n't\", 'already', 'know', 'about', 'this', '?']\n",
            "annotated_mention_list: [('wh', 'loc')]\n",
            "non_entity_list: ['going', 'already', 'really']\n",
            "wh\n",
            "2844 ['If', 'it', \"'s\", 'not', 'soon', ',', 'be', 'ready', 'for', ',', 'I', \"can't\", 'even', 'say', 'it', ',', '.', 'Ppl', 'that', 'know', 'and', 'are', 'not', 'coming', 'forward', 'you', 'are', 'as', 'guilty', 'as', 'the', 'worst', 'offenders']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['soon', 'say']\n",
            "2845 ['@USER', '@USER', 'I', 'hope', 'you', 'are', 'doing', 'the', 'same', '.', 'I', 'can', 'do', 'more', 'things', 'than', '1', 'or', '2', 'or', '3', 'I', \"'m\", 'a', 'woman']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['woman', 'things']\n",
            "2846 ['@USER', '@USER', 'Not', 'could', ',', 'SHOULD', 'torment', '@USER', ',', 'he', 'deserves', 'it', '!']\n",
            "annotated_mention_list: []\n",
            "2847 ['Is', 'it', 'just', 'me', ',', 'or', 'does', '@USER', 'look', 'like', 'a', 'vampire', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['vampire', 'look']\n",
            "2848 ['@USER', 'Do', \"n't\", 'think', 'he', 'was', 'really', 'impressed', 'with', 'your', '\"', 'muscle', 'flexing', '\"', '.', 'I', 'doubt', 'he', 'listened', 'to', 'anything', 'you', 'said', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['think', 'said', 'really']\n",
            "2849 ['@USER', 'The', 'way', 'you', 'solved', 'Syria', 'using', 'bombs', 'to', 'have', 'a', 'failed', 'mission', 'and', 'outcome', 'because', 'you', 'have', 'stock', 'in', 'the', 'bombs', 'you', 'used', '?']\n",
            "annotated_mention_list: [('syria', 'loc')]\n",
            "non_entity_list: ['stock', 'using', 'way', 'bombs', 'used']\n",
            "syria\n",
            "2850 ['s', 'Law', 'of', 'Physics', 'Action', '\"', 'For', 'Every', 'Action', ',', 'There', 'is', 'an', 'Equal', 'and', 'Opposite', 'Old', 'Trump', 'Tweet', '\"']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['law', 'action', 'tweet']\n",
            "trump\n",
            "2851 ['If', 'we', 'put', 'boots', 'on', 'the', 'ground', 'in', 'Syria', 'or', 'North', 'Korea', '.', 'I', 'say', 'Draft', 'Eric', 'Trump', '@USER', 'he', 'will', 'talk', 'and', 'bore', 'them', 'to', 'death']\n",
            "annotated_mention_list: [('syria', 'loc'), ('north korea', 'loc'), ('eric trump', 'per')]\n",
            "non_entity_list: ['put', 'north', 'talk', 'say', 'death']\n",
            "syria\n",
            "north korea\n",
            "eric trump\n",
            "2852 ['Wear', 'it', 'like', 'a', 'badge', 'of', 'honor', '!', '!']\n",
            "annotated_mention_list: []\n",
            "2853 ['Not', 'So', 'Failing', '@USER', 'big', 'Winner', 'must', 'be', 'livid']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['big']\n",
            "2854 ['@USER', 'I', 'will', 'never', 'forget', 'your', 'roots', '...']\n",
            "annotated_mention_list: []\n",
            "2855 ['Wow', '!', 'Well', ',', 'well', ',', 'well', '...', 'looky', 'here', '.']\n",
            "annotated_mention_list: []\n",
            "2856 ['You', 'are', 'so', ',', '@USER', '!', 'for', ',', ',', 'and', '.', 'Preferably', 'on', 'reality', 'TV', '!']\n",
            "annotated_mention_list: []\n",
            "2857 ['@USER', '@USER', '@USER', 'Is', 'this', 'official', 'US', 'policy', '?', 'The', 'US', 'responds', 'when', 'Ivanka', 'is', 'unhappy', '?', 'Um', ',', 'I', \"'m\", 'kind', 'of', 'unhappy', 'about', 'a', 'stolen', 'election', '.']\n",
            "annotated_mention_list: [('us', 'loc'), ('us', 'loc'), ('ivanka', 'per')]\n",
            "non_entity_list: ['um', 'official', 'election']\n",
            "us\n",
            "us\n",
            "ivanka\n",
            "2858 ['If', '@USER', 'can', 'do', 'this', '2', 'his', 'nephew', \"'s\", 'sick', 'baby', 'how', 'can', 'any', '1', 'say', 'he', 'cares', 'abt', 'Syrian', 'children', '?']\n",
            "annotated_mention_list: [('syrian', 'misc')]\n",
            "non_entity_list: ['say', 'children']\n",
            "syrian\n",
            "2859 ['Maybe', 'they', 'have', 'small', 'hands', 'like', 'their', 'daddy', '@USER', ',', 'trying', 'to', 'prove', 'otherwise', 'by', 'shooting', 'wild', 'animals', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['hands', 'daddy']\n",
            "2860 ['@USER', '@USER', 'Anything', 'that', 'starts', 'with', '\"', 'trump', 'says', '\"', '=', 'BS', 'A', 'lot', 'of', 'people', 'say', 'he', 'scored', '389', 'total', '.', '≡', 'ƒÿë']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['says', 'starts', 'total', 'say', 'people']\n",
            "trump\n",
            "2861 ['Meanwhile', ',', 'with', 'the', 'conspiracy', 'all', 'but', 'dead', ',', 'the', 'MSM', 'hacks', 'find', 'new', 'material', '.', 'The', 'Easter', 'Egg', 'Roll', 'crisis', '!', 'Obviously', 'racist', '!']\n",
            "annotated_mention_list: [('easter egg roll', 'misc')]\n",
            "non_entity_list: ['new', 'find', 'roll']\n",
            "easter egg roll\n",
            "2862 ['@USER', 'in', 'history', 'will', 'tell', 'a', 'dark', 'tale', 'abt']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['history']\n",
            "2863 ['RT', 'if', 'u', 'agree', '@USER', \"'\", 's', 'meddling', 'w', '/', 'Fed', 'investigation', 'and', 'obstructing', 'justice']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['investigation', 'fed', 'agree', 'justice']\n",
            "2864 ['RT', 'if', 'u', 'want', 'to', 'trend']\n",
            "annotated_mention_list: []\n",
            "2865 ['RT', 'if', 'u', 'want', 'to', 'trend']\n",
            "annotated_mention_list: []\n",
            "2866 ['@USER', 'Hey', '@USER', 'great', 'question', 'here', '.', 'The', 'President', 'is', 'being', 'INVESTIGATED', 'yet', 'you', 'have', 'nothing', 'about', 'that', 'on', 'the', 'top', 'of', 'your', 'site', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['great']\n",
            "2867 ['@USER', 'blocked', 'me']\n",
            "annotated_mention_list: []\n",
            "2868 ['@USER', 'would', 'derive', 'too', 'much', 'pleasure', 'from', 'that', '.', 'instead']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['instead']\n",
            "2869 ['Video', ':', '\"', 'I', \"'ve\", 'been', 'to', 'China', 'many', 'times', '\"', 'for', 'business', 'and', '\"', 'I', 'love', 'China', '\"', 'Eric', 'Trump']\n",
            "annotated_mention_list: [('china', 'loc'), ('china', 'loc'), ('eric trump', 'per')]\n",
            "non_entity_list: ['times', 'video', 'business']\n",
            "china\n",
            "china\n",
            "eric trump\n",
            "2870 ['just', 'by', 'making', 'this', 'comment', 'ERIC', 'proved', 'there', 'most', 'definitely', 'is', '/', 'was', 'collusion', 'with', 'Russia', '.', 'Eric', 'is', 'a', 'HUGE', 'moron']\n",
            "annotated_mention_list: [('eric', 'per'), ('russia', 'loc'), ('eric', 'per')]\n",
            "non_entity_list: ['moron', 'definitely', 'collusion', 'comment']\n",
            "eric\n",
            "russia\n",
            "eric\n",
            "2871 [':', 'Eric', 'Trump', 'said', 'most', 'of', 'the', 'Trump', \"'s\", 'Soho', 'buyers', '\"', 'were', 'foreigners', '-', 'including', 'a', 'lot', 'of', 'Russians', '\"']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('trump', 'per'), ('soho', 'loc'), ('russians', 'misc')]\n",
            "non_entity_list: ['said']\n",
            "eric trump\n",
            "trump\n",
            "soho\n",
            "russians\n",
            "2872 [':', 'Don', 'Jr', 'and', 'Eric', 'Trump', 'met', 'w', '/', 'Russian', 'billionaire', '/', 'friend', 'of', 'Putin', \"'s\", 'son', '\"', 'many', 'times', '\"', 'for', 'biz', '.', 'ΓÇª']\n",
            "annotated_mention_list: [('don jr', 'per'), ('eric trump', 'per'), ('russian', 'misc'), ('putin', 'per')]\n",
            "non_entity_list: ['son', 'times']\n",
            "don jr\n",
            "eric trump\n",
            "russian\n",
            "putin\n",
            "2873 ['Eric', 'Trump', \"'s\", 'business', 'trip', 'to', 'Uruguay', 'cost', 'taxpayers', '$', '97,830', 'in', 'hotel', 'bills']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('uruguay', 'loc')]\n",
            "non_entity_list: ['trip', 'business', 'taxpayers']\n",
            "eric trump\n",
            "uruguay\n",
            "2874 [':', 'Eric', 'Trump', 'filed', 'papers', 'to', 'open', 'a', 'new', 'branch', 'of', 'his', 'foundation', 'in', 'North', 'Dakota', 'on', 'Election', 'Day']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('north dakota', 'loc'), ('election day', 'misc')]\n",
            "non_entity_list: ['foundation', 'north', 'branch', 'new', 'day', 'election']\n",
            "eric trump\n",
            "north dakota\n",
            "election day\n",
            "2875 ['Video', ':', 'Eric', 'Trump', 'says', 'Trump', 'Org', 'plans', 'to', 'do', 'more', 'business', 'in', 'Shanghai', ',', 'Hong', 'Kong', 'and', 'Beijing']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('trump org', 'org'), ('shanghai', 'loc'), ('hong kong', 'loc'), ('beijing', 'loc')]\n",
            "non_entity_list: ['video', 'business', 'says']\n",
            "eric trump\n",
            "trump org\n",
            "shanghai\n",
            "hong kong\n",
            "beijing\n",
            "2876 ['WE', 'NEED', 'YOUR', 'VOTE', '!', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['need']\n",
            "2877 ['Video', ':', 'Eric', 'Trump', 'in', 'the', 'philippines', '-', 'saying', 'their', 'best', 'biz', 'project', 'ever', 'will', 'be', 'in', 'Manila']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('philippines', 'loc'), ('manila', 'loc')]\n",
            "non_entity_list: ['project', 'saying', 'video']\n",
            "eric trump\n",
            "philippines\n",
            "manila\n",
            "2878 ['Photo', ':', 'Eric', 'Trump', 'and', 'Don', 'Jr', 'w', '/', 'mob', 'related', 'felon', 'Joey', \"'\", 'No', 'Socks', \"'\", 'Cinque', 'at', 'Tsar-a-Lago', 'on', 'New', 'Years', '-', '3', 'yrs', 'ago']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('don jr', 'per'), (\"joey ' no socks ' cinque\", 'per'), ('tsar-a-lago', 'loc')]\n",
            "non_entity_list: ['socks', 'new', 'years']\n",
            "eric trump\n",
            "don jr\n",
            "joey ' no socks ' cinque\n",
            "tsar-a-lago\n",
            "2879 ['He', \"'s\", 'going', 'to', 'be', 'surprised', 'at', 'their', 'response', 'when', 'they', 'nuke', 'us', 'right', 'out', 'of', 'the', 'gate', '!', 'Completely', 'clueless', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['right', 'completely', 'us', 'going', 'response', 'gate']\n",
            "2880 ['Did', 'you', 'know', 'that', 'trumpy', 'has', 'never', 'had', 'a', 'pet', '?', 'Who', 'do', 'you', 'know', 'that', 'has', 'never', 'had', 'a', 'pet', '?', '?', '?', 'Creepy', 'weirdos', '!']\n",
            "annotated_mention_list: [('trumpy', 'per')]\n",
            "trumpy\n",
            "2881 ['The', 'were', 'inept', 'and', 'ineffective', 'so', 'they', 'blame', '@USER', 'nice']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['blame']\n",
            "2882 ['\"', 'Syrian', 'rebels', 'are', 'also', 'responsible', 'for', 'stealing', 'US', 'election', ',', 'hacking', 'DNC', 'and', 'spreading', 'fake', 'news', 'via', 'Russian', 'bots', '.', 'Promise', '!', '\"']\n",
            "annotated_mention_list: [('syrian', 'misc'), ('us election', 'misc'), ('dnc', 'org'), ('russian', 'misc')]\n",
            "non_entity_list: ['news', 'fake', 'us', 'election']\n",
            "syrian\n",
            "us election\n",
            "dnc\n",
            "russian\n",
            "2883 ['I', 'have', 'never', 'heard', 'of', 'Erik', 'Prince', ',', 'brother', 'of', 'Betsy', 'Devos', '.', 'Can', 'dread', 'it', '.', 'Xxxii', '.', 'is', 'a', 'sign', 'of', 'the', 'times', '.']\n",
            "annotated_mention_list: [('erik prince', 'per'), ('betsy devos', 'per')]\n",
            "non_entity_list: ['heard', 'times']\n",
            "erik prince\n",
            "betsy devos\n",
            "2884 ['Not', 'me', '.']\n",
            "annotated_mention_list: []\n",
            "2885 ['What', 'is', 'taking', 'you', 'so', 'long', '?']\n",
            "annotated_mention_list: []\n",
            "2886 ['@USER', 'One', 'big', ',', 'happy', \"'\", 'family', \"'\", 'photo', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['family', 'big', 'one']\n",
            "2887 ['trump', '/', 'admin', '/', 'campaign', 'INVESTIGATED', 'BY', 'FBI', 'for', 'ATTACK', 'ON', 'OUR', 'DEMOCRACY']\n",
            "annotated_mention_list: [('trump', 'per'), ('fbi', 'org'), ('democracy', 'misc')]\n",
            "non_entity_list: ['admin', 'attack', 'campaign']\n",
            "trump\n",
            "fbi\n",
            "democracy\n",
            "2888 ['Wow.Gee', '!', 'I', 'HOPE', 'they', 'made', 'all', 'their', 'appointments', 'and', 'made', 'LOTS', 'of', 'money', 'on', 'deals', 'gee', 'wiz', ',', 'WISH', 'MY', 'family', 'was', 'ruining', ',', 'I', 'mean', 'running', 'a', 'country']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['family', 'money', 'made', 'mean']\n",
            "2889 ['@USER', 'Correction', ':', 'Trump', 'is', 'looking', 'for', 'trouble', '...', 'and', 'a', 'diversion', 'from']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['correction']\n",
            "trump\n",
            "2890 ['Everyone', 'in', 'the', 'Trump', '\"', 'family', '\"', 'is', 'CORRUPT', 'and', 'MONEY', 'DRIVEN', '!', 'It', \"'s\", 'in', 'their', 'nature', '!', 'Cultivated', 'by', 'the', '!']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['family', 'money']\n",
            "trump\n",
            "2891 ['@USER', 'What', 'a', 'fucking', 'surprise', '!']\n",
            "annotated_mention_list: []\n",
            "2892 ['Thread', 'bu', '@USER', 'abt', 'the', 'dangers', 'of', '.']\n",
            "annotated_mention_list: []\n",
            "2893 ['Daily', 'reminder', ':', '@USER', '@USER', 'is', 'under', 'investigation', 'by', '@USER', 'for', 'collusion', 'in', 'election', '.', 'Demand', 'transparency', 'and', 'answers']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['daily', 'investigation', 'demand', 'collusion', 'election']\n",
            "2894 ['@USER', '@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "2895 ['The', 'latest', 'The', 'Ulrike', 'Beudgen', 'Daily', '!', 'Thanks', 'to', '@USER', '@USER', '@USER']\n",
            "annotated_mention_list: [('ulrike beudgen daily', 'org')]\n",
            "non_entity_list: ['latest', 'daily']\n",
            "ulrike beudgen daily\n",
            "2896 ['Why', 'is', 'this', 'not', 'on', 'TV', 'news', '...', 'oh', 'yeah', ',', 'war', 'mongering', 'is', 'the', 'most', 'recent', 'Trump', 'project', '.']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['war', 'project', 'news']\n",
            "trump\n",
            "2897 ['Administration', 'Priorities', 'ΓÇó', 'Collusion', \"Alibi's\", 'ΓÇó', 'Defending', 'Idiotic', 'Tweets', 'ΓÇó', 'Golfing', 'Vacations', 'Easter', 'Egg', 'Roll', 'Not', 'So', 'Much']\n",
            "annotated_mention_list: [('easter egg roll', 'misc')]\n",
            "non_entity_list: ['administration', 'golfing', 'collusion', 'roll']\n",
            "easter egg roll\n",
            "2898 ['@USER', 'because', 'she', \"'s\", 'grotesque', '.']\n",
            "annotated_mention_list: []\n",
            "2899 ['Your', 'views', '?', '\"', 'Heartbroken', '\"', 'Ivanka', 'swayed', \"'\", 's', 'decision', 'to', 'strike', 'Syria', 'according', 'to', 'Eric', 'Trump', '!']\n",
            "annotated_mention_list: [('ivanka', 'per'), ('syria', 'loc'), ('eric trump', 'per')]\n",
            "non_entity_list: ['strike', 'decision', 'according', 'swayed']\n",
            "ivanka\n",
            "syria\n",
            "eric trump\n",
            "2900 ['@USER', '@USER', '@USER', '@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "2901 ['Interesting', '.', 'After', 'RT', 'was', 'only', 'source', 'saying', '\"', 'connected', 'to', 'election', ',', '\"', 'now', 'DOJ', 'says', '\"', 'we', \"'ll\", 'be', 'asking', '.', '\"']\n",
            "annotated_mention_list: [('doj', 'org')]\n",
            "non_entity_list: ['source', 'saying', 'says', 'election']\n",
            "doj\n",
            "2902 ['@USER', 'Jeffrey', 'Lord', 'is', 'that', 'stupid', '.', 'I', 'turn', 'off', 'any', 'program', 'that', 'features', 'him', '.', '@USER']\n",
            "annotated_mention_list: [('jeffrey lord', 'per')]\n",
            "non_entity_list: ['lord', 'stupid']\n",
            "jeffrey lord\n",
            "2903 ['Admitting', 'he', 'bombed', 'Russia', 'just', 'to', 'disprove', 'Russian', 'ties', ',', 'proves', 'he', 'HAS', 'Russian', 'ties', ',', 'and', 'that', 'he', \"'s\", 'a', 'pathological', 'asshole', ',', 'right', '?']\n",
            "annotated_mention_list: [('russia', 'loc'), ('russian', 'misc'), ('russian', 'misc')]\n",
            "non_entity_list: ['right', 'bombed', 'asshole', 'ties']\n",
            "russia\n",
            "russian\n",
            "russian\n",
            "2904 ['and', 'not', ',', 'too', 'bright', '.', 'Gullible', 'liberals', '!', 'Note', 'Eric', 'Trump', '!']\n",
            "annotated_mention_list: [('eric trump', 'per')]\n",
            "eric trump\n",
            "2905 ['Lucky', 'Sperm', 'and', 'Animal', 'Killers', 'Convince', 'Locals', 'To', 'Help', 'Them', 'Bury', 'Bachelor', 'Party', 'Stripper']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['help', 'party', 'convince', 'lucky', 'animal', 'bury']\n",
            "2906 ['@USER', '@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "2907 ['Eric', 'Trump']\n",
            "annotated_mention_list: [('eric trump', 'per')]\n",
            "eric trump\n",
            "2908 ['DONALD', 'TRUMP', 'CAN', 'TAKE', 'US', 'TO', 'WAR', ',', 'BUT', 'WE', 'THE', 'PEOPLE', 'ARE', 'FOCUSED', 'ON']\n",
            "annotated_mention_list: [('donald trump', 'per')]\n",
            "non_entity_list: ['war', 'take', 'people', 'us']\n",
            "donald trump\n",
            "2909 ['BREAKING', ':', 'Eric', 'Trump', \"'s\", 'biological', 'father', 'speaks', 'out', 'about', 'being', 'fired', 'on', 'Season', '4', 'of', 'The', 'Apprentice']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('apprentice', 'misc')]\n",
            "non_entity_list: ['fired', 'breaking', 'father']\n",
            "eric trump\n",
            "apprentice\n",
            "2910 ['@USER', 'welp', '...']\n",
            "annotated_mention_list: []\n",
            "2911 ['@USER', '@USER', 'Elaborate', 'staging', 'for', 'a', 'lovers', 'quarrel', '.', 'They', 'do', \"n't\", 'mind', 'sacrificing', 'children', 'to', 'push', 'their', 'agenda']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['children']\n",
            "2912 ['Oh', 'HELL', 'YES', ',', \"WE'RE\", 'DEFINITELY', 'SEIZING', 'THEIR', 'ASSETS']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['definitely']\n",
            "2913 ['61', '%', 'of', 'people', 'polled', 'do', 'not', 'agree', 'w', '/', '45', \"'\", 's', 'decision', 'to', 'escalate', 'US', 'involvement', 'w', '/', 'Syria', 'air', 'strikes', '.']\n",
            "annotated_mention_list: [('us', 'loc'), ('syria', 'loc')]\n",
            "non_entity_list: ['decision', 'agree', 'air', 'people', 'strikes']\n",
            "us\n",
            "syria\n",
            "2914 ['Goals', '!', 'Congratulations', '@USER', 'for', 'getting', 'blocked', 'by', 'a', 'trump', '.', 'Wear', 'it', 'like', 'a', 'badge', 'of', 'honor', '.']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['getting']\n",
            "trump\n",
            "2915 ['continues']\n",
            "annotated_mention_list: []\n",
            "2916 ['You', 'and', 'Kim', 'Jong', 'Un', 'could', 'be', ',', '@USER', '!', 'for', ',', ',', 'and', '!']\n",
            "annotated_mention_list: [('kim jong un', 'per')]\n",
            "kim jong un\n",
            "2917 ['@USER', 'You', \"'re\", 'always', 'doing', 'the', 'right', 'thing', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['right', 'thing']\n",
            "2918 ['Look', 'at', '@USER', '(', 'Lurch', ')', 'another', 'TWIT', 'on', 'the', 'loose', 'that', 'should', 'be', 'put', 'away', 'FOR', 'EVALUATION', '..', ',', 'Mental', 'it', 'is', '!', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['look', 'away', 'put']\n",
            "2919 ['@USER', '@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "2920 ['As', 'a', 'time-saver', ',', 'Donald', 'should', 'start', 'delivering', 'orders', 'in', 'their', 'original', 'Russian', '.', '@USER', '@USER', '@USER', '@USER']\n",
            "annotated_mention_list: [('donald', 'per'), ('russian', 'misc')]\n",
            "non_entity_list: ['orders']\n",
            "donald\n",
            "russian\n",
            "2921 ['I', 'knew', 'Putin', 'had', 'his', 'hand', 'up', 'Trump', \"'s\", 'ass', ',', 'but', 'apparently', 'there', \"'s\", 'enough', 'room', 'for', 'Ivanka', ',', 'too', '-', 'her', 'idea', 'not', 'HIS']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per'), ('ivanka', 'per')]\n",
            "non_entity_list: ['ass', 'knew', 'apparently']\n",
            "putin\n",
            "trump\n",
            "ivanka\n",
            "2922 ['@USER', 'So', 'what', 'are', 'you', 'going', 'to', 'do', 'about', 'it', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['going']\n",
            "2923 ['@USER', '@USER', '@USER', 'If', 'there', 'were', 'no', 'Russian', 'ties', ',', 'then', '@USER', 'would', 'welcome', 'the', 'investigations', '.', 'Maybe', 'even', 'help', ',', 'instead', 'of', 'hinder', '.']\n",
            "annotated_mention_list: [('russian', 'misc')]\n",
            "non_entity_list: ['instead', 'help', 'ties', 'investigations']\n",
            "russian\n",
            "2924 ['@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "2925 ['We', 'are', 'being', 'played', '.', 'Trump', '/', 'Tillerson', 'have', 'NO', 'intention', 'of', 'messing', 'w', '/', 'Assad', 'or', 'Putin', 'and', 'knew', 'it', 'would', \"n't\", 'be', 'supported', '.', 'It', \"'s\", 'a', 'shell', 'game', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('tillerson', 'per'), ('assad', 'per'), ('putin', 'per')]\n",
            "non_entity_list: ['played', 'knew']\n",
            "trump\n",
            "tillerson\n",
            "assad\n",
            "putin\n",
            "2926 ['The', 'Monument', 'to', 'the', 'Conquerors', 'of', 'Space']\n",
            "annotated_mention_list: []\n",
            "2927 ['@USER', '@USER', 'you', \"'ve\", 'reached', 'new', 'record', 'lows', 'you']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['new']\n",
            "2928 ['Birds', 'of', 'a', 'Feather', '...']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['feather']\n",
            "2929 ['EXACTLY', 'HOW', 'MUCH', 'DOES', 'SECURITY', 'COST', 'US', 'TAXPAYERS', 'FOR', 'ERIC', ',', 'IVANKA', 'AND', 'ADOLPH', 'TRUMP', '?', 'Hang', 'ALL', 'THE', 'TRUMPS', '~', 'AMERICAS', 'FIRST', 'FAMILY', 'OF', 'TRAITORS', '.']\n",
            "annotated_mention_list: [('eric', 'per'), ('ivanka', 'per'), ('adolph trump', 'per'), ('trumps', 'misc'), ('americas', 'loc')]\n",
            "non_entity_list: ['family', 'taxpayers', 'first', 'us']\n",
            "eric\n",
            "ivanka\n",
            "adolph trump\n",
            "trumps\n",
            "americas\n",
            "2930 ['@USER', 'that', 'is', 'some', 'psycho', 'shit', ',', 'man', '.', 'what', 'a', 'freak', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['man']\n",
            "2931 ['As', 'usual', '.']\n",
            "annotated_mention_list: []\n",
            "2932 [':', 'Trilateral', 'meeting', 'to', 'take', 'place', 'between', '/', 'n', ',', '/', 'n', 'and', '/', 'ian', 'foreign', 'ministers', 'in', 'soon', '.', 'via', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['take', 'meeting', 'foreign', 'soon']\n",
            "2933 ['@USER', 'Looking', 'forward', 'to', 'seeing', 'you', 'in', 'Hillsboro', 'to', 'thank', 'you', 'on', 'standing', 'strong', 'against', '45', \"'\", 's', 'agenda', '!']\n",
            "annotated_mention_list: [('hillsboro', 'loc')]\n",
            "hillsboro\n",
            "2934 ['foreign', 'minister', 'at', ':', 'must', 'not', 'be', \"'\", 'pushed', 'into', 'a', 'corner', \"'\", 'over', '.', '@USER', 'Exactly', 'what', 'is', 'coming', 'to', 'for']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['minister', 'foreign']\n",
            "2935 ['Nepotism', 'is', '\"', 'beautiful', '\"']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['nepotism', 'beautiful']\n",
            "2936 ['@USER', '@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "2937 ['Trump', '@USER', '/', 'Trump', 'kids', '@USER', '@USER', 'ARE', 'OPPORTUNISTS', '!']\n",
            "annotated_mention_list: [('trump', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['kids']\n",
            "trump\n",
            "trump\n",
            "2938 ['Is', 'it', 'just', 'me', 'but', 'do', 'those', '2', 'have', 'Menendez', 'brothers', 'written', 'all', 'over', 'them', '?']\n",
            "annotated_mention_list: [('menendez', 'per')]\n",
            "non_entity_list: ['brothers']\n",
            "menendez\n",
            "2939 ['How', 'many', 'investigations', 'is', 'Trump', 'under', 'now', '?', 'FBI', ',', 'Congress', ',', 'GAO', ',', 'and', 'all', 'his', 'other', 'lawsuits', '...']\n",
            "annotated_mention_list: [('trump', 'per'), ('fbi', 'org'), ('congress', 'org'), ('gao', 'org')]\n",
            "non_entity_list: ['investigations']\n",
            "trump\n",
            "fbi\n",
            "congress\n",
            "gao\n",
            "2940 ['Love', 'Shawn', '.', 'Love', 'Jackie', '.']\n",
            "annotated_mention_list: [('shawn', 'per'), ('jackie', 'per')]\n",
            "shawn\n",
            "jackie\n",
            "2941 ['being', 'labeled', 'a', '!']\n",
            "annotated_mention_list: []\n",
            "2942 ['Betsy', 'Devos', '.', 'Erik', 'Prince', '.', 'Blackwater', 'scandal', '.', 'Seychelles', '.', 'Treaty', 'was', 'made', 'designedly', 'for', 'us', '.']\n",
            "annotated_mention_list: [('betsy devos', 'per'), ('erik prince', 'per'), ('blackwater', 'org'), ('seychelles', 'loc')]\n",
            "non_entity_list: ['scandal', 'made', 'us']\n",
            "betsy devos\n",
            "erik prince\n",
            "blackwater\n",
            "seychelles\n",
            "2943 ['@USER', 'trump', 'would', 'burst', 'into', 'flames', '.', 'Its', 'why', 'the', 'devil', 'stays', 'away', 'from', 'all', 'things', 'holy', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['devil', 'away', 'things', 'holy']\n",
            "2944 ['This', 'stuff', 'is', 'moving', 'way', 'to', 'fast', '.', 'Historically', 'we', 'have', 'done', 'exactly', 'what', 'Putin', 'is', 'talking', 'about', '.', 'Gulf', 'of', 'Tonkin', 'for', 'example', '.', 'This', 'is', 'so', 'wrong', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('gulf of tonkin', 'loc')]\n",
            "non_entity_list: ['stuff', 'way', 'talking']\n",
            "putin\n",
            "gulf of tonkin\n",
            "2945 ['people', 'actually', 'think', 'Trump', 'can', 'make', 'anything', 'great', 'besides', 'his', 'bank', 'accounts', '.']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['bank', 'think', 'great', 'people', 'actually']\n",
            "trump\n",
            "2946 ['in', 'what', 'part', 'of', 'any', 'of', 'his', 'statements', 'is', 'he', 'wrong', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['statements']\n",
            "2947 ['@USER', '@USER', '@USER', '@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "2948 ['Did', \"n't\", 'Tillerson', 'have', 'this', 'visit', 'to', 'Russia', 'planned', 'before', 'the', 'missile', 'strikes', '?']\n",
            "annotated_mention_list: [('tillerson', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['strikes', 'planned', 'missile']\n",
            "tillerson\n",
            "russia\n",
            "2949 ['If', 'trump', 'is', 'supporter', 'of', 'candidate', 'vote', 'for', 'Democrat', 'or', 'your', 'health', 'care', ',', 'taxes', 'cut', 'for', 'rich', ',', '3war', '!', 'Stop', 'them']\n",
            "annotated_mention_list: [('democrat', 'misc')]\n",
            "non_entity_list: ['candidate', 'supporter', 'cut', 'stop']\n",
            "democrat\n",
            "2950 ['He', 'wishes', '.', 'Might', 'be', 'plausible', 'but', 'they', 'told', 'Putin', 'in', 'time', 'to', 'move', 'their', 'planes', 'and', 'personnel', 'out', 'of', 'the', 'way', '.', 'Proof', 'more']\n",
            "annotated_mention_list: [('putin', 'per')]\n",
            "non_entity_list: ['time', 'planes', 'move', 'way', 'told']\n",
            "putin\n",
            "2951 ['@USER', 'Just', 'like', 'your', 'father', '.', 'Loves', 'dictators', '!', 'Piss', 'ants', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['father', 'loves', 'dictators']\n",
            "2952 ['You', 'mean', 'the', 'country', 'where', 'the', 'president', 'is', 'very', 'fond', 'of', 'extrajudicial', 'killings', '?', 'prefers', 'autocrats', 'and', 'kleptocrats']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['mean']\n",
            "2953 ['@USER', '@USER', '@USER', '@USER', '@USER', '@USER', '@USER', 'He', 'is', 'already', 'and', 'has', 'been', 'in', 'the', 'process', 'of', 'doing', 'just', 'that', 'with', 'his', 'buddy', 'putin', '.']\n",
            "annotated_mention_list: [('putin', 'per')]\n",
            "non_entity_list: ['already']\n",
            "putin\n",
            "2954 ['*', '45', 'backlash', 'about', 'to', 'hit', 'Kansas', '.', 'in', 'trouble', '!', 'Γ', '£', 'è']\n",
            "annotated_mention_list: [('kansas', 'loc')]\n",
            "kansas\n",
            "2955 ['Don', 'Jr', 'and', 'Eric', 'look', 'like', 'they', 'are', 'thinking', 'how', 'much', 'better', 'they', 'are', 'than', 'others', ',', 'arrogant', 'little', 'pricks']\n",
            "annotated_mention_list: [('don jr', 'per'), ('eric', 'per')]\n",
            "non_entity_list: ['better', 'little', 'others', 'look', 'thinking']\n",
            "don jr\n",
            "eric\n",
            "2956 ['Jumpsuits', '4', 'all', 'these', 'traitors']\n",
            "annotated_mention_list: []\n",
            "2957 ['Narcissistic', 'Authoritarian', 'Regime', 'Will', 'Rise', 'Up']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['regime', 'rise']\n",
            "2958 ['@USER', '@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "2959 ['Saying', 'is', 'not', 'anti', 'semitic', 'because', 'kushner', 'is', 'Jewish', 'is', 'laughable', '.', 'and', 'Jared', 'are', 'also', 'democrats', '.']\n",
            "annotated_mention_list: [('kushner', 'per'), ('jewish', 'misc'), ('jared', 'per'), ('democrats', 'misc')]\n",
            "non_entity_list: ['saying', 'anti']\n",
            "kushner\n",
            "jewish\n",
            "jared\n",
            "democrats\n",
            "2960 ['Thank', 'you', '@USER', 'and', '@USER']\n",
            "annotated_mention_list: []\n",
            "2961 ['Data', 'Patterns', 'Reveal', 'Trump', 'Tower', '/', 'Spectrum', 'Health', 'Ran', 'a', 'Stealth', 'Data', 'Machine', 'With', 'Russia', '.']\n",
            "annotated_mention_list: [('trump tower', 'loc'), ('spectrum', 'org'), ('russia', 'loc')]\n",
            "non_entity_list: ['tower']\n",
            "trump tower\n",
            "spectrum\n",
            "russia\n",
            "2962 ['@USER', 'if', 'you', 'wo', \"n't\", 'hold', 'a', 'town', 'hall', '...', 'The', 'least', 'you', 'can', 'do', 'is', 'mosey', 'down', 'to', 'CowTown', 'on', 'Saturday', '.', 'just', 'might', 'inspire', 'you', '.']\n",
            "annotated_mention_list: [('cowtown', 'loc')]\n",
            "non_entity_list: ['least', 'hold', 'hall']\n",
            "cowtown\n",
            "2963 ['Congrats', 'lunatics', 'at', 'Washington', '!', '\"', 'America', 'authorized', 'you', 'bomb', 'world', 'showing', 'empire', 'muscle', '!', 'Twist', 'America', 'around', 'your', 'little', 'fingerand', 'they', 'forget']\n",
            "annotated_mention_list: [('washington', 'loc'), ('america', 'loc'), ('america', 'loc')]\n",
            "non_entity_list: ['bomb', 'world', 'empire', 'little']\n",
            "washington\n",
            "america\n",
            "america\n",
            "2964 ['Trump', 'has', 'flip', 'flopped', 'and', 'been', 'all', 'over', 'the', 'place', 'on', 'every', 'policy', 'position', 'except', 'his', 'admiration', 'of', 'Putin', '.', 'I', \"'m\", 'not', 'distracted', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('putin', 'per')]\n",
            "non_entity_list: ['position']\n",
            "trump\n",
            "putin\n",
            "2965 ['says', 'more', 'chemical', 'attacks', 'planned', 'against', 'and', 'calls', 'for', 'a', 'thorough', 'investigation']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['chemical', 'investigation', 'planned', 'says']\n",
            "2966 ['@USER', '@USER', '@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "2967 ['100', 'days', 'cost', 'more', 'then', '8']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['days']\n",
            "2968 ['@USER', 'YOU', 'LIE']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['lie']\n",
            "2969 ['Keep', 'doing', 'what', 'you', \"'re\", 'doing', '!', 'We', 'are', 'all', 'behind', 'you', '!']\n",
            "annotated_mention_list: []\n",
            "2970 ['Trump', \"'s\", 'base', 'is', 'the', 'basest', '.']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['base']\n",
            "trump\n",
            "2971 ['@USER', '@USER', '@USER', '@USER', 'It', 'shows', 'that', 'illegitimate', 'Trump', 'is', 'UNFIT', '...', 'duh', '!', 'Impeach', '-', 'Imprison']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['shows']\n",
            "trump\n",
            "2972 ['And', 'the', 'FBI', 'is', 'Aaron', 'Burr', '.']\n",
            "annotated_mention_list: [('fbi', 'org'), ('aaron burr', 'per')]\n",
            "fbi\n",
            "aaron burr\n",
            "2973 ['@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "2974 ['Russia', 'Knew', 'in', 'advance', ',', 'and', 'let', 'women', 'and', 'children', 'die']\n",
            "annotated_mention_list: [('russia', 'loc')]\n",
            "non_entity_list: ['knew', 'children']\n",
            "russia\n",
            "2975 ['trump', '/', 'admin', '/', 'campaign', 'being', 'INVESTIGATED', 'BY', 'FBI', 'ATTACK', 'ON', 'OUR', 'DEMOCRACY']\n",
            "annotated_mention_list: [('fbi', 'org'), ('democracy', 'misc')]\n",
            "non_entity_list: ['admin', 'attack', 'campaign']\n",
            "fbi\n",
            "democracy\n",
            "2976 ['Also', 'see', ':', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['see']\n",
            "2977 ['Sincere', 'thanks', 'to', 'those', 'in', 'the', 'media', 'doing', 'their', 'jobs', 'by', 'investigating', 'and', 'reporting', 'on', 'Trump', 'and', 'Russia', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['media']\n",
            "trump\n",
            "russia\n",
            "2978 ['Wow', '.', 'Those', 'of', 'you', 'following', 'me', 'seem', 'to', 'have', 'lost', 'an', 'awful', 'lot', 'in', 'translation', '.', \"'\", '-', 'Christ']\n",
            "annotated_mention_list: [('christ', 'per')]\n",
            "non_entity_list: ['following', 'awful', 'lost']\n",
            "christ\n",
            "2979 ['1', '.', 'Defeat', 'ISIS', 'in', '30', 'days', '2', '.', 'Repeal', 'Obamacare', '3', '.', 'Mexico', 'to', 'pay', 'for', 'wall', '4', '.', 'Play', 'lots', 'of', 'golf']\n",
            "annotated_mention_list: [('isis', 'org'), ('obamacare', 'misc'), ('mexico', 'loc'), ('golf', 'misc')]\n",
            "non_entity_list: ['wall', 'days', 'repeal', 'pay']\n",
            "isis\n",
            "obamacare\n",
            "mexico\n",
            "golf\n",
            "2980 ['@USER', '@USER', '-', 'Do', \"n't\", 'be', 'fooled', 'by', 'this', '\"', 'FAKE', '\"', 'animosity', 'between', 'Putin', '/', 'White', 'House', '.', 'It', 'started', 'with', 'BS', 'bombing', 'in', 'Syria']\n",
            "annotated_mention_list: [('putin', 'per'), ('white house', 'loc'), ('syria', 'loc')]\n",
            "non_entity_list: ['bombing', 'fake']\n",
            "putin\n",
            "white house\n",
            "syria\n",
            "2981 ['Well', '..', 'at', 'least', 'we', 'can', 'be', 'sure', 'that', 'the', 'US', 'iis', 'not', 'going', 'to', 'attack', 'China', '...']\n",
            "annotated_mention_list: [('china', 'loc')]\n",
            "non_entity_list: ['going', 'attack', 'least', 'us']\n",
            "china\n",
            "2982 ['reminder', 'to', 'DON', 'THE', 'CON']\n",
            "annotated_mention_list: [('don the con', 'per')]\n",
            "non_entity_list: ['con']\n",
            "don the con\n",
            "2983 ['Truth', 'Will', 'Find', 'A', 'Way', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['way', 'find']\n",
            "2984 ['Duh', '!', 'has', 'wanted', 'a', 'hotel', 'in', 'for', 'a', 'long', 'time', '.', 'Does', 'greasing', 'palm', 'his', 'only', 'way', 'in', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['time', 'way', 'wanted']\n",
            "2985 ['Can', 'we', 'have', 'an', 'update', 'on', 'the', 'investigation', '?', 'Comey', '?', '@USER', '?']\n",
            "annotated_mention_list: [('comey', 'per')]\n",
            "non_entity_list: ['investigation']\n",
            "comey\n",
            "2986 ['Yeah', 'loved', 'the', 'Asian', 'women', '.', 'What', 'a', 'loser']\n",
            "annotated_mention_list: [('asian', 'misc')]\n",
            "asian\n",
            "2987 ['Rex', 'Tillerson', 'asks', 'why', 'US', 'should', 'care', 'about', 'Ukraine', '.', 'Feels', 'like', 'prelude', 'to', 'lifting', 'sanctions', 'on', 'Russia', '.']\n",
            "annotated_mention_list: [('rex tillerson', 'per'), ('us', 'loc'), ('ukraine', 'loc'), ('russia', 'loc')]\n",
            "non_entity_list: ['feels', 'sanctions']\n",
            "rex tillerson\n",
            "us\n",
            "ukraine\n",
            "russia\n",
            "2988 ['The', 'FEW', '!']\n",
            "annotated_mention_list: []\n",
            "2989 ['@USER', 'has', 'a', 'great', 'team', 'behind', 'her', 'doing', 'research', ',', 'and', 'production', '.', 'Credit', 'goes', 'to', 'all', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['great', 'goes', 'team', 'research']\n",
            "2990 ['@USER', 'Hmmm', ',', 'another', 'Squirrel', '!', 'Nothing', 'to', 'see', 'here', '.']\n",
            "annotated_mention_list: [('squirrel', 'misc')]\n",
            "non_entity_list: ['see']\n",
            "squirrel\n",
            "2991 ['@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "2992 ['@USER', '@USER', '...', 'sorry', 'Big', 'O', 'for', 'putting', 'the', 'orange', 'taint', 'on', 'your', 'successes']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['putting', 'big', 'orange']\n",
            "2993 ['@USER', '@USER', 'Given', 'the', 'political', 'machinations', 'of', 'I', \"'m\", 'not', 'surprised']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['political']\n",
            "2994 ['In', 'other', 'words', ':', 'it', \"'s\", 'okay', 'if', 'you', \"'re\", 'a', 'white', 'guy', '.', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['guy']\n",
            "2995 ['That', \"'s\", 'not', 'shady', 'at', 'all']\n",
            "annotated_mention_list: []\n",
            "2996 ['@USER', '@USER', '@USER', 'Trust', 'me', ',', 'your', 'precious', 'gop', 'will', 'come', 'around', 'soon', '.', 'Not', 'to', 'mention', 'they', 'will', 'lose', 'the', 'majority', 'in', '2018', 'anyway', '.']\n",
            "annotated_mention_list: [('gop', 'org')]\n",
            "non_entity_list: ['trust', 'mention', 'come', 'anyway', 'soon']\n",
            "gop\n",
            "2997 ['@USER', 'Too', 'bad', 'it', \"'s\", 'not', '\"', 'regime', 'change', 'Tuesday', '\"', 'in', 'our', 'country', 'today', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['regime', 'bad']\n",
            "2998 ['Where', 'are', 'our', 'MoC', 'today', '?', 'Find', 'them', ',', 'contact', 'them', ',', 'and', 'demand', 'they', 'act', 're', 'and', '.', 'Per', '45', 'himself', ',', '\"', 'We', 'attacked', 'Syria', '\"']\n",
            "annotated_mention_list: [('syria', 'loc')]\n",
            "non_entity_list: ['demand', 'per', 'find']\n",
            "syria\n",
            "2999 ['Who', 'wants', 'a', 'man', 'under', 'criminal', 'investigation', 'deciding', 'the', 'fate', 'of', 'our', 'country', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['investigation', 'wants', 'man']\n",
            "3000 ['@USER', 'Only', ',', 'this', 'time', 'there', 'were', 'no', 'cartoon', 'drawings', 'or', 'suppositions', ',', 'but', 'real', 'people', 'and', 'families', 'who', 'were', 'killed']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['killed', 'people', 'time']\n",
            "3001 ['@USER', 'we', 'need', 'an', 'impartial', 'investigation', 'on', '!', 'Stand', 'up', '!', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['investigation', 'need']\n",
            "3002 ['They', \"'re\", 'behind', 'schedule', 'cuz', 'they', 'asked', 'Putin', \"'s\", 'help', 'and', 'Russian', 'Easter', 'is', 'a', 'week', 'later', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('russian easter', 'misc')]\n",
            "non_entity_list: ['week', 'help', 'asked', 'later']\n",
            "putin\n",
            "russian easter\n",
            "3003 ['Can', 'I', 'ASK', 'WHY', 'HE', 'HAS', 'CEO', '-', 's', 'AT', 'THE', 'WHITE', 'HOUSE', 'INTEAD', 'OF', 'ACTUALLY', 'WORKING', 'ON', 'THE', 'DEBT', 'CEILING', 'DUE', 'THIS', 'MONTH', '?', '!']\n",
            "annotated_mention_list: [('ceo', 'misc'), ('white house', 'loc')]\n",
            "non_entity_list: ['due', 'actually']\n",
            "ceo\n",
            "white house\n",
            "3004 ['@USER', 'trump']\n",
            "annotated_mention_list: []\n",
            "3005 ['You', 'do', 'realize', 'you', 'are', 'echoing', 'Putin', \"'s\", 'words', '?', 'Strange', 'since', 'you', \"'ve\", 'spent', 'so', 'much', 'time', 'trying', 'to', 'prove', 'ties', '.']\n",
            "annotated_mention_list: [('putin', 'per')]\n",
            "non_entity_list: ['time', 'ties']\n",
            "putin\n",
            "3006 ['More', 'like', 'once', 'again', 'we', 'found', 'a', 'way', 'to', 'blame', 'a', 'woman', 'for', 'the', 'shit', 'men', 'do', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['men', 'way', 'blame', 'woman']\n",
            "3007 ['*', 'THIS', '*', 'is', 'what', 'we', 'have', 'been', 'reduced', 'to', '...']\n",
            "annotated_mention_list: []\n",
            "3008 ['EO', 'to', 'pollute', 'rivers', 'w', '/', 'TOXIC', 'Coal', 'Waste', 'EO', 'allowing', 'DOW', 'pesticide', 'that', 'harms', 'children', \"'s\", 'brains']\n",
            "annotated_mention_list: [('eo', 'org'), ('eo', 'org'), ('dow', 'org')]\n",
            "non_entity_list: ['children']\n",
            "eo\n",
            "eo\n",
            "dow\n",
            "3009 ['Not', 'certain', 'and', 'are', 'true', 'name', 'only']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['name']\n",
            "3010 ['Funny', '!', 'Gettin', \"'\", 'under', 'a', 'bit', 'of', 'pasty', ',', 'privileged', 'skin', ',', 'eh', '?']\n",
            "annotated_mention_list: []\n",
            "3011 ['Get', 'these', 'Stooges', 'OUT', 'OF', 'OFFICE', '...', 'NOW', '!', '!', '!', '≡', 'ƒÿá', '≡', 'ƒûò', '≡', 'ƒÿá', '≡', 'ƒûò', '≡', 'ƒÿá', '≡', 'ƒûò', '≡', 'ƒÿá']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['office', 'get']\n",
            "3012 ['@USER', 'She', 'is', 'but', 'still', 'up', 'to', 'her', 'eyeballs', 'in']\n",
            "annotated_mention_list: []\n",
            "3013 ['I', \"'m\", 'over', 'his', 'Γ', '¥', 'ñ', 'of', 'attention', '4', 'his', 'bad', 'actions', '.', 'is', 'enough.Remove', 'him', '@USER', '@USER', '@USER', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['bad']\n",
            "3014 ['Last', 'Weekend', '.', 'April', '.', 'Spring', '≡', 'ƒç', '▓', '≡', 'ƒç', '╕', '≡', 'ƒç', '░', '≡', 'ƒÄ', '¼', 'ΓÇª']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['last']\n",
            "3015 ['The', 'IS', 'in', 'fact', 'the', 'BOARD', 'OF', 'DIRECTORS', 'for', 'CORPORATE', 'AMERICA', '.']\n",
            "annotated_mention_list: [('america', 'loc')]\n",
            "non_entity_list: ['board']\n",
            "america\n",
            "3016 ['Gee', ',', 'I', 'wonder', 'which', 'oil', 'company', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['oil']\n",
            "3017 ['Love', 'the', 'gif']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['gif']\n",
            "3018 ['Gosh', 'what', 'a', 'coincidence', 'prefers', 'authoritarian', 'governments']\n",
            "annotated_mention_list: []\n",
            "3019 ['and', 'both', 'are', 'narcissistic', 'on', 'top', 'of', 'it', ',', 'which', 'is', 'even', 'worse', '..']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['worse']\n",
            "3020 ['@USER', '@USER', '@USER', 'Trump', 'is', 'a', 'dumb', 'mans', 'idea', 'of', 'a', 'smart', 'man', ';', 'a', 'poor', 'mans', 'idea', 'of', 'a', 'rich', 'man', 'and', 'a', 'weak', 'mans', 'idea', 'of', 'a', 'strong', 'man', '!']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['poor', 'dumb', 'man']\n",
            "trump\n",
            "3021 ['What', 'an', 'ass', '.', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['ass']\n",
            "3022 ['Shut', 'up', 'Eric', '.', 'The', 'FBI', 'sees', 'all', 'of', 'it', '.', 'Oh', 'and']\n",
            "annotated_mention_list: [('eric', 'per'), ('fbi', 'org')]\n",
            "non_entity_list: ['shut']\n",
            "eric\n",
            "fbi\n",
            "3023 ['Succinct', '.']\n",
            "annotated_mention_list: []\n",
            "3024 ['Where', 'there', \"'s\", 'smoke', ',', 'there', \"'s\", 'fire', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['fire']\n",
            "3025 ['Cover', 'up', '.', 'Lock', 'him', 'up', 'too', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['cover']\n",
            "3026 ['Inside', 'Politics', 'Panel', ':', 'Syria', 'Looms', 'Over', 'Tillerson', 'Visit', 'To', 'Moscow', '.', '@USER', '@USER', ':', 'via', '@USER']\n",
            "annotated_mention_list: [('syria', 'loc'), ('tillerson', 'per'), ('moscow', 'loc')]\n",
            "non_entity_list: ['politics', 'inside']\n",
            "syria\n",
            "tillerson\n",
            "moscow\n",
            "3027 ['@USER', '@USER', 'is', 'sooo', 'proud', '.']\n",
            "annotated_mention_list: []\n",
            "3028 ['@USER', 'Let', \"'s\", 'follow', 'their', 'lead', 'and', 'do', 'this', 'at', 'the', 'national', 'level', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['lead', 'level', 'national']\n",
            "3029 ['@USER', 'the', 'fact', 'you', 'take', 'a', 'potential', 'for', 'WW3', 'so', 'lightly', 'you', 'are', 'willing', 'to', 'tweet', 'about', 'it', 'is', 'disgusting', '.', 'I', 'pray', 'stops', 'you', 'soon', '.']\n",
            "annotated_mention_list: [('ww3', 'misc')]\n",
            "non_entity_list: ['take', 'soon', 'tweet']\n",
            "ww3\n",
            "3030 ['If', 'you', 'do', \"n't\", 'understand', 'trip', 'wires', 'and', 'claymores', 'strategy', 'then', 'obviously', 'this', 'would', \"n't\", 'make', 'any', 'sense', 'to', 'you', '.', 'Set', 'up', 'ambush', '.', 'Wait', 'for', 'response']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['set', 'trip', 'response', 'wait']\n",
            "3031 ['Of', 'what', 'year', '?', '?']\n",
            "annotated_mention_list: []\n",
            "3032 ['Retweeted', 'Scott', 'Dworkin', '(', '@USER', '):', 'RT', 'if', 'you', \"'ll\", 'never', 'let', 'the', 'saga', 'die']\n",
            "annotated_mention_list: [('scott dworkin', 'per')]\n",
            "scott dworkin\n",
            "3033 ['Afternoon', 'coffee', ',', 'side-parted', 'blow-dry', 'and']\n",
            "annotated_mention_list: []\n",
            "3034 ['More', 'smoke', '.', ',', 'please', 'do', \"n't\", ',', 'for', 'once', ',', 'amplify', 'their', 'distraction', 'play', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['distraction']\n",
            "3035 ['Days', 'at', 'Golf', 'Course', 'having', 'Productive', 'meetings', '?', 'President', 'Trump', ':', '17', 'Obama', ':', 'Stupid', 'Americans', ',', 'they', 'just', 'need', 'to', 'obey', 'me', '.']\n",
            "annotated_mention_list: [('president trump', 'per'), ('obama', 'per'), ('americans', 'misc')]\n",
            "non_entity_list: ['need', 'days', 'stupid']\n",
            "president trump\n",
            "obama\n",
            "americans\n",
            "3036 ['Trump', 'is', 'being', 'investigated', 'by', 'the', 'FBI', 'and', 'Congress', '.', 'Why', 'is', 'nothing', 'about', 'this', 'on', 'CNN', 'front', 'page', 'right', 'now', '?']\n",
            "annotated_mention_list: [('trump', 'per'), ('fbi', 'org'), ('congress', 'org'), ('cnn', 'org')]\n",
            "non_entity_list: ['right']\n",
            "trump\n",
            "fbi\n",
            "congress\n",
            "cnn\n",
            "3037 ['Retweeted', 'Impeach', 'Trump', '(', '@USER', '):', 'Hey', '@USER', '!', 'Tax', 'cuts', 'for', 'who', '?', '...']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['tax']\n",
            "trump\n",
            "3038 ['@USER', \"U'r\", 'not', 'gonna', 'make', 'it', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['gonna']\n",
            "3039 ['Why', 'does', 'the', 'gov', 'pay', 'the', 'billionaire', 'his', 'hotel', 'bill', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['gov', 'pay']\n",
            "3040 ['@USER', ',', 'been', 'trying', 'to', 'get', '@USER', \"'\", 's', 'father', ',', '@USER', 'to', 'do', 'that', 'forever', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['get', 'father']\n",
            "3041 ['darn', 'Skippy', '..']\n",
            "annotated_mention_list: [('skippy', 'per')]\n",
            "skippy\n",
            "3042 ['@USER', 'you', \"'re\", 'just', 'too', 'stupid', 'to', 'stfu', ',', 'are', \"n't\", 'you', '?', 'Keep', 'it', 'up', '.', 'You', \"'ll\", 'eventually', 'help', 'get', 'your', 'pathetic', 'father', 'impeached', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['help', 'get', 'father', 'stupid']\n",
            "3043 ['@USER', '@USER', 'And', 'no', 'question', 'who', 'really', 'is', 'the', 'worst', 'president', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['really']\n",
            "3044 ['Stop', 'the', 'and', 'get', 'on', 'with', 'an', 'into']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['get', 'stop']\n",
            "3045 ['something', 'tells', 'me', 'ERIC', 'isnt', 'so', 'dumb', ',', 'he', 'may', 'be', 'trying', 'to', 'take', 'down', 'the', 'family', ',', 'and', 'become', 'favorite', 'child']\n",
            "annotated_mention_list: [('eric', 'per')]\n",
            "non_entity_list: ['take', 'family', 'may', 'dumb', 'tells']\n",
            "eric\n",
            "3046 ['In', 'Russia', ',', 'Medvedev', 'and', 'Lavrov', 'carry', 'no', 'weight', '.', 'Likewise', ',', 'Tillerson', 'and', 'Haley', 'do', \"n't\", 'count', 'to', 'Putin', '.', 'Only', 'Trump', 'who', 'remains', 'silent', '.']\n",
            "annotated_mention_list: [('russia', 'loc'), ('medvedev', 'per'), ('lavrov', 'per'), ('tillerson', 'per'), ('haley', 'per'), ('putin', 'per'), ('trump', 'per')]\n",
            "russia\n",
            "medvedev\n",
            "lavrov\n",
            "tillerson\n",
            "haley\n",
            "putin\n",
            "trump\n",
            "3047 ['Hamilton', \"'s\", 'father', 'covertly', 'made', 'voyeuristic', 'etchings', 'of', 'his', 'relatives', 'in', 'the', 'act', 'of', 'sexual', 'congress', '?', 'Ehgads', ',', 'sir', '!']\n",
            "annotated_mention_list: [('hamilton', 'per')]\n",
            "non_entity_list: ['father', 'made', 'sexual']\n",
            "hamilton\n",
            "3048 ['@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "3049 ['of', 'the', '@USER', 'and', 'continues', 'to', 'STUN', 'and', 'HORRIFY', 'Americans', '!']\n",
            "annotated_mention_list: [('americans', 'misc')]\n",
            "americans\n",
            "3050 ['Let', \"'s\", 'have', 'an', 'RT', 'party', 'for', 'Trump', '!']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['party']\n",
            "trump\n",
            "3051 ['@USER', 'Not', 'to', 'mention', 'we', 'have', 'nothing', 'as', 'a', 'result', 'of', 'our', 'airfield', 'attack.But', 'it', 'sure', 'was', 'the', 'shony', 'object', 'that', 'got', 'attention', 'away', 'from']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['airfield', 'got', 'mention', 'away']\n",
            "3052 ['\"', 'Eric', 'Trump', '\"']\n",
            "annotated_mention_list: [('eric trump', 'per')]\n",
            "eric trump\n",
            "3053 ['RT', 'and', 'keep', 'sharing', 'this', '.', 'This', 'admin', 'needs', 'to', 'go', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['needs', 'go', 'admin']\n",
            "3054 ['CONGRATULATIONS', '!', '!', '!', '≡', 'ƒÖî', '≡', 'ƒæÅ', 'U', 'HAVE', 'EARNED', 'A', '!', '!', '≡', 'ƒÿé', '≡', 'ƒÿé']\n",
            "annotated_mention_list: []\n",
            "3055 ['How', 'can', 'stop', 'shutdown', 'by', '45', 'of', 'on', 'KEEP', 'PUSHING', 'IT']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['stop']\n",
            "3056 ['Sounds', 'a', 'lot', 'more', 'like', 'it', '!', 'He', 'was', 'not', 'even', 'near', 'top', 'of', 'class']\n",
            "annotated_mention_list: []\n",
            "3057 ['Graham', 'Discusses', 'and', 'Visit', 'to', 'on']\n",
            "annotated_mention_list: [('graham', 'per')]\n",
            "graham\n",
            "3058 ['Stop', 'him', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['stop']\n",
            "3059 ['Scaramucci', 'is', 'another', 'delusional', 'liar', '.', 'Alexander', 'Hamilton', 'my', 'ass', '!', 'More', 'like', 'Harry', 'Potter', 'without', 'the', 'magic', '!']\n",
            "annotated_mention_list: [('scaramucci', 'per'), ('alexander hamilton', 'per'), ('harry potter', 'per')]\n",
            "non_entity_list: ['liar', 'ass']\n",
            "scaramucci\n",
            "alexander hamilton\n",
            "harry potter\n",
            "3060 ['Apr', '11', '19:30', 'Temperature', '10C', 'light', 'showers', 'Wind', 'W', '11', 'km', '/', 'h', 'Humidity', '80', '%', 'Russia', '..']\n",
            "annotated_mention_list: [('russia', 'loc')]\n",
            "russia\n",
            "3061 ['@USER', 'we', 'really', 'hope', \"y'all\", 'finish', 'up', 'on', 'this', 'Probe', 'before', '@USER', 'get', 'us', 'all', 'killed', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['probe', 'us', 'killed', 'get', 'really']\n",
            "3062 ['@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "trump\n",
            "3063 ['@USER', 'You', \"'re\", 'not', 'distracting', 'us', 'from', 'your', 'father', \"'s\", '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['father', 'us']\n",
            "3064 ['@USER', 'Stop', 'the', 'and', 'get', 'on', 'with', 'an', 'into']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['get', 'stop']\n",
            "3065 ['Oh', 'and', 'he', 'is', 'a', 'traitor']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['traitor']\n",
            "3066 ['@USER', 'I', 'hate', 'that', 'this', 'man', 'is', 'supposed', 'to', 'speak', 'for', 'me', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['man']\n",
            "3067 ['Obstruction', 'of', 'justice', 'by', 'trying', 'to', 'cover', 'it', 'up', '.', 'He', \"'s\", 'telling', 'us', 'the', 'exact', 'reason', 'the', 'Orange', 'Menace', 'ejuaculated', 'missiles', 'over', 'a', 'barren', 'area', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['cover', 'justice', 'us', 'orange']\n",
            "3068 ['Now', 'that', \"'s\", 'what', 'I', 'call', 'marketing', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['call', 'marketing']\n",
            "3069 ['It', \"'s\", 'like', 'a', 'black-tie', 'RICO', 'indictment', 'To', 'quinn', 'cummings', '(', 'or', 'quinncy', ')', 'dated', 'April', '11', ',', '2017']\n",
            "annotated_mention_list: [('rico', 'misc'), ('quinn cummings', 'per'), ('quinncy', 'per')]\n",
            "rico\n",
            "quinn cummings\n",
            "quinncy\n",
            "3070 ['Conspiring', 'once', 'again', '#', 'kill', 'the', 'innocents']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['kill']\n",
            "3071 ['Lucky', 'Sperm', 'and', 'Animal', 'Killers', 'Convince', 'Locals', 'To', 'Help', 'Them', 'Bury', 'Bachelor', 'Party', 'Stripper', 'To', 'quinn', 'cummings', '(', 'or', 'quinncy', ')', 'dated', 'April', '11', ',', '2017']\n",
            "annotated_mention_list: [('quinn cummings', 'per'), ('quinncy', 'per')]\n",
            "non_entity_list: ['help', 'convince', 'animal', 'bury', 'party', 'lucky']\n",
            "quinn cummings\n",
            "quinncy\n",
            "3072 ['Sincere', 'thanks', 'to', 'those', 'in', 'the', 'media', 'doing', 'their', 'jobs', 'by', 'investigating', 'and', 'reporting', 'on', 'Trump', 'and', 'Russia', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['media']\n",
            "trump\n",
            "russia\n",
            "3073 ['1', '.', 'Defeat', 'ISIS', 'in', '30', 'days', '2', '.', 'Repeal', 'Obamacare', '3', '.', 'Mexico', 'to', 'pay', 'for', 'wall', '4', '.', 'Play', 'lots', 'of', 'golf', '@USER']\n",
            "annotated_mention_list: [('isis', 'org'), ('obamacare', 'misc'), ('mexico', 'loc')]\n",
            "non_entity_list: ['wall', 'days', 'repeal', 'pay']\n",
            "isis\n",
            "obamacare\n",
            "mexico\n",
            "3074 ['@USER', 'Amaliada', '@USER', 'dremmelqueen', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('amaliada', 'per'), ('dremmelqueen', 'per'), ('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "amaliada\n",
            "dremmelqueen\n",
            "putin\n",
            "trump\n",
            "3075 ['Russian', 'arrested', 'for', \"'\", 'hacking', \"'\", 'US', 'election']\n",
            "annotated_mention_list: [('russian', 'misc'), ('us', 'loc')]\n",
            "non_entity_list: ['election']\n",
            "russian\n",
            "us\n",
            "3076 ['How', 'many', 'investigations', 'is', 'Trump', 'under', 'now', '?', 'FBI', ',', 'Congress', ',', 'GAO', ',', 'and', 'all', 'his', 'other', 'lawsuits', '...']\n",
            "annotated_mention_list: [('trump', 'per'), ('fbi', 'org'), ('congress', 'org'), ('gao', 'org')]\n",
            "non_entity_list: ['investigations']\n",
            "trump\n",
            "fbi\n",
            "congress\n",
            "gao\n",
            "3077 ['LOCK', 'HIM', 'UP', ',', 'LOCK', 'HIM', 'UP', ',', 'I', 'want', 'to', 'see', 'how', 'well', 'tRumps', 'orange', 'hair', 'goes', 'with', 'his', 'orange', 'jump', 'suit']\n",
            "annotated_mention_list: [('trumps', 'misc')]\n",
            "non_entity_list: ['see', 'goes', 'orange']\n",
            "trumps\n",
            "3078 ['@USER', 'Just', 'look', 'at', 'that', 'fat', 'fuck', '.', 'Thinks', 'he', \"'s\", 'Patton', 'standing', 'in', 'front', 'of', 'that', 'flag', '.', 'We', 'could', 'be', 'fucked', '.']\n",
            "annotated_mention_list: [('patton', 'per')]\n",
            "non_entity_list: ['fucked', 'thinks', 'look']\n",
            "patton\n",
            "3079 ['Putin', 'says', 'US', 'is', 'preparing', 'to', 'bomb', 'Syrian', 'capital', 'and', 'will', 'blame', 'Bashar-al', 'Assad', 'Helping', 'his', 'puppet', '!']\n",
            "annotated_mention_list: [('putin', 'per'), ('us', 'loc'), ('syrian', 'misc'), ('bashar-al assad', 'per')]\n",
            "non_entity_list: ['puppet', 'says', 'bomb', 'capital', 'blame']\n",
            "putin\n",
            "us\n",
            "syrian\n",
            "bashar-al assad\n",
            "3080 ['He', \"'s\", 'hiding', 'Russia', 'in', 'there', '.']\n",
            "annotated_mention_list: [('russia', 'loc')]\n",
            "non_entity_list: ['hiding']\n",
            "russia\n",
            "3081 ['Another', 'tweet', 'aging', 'horribly', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['tweet']\n",
            "3082 ['...', 'keep', 'watching', '...', 'this', 'is', 'where', '@USER', 'and', 'are', 'bringing', 'us', '!', 'We', 'Have', 'NOT', 'forgotten', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['watching', 'us']\n",
            "3083 ['@USER', '@USER', 'she', 'needs', 'to', 'be', 'saved', '.', 'What', 'has', 'he', 'accomplished', 'to', 'date', '?', '@USER', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['needs']\n",
            "3084 ['Trump', '-', 'Russia', 'Links', 'should', 'Proceed', 'via', '@USER', '-', 'DT', 'can', 'run', 'but', 'cant', 'hide-keep', 'focused']\n",
            "annotated_mention_list: [('trump', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['run']\n",
            "trump\n",
            "russia\n",
            "3085 ['@USER', '@USER', 'Stop', 'the', 'and', 'get', 'on', 'with', 'an', 'into']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['get', 'stop']\n",
            "3086 ['The', 'trump', '-', 'syria', 'situation', 'is', 'a', 'deflection', 'ppl', '.', 'Putin', 'is', 'Trump', \"'s\", 'puppet', '.', 'Period']\n",
            "annotated_mention_list: [('trump', 'per'), ('syria', 'loc'), ('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['puppet']\n",
            "trump\n",
            "syria\n",
            "putin\n",
            "trump\n",
            "3087 ['TREASON', 'is', 'still', 'happening', 'today', 'Was', \"n't\", 'just', 'the', 'election', 'Russian', 'Rogues', 'Gallery', 'grows', 'larger', 'day', 'by', 'day', 'You', 'have', 'no', 'idea', 'how', 'deep', 'this', 'goes']\n",
            "annotated_mention_list: [('russian rogues gallery', 'org')]\n",
            "non_entity_list: ['treason', 'goes', 'deep', 'day', 'election']\n",
            "russian rogues gallery\n",
            "3088 ['Let', \"'s\", 'see', 'what', 'they', 'do', 'to', 'this', 'slimeball', 'If', 'it', 'was', 'us', 'we', \"'d\", 'have', 'our', 'doors', 'kicked', 'in', 'by', 'dirty', 'cops']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['see', 'dirty', 'us']\n",
            "3089 ['why', 'is', '@USER', 'okay', 'with', 'this', '?']\n",
            "annotated_mention_list: []\n",
            "3090 ['Hey', ',', '@USER', '-', '-', '@USER', 'got', 'blocked', 'for', 'this', 'Bet', 'you', 'can', 'too', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['bet', 'got']\n",
            "3091 ['@USER', '@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "3092 ['trump', 'campaign', 'INVESTIGATED', 'BY', 'FBI', 'ATTACK', 'ON', 'OUR', 'DEMOCRACY']\n",
            "annotated_mention_list: [('trump campaign', 'misc'), ('fbi', 'org'), ('democracy', 'misc')]\n",
            "non_entity_list: ['campaign', 'attack']\n",
            "trump campaign\n",
            "fbi\n",
            "democracy\n",
            "3093 ['@USER', '@USER', 'Stop', 'the', 'and', 'get', 'on', 'with', 'an', 'into']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['get', 'stop']\n",
            "3094 ['If', 'was', 'a', 'project', 'manager', 'on', 'the', 'apprentice', 'he', 'would', 'have', 'surely', 'been', 'FIRED', 'by', 'now', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['project', 'fired', 'apprentice']\n",
            "3095 ['trump', \"'s\", 'boss', 'is', 'trash-talking', 'him', '?', 'In', 'public', 'no', 'less', '?']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['public']\n",
            "trump\n",
            "3096 ['@USER', 'hopefully', 'people', 'now', 'realize', 'your', 'endorsements', 'are', 'no', 'good', '-', 'a', 'CON', 'for', 'and', '!', 'VOTE', '-', 'and']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['people', 'good', 'con']\n",
            "3097 ['@USER', 'having', '45', 'jr', 'as', 'a', 'mind', 'morning', 'snack', 'today', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['morning']\n",
            "3098 ['That', \"'s\", 'the', 'plan', '.', 'That', 'has', 'always', 'been', 'the', 'plan', '.', 'Trp', ',', 'as', 'a', 'Russian', 'puppet', ',', 'will', 'ruin', 'our', 'Free', 'country', '.']\n",
            "annotated_mention_list: [('russian', 'misc')]\n",
            "non_entity_list: ['puppet', 'plan']\n",
            "russian\n",
            "3099 ['Russian', 'journalists', 'sue', 'Foreign', 'Min', 'for', 'details', 'on', 'Amb', 'Kislyak', \"'s\", 'meetings', 'w', '/', 'Sessions', ',', 'Kushner', 'and', 'Manafort']\n",
            "annotated_mention_list: [('russian', 'misc'), ('amb kislyak', 'per'), ('sessions', 'per'), ('kushner', 'per'), ('manafort', 'per')]\n",
            "non_entity_list: ['foreign']\n",
            "russian\n",
            "amb kislyak\n",
            "sessions\n",
            "kushner\n",
            "manafort\n",
            "3100 ['NEW', 'Investigation', 'into', 'Trump', ':', 'Govt', 'Accountability', 'Office', 'investigating', 'Trump', \"'s\", 'transition']\n",
            "annotated_mention_list: [('trump', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['office', 'govt', 'investigation', 'new', 'transition']\n",
            "trump\n",
            "trump\n",
            "3101 ['@USER', 'Impossible', '!', 'Tainted', ',', 'inept', ',', 'unfit', 'has', 'no', 'vehicle', 'to', 'transform', '.', 'Impeach', 'this', 'whole', 'lot', '!', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['vehicle']\n",
            "3102 ['RT', '@USER', ':', 'Keep', 'em', 'on', 'an', 'island', '!']\n",
            "annotated_mention_list: []\n",
            "3103 ['So', 'much']\n",
            "annotated_mention_list: []\n",
            "3104 ['I', 'never', 'let', 'ethics', 'interfere', 'with', 'business', '.', 'Now', 'on', 'the', 'next', 'the', 'Syracusans', 'set', 'up', 'their', 'own', 'ears', '.', '-', 'it', 'can', 'happen', 'to', 'anyone', '.']\n",
            "annotated_mention_list: [('syracusans', 'misc')]\n",
            "non_entity_list: ['set', 'next', 'business']\n",
            "syracusans\n",
            "3105 ['TWO', 'NIGHTS', '.', 'The', 'little', 'brat', 'stayed', 'TWO', 'NIGHTS', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['little']\n",
            "3106 ['Every', 'tie', 'Trump', 'wears', 'is', 'a', 'Russia', 'tie', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['tie']\n",
            "trump\n",
            "russia\n",
            "3107 ['NO', 'it', 'did', \"n't\", '!']\n",
            "annotated_mention_list: []\n",
            "3108 ['Trump', 'smirks', 'and', 'looks', 'away', ',', 'refuses', 'to', 'answer', 'questions', 'about', 'Putin']\n",
            "annotated_mention_list: [('trump', 'per'), ('putin', 'per')]\n",
            "non_entity_list: ['answer', 'questions', 'away']\n",
            "trump\n",
            "putin\n",
            "3109 ['This', 'is', 'so', 'STUPID']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['stupid']\n",
            "3110 ['@USER', '@USER', '@USER', 'Same', 'here', '.', 'We', 'must', 'stick', 'together', 'to', 'get', 'truth', 'and', 'take', 'this', 'administration', 'down', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['get', 'take', 'administration', 'stick']\n",
            "3111 ['Bull', 'shit']\n",
            "annotated_mention_list: []\n",
            "3112 ['These', 'are', 'the', 'real', 'thugs.they', 'are', 'not', 'in', 'our', 'streets', '..', 'They', 'are', 'in', 'our', 'WH', 'and', 'need', '2go', '.', 'dont', 'believe', 'in', 'their', 'bible', 'of', 'hate', '.']\n",
            "annotated_mention_list: [('wh', 'loc')]\n",
            "non_entity_list: ['need']\n",
            "wh\n",
            "3113 ['This', 'and']\n",
            "annotated_mention_list: []\n",
            "3114 ['Does', 'he', 'call', 'this', 'a', '\"', 'donation', '\"', 'which', 'he', 'later', 'writes', 'off', 'on', 'his', 'tax', 'return', 'not', 'having', 'to', 'pay', 'taxes', '?', 'Legal', '?', 'Lets', 'all', 'set', 'up', '\"', 'foundations', '\"', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['later', 'tax', 'call', 'set', 'pay']\n",
            "3115 ['@USER', 'That', 'just', 'confirms', 'what', 'was', 'suspected', '...', 'that', 'the', 'attack', 'was', 'just', 'another', 'shiny', 'object', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['confirms', 'attack']\n",
            "3116 ['KANSAS', ',', 'pull', 'this', 'off', 'and', 'send', 'a', 'MESSAGE', '!', 'Get', 'over', 'with', '!']\n",
            "annotated_mention_list: [('kansas', 'loc')]\n",
            "non_entity_list: ['message', 'get']\n",
            "kansas\n",
            "3117 ['@USER', '@USER', 'You', \"'re\", 'meddling', ',', 'little', 'trump', ',', 'and', 'your', 'father', 'is', 'squatting', 'in', 'our', 'White', 'House', '.', 'He', 'and', 'Vlad', 'have', 'a', 'plan', 'to', 'hide', 'and', 'we', 'will', '!']\n",
            "annotated_mention_list: [('trump', 'per'), ('white house', 'loc'), ('vlad', 'per')]\n",
            "non_entity_list: ['little', 'father', 'plan']\n",
            "trump\n",
            "white house\n",
            "vlad\n",
            "3118 ['@USER', '@USER', 'Stop', 'the', 'and', 'get', 'on', 'with', 'an', 'into']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['get', 'stop']\n",
            "3119 ['@USER', 'SHUT', 'UP', ',', 'YOU', 'CLUELESS', 'SHITGIBBON', '!', '!', 'You', 'want', 'war', 'for', 'no', 'reason', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['war', 'shut']\n",
            "3120 ['@USER', '@USER', '@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "3121 ['should', 'go', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['go']\n",
            "3122 ['That', 'is', 'disgustingly', 'deplorable']\n",
            "annotated_mention_list: []\n",
            "3123 ['@USER', '@USER', 'Remember', ',', 'we', 'have', 'everything', 'to', 'win', 'and', 'nothing', 'to', 'lose', '!', 'Today', ',', 'we', 'all', 'live', 'in', 'Kansas', '.']\n",
            "annotated_mention_list: [('kansas', 'loc')]\n",
            "non_entity_list: ['win', 'live']\n",
            "kansas\n",
            "3124 ['Find', 'em', 'all', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['find']\n",
            "3125 ['She', 'only', 'advocates', 'for', 'things', 'she', 'cares', 'about', '.', 'Like', 'taking', 'the', 'heat', 'off', 'daddy', \"'s\", 'investigation', '.', '@USER', 'fools', 'no', 'one', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['investigation', 'things', 'daddy', 'one']\n",
            "3126 ['\"', 'Eric', 'Trump', '\"', 'ANIMAL', 'KILLERS']\n",
            "annotated_mention_list: [('eric trump', 'per')]\n",
            "non_entity_list: ['animal']\n",
            "eric trump\n",
            "3127 ['@USER', \"'\", 's', 'robocall', 'sucked', '.', 'It', 'sounds', 'like', 'he', 'was', 'being', 'held', 'hostage', '!']\n",
            "annotated_mention_list: []\n",
            "3128 ['@USER', '@USER', 'Oh', 'right', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['right']\n",
            "3129 ['They', 'treat', 'people', 'this', 'way', 'because', 'they', 'are', 'idiots', 'themselves', '.', 'It', \"'s\", 'all', 'they', 'know', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['people', 'way', 'idiots']\n",
            "3130 ['It', \"'s\", 'all', 'just', 'a', 'show']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['show']\n",
            "3131 ['@USER', '@USER', 'Stop', 'the', 'and', 'get', 'on', 'with', 'an', 'into']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['get', 'stop']\n",
            "3132 ['Dictator', 'huh', '?', 'And', 'what', 'about', 'the', 'Corrupt', 'Congress', 'that', 'doesnt', 'enforce', 'the', 'Constitution', '?']\n",
            "annotated_mention_list: [('congress', 'org'), ('constitution', 'misc')]\n",
            "non_entity_list: ['dictator']\n",
            "congress\n",
            "constitution\n",
            "3133 ['@USER', 'Epic', 'fail', '.']\n",
            "annotated_mention_list: []\n",
            "3134 ['FM', 'Zarif', 'will', 'travel', 'to', 'on', 'Friday', 'April', '14', 'to', 'meet', 'and', 'FMs', '.', 'Three', 'FMs', 'will', 'also', 'have', 'a', 'trilateral', 'meeting', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['meeting', 'fms']\n",
            "3135 ['@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "trump\n",
            "3136 ['@USER', '@USER', '@USER', '@USER', '@USER', '≡', 'ƒñö', 'Trumpcare', 'fail', 'Flynn', 'resigned', 'Nunes', 'recused', 'Bannon', 'booted', 'from', 'NSC', 'FBI', 'investigation', 'Jared', 'lied', 'pervert', 'and', 'crook']\n",
            "annotated_mention_list: [('trumpcare', 'misc'), ('flynn', 'per'), ('nunes', 'per'), ('bannon', 'per'), ('nsc', 'org'), ('fbi', 'org'), ('jared', 'per')]\n",
            "non_entity_list: ['investigation', 'lied']\n",
            "trumpcare\n",
            "flynn\n",
            "nunes\n",
            "bannon\n",
            "nsc\n",
            "fbi\n",
            "jared\n",
            "3137 ['@USER', 'More', 'posturing', 'to', 'be', 'sure', '.', 'Keep', 'your', 'eyes', 'on', '\"', 'Peace', 'Agreement', '\"', 'that', 'includes', 'lifting', 'sanctions', ',', 'unilaterally', 'if', 'necessary']\n",
            "annotated_mention_list: [('peace agreement', 'misc')]\n",
            "non_entity_list: ['eyes', 'sanctions', 'peace']\n",
            "peace agreement\n",
            "3138 ['Text', '50409', 'is']\n",
            "annotated_mention_list: []\n",
            "3139 ['is', 'all', 'there', 'is', '.', 'Treason', 'in', 'the', 'white', 'house', 'takes', 'precedence', 'over', 'all', 'the', 'BS', 'they', \"'re\", 'throwing', 'out', 'there', '.', 'FOCUS', '!']\n",
            "annotated_mention_list: [('white house', 'loc')]\n",
            "non_entity_list: ['treason', 'throwing', 'takes']\n",
            "white house\n",
            "3140 ['yes', 'Trump', 'fooled', 'us', 'again', '!']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['us']\n",
            "trump\n",
            "3141 ['All', 't', 'Trumps', 'use', 'Charities', 'like', 'personal', 'pggy', 'banks', '.', 'Daddy', 'taught', 'them', 'this', '.', 'They', 'also', 'use', 'thm', 't', 'launder', 'money', '.', 'Someone', 'needs', 'to', 'watch', 'this', '.']\n",
            "annotated_mention_list: [('trumps', 'misc')]\n",
            "non_entity_list: ['needs', 'use', 'money', 'daddy']\n",
            "trumps\n",
            "3142 ['\"', 'A', 'Russian', 'Activist', 'Caught', 'Putin', \"'s\", 'Spokesman', 'On', 'A', '$', '425,000-', 'A-Week', 'Yacht', '\"', '(', '2015', ')', '@USER', '@USER']\n",
            "annotated_mention_list: [('russian', 'misc'), ('putin', 'per')]\n",
            "non_entity_list: ['spokesman']\n",
            "russian\n",
            "putin\n",
            "3143 ['I', 'do', \"n't\", 'give', 'AF', 'about', '@USER', '.', 'That', 'shit', 'has', 'nothing', 'to', 'do', 'with', 'me', '.', 'I', 'wanna', 'hear', 'more', 'about']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['give']\n",
            "3144 ['...', 'and', 'he', \"'s\", 'STILL', 'IN', 'OFFICE', '!', '!', '!', 'WHY', '!', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['office']\n",
            "3145 ['@USER', 'One', 'Beavis', 'and', 'an', 'administration', 'full', 'of', 'Buttheads', '.']\n",
            "annotated_mention_list: [('beavis', 'per')]\n",
            "non_entity_list: ['administration', 'full', 'one']\n",
            "beavis\n",
            "3146 ['@USER', '@USER', 'Which', 'is', 'exactly', 'what', 'promised', 'he', 'would', \"n't\", 'allow', '.', 'More', 'broken', 'promises', 'by', 'a', 'disastrous', 'cabinet', '.']\n",
            "annotated_mention_list: []\n",
            "3147 ['lol', '...', 'he', 'is', 'no', 'big', 'loss']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['big']\n",
            "3148 ['You', 'do', \"n't\", 'give', 'universal', 'healthcare', '-', 'a', 'basic', 'human', 'right', '-', 'and', 'walk', 'back', '.', 'How', 'stupid', 'are', 'these', 'dudes', '?', 'so', 'embarrassing', '.']\n",
            "annotated_mention_list: [('universal healthcare', 'misc')]\n",
            "non_entity_list: ['right', 'embarrassing', 'back', 'human', 'give', 'healthcare', 'stupid']\n",
            "universal healthcare\n",
            "3149 ['You', 'do', \"n't\", 'give', 'universal', 'healthcare', '-', 'a', 'basic', 'human', 'right', '-', 'and', 'walk', 'back', '.', 'How', 'stupid', 'are', 'these', 'dudes', '?', 'so', 'embarrassing', '.']\n",
            "annotated_mention_list: [('universal healthcare', 'misc')]\n",
            "non_entity_list: ['right', 'embarrassing', 'back', 'human', 'give', 'healthcare', 'stupid']\n",
            "universal healthcare\n",
            "3150 ['Tea', 'Leaves', 'can', 'tell', 'you', 'stuff', '.', 'Of', 'incomparable', 'sweetness', '.', 'Add', 'to', 'this', 'plan', ',', 'so', 'as', 'to', 'exercise', 'their', 'navy', '.', 'folks', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['stuff', 'navy', 'plan']\n",
            "3151 ['I', \"'m\", 'sure', 'taxpayers', 'paid', 'for', 'this', 'trip', 'too', '!', '\"', 'Eric', 'Trump', '\"']\n",
            "annotated_mention_list: [('eric trump', 'per')]\n",
            "non_entity_list: ['trip', 'taxpayers']\n",
            "eric trump\n",
            "3152 ['@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "3153 ['WAG', 'THE', 'DOG', '!', 'on']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['dog']\n",
            "3154 ['@USER', 'So', ',', 'he', 'is', 'implying', 'the', 'ulterior', 'motive', 'was', 'to', 'INDEED', 'to', 'defer', 'from', '?', 'Thinking', ',', 'someone', \"'s\", 'got', 'some', \"'\", 'splaining', 'to', 'do', '...']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['thinking', 'got']\n",
            "3155 ['This', 'is', 'the', 'body', 'language', 'of', 'a', 'girl', 'who', \"'s\", 'tired', 'of', 'people', 'telling', 'her', 'that', 'her', 'boyfriend', 'is', 'no', 'good', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['people', 'good', 'girl', 'tired']\n",
            "3156 ['Reminder', 'To', 'All', 'of', 'Us', ':', 'Our', 'voices', 'were', 'the', 'only', 'ones', 'out', 'there', 'when', 'most', 'media', 'and', 'pols', 'were', 'silent', '.', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['media', 'voices', 'us']\n",
            "3157 ['@USER', 'and', '@USER', 'get', 'out', 'and', 'VOTE', '!', '!', '@USER', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['get']\n",
            "3158 ['is', 'a', 'special', 'kind', 'of', 'stupid', 'but', 'thanks', 'for', 'confirming', 'what', 'we', 'thought', '.', 'It', 'was', 'all', 'for', 'show', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['show', 'stupid', 'thought']\n",
            "3159 ['arrests', 'who', 'had', 'infected', '100K', 'computers', 'worldwide', ',', '5-10', '%', 'were', 'inside', 'the', 'US', '-', 'linked', 'to']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['us', 'inside']\n",
            "3160 ['...', 'How', 'can', 'anyone', 'be', 'this', 'stupid', '...', '@USER', '...', 'shit', 'I', 'forgot', '@USER', '!', 'We', 'Have', 'NOT', 'forgotten', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['forgot', 'stupid']\n",
            "3161 ['Safe', 'to', 'say', 'the', 'American', 'public', 'is', 'gonna', 'be', 'REALLY', 'SURPRISED', 'when', 'this', 'stuff', 'goes', 'down', '.', 'ΓÅ', '▒']\n",
            "annotated_mention_list: [('american', 'misc')]\n",
            "non_entity_list: ['public', 'stuff', 'goes', 'gonna', 'say', 'really']\n",
            "american\n",
            "3162 ['@USER', 'we', 'need', 'to', 'FOCUS', 'on', 'and', 'identify', 'and', 'prosecute', 'all', 'of', \"'\", 's', 'players', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['need']\n",
            "3163 ['This', 'pretty', 'much', 'sums', 'it', 'up', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['pretty']\n",
            "3164 ['Trump', 'just', 'made', 'another', 'move', 'that', 'will', 'anger', 'russia', '-', 'approving', 'the', 'addition', 'of', 'Montenegro', 'to', 'NATO']\n",
            "annotated_mention_list: [('trump', 'per'), ('russia', 'loc'), ('montenegro', 'loc'), ('nato', 'org')]\n",
            "non_entity_list: ['move', 'made']\n",
            "trump\n",
            "russia\n",
            "montenegro\n",
            "nato\n",
            "3165 ['@USER', '@USER', 'Get', 'out', 'of', 'our', 'way', ',', 'little', 'trump', '.', 'You', \"can't\", 'protect', 'your', 'traitor', 'dad', 'and', 'we', \"'ll\", 'take', 'you', 'down', 'too', '.', 'OOJ', '!', 'Shoo', ',', 'scat', '!']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['take', 'little', 'get', 'way', 'traitor', 'dad']\n",
            "trump\n",
            "3166 ['He', \"'s\", 'in', 'Russia', 'so', 'Geppetto', \"'s\", 'hand', 'is', 'firmly', 'back', 'up', 'his', 'arse']\n",
            "annotated_mention_list: [('russia', 'loc'), ('geppetto', 'per')]\n",
            "non_entity_list: ['back']\n",
            "russia\n",
            "geppetto\n",
            "3167 ['@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "3168 ['Yeah', '..', 'Apple', 'vs', '.', 'tree', 'vs', '.', 'gravity', '.', 'Turns', 'out', 'Eric', 'is', 'even', 'stupider', 'than', 'his', 'father', '!']\n",
            "annotated_mention_list: [('eric', 'per')]\n",
            "non_entity_list: ['turns', 'father']\n",
            "eric\n",
            "3169 ['More', 'mainstream', 'media', 'needs', 'to', 'do', 'its', ',', 'yes', ',', 'Constitutional', 'Duty', '!', 'It', 'irks', 'me', 'when', 'press', 'fawns', 'over', '45', 'in', 'hopes', 'of', 'normality', '.', '45', 'is', 'NOT', 'normal', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['mainstream', 'press', 'media', 'needs']\n",
            "3170 ['I', 'like', 'this', 'cat']\n",
            "annotated_mention_list: []\n",
            "3171 ['We', \"'re\", 'looking', 'at', 'you', ',', '@USER', '!', 'You', \"'re\", 'doing', 'a', 'stand', 'up', ',', 'A', '+', 'job', '!', 'And', 'we', 'ΓÖí', 'you', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['job']\n",
            "3172 ['is', 'personified', '.']\n",
            "annotated_mention_list: []\n",
            "3173 ['Forget', 'this', 'crap', 'this', 'presidency', 'is', 'runining', 'us', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['presidency', 'us']\n",
            "3174 ['His', 'boys', 'look', 'like', 'they', 'are', 'kids', 'that', 'got', 'beat', 'up', 'at', 'recess', 'every', 'day', '.', 'Could', 'explain', 'the', 'drain', 'bamage', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['got', 'day', 'kids', 'look']\n",
            "3175 ['As', 'an', 'American', ',', 'I', \"'m\", 'deeply', 'concerned', 'by', 'the', 'actions', 'of', 'the', 'criminal', 'US', 'government', 'as', 'it', 'relates', 'to', 'Venezuela', ',', 'Iran', ',', 'Libya', ',', 'Iraq', ',', 'Syria', ',', 'Haiti', ',', 'Honduras', ',', 'Afghanistan', ',', 'Yemen', ',', 'Palestine', '...', 'the', 'list', 'goes', 'on', '.', '#HandsOffVenezuela']\n",
            "annotated_mention_list: [('american', 'misc'), ('us', 'loc'), ('venezuela', 'loc'), ('iran', 'loc'), ('libya', 'loc'), ('iraq', 'loc'), ('syria', 'loc'), ('haiti', 'loc'), ('honduras', 'loc'), ('afghanistan', 'loc'), ('yemen', 'loc'), ('palestine', 'loc')]\n",
            "non_entity_list: ['goes', 'government', 'list']\n",
            "american\n",
            "us\n",
            "venezuela\n",
            "iran\n",
            "libya\n",
            "iraq\n",
            "syria\n",
            "haiti\n",
            "honduras\n",
            "afghanistan\n",
            "yemen\n",
            "palestine\n",
            "3176 ['@USER', 'a', 'lot', 'of', 'ppl', 'did', \"n't\", 'wont', 'this', 'judge', '.', 'So', 'we', 'are', 'not', 'pleased', 'with', 'how', 'it', 'was', 'gone', 'about', 'to', 'get', 'him', 'in', 'there', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['wont', 'get', 'gone', 'judge']\n",
            "3177 ['Oh', 'he', 'wasnΓÇÖt', 'kidding', ',', 'He', 'love', 'the', 'uneducated', ',', 'like', 'minded']\n",
            "annotated_mention_list: []\n",
            "3178 ['@USER', '@USER', 'Got', '$', '1,000', ':', '-', 'riding', 'on', 'Trump', 'not', 'being', 'president', 'end', 'of', 'May', '.', 'So', 'speed', 'those', 'investigations', 'up', 'will', 'you', '.']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['may', 'got', 'end', 'investigations']\n",
            "trump\n",
            "3179 ['Didnt', '@USER', 'say', 'one', 'time', 'that', 'if', 'youre', 'being', 'investigated', 'by', 'the', 'FBI', 'you', 'shoudlnt', 'be', 'president', '?', 'So', 'he', 's', '/', 'b', 'resigning', 'soon', ',', 'yes', '?']\n",
            "annotated_mention_list: [('fbi', 'org')]\n",
            "non_entity_list: ['time', 'say', 'soon', 'one']\n",
            "fbi\n",
            "3180 ['Interesting', '.']\n",
            "annotated_mention_list: []\n",
            "3181 ['@USER', '@USER', '@USER', '@USER', '@USER', 'Bernie', 'Sanders', 'can', 'not', 'make', 'the', 'FBI', 'investigation', 'into', 'move', 'any', 'quicker', '.', 'Not', 'sure', 'what', 'else', 'you', 'want', 'him', 'to', 'do', '.', 'Read', 'his', 'feed', '.']\n",
            "annotated_mention_list: [('bernie sanders', 'per'), ('fbi', 'org')]\n",
            "non_entity_list: ['investigation', 'move', 'feed']\n",
            "bernie sanders\n",
            "fbi\n",
            "3182 ['WTF', 'is', 'up', 'with', 'Eric', 'Trump', 'bragging', 'about', 'all', 'the', 'DJT', 'bs', 'today', '.', 'Hes', 'just', 'like', 'DJT', 'a', 'POS', 'THIEF']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('djt', 'per'), ('djt', 'per')]\n",
            "eric trump\n",
            "djt\n",
            "djt\n",
            "3183 ['Thankfully', ',', 'we', 'have', 'people', 'who', 'actuallt', 'take', 'this', 'seriously']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['take', 'people', 'seriously']\n",
            "3184 ['@USER', '@USER', 'Like', 'father', 'like', 'sons', '\"', 'HAPPY', 'SIBLINGS', 'DAY', 'COWARDS', '\"', '@USER', '@USER', '@USER', '@USER', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['father', 'day']\n",
            "3185 ['@USER', '@USER', 'w', '/', 'mob', 'associate', 'felon', 'Joey', \"'\", 'No', 'Socks', \"'\", 'Cinque', 'and', 'Tsar-a-Lago', 'on', 'New', 'Yrs', '-', '3', 'yrs', 'ago']\n",
            "annotated_mention_list: [(\"joey ' no socks ' cinque\", 'per'), ('tsar-a-lago', 'loc')]\n",
            "non_entity_list: ['socks', 'new']\n",
            "joey ' no socks ' cinque\n",
            "tsar-a-lago\n",
            "3186 ['YES', 'killers', '!']\n",
            "annotated_mention_list: []\n",
            "3187 ['@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "3188 ['It', 'would', 'take', 'a', 'MASSIVE', 'extended', 'March', '.', 'It', 'took', 'S', 'Koreans', '5', 'months', 'of', 'continual', 'march', 'to', 'get', 'rid', 'of', 'their', 'criminal', 'leader', '.']\n",
            "annotated_mention_list: [('s koreans', 'misc')]\n",
            "non_entity_list: ['take', 'leader', 'took', 'get', 'march']\n",
            "s koreans\n",
            "3189 ['If', 'a', 'major', 'report', 'by', 'eminent', 'economists', 'found', 'that', '#Venezuela', 'suffering', 'and', 'thousands', 'of', 'deaths', 'were', 'caused', 'by', 'Maduro', \"'s\", 'policies', ',', 'it', 'would', 'be', 'US', '-', 'UK', 'headline', 'news', '.', 'But', 'as', 'the', 'report', 'found', 'US', 'sanctions', 'were', 'to', 'blame', ',', 'in', 'US', '-', 'UK', 'media', 'it', 'was', 'ignored', '@USER']\n",
            "annotated_mention_list: [('maduro', 'per'), ('us', 'loc'), ('uk', 'loc'), ('us', 'loc'), ('us', 'loc'), ('uk', 'loc')]\n",
            "non_entity_list: ['suffering', 'media', 'blame', 'caused', 'sanctions', 'news']\n",
            "maduro\n",
            "us\n",
            "uk\n",
            "us\n",
            "us\n",
            "uk\n",
            "3190 ['@USER', 'Ca', \"n't\", 'we', 'get', 'rid', 'of', 'him', 'already', '!', 'Media', 'please', 'Focus', 'on', 'Russia', 'links']\n",
            "annotated_mention_list: [('russia', 'loc')]\n",
            "non_entity_list: ['already', 'media', 'get']\n",
            "russia\n",
            "3191 ['This', 'is', 'important', 'for', 'everyone', 'in', 'the', 'UK', 'and', 'the', 'US', 'to', 'watch', '.', 'We', 'are', 'constantly', 'bombarded', 'with', 'right', 'wing', 'propaganda', 'much', 'of', 'which', 'includes', 'fake', 'news', '.', 'Apart', 'from', 'the', 'elite', 'and', 'well', 'off', ',', 'Venezuelan', 'people', 'do', \"n't\", 'want', 'this', 'intervention', '.', 'US', 'sanctions', 'have', 'killed', 'over', '40K', '#Venezuela']\n",
            "annotated_mention_list: [('uk', 'loc'), ('us', 'loc'), ('venezuelan', 'misc'), ('us', 'loc')]\n",
            "non_entity_list: ['right', 'killed', 'people', 'wing', 'fake', 'sanctions', 'news']\n",
            "uk\n",
            "us\n",
            "venezuelan\n",
            "us\n",
            "3192 ['While', 'the', 'media', 'is', 'fixated', 'on', 'the', 'attempted', 'coup', 'in', '#Venezuela', ',', 'they', 'are', 'completely', 'silent', 'on', 'the', 'riots', 'in', '#Honduras', ',', 'where', 'a', 'government', 'building', 'was', 'set', 'on', 'fire', '.', 'That', \"'s\", 'because', 'the', 'president', 'is', 'a', 'US', 'puppet', 'installed', 'after', 'the', '2009', 'Obama', '-', 'Hillary', 'coup', ',', 'so', 'nothing', 'to', 'see', 'here', '.']\n",
            "annotated_mention_list: [('us', 'loc'), ('obama', 'per'), ('hillary', 'per')]\n",
            "non_entity_list: ['puppet', 'completely', 'see', 'media', 'government', 'set', 'coup', 'fire']\n",
            "us\n",
            "obama\n",
            "hillary\n",
            "3193 ['Probably', 'so', 'Eric', 'could', 'buy', 'a', 'large', 'portrait', 'of', 'himself', '.', 'That', 'seems', 'to', 'be', 'what', 'the', 'foundation', 'is', 'for', ',', 'or', 'maybe', 'his', 'personal', 'legal', 'fund', '.']\n",
            "annotated_mention_list: [('eric', 'per')]\n",
            "non_entity_list: ['foundation']\n",
            "eric\n",
            "3194 ['@USER', '@USER', 'you', 'are', 'not', 'us', '.', 'You', 'will', 'never', 'be', 'us', '.', 'You', 'do', \"n't\", 'have', 'a', 'clue', '.', 'Babysit', 'your', 'dad', '.', 'Stop', 'telling', 'him', 'to', 'drop', 'bombs', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['stop', 'dad', 'us', 'bombs']\n",
            "3195 ['Thread', 'read', 'it', 'all']\n",
            "annotated_mention_list: []\n",
            "3196 ['I', 'hear', 'his', 'golfing', 'companions', 'say', 'it', \"'s\", 'well-known', 'he', 'cheats', 'at', 'golf', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['say', 'golfing']\n",
            "3197 ['5', '.', 'Make', 'lots', 'of', 'money', 'by', 'going', 'to', 'self-owned', 'properties']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['going', 'money']\n",
            "3198 ['@USER', 'Rex', 'trying', 'to', 'find', 'a', 'way', 'to', 'deliver', 'Exxon', \"'s\", 'Patented', 'Technology', 'that', 'would', 'allow', 'Russia', 'to', 'reach', '45', '%', 'more', 'of', 'it', \"'s\", 'oil', 'reserves']\n",
            "annotated_mention_list: [('rex', 'per'), ('exxon', 'org'), ('russia', 'loc')]\n",
            "non_entity_list: ['oil', 'reach', 'way', 'find']\n",
            "rex\n",
            "exxon\n",
            "russia\n",
            "3199 ['I', \"'m\", 'so', 'sick', 'of', 'this', '!', '!', '!']\n",
            "annotated_mention_list: []\n",
            "3200 ['Everyday', 'all', 'day']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['everyday', 'day']\n",
            "3201 ['@USER', '@USER', '@USER', 'He', 'knows', 'he', \"'s\", 'done', '.', 'I', 'love', 'it', '.', 'Squirming', 'like', 'a', 'worm', 'in', 'the', 'hot', 'sun', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['knows']\n",
            "3202 ['This', 'is', 'the', 'power', 'of', 'public', 'outrage', '.', 'We', 'have', 'power', '.', 'Let', \"'s\", 'keep', 'marching', 'on', 'the', 'says', 'to']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['says', 'power', 'public']\n",
            "3203 ['US', 'interventions', 'in', ':', '#Iraq', '->', 'Millions', 'killed', 'and', 'displaced', '+', 'the', 'rise', 'of', 'ISIS', '.', '#Libya', '->', 'Thousands', 'killed', ',', 'millions', 'displaced', '+', 'slave', 'markets', '.', '#Syria', '->', 'Death', 'and', 'destruction', '+', 'millions', 'displaced', '.', 'But', 'sure', ',', 'US', 'intervention', 'in', '#Venezuela', 'sounds', 'like', 'a', 'totally', 'wonderful', 'idea', '.']\n",
            "annotated_mention_list: [('us', 'loc'), ('isis', 'org'), ('us', 'loc')]\n",
            "non_entity_list: ['killed', 'death', 'rise', 'millions']\n",
            "us\n",
            "isis\n",
            "us\n",
            "3204 ['Just', 'as', 'the', 'case', 'was', 'with', '#Syria', ',', 'Western', 'news', 'outlets', 'refuse', 'to', 'cover', 'the', 'massive', 'rallies', 'launched', 'by', 'the', 'people', 'of', '#Venezuela', 'today', 'against', 'the', 'latest', 'US', '-', 'backed', 'military', 'coup', 'attempt', 'because', 'it', 'does', \"n't\", 'advance', 'their', 'pro-war', ',', 'regime', 'change', 'agenda', '.', '#HandsOffVenezuela']\n",
            "annotated_mention_list: [('us', 'loc')]\n",
            "non_entity_list: ['latest', 'regime', 'cover', 'western', 'people', 'coup', 'case', 'news']\n",
            "us\n",
            "3205 ['@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "3206 ['Like', 'the', 'sitcom', ',', '\"', 'All', 'in', 'the', 'family', '\"', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['family']\n",
            "3207 ['arrives', 'in', 'and', 'will', 'meet', 'with', 'via', '@USER']\n",
            "annotated_mention_list: []\n",
            "3208 ['Follow', 'Facts', ',', 'Stand', 'up', 'to', 'injustice', 'Expose', 'bullies', '-']\n",
            "annotated_mention_list: []\n",
            "3209 ['Good', 'gawd', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['good']\n",
            "3210 ['@USER', ',', '@USER', 'I', 'agree', 'with', 'Mr', 'Trump', 'on', 'sign', '.', 'This', 'is', 'the', 'sign', 'language', 'sign', 'for', \"'\", 'Loser', \"'\", '!', 'And', 'he', 'will', 'definitely', 'lose', 'in', 'these', 'days', 'ahead', '.']\n",
            "annotated_mention_list: [('mr trump', 'per')]\n",
            "non_entity_list: ['agree', 'definitely', 'ahead', 'days']\n",
            "mr trump\n",
            "3211 ['Too', 'late', 'he', 'sold', 'out', '!']\n",
            "annotated_mention_list: []\n",
            "3212 ['Vote', 'goddamn', 'it', '!']\n",
            "annotated_mention_list: []\n",
            "3213 ['Trump', 'has', 'tied', 'up', 'our', 'entire', 'government', 'in', 'investigating', 'him', 'as', 'well', 'as', 'his', 'staff', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['government', 'entire', 'staff']\n",
            "3214 ['@USER', 'Keep', 'your', 'eyes', 'on', 'the', 'prize', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['eyes']\n",
            "3215 ['@USER', 'Did', 'you', 'really', 'make', 'a', 'meme', 'out', 'of', 'this', '3rd', 'grade', 'tweet', '?', 'You', 'are', 'as', 'big', 'a', 'joke', 'as', 'he', 'is', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['joke', 'meme', 'really', 'big', 'tweet']\n",
            "3216 ['The', 'blackmail', 'is', 'EXACTLY', 'what', 'I', 'think', 'it', 'is', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['think']\n",
            "3217 ['@USER', '@USER', 'we', 'will', 'ppl', 'who', 'will', 'be']\n",
            "annotated_mention_list: []\n",
            "3218 ['Such', 'hubris', '!', 'Hamilton', 'was', 'poor', ',', 'in', 'the', 'army', ',', 'believed', 'in', 'equality', 'and', 'opposed', 'slavery', '.', 'Not', 'at', 'all', 'like', '@USER']\n",
            "annotated_mention_list: [('hamilton', 'per')]\n",
            "non_entity_list: ['poor', 'army']\n",
            "hamilton\n",
            "3219 ['This', 'was', 'clear', 'to', 'the', 'People', 'within', '48', 'hours', 'of', 'his', 'ridiculous', 'little', 'act', 'on', 'the', 'WH', 'lawn', '.']\n",
            "annotated_mention_list: [('wh', 'loc')]\n",
            "non_entity_list: ['people', 'lawn', 'hours', 'little']\n",
            "wh\n",
            "3220 ['money', 'hungry', 'SOB', \"'s\", '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['money']\n",
            "3221 ['This', 'entire', 'family', 'is', 'just', 'so', 'disgusting', '.', 'Will', 'be', 'a', 'beautiful', 'thing', 'to', 'watch', 'when', 'the', 'dominoes', 'start', 'to', 'fall']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['fall', 'thing', 'entire', 'family', 'beautiful']\n",
            "3222 ['@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "3223 ['KANSAS', 'DEMS', 'on', 'GOTV', 'tODAY', 'at', 'KS04', '!', '@USER', 'running', 'strong', 'against', '@USER']\n",
            "annotated_mention_list: [('kansas dems', 'misc'), ('gotv', 'org'), ('ks04', 'misc')]\n",
            "kansas dems\n",
            "gotv\n",
            "ks04\n",
            "3224 ['Guess', 'this', 'pic', 'got', 'to', 'her', 'head', '.', 'She', \"'s\", 'the', 'VP', 'now', '.', 'Next', 'stop', ',', 'taking', 'over', 'daddy', \"'s\", 'duties', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['next', 'got', 'daddy', 'stop']\n",
            "3225 ['.', '@USER', '.', '@USER', 'will', 'cause', '/', 'start', 'WWIII', ',', 'all', 'to', 'try-cover', 'up', 'liar-cheat', ',', 'hacking', ',', 'propaganda', ',', 'lack', 'of', '10', 'yrs', 'taxes', 'pd']\n",
            "annotated_mention_list: [('wwiii', 'misc')]\n",
            "wwiii\n",
            "3226 ['@USER', '@USER', '@USER', 'What', 'a', 'very', 'bigly', 'surprise', 'that', 'he', 'keeps', 'INflating', 'numbers', '...', 'NOT', '!', 'LIAR', 'and', 'TRAITOR', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['liar', 'keeps', 'bigly', 'traitor']\n",
            "3227 ['administration', 'Blue', 'Lives', 'Matter', 'approach', 'to', 'immigration', 'enforcement', ':', 'Russian', 'Op']\n",
            "annotated_mention_list: [('blue lives matter', 'misc'), ('russian op', 'org')]\n",
            "non_entity_list: ['administration']\n",
            "blue lives matter\n",
            "russian op\n",
            "3228 ['@USER', 'Is', 'someone', 'implying', 'that', 'the', 'United', 'incident', 'was', 'a', 'false', 'flag', 'operation', 'to', 'distract', 'us', 'from', '?']\n",
            "annotated_mention_list: [('united', 'org')]\n",
            "non_entity_list: ['us', 'incident']\n",
            "united\n",
            "3229 ['@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "3230 ['@USER', 'I', 'second', 'that', '!']\n",
            "annotated_mention_list: []\n",
            "3231 ['Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "3232 ['Eric', 'Trump', 'sure', 'showed', 'us', 'why', 'he', 'should', 'stick', 'to', 'fucking', 'up', 'at', 'the', 'Trump', 'winery', '.', 'Did', \"n't\", 'he', 'JUST', 'interfere', 'in', 'investigation', 'now', '?']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['investigation', 'showed', 'stick', 'us']\n",
            "eric trump\n",
            "trump\n",
            "3233 ['Vlad', 'and', 'Co', '.', 'needs', 'cash', '-', 'now', '.', 'Part', 'of', 'what', 'is', 'going', 'on', '.']\n",
            "annotated_mention_list: [('vlad', 'per')]\n",
            "non_entity_list: ['going', 'co', 'needs']\n",
            "vlad\n",
            "3234 ['@USER', 'Then', 'why', 'was', 'putin', 'called', 'first', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['first', 'called']\n",
            "3235 ['@USER', '@USER', '@USER', '@USER', 'The', 'only', 'troll', 'I', 'see', 'here', 'is', 'a', 'trump', 'troll', '.', 'but', 'good', 'one', 'on', 'thinking', 'trump', 'has', 'sone', 'anything', 'to', 'help', 'MAGA', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('maga', 'org')]\n",
            "non_entity_list: ['help', 'thinking', 'see', 'good', 'one']\n",
            "trump\n",
            "maga\n",
            "3236 ['IMPORTANT', ':']\n",
            "annotated_mention_list: []\n",
            "3237 ['barely', 'mentioned', 'by', ',', 'obsessed', 'with', 'United', '.']\n",
            "annotated_mention_list: [('united', 'org')]\n",
            "united\n",
            "3238 ['Eric', 'Trump', ':', 'Syria', 'Strike', 'Proves', 'My', 'Dad', 'Has', 'No', 'Russia', 'Ties', 'There', 'is', 'no', 'question', 'Trump', 'has', 'Russian', 'ties']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('syria strike', 'misc'), ('russia', 'loc'), ('trump', 'per'), ('russian', 'misc')]\n",
            "non_entity_list: ['strike', 'ties', 'dad']\n",
            "eric trump\n",
            "syria strike\n",
            "russia\n",
            "trump\n",
            "russian\n",
            "3239 ['They', 'are', 'all', 'stalled', 'by', 'corruption', '!', 'Traitors']\n",
            "annotated_mention_list: []\n",
            "3240 ['Not', 'fast', 'enough', '.']\n",
            "annotated_mention_list: []\n",
            "3241 ['Is', 'it', 'North', 'Korea', 'looking', 'for', 'trouble', 'or', 'is', 'it', 'Trump', 'to', 'make', 'himself', 'look', 'tough', 'for', 'his', 'followers']\n",
            "annotated_mention_list: [('north korea', 'loc'), ('trump', 'per')]\n",
            "non_entity_list: ['north', 'look']\n",
            "north korea\n",
            "trump\n",
            "3242 ['We', 'want', 'INDEPENDENT', 'commission', 'to', 'review', 'ties', '!', '@USER', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['independent', 'ties']\n",
            "3243 ['This', 'will', 'be', 'yet', 'another', 'loss', '.', 'For', 'you', 'Mr', '.', '\"', 'Winning', '\"', '.', 'Whoops', '.', 'Misspelled', 'WHINING', '.', 'LOSER', '.']\n",
            "annotated_mention_list: []\n",
            "3244 ['@USER', '@USER', 'Thank', 'you', '!', '!']\n",
            "annotated_mention_list: []\n",
            "3245 ['Lucky', 'you', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['lucky']\n",
            "3246 ['Secretary', 'Tillerson', 'has', 'arrived', 'in', ',', 'where', 'he', 'will', 'meet', 'with', 'FM', 'Lavrov', 'and', 'discuss']\n",
            "annotated_mention_list: [('secretary tillerson', 'per'), ('fm lavrov', 'per')]\n",
            "non_entity_list: ['secretary']\n",
            "secretary tillerson\n",
            "fm lavrov\n",
            "3247 ['Nailed', 'it', '!']\n",
            "annotated_mention_list: []\n",
            "3248 ['Another', 'day', 'another', 'for', 'trump', '!']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['day']\n",
            "trump\n",
            "3249 ['@USER', 'Stop', 'tweeting', 'this', 'stuff', 'you', 'dumbass', ',', 'this', 'is', 'NOT', 'a', 'game', '!', 'This', 'is', 'NOT', 'how', 'America', 'handles', 'foreign', 'policy', ',', 'you', 'overgrown', 'child', '!']\n",
            "annotated_mention_list: [('america', 'loc')]\n",
            "non_entity_list: ['stuff', 'foreign', 'stop']\n",
            "america\n",
            "3250 ['Smirking', 'President', '.']\n",
            "annotated_mention_list: []\n",
            "3251 ['@USER', 'If', 'it', \"'s\", 'not', 'a', 'cheer', ',', 'then', 'maybe', 'he', 'just', 'spelled', '\"', 'SAD', '\"', 'wrong', '.']\n",
            "annotated_mention_list: []\n",
            "3252 ['@USER', 'How', 'wonderfully', 'convenient', '.']\n",
            "annotated_mention_list: []\n",
            "3253 ['Please', 'make', 'this', 'quick', '!']\n",
            "annotated_mention_list: []\n",
            "3254 ['I', 'underestimated', 'the', 'power', 'and', 'control', 'has', 'over', '.', 'Did', 'not', 'factor', 'in', '@USER', '$', '$', '.', '≡', 'ƒÿ', '╛']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['power']\n",
            "3255 ['That', 'face', 'alone', 'disqualifies', '@USER', 'from', 'job', 'as', 'POTUS']\n",
            "annotated_mention_list: [('potus', 'per')]\n",
            "non_entity_list: ['job', 'face']\n",
            "potus\n",
            "3256 ['@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "3257 ['@USER', '@USER', '@USER', 'The', 'WORLD', 'is', 'watching', 'History', 'is', 'being', 'made']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['watching', 'world', 'history', 'made']\n",
            "3258 ['@USER', '@USER', 'Spot', 'on', '.', 'Careless', '.']\n",
            "annotated_mention_list: []\n",
            "3259 ['Wow', ',', '@USER', 'just', 'reporting', 'big', 'news', '.', 'Seventy', 'men', '.', 'is', 'a', 'sign', 'of', 'the', 'times', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['men', 'times', 'big', 'news']\n",
            "3260 ['s', 'redline', 'is', 'more', 'twisted', 'than', 'todays', 'curve', '.', 'Hey', ',', 'they', 'may', 'be', 'related', 'in', 'some', 'strange', 'sort', 'of', 'way', '...']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['may', 'way']\n",
            "3261 ['@USER', '@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "3262 ['Government', 'Accountability', 'Office', 'investigating', 'Trump', \"'s\", 'transition']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['office', 'government', 'transition']\n",
            "trump\n",
            "3263 ['Trump', 'could', \"n't\", 'find', 'Montenegro', 'on', 'a', 'labeled', 'map']\n",
            "annotated_mention_list: [('trump', 'per'), ('montenegro', 'loc')]\n",
            "non_entity_list: ['find']\n",
            "trump\n",
            "montenegro\n",
            "3264 ['deep', 'state']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['deep', 'state']\n",
            "3265 ['@USER', '@USER', '@USER', 'and', '@USER', 'called', 'beforehand', '=', 'coordinating', 'w', '/', 'Russians', 'on', '?', 'probably', 'said', 'NYET', 'to', 'bombing', 'runways']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['said', 'called', 'bombing', 'beforehand']\n",
            "3266 ['Follow', 'the', 'Bitcoin', ':', '@USER', 'mystery', '4M', 'in', 'bitcoin', 'by', '@USER']\n",
            "annotated_mention_list: [('bitcoin', 'org')]\n",
            "bitcoin\n",
            "3267 ['Rule', 'of', 'Thumb', ':', 'Truth', 'is', 'exact', 'opposite', 'of', 'what', 'WH', 'says', 'is', 'the', 'reason', 'for', 'any', 'action', '.', 'Exception', ':', 'When', 'it', \"'s\", 'a', 'blackmailer', 'leak']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['action', 'says']\n",
            "3268 ['@USER', '@USER', 'Info', 'spread', 'click', '.', 'Info', 'and', 'assumptions', 'there', 'belong', 'to', '@USER', '.', 'Me', '?', 'I', 'suspect', '-', 'Tillerson', 'now', 'is', 'collusion', '.']\n",
            "annotated_mention_list: [('tillerson', 'per')]\n",
            "non_entity_list: ['collusion', 'info']\n",
            "tillerson\n",
            "3269 ['Rex', 'Tillerson', 'says', 'Russia', 'should', 'fess', 'up', 'on', 'election', 'meddling-BULLSHIT', '.', 'LIAR', '.']\n",
            "annotated_mention_list: [('rex tillerson', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['liar', 'says', 'election']\n",
            "rex tillerson\n",
            "russia\n",
            "3270 ['@USER', 'charade', '.', 'Guess', 'they', 'think', 'if', 'they', 'can', 'fool', '63M', 'Americans', ',', 'they', 'can', 'fool', 'the', 'rest', 'of', 'us', '.']\n",
            "annotated_mention_list: [('americans', 'misc')]\n",
            "non_entity_list: ['think', 'rest', 'us']\n",
            "americans\n",
            "3271 ['How', 'Twisted', 'Do', 'They', 'Think', 'We', 'Are', 'That', 'Stupid']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['think', 'stupid']\n",
            "3272 ['If', 'you', 'think', 'Trump', 'has', 'ethics', 'or', 'is', 'normal', ',', 'think', 'again', '.', 'Tax', 'free', 'transaction', '.', 'If', 'it', 'smells', 'fishy', 'to', 'you', ',', 'that', \"'s\", 'because', 'it', 'is', '.']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['think', 'tax']\n",
            "trump\n",
            "3273 ['killing', 'innocent', 'people', '/', 'children', 'does', \"n't\", 'phase', 'them', '!', 'Psychopaths', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['people', 'innocent', 'children']\n",
            "3274 ['Do', \"n't\", 'ya', 'think', 'if', 'Putin', 'was', 'really', 'pissed', 'about', 'he', \"'d\", 'cancel', 'the', 'Tillerson', 'visit', '?', '≡', 'ƒñö']\n",
            "annotated_mention_list: [('putin', 'per'), ('tillerson', 'per')]\n",
            "non_entity_list: ['think', 'really']\n",
            "putin\n",
            "tillerson\n",
            "3275 ['You', 'DA', 'MAN', '!', '!', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['man']\n",
            "3276 ['\"', 'U', 'CAN', 'HELP', 'OTHERS', 'WITH', 'ADDICTIONS', '\"', 'we', 'got', 'this', 'THANK', 'U']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['help', 'got', 'others']\n",
            "3277 ['@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "3278 ['tiff']\n",
            "annotated_mention_list: []\n",
            "3279 ['Elect', 'a', 'Black', 'POTUS', 'and', 'we', 'end', 'up', 'with', 'these', 'jokers', '.', 'Much', 'harm', 'being', 'inflicted', 'on', 'all', 'Americans', ',', 'and', 'the', 'entire', 'planet', '.']\n",
            "annotated_mention_list: [('potus', 'per'), ('americans', 'misc')]\n",
            "non_entity_list: ['planet', 'black', 'entire', 'end']\n",
            "potus\n",
            "americans\n",
            "3280 ['@USER', '@USER', 'Get', 'ready', 'for', 'impeachment', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['get']\n",
            "3281 ['@USER', 'Suddenly', 'I', 'wish', 'there', 'was', 'a', 'Trump', 'Tower', 'closer', 'to', 'Seattle', '.']\n",
            "annotated_mention_list: [('trump tower', 'loc'), ('seattle', 'loc')]\n",
            "non_entity_list: ['tower']\n",
            "trump tower\n",
            "seattle\n",
            "3282 ['Also', ',', 'if', 'he', 'were', 'to', 'actually', 'pay', 'taxes', ',', 'he', 'would', 'get', 'a', 'tax', 'deduction', 'for', 'the', \"'\", 'donation', \"'\"]\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['actually', 'get', 'tax', 'pay']\n",
            "3283 ['YES', '!', 'Why', 'has', \"n't\", 'he', 'released', 'his', 'taxes', '?', 'What', 'does', 'he', 'have', 'to', 'hide', '?']\n",
            "annotated_mention_list: []\n",
            "3284 ['is', 'real', '.', 'and', \"'\", 's', '\"', 'anger', '\"', 'is', 'false', '.', 'Make', 'no', 'mistake', ',', 'Putin', 'knew']\n",
            "annotated_mention_list: [('putin', 'per')]\n",
            "non_entity_list: ['knew']\n",
            "putin\n",
            "3285 ['Waiting', 'on', 'Yates', '...', 'we', 'need', 'some', 'TRUTH', 'right', 'about', 'now', '!']\n",
            "annotated_mention_list: [('yates', 'per')]\n",
            "non_entity_list: ['right', 'need']\n",
            "yates\n",
            "3286 ['@USER', 'Why', 'not', 'they', 'have', 'gotten', 'away', 'with', 'fleecing', 'America', 'on', 'the', 'daily', '.']\n",
            "annotated_mention_list: [('america', 'loc')]\n",
            "non_entity_list: ['away', 'daily']\n",
            "america\n",
            "3287 ['Michael', 'Flynn', ':', 'new', 'evidence', 'spy', 'chiefs', 'had', 'concerns', 'about', 'Russian', 'ties', '.', '\"', 'Los', 'Angeles', 'Times', '\"', 'ΓÇª']\n",
            "annotated_mention_list: [('michael flynn', 'per'), ('russian', 'misc'), ('los angeles times', 'org')]\n",
            "non_entity_list: ['new', 'times', 'ties', 'spy']\n",
            "michael flynn\n",
            "russian\n",
            "los angeles times\n",
            "3288 ['@USER', 'You', 'fucking', 'asshole', '.', 'You', 'will', 'go', 'down', 'for', 'on', 'top', 'of', 'you', \"'re\", 'out', 'of', 'your', 'league', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['go', 'asshole']\n",
            "3289 ['@USER', 'It', \"'s\", 'possible', 'trump', 'knew', 'too', 'in', 'advance', 'that', 'chem', 'attack', 'was', 'going', '2', 'occur.Chess', 'game', '2', 'lift', 'sanctions', 'in', 'xchange', 'for', 'burying', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['sanctions', 'attack', 'going', 'knew', 'possible']\n",
            "3290 ['@USER', 'And', 'Eric', ',', 'you', \"'re\", 'not', 'at', 'all', 'biased', ',', 'right', '?']\n",
            "annotated_mention_list: [('eric', 'per')]\n",
            "non_entity_list: ['right']\n",
            "eric\n",
            "3291 ['So', 'the', 'big', 'man', 'that', 'murders', 'innocent', 'animals', '@USER', 'is', 'really', 'a', 'fucking', 'coward', ',', 'eh', '?', 'Just', 'like', 'his', 'worthless', 'draft', 'dodging', 'old', 'man', '.', 'SMFH']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['innocent', 'really', 'big', 'man']\n",
            "3292 ['Ya', ',', 'good', 'luck', 'with', 'that', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['luck', 'good']\n",
            "3293 ['And', 'the', 'fact', 'that', 'you', 'have', 'to', 'make', 'that', 'statement', 'proves', 'otherwise']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['statement']\n",
            "3294 ['@USER', 'probably', 'should', 'have', 'stayed', 'out', 'of', 'it', '.', 'His', 'endorsement', 'is', \"n't\", 'a', 'good', 'thing', 'right', 'now', '.', 'But', ',', 'he', \"'s\", 'a', 'twit', ',', 'so', '...']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['right', 'thing', 'good']\n",
            "3295 ['@USER', 'your', 'gross', 'inexperience', 'here', 'demos', 'there', '*', 'is', '*', 'a', 'connx', '.', 'You', 'made', 'it', 'worse', '.', 'cc', ':', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['worse', 'made']\n",
            "3296 ['They', 'have', 'no', 'comment', 'about', 'everything']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['comment']\n",
            "3297 ['NEW', 'Investigation', 'into', 'Trump', ':', 'Govt', 'Accountability', 'Office', 'investigating', 'Trump', \"'s\", 'transition']\n",
            "annotated_mention_list: [('trump', 'per'), ('govt accountability office', 'org'), ('trump', 'per')]\n",
            "non_entity_list: ['office', 'govt', 'investigation', 'new', 'transition']\n",
            "trump\n",
            "govt accountability office\n",
            "trump\n",
            "3298 ['Rex', 'Tillerson', 'says', 'Russia', 'should', 'fess', 'up', 'on', 'election', 'meddling', '-', 'BULLSHIT', '.', 'LIAR', '.']\n",
            "annotated_mention_list: [('rex tillerson', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['liar', 'says', 'election']\n",
            "rex tillerson\n",
            "russia\n",
            "3299 ['@USER', 'No', ',', 'Eric', ',', 'the', 'ties', 'are', 'made', 'in', 'China', '.', 'Your', 'dad', 'is']\n",
            "annotated_mention_list: [('eric', 'per'), ('china', 'loc')]\n",
            "non_entity_list: ['made', 'ties', 'dad']\n",
            "eric\n",
            "china\n",
            "3300 ['What', 'a', 'dufus', '!']\n",
            "annotated_mention_list: []\n",
            "3301 ['Panicking', ',', '@USER', '?']\n",
            "annotated_mention_list: []\n",
            "3302 ['@USER', 'Thanks', 'for', 'the', 'follow', 'honeyΓ', '£', 'í']\n",
            "annotated_mention_list: []\n",
            "3303 ['Wonder', 'who', 'the', 'royal', 'court', 'photographer', 'is', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['royal', 'court']\n",
            "3304 ['U', '.', 'S', '.', 'A', 'is', 'in', 'the', 'hands', 'of', 'a', 'thug', '.']\n",
            "annotated_mention_list: [('u . s . a', 'loc')]\n",
            "non_entity_list: ['hands']\n",
            "u . s . a\n",
            "3305 ['This', 'is', 'wrong', 'on', 'so', 'many', 'levels', '!']\n",
            "annotated_mention_list: []\n",
            "3306 ['Hey', '@USER', ',', 'do', \"n't\", 'be', 'surprised', 'if', 'you', 'are', \"n't\", 'executed', 'right', 'along', 'side', 'your', 'father', '@USER', 'for', 'and', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['along', 'father', 'right']\n",
            "3307 ['@USER', 'Do', \"n't\", 'believe', 'the', 'hype', '...', 'It', \"'s\", 'all', 'a', 'diversion', '.', 'Putin', 'still', 'pulling', 'strings', '.', 'Trump', 'using', 'Syria', 'to', 'get', 'out', 'of', 'daily', 'headlines', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per'), ('syria', 'loc')]\n",
            "non_entity_list: ['get', 'using', 'daily']\n",
            "putin\n",
            "trump\n",
            "syria\n",
            "3308 ['@USER', '@USER', 'Time', 'to', 'get', 'serious', ',', 'about', 'impeachment', '.']\n",
            "annotated_mention_list: [('impeachment', 'misc')]\n",
            "non_entity_list: ['get', 'time']\n",
            "impeachment\n",
            "3309 ['@USER', 'ALL', 'COMPLICIT', '!']\n",
            "annotated_mention_list: []\n",
            "3310 ['@USER', 'It', \"'s\", 'funny', 'u', 'should', 'post', 'this', '.', 'I', 'have', 'been', 'feeling', 'especially', 'down', 'trodden', 'and', 'hopeless', 'today', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['post']\n",
            "3311 ['People', 'cried', 'foul', 'when', 'Clinton', 'bombed', 'the', 'Balkans', 'while', 'getting', 'investigated', 'for', 'a', 'WH', 'BJ', '.', 'The', 'FBI', 'is', 'literally', 'investigating', '.']\n",
            "annotated_mention_list: [('clinton', 'per'), ('balkans', 'loc'), ('wh bj', 'loc'), ('fbi', 'org')]\n",
            "non_entity_list: ['bombed', 'people', 'getting', 'cried']\n",
            "clinton\n",
            "balkans\n",
            "wh bj\n",
            "fbi\n",
            "3312 ['Trump', \"'s\", 'ties', 'are', 'made', 'in', 'China', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('china', 'loc')]\n",
            "non_entity_list: ['made', 'ties']\n",
            "trump\n",
            "china\n",
            "3313 ['This', 'means', '@USER', 'and', 'his', 'should', 'leave', '!', 'We', 'are', 'not', 'fooled', '!', 'Hillary', 'warned', 'us', '.']\n",
            "annotated_mention_list: [('hillary', 'per')]\n",
            "non_entity_list: ['means', 'leave', 'us']\n",
            "hillary\n",
            "3314 ['Ivanka', ':', '\"', 'We', 'have', 'to', 'look', 'like', 'we', 'care', '\"', 'It', \"'s\", 'all', 'really', 'bad', 'Reality', 'TV', '.', 'Bad', 'ratings', '.', 'Sad', '.']\n",
            "annotated_mention_list: [('ivanka', 'per')]\n",
            "non_entity_list: ['bad', 'really', 'look']\n",
            "ivanka\n",
            "3315 ['SKEEVY']\n",
            "annotated_mention_list: []\n",
            "3316 ['Watch', 'Live', ':', 'Rex', 'Tillerson', 'Arrives', 'In', '|', 'Zero', 'Hedge']\n",
            "annotated_mention_list: [('rex tillerson', 'per')]\n",
            "non_entity_list: ['live', 'zero']\n",
            "rex tillerson\n",
            "3317 ['@USER', '@USER', '@USER', 'let', \"'s\", 'get', 'back', 'to']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['get', 'back']\n",
            "3318 ['Only', 'if', 'they', 'survive', 'PUTIN', \"'s\", 'reach', '-', '-', 'that', 'is', \"n't\", 'a', 'given', '.']\n",
            "annotated_mention_list: [('putin', 'per')]\n",
            "non_entity_list: ['reach']\n",
            "putin\n",
            "3319 ['Why', 'is', 'anyone', 'surprised', '?']\n",
            "annotated_mention_list: []\n",
            "3320 ['@USER', 'Those', 'people', 'have', 'no', 'heart', '.', 'How', 'could', 'any', 'of', 'them', 'be', '\"', 'moved', '\"', 'by', 'Assad', \"'s\", 'actions', '?', 'Smoke', 'screen', 'much', '?']\n",
            "annotated_mention_list: [('assad', 'per')]\n",
            "non_entity_list: ['people']\n",
            "assad\n",
            "3321 ['@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "3322 ['@USER', 'Least', 'of', 'our', 'worries', 'right', 'now', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['right', 'least']\n",
            "3323 ['@USER', 'Putin', 'is', 'sounding', 'more', 'and', 'more', 'like', 'Trump', 'everyday', ',', '\"', 'I', 'heard', '\"', '\"', 'We', 'Heard', '\"', 'WTH', 'say', '\"', 'We', 'are', 'planning', '\"', 'herein', 'lies', 'the', 'truth', '.']\n",
            "annotated_mention_list: [('putin', 'per'), ('trump', 'per')]\n",
            "non_entity_list: ['heard', 'sounding', 'lies', 'say', 'everyday']\n",
            "putin\n",
            "trump\n",
            "3324 ['@USER', '@USER', 'and', 'where', 'was', 'congress', 'with', 'OBAMA', '?', '@USER', 'has', 'more', 'power', 'than', 'congress', '@USER']\n",
            "annotated_mention_list: [('obama', 'per'), ('congress', 'org')]\n",
            "non_entity_list: ['power']\n",
            "obama\n",
            "congress\n",
            "3325 ['is', 'trending', 'and', 'taking', 'attention', 'off', 'Trump', 'and', 'my', 'investigative', 'journalism', '.', 'RIS', 'operation', '?']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['trending']\n",
            "trump\n",
            "3326 ['Follow', 'the', 'money', '!', 'Follow', 'the', 'Data', '!', 'Russian', 'connection', '/', 'Taxes', 'illegitimately', 'elected', ',']\n",
            "annotated_mention_list: [('russian', 'misc')]\n",
            "non_entity_list: ['elected', 'connection', 'money']\n",
            "russian\n",
            "3327 ['Investigators', 'looking', 'at', 'the', 'Trump', 'Transition', 'team', '.', 'Hopefully', ',', 'unbiased', '!']\n",
            "annotated_mention_list: [('trump transition team', 'org')]\n",
            "non_entity_list: ['team', 'transition']\n",
            "trump transition team\n",
            "3328 ['@USER', '@USER', 'follow', 'the', 'Bitcoin']\n",
            "annotated_mention_list: [('bitcoin', 'org')]\n",
            "bitcoin\n",
            "3329 ['All', 'clear', 'given', 'at', 'US', 'Army', \"'\", 's', 'Fort', 'Lee', 'base', 'where', 'an', 'active', 'shooter', 'had', 'earlier', 'been', 'reported']\n",
            "annotated_mention_list: [('us army', 'org'), ('fort lee', 'loc')]\n",
            "non_entity_list: ['base', 'reported', 'us', 'army']\n",
            "us army\n",
            "fort lee\n",
            "3330 ['GREAT', 'ANSWER', '!', '!', '!', 'AND', 'I', 'AGREE', 'TOO', '!', '!', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['great', 'answer', 'agree']\n",
            "3331 ['Thread']\n",
            "annotated_mention_list: []\n",
            "3332 ['I', 'finished', 'connecting', 'all', 'the', 'dots', ':']\n",
            "annotated_mention_list: []\n",
            "3333 ['We', 'want', 'it', ',', 'wont', 'rest', 'til', 'we', 'get', 'it', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['wont', 'get', 'rest']\n",
            "3334 ['@USER', '@USER', 'PR', 'campaign', '?', 'This', 'does', \"n't\", 'make', 'look', 'human', '.', 'It', 'validates', 'his', 'ignorance', 'and', 'total', 'disregard', 'to', 'the', 'Constitution', '!']\n",
            "annotated_mention_list: [('constitution', 'misc')]\n",
            "non_entity_list: ['campaign', 'human', 'look', 'total', 'ignorance', 'pr']\n",
            "constitution\n",
            "3335 ['@USER', '@USER', '@USER', 'Impeachment', ',', 'is', 'the', 'only', 'answer', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['answer']\n",
            "3336 ['Tillerson', 'said', 'more', 'to', 'this', 'guy', 'than', 'he', 'has', 'to', 'any', 'reporters', 'in', 'the', 'pool', '.']\n",
            "annotated_mention_list: [('tillerson', 'per')]\n",
            "non_entity_list: ['said', 'guy']\n",
            "tillerson\n",
            "3337 ['@USER', 'That', 'was', 'the', 'strategy', 'where', '@USER', 'crossed', 'the', 'red', 'line', '.', 'He', 'ran', 'the', 'most', 'vicious', 'campaign', 'in', 'history', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['line', 'history', 'campaign']\n",
            "3338 ['Repeat', 'after', 'me', '.', 'Statements', 'by', 'this', 'family', 'are', 'the', 'opposite', 'of', 'what', 'is', 'true', '.', 'Remember', 'that', '-', 'makes', 'life', 'easier', 'for', 'sane', 'people', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['repeat', 'statements', 'family', 'people', 'makes']\n",
            "3339 ['This', 'image', 'is', 'absolutely', 'frightening', '...', 'they', 'look', 'like', 'a', 'family', 'of', 'serial', 'killers', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['family', 'look']\n",
            "3340 ['And', 'there', 'should', 'be', 'a', 'lot', 'more', 'of', 'them']\n",
            "annotated_mention_list: []\n",
            "3341 ['@USER', 'Thanks', 'for', 'the', 'follow', 'honey']\n",
            "annotated_mention_list: []\n",
            "3342 ['You', \"'ll\", 'get', 'the', 'chance', 'to', 'make', 'your', 'case', 'when', 'you', \"'re\", 'deposed', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['chance', 'get', 'case']\n",
            "3343 ['An', 'exhaustive', 'timeline', 'of', 'the', 'Trump', '-', 'Russia', 'connections', 'starting', 'from', '1979']\n",
            "annotated_mention_list: [('trump', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['connections']\n",
            "trump\n",
            "russia\n",
            "3344 ['This', 'is', 'wrong', 'on', 'so', 'many', 'levels', '!']\n",
            "annotated_mention_list: []\n",
            "3345 ['@USER', '@USER', 'IS', 'DEFLECTING', 'from', 'YOU', '/', '@USER', 'SUCH', 'RUMP', 'PATSIES', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['rump']\n",
            "3346 ['\"', 'This', 'is', 'The', 'Future', 'Liberals', 'Want', '!', '\"']\n",
            "annotated_mention_list: [('liberals', 'misc')]\n",
            "liberals\n",
            "3347 ['@USER', 'Come', 'on', 'stand', 'together', 'Democratic', 'strong', 'RT']\n",
            "annotated_mention_list: [('democratic', 'misc')]\n",
            "non_entity_list: ['come']\n",
            "democratic\n",
            "3348 ['@USER', '@USER', 'Lord', 'can', 'we', 'stop', 'this', 'bullshit', 'administration', 'yet', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['administration', 'lord', 'stop']\n",
            "3349 ['@USER', '@USER', '@USER', 'Satan', 'is', 'already', 'standing', 'with', '@USER']\n",
            "annotated_mention_list: [('satan', 'misc')]\n",
            "non_entity_list: ['already']\n",
            "satan\n",
            "3350 ['@USER', 'where', \"'s\", 'your', 'comment', '@USER', '?', 'Cat', 'got', 'your', 'tongue', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['got', 'comment']\n",
            "3351 ['True', '.', 'His', 'ties', 'are', 'Chinese', '.', 'His', 'colluders', 'and', 'connections', 'are', 'Russian', '.']\n",
            "annotated_mention_list: [('chinese', 'misc'), ('russian', 'misc')]\n",
            "non_entity_list: ['connections', 'ties']\n",
            "chinese\n",
            "russian\n",
            "3352 ['Lord', 'help', '!']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['help', 'lord']\n",
            "3353 ['Eric', 'Trump', 'needs', 'to', 'be', 'renamed', '\"', 'Dump', 'as', 'Stump', '\"']\n",
            "annotated_mention_list: [('eric trump', 'per')]\n",
            "non_entity_list: ['needs', 'dump']\n",
            "eric trump\n",
            "3354 ['@USER', '-', 'PEETape', 'will', 'reveal', 'all', '!', 'knows', 'that', 'it', \"'ll\", 'be', 'released', '-', 'WikiLeaks', 'and', 'it', \"'s\", 'not', 'Melania', 'peeing', 'on', 'his', 'head', '!']\n",
            "annotated_mention_list: [('wikileaks', 'org'), ('melania', 'per')]\n",
            "non_entity_list: ['knows']\n",
            "wikileaks\n",
            "melania\n",
            "3355 ['Do', \"n't\", 'we', 'ever', 'get', 'tired', 'of', 'being', 'pushed', 'around', 'by', 'bullies', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['get', 'tired']\n",
            "3356 ['All', 'the', 'junior', 'Trump', '(', '@USER', ',', '@USER', ')', 'story', 'lines', 'are', 'a', 'reminder', 'that', 'we', 'are', 'being', 'run', 'by', 'the', 'East', 'Coast', \"'s\", 'Kardashians', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('east coast', 'loc'), ('kardashians', 'per')]\n",
            "non_entity_list: ['junior', 'run', 'story']\n",
            "trump\n",
            "east coast\n",
            "kardashians\n",
            "3357 ['We', 'need', 'more', 'than', 'letters', ',', 'Congress', '.', 'Take', 'decisive', 'action', 'to', 'kick', 'out', 'Trump', '.']\n",
            "annotated_mention_list: [('congress', 'org'), ('trump', 'per')]\n",
            "non_entity_list: ['take', 'action', 'need']\n",
            "congress\n",
            "trump\n",
            "3358 ['And', 'the', 'fact', 'that', 'a', 'Trump', 'is', 'making', 'that', 'statement', ',', 'proves', 'otherwise']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['statement']\n",
            "trump\n",
            "3359 ['Panicking', ',', '@USER', '?']\n",
            "annotated_mention_list: []\n",
            "3360 ['Still', 'wo', \"n't\", 'help', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['help']\n",
            "3361 ['Trump', 'is', 'going', 'to', 'have', 'more', 'investigations', 'than', 'law', 'suits', '(', '3,500', ')', 'before', 'he', 'is', 'impeached', '.']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['going', 'law', 'investigations']\n",
            "trump\n",
            "3362 ['Nice', 'TRY', 'We', 'are', 'not', 'going', 'for', 'it', '.', 'Perhaps', 'if', 'add', 'some', 'Pepsi', 'and', 'some', 'Skittles']\n",
            "annotated_mention_list: [('pepsi', 'misc'), ('skittles', 'misc')]\n",
            "non_entity_list: ['going']\n",
            "pepsi\n",
            "skittles\n",
            "3363 ['And', 'yet', 'we', 'have', '0', '!', 'I', 'wld', 'have', 'been', 'nice', 'if', 'GOPers', 'like', '@USER', 'wld', 'have', 'blown', 'the', 'whistle', 'when', 'he', 'found', 'out', 'b4', 'the', 'election', '!', 'but', '..']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['wld', 'election']\n",
            "3364 ['RT', 'TeaPainUSA', ':', 'Trump', 'simply', 'turnin', \"'\", 'over', 'his', 'taxes', 'would', 'have', 'been', '84', 'million', 'dollars', 'cheaper', '.']\n",
            "annotated_mention_list: [('teapainusa', 'org'), ('trump', 'per')]\n",
            "teapainusa\n",
            "trump\n",
            "3365 ['RT', 'funder', ':', 'Rex', 'Tillerson', 'says', 'Russia', 'should', 'fess', 'up', 'on', 'election', 'meddling-BULLSHIT', '.', 'LIAR', '.']\n",
            "annotated_mention_list: [('rex tillerson', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['liar', 'says', 'election']\n",
            "rex tillerson\n",
            "russia\n",
            "3366 ['RT', 'funder', ':', 'Eric', 'Trump', ':', 'Syria', 'Strike', 'Proves', 'My', 'Dad', 'Has', 'No', 'Russia', 'Ties', 'There', 'is', 'no', 'question', 'Trump', 'has', 'Russian', 'ties', 'ΓÇª']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('syria', 'loc'), ('russia', 'loc'), ('trump', 'per'), ('russian', 'misc')]\n",
            "non_entity_list: ['strike', 'ties', 'dad']\n",
            "eric trump\n",
            "syria\n",
            "russia\n",
            "trump\n",
            "russian\n",
            "3367 ['Scarier', 'than', 'a', 'President', 'Snow', '.']\n",
            "annotated_mention_list: []\n",
            "3368 ['If', 'Usay', 'and', 'Qusay', 'Trump', 'are', 'Executive', 'Vice', 'Presidents', 'of', 'the', 'Trump', 'organization', ',', 'who', 'holds', 'the', 'title', 'of', 'Prez', '.', 'of', 'Trump', 'Ent', '.', '?', 'USA', 'lied', 'to', 'again']\n",
            "annotated_mention_list: [('usay', 'per'), ('qusay trump', 'per'), ('trump organization', 'org'), ('trump ent', 'org'), ('usa', 'loc')]\n",
            "non_entity_list: ['presidents', 'organization', 'vice', 'lied', 'prez']\n",
            "usay\n",
            "qusay trump\n",
            "trump organization\n",
            "trump ent\n",
            "usa\n",
            "3369 ['Russia', 'May', 'Add', '$', '140', 'Million', 'To', 'Reserve', 'Fund', 'This', 'Year']\n",
            "annotated_mention_list: [('russia', 'loc')]\n",
            "non_entity_list: ['may']\n",
            "russia\n",
            "3370 ['@USER', '@USER', '@USER', '@USER', 'Standing', 'by', 'one', \"'s\", 'country', 'makes', 'one', 'a', 'patriot', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['makes', 'one']\n",
            "3371 ['Glad', 'that', \"'s\", 'settled', '.', 'Eric', 'Trump', ':', 'Syria', 'missile', 'strikes', 'prove', 'there', \"'s\", 'no', 'trump', '-', 'russia', 'connection']\n",
            "annotated_mention_list: [('eric trump', 'per'), ('syria', 'loc'), ('trump', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['strikes', 'connection', 'missile']\n",
            "eric trump\n",
            "syria\n",
            "trump\n",
            "russia\n",
            "3372 ['@USER', 'Yeah', ',', 'righhhht', '!', 'We', 'are', 'not', 'stupid', ',', 'only', 'DT', 'supporters', 'are', 'because', 'they', 'believe', 'all', 'the', 'lies', '!']\n",
            "annotated_mention_list: [('dt', 'per')]\n",
            "non_entity_list: ['stupid', 'lies', 'supporters']\n",
            "dt\n",
            "3373 ['It', 'Is', 'ABOUT', 'time', '!', 'Yes', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['time']\n",
            "3374 ['You', \"'d\", 'think', 'that', 'with', 'Hollywood', 'pumping', 'out', 'at', 'least', 'a', 'couple', 'of', 'Holocaust', 'movies', 'a', 'year', '@USER', 'Sean', 'Spicer', 'would', 'know', 'about', 'gas', 'chambers']\n",
            "annotated_mention_list: [('hollywood', 'misc'), ('holocaust', 'misc'), ('sean spicer', 'per')]\n",
            "non_entity_list: ['think', 'gas', 'least']\n",
            "hollywood\n",
            "holocaust\n",
            "sean spicer\n",
            "3375 ['Now', 'I', 'know', 'why', '@USER', 'is', 'not', 'presidential', ',', 'he', 'has', 'DNA', 'related', 'to', 'a', 'sea', 'turtle', 'as', 'evident', 'in', 'his', 'ability', 'to', 'retract', 'his', 'head']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['presidential', 'sea']\n",
            "3376 ['ΓÖª', '∩', '╕', 'ÅHow', 'FunnyΓÇ', '╝', '∩', '╕', 'TRUMPs', 'Are', 'So', 'Bad', 'At', 'Covering', 'Their', 'TracksΓÇ', '╝', '∩', '╕', 'ÅDo', 'They', 'Think', 'We', 'Are', 'That', 'StupidΓüë', '∩', '╕', 'Å']\n",
            "annotated_mention_list: [('trumps', 'misc')]\n",
            "non_entity_list: ['think', 'bad']\n",
            "trumps\n",
            "3377 ['This', 'is', 'way', 'wrong', '.', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['way']\n",
            "3378 ['meets', 'in', 'about', 'I', 'wonder', 'how', 'it', 'will', 'go', '?']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['go', 'meets']\n",
            "3379 ['And', 'General', 'met', 'with', 'someone', 'from', 'Kaspersky', 'when', 'he', 'visited']\n",
            "annotated_mention_list: [('kaspersky', 'per')]\n",
            "non_entity_list: ['general']\n",
            "kaspersky\n",
            "3380 ['Sorry', '@USER', 'it', 'doesnt', '.']\n",
            "annotated_mention_list: []\n",
            "3381 ['The', 'fact', 'that', 'Trump', 'called', 'to', 'warn', 'Russia', 'before', 'they', 'bombed', 'it', '(', 'and', 'before', 'they', 'told', 'Congress', '!', ')', 'DOES', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('russia', 'loc'), ('congress', 'org')]\n",
            "non_entity_list: ['bombed', 'called', 'warn', 'told']\n",
            "trump\n",
            "russia\n",
            "congress\n",
            "3382 ['@USER', 'Trump', 'fired', '59', 'Tomahawks', 'to', 'sink', 'worked', 'about', 'as', 'good', 'on', 'the', 'Syrian', 'runways', 'used', 'by', 'jets', 'the', 'next', 'day', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('tomahawks', 'misc'), ('syrian', 'misc')]\n",
            "non_entity_list: ['fired', 'next', 'worked', 'sink', 'good', 'day', 'used']\n",
            "trump\n",
            "tomahawks\n",
            "syrian\n",
            "3383 ['Call', 'your', 'Reps', 'in', 'the', 'House', 'for', 'H', '.', 'R', '.', '305', 'and', 'Senators', 'for', 'S', '.', '26', 'Presidential', 'Tax', 'Transparency', 'Act', '202-224-3121', 'ΓÇª']\n",
            "annotated_mention_list: [('house', 'org'), ('presidential tax transparency act', 'misc')]\n",
            "non_entity_list: ['call', 'presidential', 'reps', 'tax']\n",
            "house\n",
            "presidential tax transparency act\n",
            "3384 ['This', 'wo', \"n't\", 'make', 'it', 'go', 'away', '!', 'via', '@USER']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['go', 'away']\n",
            "3385 ['arrives', 'in', 'without', 'game', 'plan', 'from', 'KMIZ']\n",
            "annotated_mention_list: [('kmiz', 'org')]\n",
            "non_entity_list: ['plan']\n",
            "kmiz\n",
            "3386 ['The', 'strike', 'did', \"n't\", 'do', 'any', 'damage', 'and', 'left', 'the', 'airfields', 'intact', '.', 'A', 'fake', 'attack', 'for', 'show', '.']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['strike', 'attack', 'show', 'left', 'fake']\n",
            "3387 ['Another', 'wasteful', 'investigation', '.', 'Intelligent', 'ppl', 'will', 'not', 'back', 'down', '.', 'Russia', 'is', 'our', 'leader']\n",
            "annotated_mention_list: [('russia', 'loc')]\n",
            "non_entity_list: ['investigation', 'back', 'leader']\n",
            "russia\n",
            "3388 ['I', 'have', 'to', 'flee', 'to', 'a', 'resort']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['resort']\n",
            "3389 ['If', 'anything', ',', 'the', 'fact', 'that', '@USER', 'feels', 'the', 'need', 'to', 'spin', 'it', 'like', 'that', 'validates', 'that', 'there', 'ARE', 'Russia', 'ties', '!']\n",
            "annotated_mention_list: [('russia', 'loc')]\n",
            "non_entity_list: ['ties', 'need', 'spin', 'feels']\n",
            "russia\n",
            "3390 ['Hold', 'on', ',', 'pal', '.', 'You', \"can't\", 'accuse', 'our', 'President', 'of', 'spreading', 'fake', 'news', '.', 'Oh', ',', 'wait', '...']\n",
            "annotated_mention_list: [('president', 'per')]\n",
            "non_entity_list: ['wait', 'fake', 'hold', 'news']\n",
            "president\n",
            "3391 ['Disappointed', 'with', 'CA', 'Republicans', 'for', 'towing', 'the', 'line', 'and', 'following', 'blindly', '.', 'Thought', 'you', 'were', 'better', 'than', 'that', '.']\n",
            "annotated_mention_list: [('ca republicans', 'misc')]\n",
            "non_entity_list: ['line', 'better', 'following', 'thought']\n",
            "ca republicans\n",
            "3392 ['Trump', 'turning', 'over', 'his', 'taxes', 'would', 'have', 'saved', 'us', 'ALL', 'this', 'fucking', 'mess', 'to', 'begin', 'with', '.']\n",
            "annotated_mention_list: [('trump', 'per')]\n",
            "non_entity_list: ['mess', 'us']\n",
            "trump\n",
            "3393 ['@USER', 'In', 'Soviet', 'Russia', ',', 'Page', 'carts', 'Carter', 'around', '!']\n",
            "annotated_mention_list: [('soviet russia', 'loc'), ('page', 'per'), ('carter', 'per')]\n",
            "soviet russia\n",
            "page\n",
            "carter\n",
            "3394 ['Tillerson', 'arrives', 'in', 'without', 'game', 'plan', 'from', 'KMIZ']\n",
            "annotated_mention_list: [('tillerson', 'per'), ('kmiz', 'org')]\n",
            "non_entity_list: ['plan']\n",
            "tillerson\n",
            "kmiz\n",
            "3395 ['I', 'voted', 'Bernie', '.']\n",
            "annotated_mention_list: [('bernie', 'per')]\n",
            "bernie\n",
            "3396 ['These', '2', 'senators', '=', 'supporters', '.', 'Not', 'helping', 'America', 'obstruct', 'Vote', 'them', 'out']\n",
            "annotated_mention_list: [('america', 'loc')]\n",
            "non_entity_list: ['supporters']\n",
            "america\n",
            "3397 ['Names', 'and', 'Twitter', 'accounts', 'of', 'every', 'opposing', 'an', 'Independent', 'Investigation', 'of', '.', 'Covering', 'up', '?']\n",
            "annotated_mention_list: [('twitter', 'org')]\n",
            "non_entity_list: ['investigation', 'independent']\n",
            "twitter\n",
            "3398 ['@USER', '@USER', 'I', 'applaud', 'your', 'accomplishment', '!', 'You', 'must', 'have', 'hit', 'a', 'nerve', 'with', 'him', '!', 'Ha', 'ha']\n",
            "annotated_mention_list: []\n",
            "non_entity_list: ['nerve']\n",
            "3399 ['Hey', 'Eric', ',', 'shut', 'your', 'lying', 'mouth', '.']\n",
            "annotated_mention_list: [('eric', 'per')]\n",
            "non_entity_list: ['mouth', 'shut', 'lying']\n",
            "eric\n",
            "3400 ['Oh', ',', 'I', 'dunno', ',', 'maybe', 'two', 'toddlers', 'with', 'nukes', 'off', 'the', 'Korean', 'Peninsula', 'and', 'one', 'of', 'them', 'has', 'had', 'a', 'really', 'bad', 'day', '?']\n",
            "annotated_mention_list: [('korean peninsula', 'loc')]\n",
            "non_entity_list: ['bad', 'really', 'day', 'one']\n",
            "korean peninsula\n",
            "3401 ['Did', 'Carter', 'Page', 'have', 'any', 'dealings', 'with', 'Russia', '?']\n",
            "annotated_mention_list: [('carter page', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['dealings']\n",
            "carter page\n",
            "russia\n",
            "3402 ['But', 'but', '...', 'Rexypoo', 'is', 'going', 'to', 'make', 'Pooty', 'very', 'angry', 'if', 'he', 'keeps', 'pretending', 'to', 'want', 'RU', 'to', 'come', 'clean', '.']\n",
            "annotated_mention_list: [('rexypoo', 'per'), ('pooty', 'per'), ('ru', 'loc')]\n",
            "non_entity_list: ['going', 'keeps', 'angry', 'come']\n",
            "rexypoo\n",
            "pooty\n",
            "ru\n",
            "3403 ['@USER', 'must', 'be', 'so', 'proud']\n",
            "annotated_mention_list: []\n",
            "3404 ['@USER', 'Please', 'Expedite', 'FBI', 'Investigation', '!']\n",
            "annotated_mention_list: [('fbi', 'org')]\n",
            "non_entity_list: ['investigation']\n",
            "fbi\n",
            "3405 ['Add', 'ur', 'endless', 'trips', '2', 'Mar-a-Lago', '2', 'the', 'bill', 'draining', 'taxpayers', 'pockets', '.', 'We', 'need', '2', 'drain', 'Ur', 'Liar', 'swamp', '2']\n",
            "annotated_mention_list: [('mar-a-lago', 'loc')]\n",
            "non_entity_list: ['liar', 'need', 'taxpayers']\n",
            "mar-a-lago\n",
            "3406 ['nothing', 'but', 'broken', 'promises', 'at', 'washington']\n",
            "annotated_mention_list: [('washington', 'loc')]\n",
            "washington\n",
            "3407 ['Is', 'this', 'a', 'joke', '?', 'prez', 'Washington', 'must', 'be', 'wondering', 'how', 'we', 'got', 'here', '!']\n",
            "annotated_mention_list: [('washington', 'per')]\n",
            "non_entity_list: ['got', 'joke', 'prez']\n",
            "washington\n",
            "3408 ['@USER', 'Imagine', 'Washington', \"'s\", 'children', 'acting', 'this', 'wat', '!']\n",
            "annotated_mention_list: [('washington', 'per')]\n",
            "non_entity_list: ['children']\n",
            "washington\n",
            "3409 ['did', 'you', 'go', 'to', 'the', 'charter', 'at', 'Washington', 'too', '?']\n",
            "annotated_mention_list: [('washington', 'loc')]\n",
            "non_entity_list: ['charter', 'go']\n",
            "washington\n",
            "3410 ['Sean', 'Spicer', 'is', 'fucked', 'up', ',', 'United', 'Airlines', 'fucked', 'up', ',', 'Venezuela', 'is', 'fucked', 'up', ',', 'Syria', 'is', 'fucked']\n",
            "annotated_mention_list: [('sean spicer', 'per'), ('united airlines', 'org'), ('venezuela', 'loc'), ('syria', 'loc')]\n",
            "non_entity_list: ['airlines', 'fucked']\n",
            "sean spicer\n",
            "united airlines\n",
            "venezuela\n",
            "syria\n",
            "3411 ['Will', 'Americans', 'b', 'so', 'blind', 'to', 'let', 'a', 'man', 'elected', 'by', 'lead', 'us', 'into', 'war', 'b', '/', 'c', 'he', 'gave', 'u', 'shinny', 'object', 'Syria', '?']\n",
            "annotated_mention_list: [('americans', 'misc'), ('syria', 'loc')]\n",
            "non_entity_list: ['war', 'gave', 'us', 'lead', 'elected', 'man']\n",
            "americans\n",
            "syria\n",
            "3412 ['Countries', 'like', 'Romania', '🇷', '🇴', 'Russia', '🇷', '🇺', 'Serbia', '🇷', '🇸', 'Sweden', '🇸', '🇪', 'Switzerland', '🇨', '🇭', 'UK', '🇬', '🇧', 'Bahamas', '🇧', '🇸', 'Canada', '🇨', '🇦', 'CostaRica', '🇨', '🇷', 'have', 'Universal', 'Health', 'Care']\n",
            "annotated_mention_list: [('romania', 'loc'), ('russia', 'loc'), ('serbia', 'loc'), ('sweden', 'loc'), ('switzerland', 'loc'), ('uk', 'loc'), ('bahamas', 'loc'), ('canada', 'loc'), ('costarica', 'loc'), ('universal health care', 'misc')]\n",
            "romania\n",
            "russia\n",
            "serbia\n",
            "sweden\n",
            "switzerland\n",
            "uk\n",
            "bahamas\n",
            "canada\n",
            "costarica\n",
            "universal health care\n",
            "3413 ['We', 'know', 'Trump', 'is', 'two', 'faced', '-', 'look', 'what', 'he', 'said', 'about', 'Syria', 'in', '2013', '.', 'We', 'have', 'to', 'deal', 'with', 'both', 'his', 'ugly', 'faces', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('syria', 'loc')]\n",
            "non_entity_list: ['said', 'faces', 'deal', 'look']\n",
            "trump\n",
            "syria\n",
            "3414 ['\"', \"'\", 'DrPeterThraft', ':', 'Gay', 'men', '.', 'Swirling', 'and', 'rotating', 'a', 'butt', 'plug', 'in', 'your', 'partner', \"'\", 's', 'anus', 'is', 'a', 'nice', 'way', 'to', 'start', \"'\", 'making', 'love', \"'\", '.', \"'\", '\"', \"'\", 'ajwright', '1987']\n",
            "annotated_mention_list: [('drpeterthraft', 'per')]\n",
            "non_entity_list: ['men', 'way', 'butt', 'gay']\n",
            "drpeterthraft\n",
            "3415 ['Once', 'again', 'Media', 'is', 'bored', 'with', 'the', 'biggest', 'story', 'of', 'the', 'Century', '.', 'Trump', '/', 'Russia', 'and', 'the', 'selling', 'of', 'America', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('russia', 'loc'), ('america', 'loc')]\n",
            "non_entity_list: ['media', 'biggest', 'story']\n",
            "trump\n",
            "russia\n",
            "america\n",
            "3416 ['\"', \"'\", 'DrPeterThraft', ':', 'Gay', 'men', '.', 'Swirling', 'and', 'rotating', 'a', 'butt', 'plug', 'in', 'your', 'partner', \"'\", 's', 'anus', 'is', 'a', 'nice', 'way', 'to', 'start', \"'\", 'making', 'love', \"'\", '.', \"'\", '\"', \"'\", 'ajwright', '1987']\n",
            "annotated_mention_list: [('drpeterthraft', 'per')]\n",
            "non_entity_list: ['men', 'way', 'butt', 'gay']\n",
            "drpeterthraft\n",
            "3417 ['Why', 'do', 'all', 'Potterwatch', 'contributors', \"'\", 'codenames', 'start', 'with', '\"', 'R', '\"', '?']\n",
            "annotated_mention_list: [('potterwatch', 'org')]\n",
            "potterwatch\n",
            "3418 ['Russia', 'could', 'soon', 'control', 'a', 'U', '.', 'S', '.', 'oil', 'company']\n",
            "annotated_mention_list: [('russia', 'loc'), ('u . s', 'loc')]\n",
            "non_entity_list: ['oil', 'soon']\n",
            "russia\n",
            "u . s\n",
            "3419 ['RT', 'asplake', ':', 'Glad', '2', 'have', 'discovered', 'Ursula', 'Le', 'Guin', \"'\", 's', 'The', 'Dispossessed', '-', 'thx', '2', 'the', '#', 'calmalpha', 'guys', '4', 'the', 'recommendation']\n",
            "annotated_mention_list: [('ursula le guin', 'per'), ('dispossessed', 'misc')]\n",
            "non_entity_list: ['guys']\n",
            "ursula le guin\n",
            "dispossessed\n",
            "3420 ['Trump', 'Confident', 'U', '.', 'S', '.', 'Military', 'Strike', 'On', 'Syria', 'Wiped', 'Out', 'Russian', 'Scandal', 'via', '@USER']\n",
            "annotated_mention_list: [('trump', 'per'), ('u . s', 'loc'), ('syria', 'loc'), ('russian', 'misc')]\n",
            "non_entity_list: ['strike', 'scandal']\n",
            "trump\n",
            "u . s\n",
            "syria\n",
            "russian\n",
            "3421 ['Thank', 'God', 'Trump', 'acted', 'because', 'obama', 'did', 'not', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('obama', 'per')]\n",
            "non_entity_list: ['god']\n",
            "trump\n",
            "obama\n",
            "3422 ['Narsingh', 'to', 'see', 'here', ',', '[', 'r', '/', 'soccer', 'thread', ']', '(', '@USER', ')', 'totally', 'brutal']\n",
            "annotated_mention_list: [('narsingh', 'per')]\n",
            "non_entity_list: ['see']\n",
            "narsingh\n",
            "3423 ['you', 'mean', 'Tomi', 'Lahren', ',', 'I', 'just', 'referenced', 'her', 'here']\n",
            "annotated_mention_list: [('tomi lahren', 'per')]\n",
            "non_entity_list: ['mean']\n",
            "tomi lahren\n",
            "3424 ['*', '*', 'redditor', '*', '*', ':', 'JamesakaNoah']\n",
            "annotated_mention_list: [('jamesakanoah', 'per')]\n",
            "jamesakanoah\n",
            "3425 ['I', 'guess', 'Putin', \"'s\", 'gonna', 'want', 'that', 'Order', 'of', 'Friendship', 'medal', 'back']\n",
            "annotated_mention_list: [('putin', 'per')]\n",
            "non_entity_list: ['back', 'order', 'gonna']\n",
            "putin\n",
            "3426 ['Russia', 'has', '4', 'massive', 'military', 'bases', 'in', 'Syria', 'and', 'thousands', 'of', 'troops', '.', 'If', 'trump', 'take', 'out', 'Assad', 'that', 'leaves', 'Russia', 'in', 'the', 'middle']\n",
            "annotated_mention_list: [('russia', 'loc'), ('syria', 'loc'), ('trump', 'per'), ('assad', 'per'), ('russia', 'loc')]\n",
            "non_entity_list: ['take', 'troops', 'middle']\n",
            "russia\n",
            "syria\n",
            "trump\n",
            "assad\n",
            "russia\n",
            "3427 ['RT', 'asplake', ':', 'Glad', '2', 'have', 'discovered', 'Ursula', 'Le', 'Guin', \"'\", 's', 'The', 'Dispossessed', '-', 'thx', '2', 'the', '#', 'calmalpha', 'guys', '4', 'the', 'recommendation']\n",
            "annotated_mention_list: [('ursula le guin', 'per'), ('dispossessed', 'misc')]\n",
            "non_entity_list: ['guys']\n",
            "ursula le guin\n",
            "dispossessed\n",
            "3428 ['@USER', 'Openly', 'trying', 'to', 'start', 'a', 'world', 'war', 'via', 'Twitter', '?', '?', '...', 'your', 'president', 'is', 'insane', '!']\n",
            "annotated_mention_list: [('twitter', 'org')]\n",
            "non_entity_list: ['war', 'world']\n",
            "twitter\n",
            "3429 ['Tell', 'White', 'House', 'that', 'Senior', 'Adviser', 'Suspected', 'of', 'Supporting', 'Nazi', 'Allied', 'Group', ':', 'You', \"'re\", 'Fired', '!']\n",
            "annotated_mention_list: [('white house', 'org'), ('nazi', 'misc')]\n",
            "non_entity_list: ['fired', 'adviser']\n",
            "white house\n",
            "nazi\n",
            "3430 ['I', 'guess', ',', 'with', 'Gingrich', 'projected', 'to', 'win', ',', 'Romney', 'will', 'be', 'ordered', 'to', 'take', 'a', 'bath', '.', '.', '.', ';', ')', '#', 'scprimary']\n",
            "annotated_mention_list: [('gingrich', 'per'), ('romney', 'per')]\n",
            "non_entity_list: ['ordered', 'win', 'take']\n",
            "gingrich\n",
            "romney\n",
            "3431 ['Yo', 'Sean', 'Spicer', '.', 'Will', 'Hulk', 'Hogan', 'bring', 'back', 'Evil', 'NWO', 'Hulk', 'and', 'switch', 'from', 'promoting', 'Rent-A-Center', 'to', 'the', 'less', 'popular', 'Holocaust', 'Centers', '?']\n",
            "annotated_mention_list: [('sean spicer', 'per'), ('hulk hogan', 'per'), ('hulk', 'per'), ('rent-a-center', 'org'), ('holocaust centers', 'org')]\n",
            "non_entity_list: ['evil', 'back', 'centers']\n",
            "sean spicer\n",
            "hulk hogan\n",
            "hulk\n",
            "rent-a-center\n",
            "holocaust centers\n",
            "3432 ['Hi', ',', 'welcome', 'to', 'the', 'site', '.', 'You', 'say', 'the', 'Hulk', 'saw', \"'\", 'something', 'messed', 'up', \"'\", '-', 'do', 'you', 'have', 'any', 'quotes', 'or', 'information', 'from', 'the', 'film', 'that', 'would', 'help', 'explain', 'what', 'is', 'was', 'he', 'actually', 'saw', '?']\n",
            "annotated_mention_list: [('hulk', 'per')]\n",
            "non_entity_list: ['help', 'say', 'actually']\n",
            "hulk\n",
            "3433 ['If', 'you', 'know', 'ANYONE', 'in', 'KANSAS', 'RETWEET', 'THIS', 'TO', 'HELP', 'flipthe', '4th', 'follow', '@USER']\n",
            "annotated_mention_list: [('kansas', 'loc')]\n",
            "non_entity_list: ['help']\n",
            "kansas\n",
            "3434 ['Trump', \"'s\", 'been', 'groomed', 'for', 'the', 'downfall', 'of', 'the', 'USA', '.']\n",
            "annotated_mention_list: [('trump', 'per'), ('usa', 'loc')]\n",
            "non_entity_list: ['downfall']\n",
            "trump\n",
            "usa\n",
            "3435 ['America', \"'s\", 'gun', 'problem', ',', 'explained', 'by', 'Vox', 'But', '...', 'Trump', 'will', 'Fix', 'You', '!', 'The', 'thinking', '.']\n",
            "annotated_mention_list: [('america', 'loc'), ('vox', 'org'), ('trump', 'per')]\n",
            "non_entity_list: ['fix', 'thinking', 'problem']\n",
            "america\n",
            "vox\n",
            "trump\n"
          ]
        }
      ],
      "source": [
        "# #comment this out if collecting samples for training the entity phrase embedder\n",
        "# entityPhraseEmbedder.eval()\n",
        "\n",
        "candidate_embedding_dict = defaultdict(list)\n",
        "candidateBase_dict_alt = {} #<batch, length, cumulative, class>\n",
        "non_entity_count = 0\n",
        "entity_count = 0\n",
        "for tweetID in tweet_to_sentences_w_annotation.keys():\n",
        "    annotated_token_list = []\n",
        "    annotated_mention_list=tweet_to_sentences_w_annotation[tweetID][1]\n",
        "    tweet_token_list=[]\n",
        "    token_embedding_list=[]\n",
        "    local_mentions_list=[]\n",
        "    idRange=tweet_to_sentences_w_annotation[tweetID][0]\n",
        "\n",
        "    for sentID in range(idRange[0],idRange[1]):\n",
        "        tweet_token_list+=tokenized_sentences[sentID][0]\n",
        "        token_embedding_list+=tokenized_sentences[sentID][1]\n",
        "        local_mentions_list+=local_ner_arrays[sentID]\n",
        "    \n",
        "    assert len(tweet_token_list)==len(token_embedding_list)\n",
        "    print(tweetID, tweet_token_list)\n",
        "    print('annotated_mention_list:',annotated_mention_list)\n",
        "\n",
        "    \n",
        "    annotated_candidates = set([mention_tup[0].lower().strip() for mention_tup in annotated_mention_list])\n",
        "    for mention_tup in annotated_mention_list:\n",
        "        annotated_token_list+= mention_tup[0].lower().strip().split()\n",
        "    annotated_token_list = set(annotated_token_list)\n",
        "\n",
        "    #------------------------ negative candidate mining ------------------------\n",
        "    non_entity_list = list(set([elem.strip().lower() for elem in tweet_token_list]).intersection(canonical_ne_list)-annotated_candidates)\n",
        "\n",
        "    \n",
        "    if(non_entity_list):\n",
        "        print('non_entity_list:',non_entity_list)\n",
        "    \n",
        "    tweet_token_ind = 0\n",
        "    while((len(non_entity_list)>0)&(tweet_token_ind < len(tweet_token_list))):\n",
        "        #must pop from the left\n",
        "        non_entity_candidate = non_entity_list.pop(0)\n",
        "        non_entity_candidate, nonentity_type = non_entity_candidate.lower(),'ne'\n",
        "        non_entity_candidate_tokens = non_entity_candidate.split()\n",
        "        while(tweet_token_ind < len(tweet_token_list)):\n",
        "            if((' '.join(tweet_token_list[tweet_token_ind:tweet_token_ind+len(non_entity_candidate_tokens)])).strip().lower()!=non_entity_candidate):\n",
        "                # print(tweet_token_ind)\n",
        "                tweet_token_ind+=1\n",
        "            else:\n",
        "                ne_candidate=(' '.join(tweet_token_list[tweet_token_ind:tweet_token_ind+len(non_entity_candidate_tokens)])).strip().lower()\n",
        "                ne_candidate_token_embeddings = torch.stack(token_embedding_list[tweet_token_ind:tweet_token_ind+len(non_entity_candidate_tokens)]) #2d tensor of ne candidate token embeddings\n",
        "                \n",
        "                tensor_inter = torch.mean(ne_candidate_token_embeddings,dim=0)\n",
        "                tensor_inter_norm = torch.norm(tensor_inter, p=2,dim=0)\n",
        "                ne_candidate_tokens_avg_embedding = tensor_inter/tensor_inter_norm\n",
        "\n",
        "                assert torch.isnan(ne_candidate_tokens_avg_embedding).any() == False\n",
        "\n",
        "                # print(ne_candidate, ne_candidate_tokens_avg_embedding.shape)\n",
        "                if((non_entity_candidate, nonentity_type) not in candidate_embedding_dict):\n",
        "                    non_entity_count+=1\n",
        "                    candidateBase_dict_alt[non_entity_candidate+'||'+nonentity_type] = [0,len(non_entity_candidate_tokens),1,entity_types_dict[nonentity_type]]\n",
        "                else:\n",
        "                    candidateBase_dict_alt[non_entity_candidate+'||'+nonentity_type][2] += 1\n",
        "                \n",
        "                #---------------------- When training the entity phrase embedder ----------------------\n",
        "                # !!no need to unsqueeze here since not training on STS padded data\n",
        "                candidate_embedding_dict[(non_entity_candidate, nonentity_type)].append(ne_candidate_tokens_avg_embedding)\n",
        "                type_candidate_dict[nonentity_type][non_entity_candidate]=True\n",
        "\n",
        "                # #---------------------- When collecting mention phrase embeddings to train the entity classifier ----------------------\n",
        "                # # !! must unsqueeze at test time with embedder else batchnorm throws error\n",
        "                # ne_candidate_tokens_avg_embedding = ne_candidate_tokens_avg_embedding.unsqueeze(0)\n",
        "                # ne_candidate_phrase_embedding = (entityPhraseEmbedder.getEmbedding(ne_candidate_tokens_avg_embedding)).squeeze(0)\n",
        "                # # print(ne_candidate_tokens_avg_embedding.shape, ne_candidate_phrase_embedding.shape)\n",
        "                # candidate_embedding_dict[(non_entity_candidate, nonentity_type)].append(ne_candidate_phrase_embedding)\n",
        "\n",
        "                tweet_token_ind+=len(non_entity_candidate_tokens)\n",
        "                break\n",
        "    #------------------------ negative candidate mining ------------------------\n",
        "\n",
        "    #------------------------ positive candidate mining ------------------------\n",
        "    tweet_token_ind = 0\n",
        "    while((len(annotated_mention_list)>0)&(tweet_token_ind < len(tweet_token_list))):\n",
        "        #must pop from the left\n",
        "        annotated_candidate_tuple = annotated_mention_list.pop(0)\n",
        "        annotated_candidate, entity_type = annotated_candidate_tuple[0].lower(),annotated_candidate_tuple[1].lower()\n",
        "        candidate_tokens = annotated_candidate.split()\n",
        "\n",
        "        print(annotated_candidate)\n",
        "        while((' '.join(tweet_token_list[tweet_token_ind:tweet_token_ind+len(candidate_tokens)])).strip().lower()!=annotated_candidate):\n",
        "            tweet_token_ind+=1\n",
        "        candidate=(' '.join(tweet_token_list[tweet_token_ind:tweet_token_ind+len(candidate_tokens)])).strip().lower()\n",
        "        candidate_token_embeddings = torch.stack(token_embedding_list[tweet_token_ind:tweet_token_ind+len(candidate_tokens)]) #2d tensor of candidate token embeddings\n",
        "        tensor_inter = torch.mean(candidate_token_embeddings,dim=0)\n",
        "        tensor_inter_norm = torch.norm(tensor_inter, p=2,dim=0)\n",
        "        candidate_tokens_avg_embedding = tensor_inter/tensor_inter_norm\n",
        "\n",
        "        assert torch.isnan(candidate_tokens_avg_embedding).any() == False\n",
        "        # print(candidate,annotated_candidate,candidate_token_embeddings.shape)\n",
        "\n",
        "        if((annotated_candidate, entity_type) not in candidate_embedding_dict):\n",
        "            entity_count+=1\n",
        "            candidateBase_dict_alt[annotated_candidate+'||'+entity_type] = [0,len(candidate_tokens),1,entity_types_dict[entity_type]]\n",
        "        else:\n",
        "            candidateBase_dict_alt[annotated_candidate+'||'+entity_type][2] += 1\n",
        "\n",
        "        #---------------------- When training the entity phrase embedder ----------------------\n",
        "        # !!no need to unsqueeze here since not training on STS padded data\n",
        "        candidate_embedding_dict[(annotated_candidate, entity_type)].append(candidate_tokens_avg_embedding)\n",
        "        type_candidate_dict[entity_type][annotated_candidate]=True\n",
        "\n",
        "        # #---------------------- When collecting mention phrase embeddings to train the entity classifier ----------------------\n",
        "        # # !! must unsqueeze at test time with embedder else batchnorm throws error\n",
        "        # candidate_tokens_avg_embedding = candidate_tokens_avg_embedding.unsqueeze(0)\n",
        "        # candidate_phrase_embedding = (entityPhraseEmbedder.getEmbedding(candidate_tokens_avg_embedding)).squeeze(0)\n",
        "        # # print(candidate_tokens_avg_embedding.shape, candidate_phrase_embedding.shape)\n",
        "        # candidate_embedding_dict[(annotated_candidate, entity_type)].append(candidate_phrase_embedding)\n",
        "\n",
        "        tweet_token_ind+=len(candidate_tokens)\n",
        "    #------------------------ positive candidate mining ------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_VMi-RUegkN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "118ced16-d4b7-4d7d-96dd-947ae101b00d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1760 candidates in training set\n",
            "Found 1133 entities in training set\n",
            "Found 627 non entities in training set\n",
            "========\n"
          ]
        }
      ],
      "source": [
        "print('Found '+str(len(candidate_embedding_dict))+' candidates in training set')\n",
        "print('Found '+str(entity_count)+' entities in training set')\n",
        "print('Found '+str(non_entity_count)+' non entities in training set')\n",
        "print('========')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmj4tewsyPCv"
      },
      "source": [
        "## **Training the Entity Phrase Embedder**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z65DSXfnjdRb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d673b3bc-e865-4780-e832-a4bce6ad5469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent||ne': [0, 1, 45, 0], 'government||ne': [0, 1, 16, 0], 'fbi||org': [0, 1, 560, 1], 'fisa warrant||misc': [0, 2, 385, 2], 'trump||per': [0, 1, 819, 4], 'russian government||org': [0, 2, 5, 1], 'day||ne': [0, 1, 17, 0], 'apple||org': [0, 1, 6, 1], 'team||ne': [0, 1, 33, 0], 'carter page||per': [0, 2, 1202, 4], 'time||ne': [0, 1, 38, 0], 'tomahawks||misc': [0, 1, 3, 2], 'sean spicer||per': [0, 2, 62, 4], 'foreign||ne': [0, 1, 37, 0], 'session||per': [0, 1, 1, 4], 'gave||ne': [0, 1, 11, 0], 'flynn||per': [0, 1, 26, 4], 'russians||misc': [0, 1, 37, 2], 'social||ne': [0, 1, 8, 0], 'us||loc': [0, 1, 60, 3], 'see||ne': [0, 1, 41, 0], 'go||ne': [0, 1, 31, 0], 'problem||ne': [0, 1, 1, 0], 'susan rice||per': [0, 2, 9, 4], 'tower||ne': [0, 1, 7, 0], 'trump tower||loc': [0, 2, 7, 3], 'going||ne': [0, 1, 56, 0], 'hack||ne': [0, 1, 2, 0], 'steele||per': [0, 1, 1, 4], 'told||ne': [0, 1, 9, 0], 'hire||ne': [0, 1, 2, 0], 'aide||ne': [0, 1, 15, 0], 'last||ne': [0, 1, 42, 0], 'adviser||ne': [0, 1, 173, 0], 'take||ne': [0, 1, 30, 0], 'carter||per': [0, 1, 21, 4], 'russia||loc': [0, 1, 242, 3], 'fisa||misc': [0, 1, 75, 2], 'maxine waters||per': [0, 2, 2, 4], 'surveillance||ne': [0, 1, 15, 0], 'washington post||org': [0, 2, 65, 1], 'centers||ne': [0, 1, 8, 0], 'talk||ne': [0, 1, 10, 0], 'sean||per': [0, 1, 1, 4], 'hocaust centers||org': [0, 2, 1, 1], 'forces||ne': [0, 1, 3, 0], 'nigerian security forces||org': [0, 3, 1, 1], 'reported||ne': [0, 1, 8, 0], 'warrant||ne': [0, 1, 114, 0], 'chris hayes||per': [0, 2, 5, 4], 'way||ne': [0, 1, 21, 0], 'scott street park||loc': [0, 3, 1, 3], 'worked||ne': [0, 1, 5, 0], 'doj||org': [0, 1, 17, 1], 'fall||ne': [0, 1, 11, 0], 'syria||loc': [0, 1, 62, 3], 'raw||ne': [0, 1, 3, 0], 'gov||ne': [0, 1, 4, 0], 'louisiana||loc': [0, 1, 1, 3], 'gov . edwards||per': [0, 3, 1, 4], 'news||ne': [0, 1, 28, 0], 'dems||misc': [0, 1, 11, 2], 'america||loc': [0, 1, 31, 3], 'wapo||org': [0, 1, 32, 1], 'american||misc': [0, 1, 21, 2], 'obama||per': [0, 1, 84, 4], 'get||ne': [0, 1, 67, 0], 'win||ne': [0, 1, 13, 0], 'next||ne': [0, 1, 17, 0], 'ukraine||loc': [0, 1, 8, 3], 'portugal||loc': [0, 1, 1, 3], 'bosnia||loc': [0, 1, 1, 3], 'manafort||per': [0, 1, 10, 4], 'story||ne': [0, 1, 23, 0], 'post||ne': [0, 1, 56, 0], 'back||ne': [0, 1, 34, 0], 'ny||loc': [0, 1, 3, 3], 'nyc||loc': [0, 1, 1, 3], 'media||ne': [0, 1, 16, 0], 'video||ne': [0, 1, 6, 0], 'rather||ne': [0, 1, 2, 0], 'ghana||loc': [0, 1, 1, 3], 'investigation||ne': [0, 1, 52, 0], 'jim comey||per': [0, 2, 1, 4], 'miami||loc': [0, 1, 1, 3], 'help||ne': [0, 1, 27, 0], 'los angeles||loc': [0, 2, 1, 3], 'west hollywood||loc': [0, 2, 1, 3], 'beverly hills||loc': [0, 2, 1, 3], 'force||ne': [0, 1, 2, 0], 'gop||org': [0, 1, 27, 1], 'dem||org': [0, 1, 10, 1], 'george||per': [0, 1, 1, 4], 'probe||ne': [0, 1, 13, 0], 'ties||ne': [0, 1, 17, 0], 'claims||ne': [0, 1, 4, 0], 'jd||org': [0, 1, 1, 1], 'dr king||per': [0, 2, 1, 4], 'politics||ne': [0, 1, 4, 0], 'intel||ne': [0, 1, 9, 0], 'hyderabad||loc': [0, 1, 1, 3], 'guy||ne': [0, 1, 20, 0], 'breitbart||org': [0, 1, 6, 1], 'rep||ne': [0, 1, 3, 0], 'thing||ne': [0, 1, 19, 0], 'nunes||per': [0, 1, 25, 4], 'white house||loc': [0, 2, 12, 3], 'rep schiff||per': [0, 2, 1, 4], 'lifetime||ne': [0, 1, 3, 0], 'people||ne': [0, 1, 37, 0], 'history||ne': [0, 1, 5, 0], 'end||ne': [0, 1, 6, 0], 'said||ne': [0, 1, 29, 0], 'zero||ne': [0, 1, 2, 0], 'right||ne': [0, 1, 77, 0], 'decision||ne': [0, 1, 2, 0], 'case||ne': [0, 1, 7, 0], 'roe v wade||misc': [0, 3, 3, 2], 'abortion||misc': [0, 1, 6, 2], 'u . s . supreme court||org': [0, 6, 1, 1], 'bad||ne': [0, 1, 27, 0], 'korean peninsula||loc': [0, 2, 3, 3], 'ordered||ne': [0, 1, 2, 0], 'comrade comey||per': [0, 2, 1, 4], 'means||ne': [0, 1, 18, 0], 'hillary||per': [0, 1, 24, 4], 'andrew mccabe||per': [0, 2, 7, 4], 'lynch||per': [0, 1, 6, 4], 'rice||per': [0, 1, 8, 4], 'donald trump||per': [0, 2, 27, 4], 'forgot||ne': [0, 1, 3, 0], 'fb||org': [0, 1, 5, 1], 'campaign||ne': [0, 1, 88, 0], 'fisa court||org': [0, 2, 26, 1], 'office||ne': [0, 1, 14, 0], 'money||ne': [0, 1, 11, 0], 'de blasio||per': [0, 2, 2, 4], 'liar||ne': [0, 1, 14, 0], 'need||ne': [0, 1, 36, 0], 'give||ne': [0, 1, 10, 0], 'republican party||org': [0, 2, 1, 1], 'pretty||ne': [0, 1, 9, 0], 'least||ne': [0, 1, 4, 0], 'australia||loc': [0, 1, 2, 3], 'european||misc': [0, 1, 4, 2], 'poor||ne': [0, 1, 8, 0], 'page||per': [0, 1, 97, 4], 'heard||ne': [0, 1, 40, 0], 'impress||ne': [0, 1, 2, 0], 'deep||ne': [0, 1, 3, 0], 'fox news||org': [0, 2, 12, 1], 'passover||misc': [0, 1, 1, 2], 'emails||ne': [0, 1, 9, 0], 'james comey||per': [0, 2, 4, 4], 'morning||ne': [0, 1, 4, 0], 'spicy||per': [0, 1, 1, 4], 'joe||per': [0, 1, 3, 4], 'reportedly||ne': [0, 1, 22, 0], 'obtained||ne': [0, 1, 29, 0], 'worse||ne': [0, 1, 7, 0], 'administration||ne': [0, 1, 21, 0], 'trump administration||org': [0, 2, 5, 1], 'played||ne': [0, 1, 5, 0], 'black||ne': [0, 1, 5, 0], 'psd||misc': [0, 1, 1, 2], 'html||misc': [0, 1, 1, 2], 'jets gase||misc': [0, 2, 1, 2], 'black mirror||misc': [0, 2, 1, 2], 'morty||misc': [0, 1, 1, 2], 'advisor||ne': [0, 1, 40, 0], 'hard||ne': [0, 1, 7, 0], 'united||org': [0, 1, 14, 1], 'sam clovis||per': [0, 2, 5, 4], 'pence||per': [0, 1, 4, 4], 'saudi||loc': [0, 1, 1, 3], 'mbs||per': [0, 1, 1, 4], 'convinced||ne': [0, 1, 1, 0], 'provide||ne': [0, 1, 1, 0], 'dump||ne': [0, 1, 4, 0], 'whitehouse||loc': [0, 1, 3, 3], 'hrc||per': [0, 1, 9, 4], 'law||ne': [0, 1, 13, 0], 'set||ne': [0, 1, 6, 0], 'al||loc': [0, 1, 2, 3], 'say||ne': [0, 1, 13, 0], 'russian||misc': [0, 1, 150, 2], 'got||ne': [0, 1, 32, 0], 'watergate||misc': [0, 1, 2, 2], 'shame||ne': [0, 1, 4, 0], 'days||ne': [0, 1, 10, 0], 'spicer||per': [0, 1, 32, 4], 'answer||ne': [0, 1, 11, 0], 'doh||org': [0, 1, 1, 1], 'aspca||org': [0, 1, 1, 1], 'communications||ne': [0, 1, 5, 0], 'justice department||org': [0, 2, 1, 1], 'cnn||org': [0, 1, 10, 1], 'wolf||per': [0, 1, 1, 4], 'israel||loc': [0, 1, 4, 3], 'alabama||loc': [0, 1, 1, 3], 'new||ne': [0, 1, 30, 0], 'ag sessions||per': [0, 2, 1, 4], 'devin nunes||per': [0, 2, 8, 4], 'good||ne': [0, 1, 17, 0], 'war||ne': [0, 1, 20, 0], 'libya||loc': [0, 1, 2, 3], 'muslim brotherhood||org': [0, 2, 1, 1], 'dictator||ne': [0, 1, 2, 0], 'armed forces||org': [0, 2, 1, 1], 'miraflores||loc': [0, 1, 1, 3], 'nicholas maduro||per': [0, 2, 1, 4], 'piece||ne': [0, 1, 1, 0], 'asshole||ne': [0, 1, 1, 0], 'gen . flynn||per': [0, 3, 1, 4], 'name||ne': [0, 1, 14, 0], 'james bond||per': [0, 2, 2, 4], 'germany||loc': [0, 1, 1, 3], 'wait||ne': [0, 1, 12, 0], 'sexual||ne': [0, 1, 3, 0], 'spokesman||ne': [0, 1, 2, 0], 'says||ne': [0, 1, 20, 0], 'cliff richard||per': [0, 2, 1, 4], 'south yorkshire police||org': [0, 3, 2, 1], 'us||ne': [0, 1, 25, 0], 'comey||per': [0, 1, 41, 4], 'email||ne': [0, 1, 3, 0], 'u . s||loc': [0, 3, 15, 3], 'venezuela||loc': [0, 1, 13, 3], 'made||ne': [0, 1, 10, 0], 'mlk||per': [0, 1, 21, 4], 'took||ne': [0, 1, 6, 0], 'clinton||per': [0, 1, 10, 4], 'come||ne': [0, 1, 8, 0], 'men||ne': [0, 1, 7, 0], 'lou||per': [0, 1, 1, 4], 'ohio||loc': [0, 1, 1, 3], 'puppet||ne': [0, 1, 8, 0], 'show||ne': [0, 1, 19, 0], 'punch||ne': [0, 1, 1, 0], 'putin||per': [0, 1, 91, 4], 'judy||per': [0, 1, 1, 4], 'janesville wi||loc': [0, 2, 2, 3], 'heartbeat bills||misc': [0, 2, 1, 2], 'spies||ne': [0, 1, 15, 0], 'torterra||misc': [0, 1, 1, 2], 'power||ne': [0, 1, 16, 0], 'treason||ne': [0, 1, 17, 0], 'washpost||org': [0, 1, 2, 1], 'wh||loc': [0, 1, 12, 3], 'press||ne': [0, 1, 10, 0], 'weiner||per': [0, 1, 1, 4], 'computer||ne': [0, 1, 2, 0], 'shows||ne': [0, 1, 3, 0], 'general||ne': [0, 1, 6, 0], 'breaking||ne': [0, 1, 27, 0], 'everywhere||ne': [0, 1, 4, 0], 'psyduck||misc': [0, 1, 1, 2], 'et||ne': [0, 1, 3, 0], 'needs||ne': [0, 1, 12, 0], 'hillary clinton||per': [0, 2, 6, 4], 'went||ne': [0, 1, 2, 0], 'big||ne': [0, 1, 14, 0], 'makes||ne': [0, 1, 9, 0], 'south||ne': [0, 1, 2, 0], 'reports||ne': [0, 1, 8, 0], 'article||ne': [0, 1, 3, 0], 'fits||ne': [0, 1, 3, 0], 'intelligence||ne': [0, 1, 12, 0], 'political||ne': [0, 1, 7, 0], 'irs||org': [0, 1, 1, 1], 'airlines||ne': [0, 1, 12, 0], 'united airlines||org': [0, 2, 3, 1], 'spin||ne': [0, 1, 1, 0], 'pbo||org': [0, 1, 1, 1], 'presidential||ne': [0, 1, 8, 0], 'gas||ne': [0, 1, 4, 0], 'spying||ne': [0, 1, 8, 0], 'hitler||per': [0, 1, 16, 4], 'martin luther king||per': [0, 3, 6, 4], 'professor||ne': [0, 1, 3, 0], 'hbo||org': [0, 1, 1, 1], 'frank h . t . rhodes||per': [0, 6, 1, 4], 'cornell university||org': [0, 2, 1, 1], 'global||ne': [0, 1, 3, 0], 'global warming||misc': [0, 2, 2, 2], 'trending||ne': [0, 1, 8, 0], 'talking||ne': [0, 1, 9, 0], 'eric holder||per': [0, 2, 1, 4], 'loretta lynch||per': [0, 2, 2, 4], 'comrade||ne': [0, 1, 3, 0], 'tillerson||per': [0, 1, 15, 4], 'oil||ne': [0, 1, 10, 0], 'russia oil||org': [0, 2, 2, 1], 'deal||ne': [0, 1, 12, 0], 'green new deal||misc': [0, 3, 1, 2], 'call||ne': [0, 1, 10, 0], 'bill||per': [0, 1, 2, 4], 'think||ne': [0, 1, 46, 0], 'adope podcast||misc': [0, 2, 2, 2], 'soundcloud||org': [0, 1, 1, 1], 'exists||ne': [0, 1, 1, 0], 'works||ne': [0, 1, 2, 0], 'newsweek||org': [0, 1, 2, 1], 'maher||per': [0, 1, 1, 4], 'supreme court||org': [0, 2, 4, 1], 'claiming||ne': [0, 1, 1, 0], 'warriors||org': [0, 1, 1, 1], 'reading||ne': [0, 1, 4, 0], 'night||ne': [0, 1, 2, 0], 'breitbarters||misc': [0, 1, 1, 2], 'djt||per': [0, 1, 6, 4], 'wants||ne': [0, 1, 7, 0], 'usa||loc': [0, 1, 8, 3], 'already||ne': [0, 1, 18, 0], 'bill nye the science guy||per': [0, 5, 1, 4], 'wp||org': [0, 1, 1, 1], 'strike||ne': [0, 1, 12, 0], 'washpo||org': [0, 1, 1, 1], 'orders||ne': [0, 1, 2, 0], 'barry||per': [0, 1, 1, 4], 'admin||ne': [0, 1, 13, 0], 'brought||ne': [0, 1, 9, 0], 'lied||ne': [0, 1, 10, 0], 'congress||org': [0, 1, 20, 1], 'first||ne': [0, 1, 21, 0], 'chicago||loc': [0, 1, 1, 3], 'center||ne': [0, 1, 5, 0], 'connection||ne': [0, 1, 9, 0], 'united states foreign intelligence surveillance court||org': [0, 6, 1, 1], 'detective pikachu||misc': [0, 2, 4, 2], 'backing||ne': [0, 1, 1, 0], 'trump team||org': [0, 2, 1, 1], 'msnbc||org': [0, 1, 12, 1], 'pikachu||misc': [0, 1, 1, 2], 'fisc||misc': [0, 1, 1, 2], 'years||ne': [0, 1, 6, 0], 'bulbasaur||misc': [0, 1, 2, 2], 'ivysaur||misc': [0, 1, 1, 2], 'venasaur||misc': [0, 1, 1, 2], 'urals||misc': [0, 1, 1, 2], 'animal||ne': [0, 1, 2, 0], 'forced||ne': [0, 1, 2, 0], 'hollywood||misc': [0, 1, 2, 2], 'loves||ne': [0, 1, 3, 0], 'vlad putin||per': [0, 2, 1, 4], 'soon||ne': [0, 1, 9, 0], 'connections||ne': [0, 1, 12, 0], 'rep swalwell||per': [0, 2, 2, 4], 'manaford||per': [0, 1, 1, 4], 'president obama||per': [0, 2, 5, 4], 'court||ne': [0, 1, 10, 0], 'donald||per': [0, 1, 7, 4], 'pepsi||org': [0, 1, 6, 1], 'house republicans||misc': [0, 2, 2, 2], 'independent||ne': [0, 1, 3, 0], 'jeff sessions||per': [0, 2, 19, 4], 'holocaust centers||org': [0, 2, 13, 1], 'pika pika||misc': [0, 2, 1, 2], 'amc||org': [0, 1, 1, 1], 'keitholbermann||per': [0, 1, 4, 4], 'lucky||ne': [0, 1, 2, 0], 'pokémon||misc': [0, 1, 5, 2], 'pagie||per': [0, 1, 1, 4], 'watching||ne': [0, 1, 9, 0], 'movie||ne': [0, 1, 4, 0], 'boston globe||org': [0, 2, 1, 1], 'pokemon||misc': [0, 1, 2, 2], 'gamestop||org': [0, 1, 1, 1], 'really||ne': [0, 1, 16, 0], 'collusion||ne': [0, 1, 18, 0], 'neymar||per': [0, 1, 3, 4], 'ass||ne': [0, 1, 7, 0], 'dems||org': [0, 1, 1, 1], 'ahca||misc': [0, 1, 2, 2], 'left||ne': [0, 1, 3, 0], 'citizen||ne': [0, 1, 2, 0], 'lead||ne': [0, 1, 8, 0], 'mike flynn||per': [0, 2, 9, 4], 'foxnews||org': [0, 1, 3, 1], 'fired||ne': [0, 1, 9, 0], 'others||ne': [0, 1, 6, 0], 'thought||ne': [0, 1, 2, 0], 'moscow||loc': [0, 1, 19, 3], 'sessions||per': [0, 1, 18, 4], 'officials||ne': [0, 1, 6, 0], 'subway||org': [0, 1, 2, 1], 'shaune_mj||per': [0, 1, 1, 4], 'felt||ne': [0, 1, 2, 0], 'official||ne': [0, 1, 5, 0], 'mg kelly||per': [0, 2, 1, 4], 'youtube||org': [0, 1, 3, 1], 'via||org': [0, 1, 1, 1], 'fda||org': [0, 1, 1, 1], 'may||ne': [0, 1, 12, 0], 'world news||org': [0, 2, 1, 1], 'fire||ne': [0, 1, 12, 0], 'dt||per': [0, 1, 3, 4], 'vevo||org': [0, 1, 1, 1], 'share||ne': [0, 1, 3, 0], 'bomb||ne': [0, 1, 10, 0], 'holocaust||misc': [0, 1, 9, 2], 'mean||ne': [0, 1, 7, 0], 'voters||ne': [0, 1, 3, 0], 'election||ne': [0, 1, 17, 0], 'republican||misc': [0, 1, 2, 2], 'united states||loc': [0, 2, 4, 3], 'spy||ne': [0, 1, 23, 0], 'music||ne': [0, 1, 3, 0], 'one||ne': [0, 1, 31, 0], 'thetnkids||per': [0, 1, 1, 4], 'jtimberlake||per': [0, 1, 1, 4], 'radiodisney||org': [0, 1, 1, 1], 'supporters||ne': [0, 1, 2, 0], 'niallharbison||per': [0, 1, 1, 4], 'nytimes||org': [0, 1, 2, 1], 'leader||ne': [0, 1, 5, 0], 'eamon gilmore||per': [0, 2, 1, 4], 'labour||org': [0, 1, 1, 1], 'irishtimes||org': [0, 1, 1, 1], 'camp||ne': [0, 1, 1, 0], 'conflict||ne': [0, 1, 2, 0], 'military||org': [0, 1, 1, 1], 'nsa||org': [0, 1, 1, 1], 'gets||ne': [0, 1, 3, 0], 'saying||ne': [0, 1, 6, 0], 'find||ne': [0, 1, 7, 0], 'planned||ne': [0, 1, 2, 0], 'rachel||per': [0, 1, 6, 4], 'past||ne': [0, 1, 2, 0], 'bury||ne': [0, 1, 2, 0], 'tom clancy||per': [0, 2, 1, 4], 'hold||ne': [0, 1, 5, 0], 'complex||ne': [0, 1, 1, 0], 'millions||ne': [0, 1, 1, 0], 'complaint||ne': [0, 1, 1, 0], 'crimes||ne': [0, 1, 6, 0], 'peace||ne': [0, 1, 1, 0], 'ireland||loc': [0, 1, 1, 3], 'stupid||ne': [0, 1, 16, 0], 'collateral damage||misc': [0, 2, 1, 2], 'vimeo||org': [0, 1, 1, 1], 'cheetolini||per': [0, 1, 1, 4], 'rosneft||org': [0, 1, 5, 1], 'nunez||per': [0, 1, 1, 4], 'wash post||org': [0, 2, 4, 1], 'work||ne': [0, 1, 10, 0], 'staff||ne': [0, 1, 2, 0], 'devil||ne': [0, 1, 2, 0], 'darth vader||per': [0, 2, 1, 4], 'con||ne': [0, 1, 6, 0], 'volkswagen f015||misc': [0, 2, 1, 2], 'las vegas||loc': [0, 2, 1, 3], 'world||ne': [0, 1, 4, 0], 'wonder world tour||misc': [0, 3, 1, 2], 'break||ne': [0, 1, 5, 0], 'passes||ne': [0, 1, 1, 0], 'democrats||misc': [0, 1, 5, 2], 'house||org': [0, 1, 4, 1], 'twitter||org': [0, 1, 15, 1], 'judge||ne': [0, 1, 6, 0], 'soviet russia||loc': [0, 2, 2, 3], 'half||ne': [0, 1, 3, 0], 'level||ne': [0, 1, 6, 0], 'dealings||ne': [0, 1, 3, 0], 'things||ne': [0, 1, 8, 0], 'tomahawk||misc': [0, 1, 2, 2], 'times||ne': [0, 1, 10, 0], 'mess||ne': [0, 1, 5, 0], 'senate||org': [0, 1, 6, 1], 'republicans||misc': [0, 1, 3, 2], 'move||ne': [0, 1, 7, 0], 'scandal||ne': [0, 1, 9, 0], 'obamagate||misc': [0, 1, 1, 2], 'beer||ne': [0, 1, 3, 0], 'john fugelsang||per': [0, 2, 2, 4], 'week||ne': [0, 1, 6, 0], 'distractions||ne': [0, 1, 4, 0], 'mainstream||ne': [0, 1, 2, 0], 'almost||ne': [0, 1, 1, 0], 'don||per': [0, 1, 1, 4], 'lost||ne': [0, 1, 2, 0], 'lmao||ne': [0, 1, 3, 0], 'americans||misc': [0, 1, 11, 2], 'va||org': [0, 1, 1, 1], 'mcdonald||org': [0, 1, 1, 1], 'mike vick||per': [0, 2, 1, 4], 'merrill lynch||org': [0, 2, 1, 1], 'boom||ne': [0, 1, 11, 0], 'fake||ne': [0, 1, 4, 0], 'weird||ne': [0, 1, 2, 0], 'trumps||misc': [0, 1, 14, 2], 'list||ne': [0, 1, 6, 0], 'trump trans team||misc': [0, 3, 1, 2], 'hilary||per': [0, 1, 2, 4], 'comparison||ne': [0, 1, 1, 0], 'mlk jr||per': [0, 2, 10, 4], 'kellyanne||per': [0, 1, 1, 4], 'hpn||misc': [0, 1, 1, 2], 'paul manafort||per': [0, 2, 7, 4], 'position||ne': [0, 1, 2, 0], 'chechnya||loc': [0, 1, 2, 3], 'san bernardino||loc': [0, 2, 1, 3], 'used||ne': [0, 1, 3, 0], 'man||ne': [0, 1, 7, 0], 'prior||ne': [0, 1, 3, 0], 'god||ne': [0, 1, 7, 0], 'order||ne': [0, 1, 17, 0], 'wh||org': [0, 1, 5, 1], 'prince kushner||per': [0, 2, 1, 4], 'repeated||ne': [0, 1, 1, 0], 'democratic||misc': [0, 1, 2, 2], 'greg leppert||per': [0, 2, 1, 4], 'sudden||ne': [0, 1, 1, 0], 'polonium tea syndrome||misc': [0, 3, 1, 2], 'agree||ne': [0, 1, 7, 0], 'compared||ne': [0, 1, 3, 0], 'biggest||ne': [0, 1, 3, 0], 'justice||ne': [0, 1, 2, 0], 'jared jushner||per': [0, 2, 1, 4], 'public||ne': [0, 1, 5, 0], 'look||ne': [0, 1, 12, 0], 'following||ne': [0, 1, 5, 0], 'advisors||ne': [0, 1, 5, 0], 'traitor||ne': [0, 1, 7, 0], 'borussia dortmund||org': [0, 2, 4, 1], 'pu news||org': [0, 2, 1, 1], 'leaking||ne': [0, 1, 4, 0], 'mid||ne': [0, 1, 2, 0], 'knew||ne': [0, 1, 9, 0], 'idiot||ne': [0, 1, 13, 0], 'called||ne': [0, 1, 6, 0], 'brazil||loc': [0, 1, 1, 3], 'sounder garden||misc': [0, 2, 2, 2], 'lying||ne': [0, 1, 5, 0], 'clintons||per': [0, 1, 2, 4], 'getting||ne': [0, 1, 14, 0], 'russkies||misc': [0, 1, 1, 2], 'alex||per': [0, 1, 1, 4], 'numb||misc': [0, 1, 3, 2], 'maxine||per': [0, 1, 1, 4], 'bet||ne': [0, 1, 8, 0], 'actually||ne': [0, 1, 7, 0], 'forest gump||per': [0, 2, 1, 4], 'stop||ne': [0, 1, 10, 0], 'rosenbergs||per': [0, 1, 1, 4], 'martin luther king jr||per': [0, 4, 7, 4], 'deflect||ne': [0, 1, 2, 0], 'canary||misc': [0, 1, 8, 2], 'watched||ne': [0, 1, 1, 0], 'wanted||ne': [0, 1, 2, 0], 'bond||per': [0, 1, 1, 4], 'fisa wrnt||misc': [0, 2, 2, 2], 'russian fsb||org': [0, 2, 1, 1], 'neocons||ne': [0, 1, 1, 0], 'masters||ne': [0, 1, 1, 0], 'interview||ne': [0, 1, 8, 0], 'refugees||ne': [0, 1, 1, 0], 'syrian||misc': [0, 1, 9, 2], 'orange||ne': [0, 1, 7, 0], 'denisedresserg||per': [0, 1, 1, 4], 'washingtonpost||org': [0, 1, 1, 1], 'tom brady||per': [0, 2, 1, 4], 'thedemcoalition||org': [0, 1, 1, 1], 'mayor||ne': [0, 1, 1, 0], 'mayor murray||per': [0, 2, 1, 4], 'wikileaks||org': [0, 1, 2, 1], 'conducted||ne': [0, 1, 5, 0], 'ladies||ne': [0, 1, 1, 0], 'fisa warrants||misc': [0, 2, 7, 2], 'trumpkins||misc': [0, 1, 1, 2], 'service||ne': [0, 1, 4, 0], 'kingnivin||per': [0, 1, 1, 4], 'ifttt||org': [0, 1, 1, 1], 'instagram||org': [0, 1, 3, 1], 'subject||ne': [0, 1, 5, 0], 'fight||ne': [0, 1, 1, 0], 'ukip||org': [0, 1, 1, 1], 'british||misc': [0, 1, 4, 2], 'costa del crime||misc': [0, 3, 1, 2], 'party||ne': [0, 1, 7, 0], 'alliance party||org': [0, 2, 1, 1], 'east belfast||loc': [0, 2, 1, 3], 'putting||ne': [0, 1, 3, 0], 'fisa courts||org': [0, 2, 1, 1], 'snowden||per': [0, 1, 1, 4], 'job||ne': [0, 1, 12, 0], 'rest||ne': [0, 1, 7, 0], 'girl||ne': [0, 1, 2, 0], 'uk||loc': [0, 1, 10, 3], 'eu||org': [0, 1, 5, 1], 'dc||loc': [0, 1, 1, 3], 'housing assistance payment||misc': [0, 3, 1, 2], 'north||ne': [0, 1, 11, 0], 'bbc||org': [0, 1, 4, 1], 'distraction||ne': [0, 1, 22, 0], 'farage||per': [0, 1, 1, 4], 'govt||ne': [0, 1, 4, 0], 'n glasgow||loc': [0, 2, 1, 3], 'osborne treasury||org': [0, 2, 1, 1], 'uklabour||org': [0, 1, 1, 1], 'spicey||per': [0, 1, 4, 4], 'mulder||per': [0, 1, 1, 4], 'scully||per': [0, 1, 1, 4], 'meeting||ne': [0, 1, 5, 0], 'axios press||org': [0, 2, 1, 1], 'ny times||org': [0, 2, 1, 1], 'better||ne': [0, 1, 10, 0], 'magazine||ne': [0, 1, 1, 0], 'politico magazine||org': [0, 2, 1, 1], 'niall||per': [0, 1, 3, 4], 'scarface||misc': [0, 1, 1, 2], 'team trump||misc': [0, 2, 2, 2], 'launches||ne': [0, 1, 2, 0], 'member||ne': [0, 1, 3, 0], 'catherineanaya||per': [0, 1, 1, 4], 'us white house correspondents association||org': [0, 5, 1, 1], 'offers||ne': [0, 1, 1, 0], 'democracy||misc': [0, 1, 13, 2], 'theory||ne': [0, 1, 2, 0], 'damian maia||per': [0, 2, 1, 4], 'chester bennington||per': [0, 2, 1, 4], 'hybrid theory||misc': [0, 2, 1, 2], 'maia||per': [0, 1, 10, 4], 'bjj||misc': [0, 1, 1, 2], 'gamebread||misc': [0, 1, 1, 2], 'tries||ne': [0, 1, 1, 0], 'inside||ne': [0, 1, 2, 0], 'away||ne': [0, 1, 9, 0], 'paul ryan||per': [0, 2, 2, 4], 'version||ne': [0, 1, 2, 0], 'cvs||org': [0, 1, 1, 1], 'epipen||misc': [0, 1, 1, 2], 'trust||ne': [0, 1, 5, 0], 'rnc||org': [0, 1, 2, 1], 'paul||per': [0, 1, 1, 4], 'source||ne': [0, 1, 4, 0], 'tax||ne': [0, 1, 13, 0], 'usc||org': [0, 1, 1, 1], 'uscannenberg||org': [0, 1, 1, 1], 'gosparksc||org': [0, 1, 1, 1], 'operative||ne': [0, 1, 2, 0], 'whca||org': [0, 1, 1, 1], 'shut||ne': [0, 1, 6, 0], 'npr||org': [0, 1, 1, 1], 'state||ne': [0, 1, 6, 0], 'live||ne': [0, 1, 11, 0], 'bill remnick||per': [0, 2, 1, 4], 'ford||org': [0, 1, 1, 1], 'barra||per': [0, 1, 1, 4], 'etc||ne': [0, 1, 2, 0], 'conway||per': [0, 1, 2, 4], 'apparently||ne': [0, 1, 1, 0], 'smh||ne': [0, 1, 2, 0], 'cnbc||org': [0, 1, 3, 1], 'anyway||ne': [0, 1, 1, 0], 'catherine herridge||per': [0, 2, 1, 4], 'goes||ne': [0, 1, 7, 0], 'tired||ne': [0, 1, 2, 0], 'ol||ne': [0, 1, 1, 0], 'citizens||ne': [0, 1, 2, 0], 'leningrad||loc': [0, 1, 2, 3], 'mouth||ne': [0, 1, 3, 0], 'beyond||ne': [0, 1, 2, 0], 'sound||ne': [0, 1, 2, 0], 'total||ne': [0, 1, 1, 0], 'gonna||ne': [0, 1, 2, 0], 'adam schiff||per': [0, 2, 2, 4], 'line||ne': [0, 1, 10, 0], 'mention||ne': [0, 1, 4, 0], 'gone||ne': [0, 1, 4, 0], 'transition||ne': [0, 1, 2, 0], 'thinks||ne': [0, 1, 2, 0], 'polonium||misc': [0, 1, 1, 2], 'investigations||ne': [0, 1, 3, 0], 'eyes||ne': [0, 1, 8, 0], 'hands||ne': [0, 1, 4, 0], 'mercers||per': [0, 1, 1, 4], 'bannon||per': [0, 1, 3, 4], 'kislyak||per': [0, 1, 3, 4], 'face||ne': [0, 1, 4, 0], 'watches||ne': [0, 1, 1, 0], 'joni||per': [0, 1, 1, 4], 'adam entous||per': [0, 2, 1, 4], 'kansas||loc': [0, 1, 6, 3], 'fashion||ne': [0, 1, 2, 0], 'london college of fashion||org': [0, 4, 2, 1], 'conga||misc': [0, 1, 1, 2], 'michael flynn||per': [0, 2, 5, 4], 'roger stone||per': [0, 2, 2, 4], 'julius||per': [0, 1, 1, 4], 'ethel rosenberg||per': [0, 2, 1, 4], 'robert hansen||per': [0, 2, 1, 4], 'keeping||ne': [0, 1, 2, 0], 'levashov||per': [0, 1, 1, 4], 'spain||loc': [0, 1, 2, 3], 'trip||ne': [0, 1, 5, 0], 'corey||per': [0, 1, 1, 4], 'college||ne': [0, 1, 1, 0], 'pentagram||org': [0, 1, 1, 1], 'dominic lippa||per': [0, 2, 1, 4], 'trump campaign hq||loc': [0, 3, 1, 3], 'elected||ne': [0, 1, 2, 0], 'fucked||ne': [0, 1, 4, 0], 'florida||loc': [0, 1, 1, 3], 'ebuyhouse||org': [0, 1, 3, 1], 'plane||ne': [0, 1, 4, 0], 'knows||ne': [0, 1, 9, 0], 'save||ne': [0, 1, 6, 0], 'auntie maxine||per': [0, 2, 1, 4], 'secretary||ne': [0, 1, 3, 0], 'rex tillerson||per': [0, 2, 8, 4], 'secretary of state||per': [0, 3, 1, 4], 'junior||ne': [0, 1, 3, 0], 'google||org': [0, 1, 8, 1], 'claim||ne': [0, 1, 4, 0], 'mafia||ne': [0, 1, 1, 0], 'vlad||per': [0, 1, 5, 4], 'communists||misc': [0, 1, 1, 2], 'daily||ne': [0, 1, 7, 0], 'bombed||ne': [0, 1, 5, 0], 'great||ne': [0, 1, 23, 0], 'national||ne': [0, 1, 2, 0], 'immediately||ne': [0, 1, 3, 0], 'along||ne': [0, 1, 6, 0], 'acting attorney general||per': [0, 3, 1, 4], 'moron||ne': [0, 1, 5, 0], 'chief||ne': [0, 1, 1, 0], 'info||ne': [0, 1, 3, 0], 'senate ic||org': [0, 2, 1, 1], 'march||ne': [0, 1, 4, 0], 'little||ne': [0, 1, 14, 0], 'louisemensch||per': [0, 1, 3, 4], 'jim murray||per': [0, 2, 1, 4], 'uber||org': [0, 1, 4, 1], 'unrelated||ne': [0, 1, 1, 0], 'carterpage||per': [0, 1, 1, 4], 'platform||ne': [0, 1, 2, 0], 'huffington post||org': [0, 2, 1, 1], 'joke||ne': [0, 1, 4, 0], 'colluded||ne': [0, 1, 2, 0], 'presidency||ne': [0, 1, 6, 0], 'jefferson beauregard sessions iii||per': [0, 4, 1, 4], 'obamagate||per': [0, 1, 1, 4], 'heavily||ne': [0, 1, 1, 0], 'regime||ne': [0, 1, 4, 0], 'fisa report||misc': [0, 2, 3, 2], 'federal court||org': [0, 2, 1, 1], 'attorney general||per': [0, 2, 1, 4], 'supposedly||ne': [0, 1, 2, 0], 'writers||ne': [0, 1, 2, 0], 'trumprussia||ne': [0, 1, 1, 0], 'nkorea||loc': [0, 1, 1, 3], 'playing||ne': [0, 1, 3, 0], 'hours||ne': [0, 1, 3, 0], 'convince||ne': [0, 1, 2, 0], 'run||ne': [0, 1, 3, 0], 'embarrassing||ne': [0, 1, 4, 0], 'blame||ne': [0, 1, 6, 0], 'white house||org': [0, 2, 6, 1], 'geils||ne': [0, 1, 1, 0], 'j . geils||per': [0, 3, 1, 4], 'jared||per': [0, 1, 7, 4], 'stephen miller||per': [0, 2, 1, 4], 'jared kushner||per': [0, 2, 3, 4], 'full||ne': [0, 1, 5, 0], 'bigly||ne': [0, 1, 3, 0], 'thinking||ne': [0, 1, 7, 0], 'dropping||ne': [0, 1, 1, 0], 'awful||ne': [0, 1, 2, 0], 'certainly||ne': [0, 1, 2, 0], 'clearly||ne': [0, 1, 1, 0], 'showed||ne': [0, 1, 1, 0], 'n korea||loc': [0, 2, 3, 3], 'comes||ne': [0, 1, 5, 0], 'donald j trump||per': [0, 3, 1, 4], 'longer||ne': [0, 1, 1, 0], 'gorsuch||per': [0, 1, 2, 4], 'scotus||org': [0, 1, 2, 1], 'federal||ne': [0, 1, 2, 0], 'drag||ne': [0, 1, 1, 0], 'race||ne': [0, 1, 3, 0], 'wall||ne': [0, 1, 6, 0], 'sake||ne': [0, 1, 2, 0], 'stuff||ne': [0, 1, 10, 0], 'nazi||misc': [0, 1, 4, 2], 'huma abedin||per': [0, 2, 1, 4], 'farkas||per': [0, 1, 1, 4], 'irish news||org': [0, 2, 1, 1], 'armagh_gaa||org': [0, 1, 1, 1], 'ulster||loc': [0, 1, 1, 3], 'ulstergaa||loc': [0, 1, 1, 3], 'uscis||org': [0, 1, 2, 1], 'comment||ne': [0, 1, 2, 0], 'sanctions||ne': [0, 1, 5, 0], 'american creative workers network||org': [0, 4, 1, 1], 'dwp||org': [0, 1, 2, 1], 'army||ne': [0, 1, 2, 0], 'us army||org': [0, 2, 3, 1], 'defense||ne': [0, 1, 1, 0], 'u 2||misc': [0, 2, 1, 2], 'louise||per': [0, 1, 2, 4], 'referred||ne': [0, 1, 1, 0], 'fans||ne': [0, 1, 1, 0], 'wing||ne': [0, 1, 1, 0], 'fox||org': [0, 1, 1, 1], 'gordon||per': [0, 1, 1, 4], 'lewandowski||per': [0, 1, 1, 4], 'nazis||misc': [0, 1, 1, 2], 'north korea||loc': [0, 2, 10, 3], 'clovis||per': [0, 1, 1, 4], 'pentagon||loc': [0, 1, 2, 3], 'carter kingsford page||per': [0, 3, 1, 4], 'mitch mcconnell||per': [0, 2, 1, 4], 'latest||ne': [0, 1, 6, 0], 'new york post||org': [0, 3, 1, 1], 'barack obama||per': [0, 2, 1, 4], 'anderson cooper||per': [0, 2, 1, 4], 'aliens||ne': [0, 1, 1, 0], 'attack||ne': [0, 1, 12, 0], 'though||ne': [0, 1, 3, 0], 'ic||org': [0, 1, 5, 1], 'entire||ne': [0, 1, 5, 0], 'possible||ne': [0, 1, 2, 0], 'vehicle||ne': [0, 1, 3, 0], 'cia||org': [0, 1, 8, 1], 'um||ne': [0, 1, 2, 0], 'tried||ne': [0, 1, 2, 0], 'washington||loc': [0, 1, 6, 3], 'mark levin||per': [0, 2, 1, 4], 'stone||per': [0, 1, 2, 4], 'liberty||ne': [0, 1, 2, 0], 'seanhannity||per': [0, 1, 1, 4], 'tuckercarlson||per': [0, 1, 1, 4], 'foxandfriends||misc': [0, 1, 1, 2], 'prof||ne': [0, 1, 1, 0], 'voldemort||per': [0, 1, 1, 4], 'prof quirell||per': [0, 2, 1, 4], 'harry potter||per': [0, 2, 3, 4], 'instead||ne': [0, 1, 3, 0], 'muslims||misc': [0, 1, 1, 2], 'latinos||misc': [0, 1, 1, 2], 'analogies||ne': [0, 1, 1, 0], 'gives||ne': [0, 1, 4, 0], 'dumb||ne': [0, 1, 2, 0], 'eric||per': [0, 1, 27, 4], 'roll||ne': [0, 1, 3, 0], 'coup||ne': [0, 1, 1, 0], 'left||misc': [0, 1, 4, 2], 'dirty||ne': [0, 1, 4, 0], 'water||ne': [0, 1, 2, 0], 'asked||ne': [0, 1, 1, 0], 'proudlyliberal 2||per': [0, 2, 1, 4], 'lil||ne': [0, 1, 1, 0], 'alfalfa||misc': [0, 1, 1, 2], 'mad||ne': [0, 1, 1, 0], 'russiagate||misc': [0, 1, 1, 2], 'vacation||ne': [0, 1, 2, 0], 'seriously||ne': [0, 1, 1, 0], 'impeachment||misc': [0, 1, 5, 2], 'palmer report||misc': [0, 2, 1, 2], 'ken lay||per': [0, 2, 1, 4], 'yahoo||org': [0, 1, 1, 1], 'cover||ne': [0, 1, 3, 0], 'hiding||ne': [0, 1, 3, 0], 'trumpski||per': [0, 1, 1, 4], 'rachel maddow||per': [0, 2, 7, 4], 'ends||ne': [0, 1, 1, 0], 'fica warrant||misc': [0, 2, 1, 2], 'gazprom||misc': [0, 1, 1, 2], 'maddow||per': [0, 1, 4, 4], 'ellen nakashima||per': [0, 2, 1, 4], 'devlin barrett||per': [0, 2, 1, 4], 'lie||ne': [0, 1, 6, 0], 'actor||ne': [0, 1, 1, 0], 'holy||ne': [0, 1, 3, 0], 'co||ne': [0, 1, 3, 0], 'malcolm nance||per': [0, 2, 1, 4], 'tweet||ne': [0, 1, 10, 0], 'sink||ne': [0, 1, 1, 0], 'rick lowy||per': [0, 2, 1, 4], 'ritchfield corporation||org': [0, 2, 1, 1], 'hunger games||misc': [0, 2, 2, 2], 'microsoft||org': [0, 1, 1, 1], 'claimed||ne': [0, 1, 2, 0], 'gay||per': [0, 1, 1, 4], 'confirms||ne': [0, 1, 4, 0], 'levonmartin||per': [0, 1, 1, 4], 'andymcmahon||per': [0, 1, 1, 4], 'valentina||misc': [0, 1, 1, 2], 'apprentice||misc': [0, 1, 3, 2], 'bret michaels||per': [0, 2, 1, 4], 'clint black||per': [0, 2, 1, 4], 'strelkov||per': [0, 1, 1, 4], 'ukrainian||misc': [0, 1, 2, 2], 'meant||ne': [0, 1, 3, 0], 'navy||ne': [0, 1, 2, 0], 'hmas cerberus||loc': [0, 2, 1, 3], 'hectorlove||per': [0, 1, 2, 4], 'bank||ne': [0, 1, 7, 0], 'veb bank||org': [0, 2, 1, 1], 'kushner||per': [0, 1, 4, 4], 'veb||org': [0, 1, 1, 1], 'eric trump||per': [0, 2, 44, 4], 'roncharles||per': [0, 1, 2, 4], 'nbc||org': [0, 1, 4, 1], 'due||ne': [0, 1, 2, 0], 'seeger||per': [0, 1, 1, 4], 'news observer||org': [0, 2, 1, 1], 'tamatiellison||per': [0, 1, 1, 4], '27khv||per': [0, 1, 1, 4], 'sikorskiradek||per': [0, 1, 1, 4], 'olacicho||per': [0, 1, 1, 4], 'resort||ne': [0, 1, 2, 0], 'scottish||misc': [0, 1, 1, 2], 'gaelic||misc': [0, 1, 1, 2], 'anglo - saxon||misc': [0, 3, 1, 2], 'target||ne': [0, 1, 2, 0], 'british unemployed workers network||org': [0, 4, 1, 1], 'kumi taguchi||per': [0, 2, 1, 4], 'kumitaguchi||per': [0, 1, 1, 4], 'nfl||org': [0, 1, 2, 1], 'uvalde||loc': [0, 1, 1, 3], 'jpgaultier||per': [0, 1, 1, 4], 'shellz_zee||per': [0, 1, 1, 4], 'using||ne': [0, 1, 4, 0], 'ru||misc': [0, 1, 1, 2], 'trumpsters||misc': [0, 1, 1, 2], 'repeal||ne': [0, 1, 1, 0], 'mccain||per': [0, 1, 3, 4], 'aca||misc': [0, 1, 1, 2], 'trump wh||org': [0, 2, 2, 1], 'durham zoo||org': [0, 2, 1, 1], 'malaria||misc': [0, 1, 1, 2], 'bank of america||org': [0, 3, 4, 1], 'brian||per': [0, 1, 1, 4], 'mccain||org': [0, 1, 1, 1], 'north america||loc': [0, 2, 1, 3], 'fsb||org': [0, 1, 2, 1], 'nhjones||per': [0, 1, 2, 4], 'headed||ne': [0, 1, 2, 0], 'pesach||misc': [0, 1, 1, 2], 'guantanamo||loc': [0, 1, 1, 3], 'olga||per': [0, 1, 1, 4], 'keeps||ne': [0, 1, 4, 0], 'piersmorgan||per': [0, 1, 1, 4], 'michelle williams||per': [0, 2, 1, 4], 'heath ledger||per': [0, 2, 1, 4], 'v.putin||per': [0, 1, 2, 4], 'john barron||per': [0, 2, 1, 4], 'speaking||ne': [0, 1, 3, 0], 'nakashimae||per': [0, 1, 1, 4], 'georgedobell||per': [0, 1, 1, 4], 'cena||per': [0, 1, 1, 4], 'ryder||per': [0, 1, 1, 4], 'kane||per': [0, 1, 1, 4], 'wwe||org': [0, 1, 2, 1], 'bbc news||org': [0, 2, 1, 1], 'hong kong||loc': [0, 2, 3, 3], 'mtr||org': [0, 1, 1, 1], 'crossrail||org': [0, 1, 1, 1], 'justice dept||org': [0, 2, 3, 1], 'svr||org': [0, 1, 1, 1], 'malcolm morrison||per': [0, 2, 1, 4], 'financial||ne': [0, 1, 2, 0], 'clapper||per': [0, 1, 2, 4], 'learn||ne': [0, 1, 1, 0], 'bombing||ne': [0, 1, 4, 0], 'david cameron||per': [0, 2, 1, 4], 'isis||org': [0, 1, 4, 1], 'iraq||loc': [0, 1, 3, 3], 'tells||ne': [0, 1, 2, 0], 'pfizer||org': [0, 1, 1, 1], 'astrazeneca||org': [0, 1, 1, 1], 'pascal soriot||per': [0, 2, 1, 4], 'bbcbreaking||org': [0, 1, 1, 1], 'fed||ne': [0, 1, 1, 0], 'fed judge||per': [0, 2, 1, 4], 'support||ne': [0, 1, 6, 0], 'wh easter egg roll||misc': [0, 4, 1, 2], 'friends||ne': [0, 1, 1, 0], 'princess of monaco||per': [0, 3, 1, 4], 'downhills||loc': [0, 1, 1, 3], 'mo white||per': [0, 2, 1, 4], 'kathylette||per': [0, 1, 1, 4], 'iraqi||per': [0, 1, 1, 4], 'prime minister nuri al - maliki||per': [0, 6, 1, 4], 'put||ne': [0, 1, 4, 0], 'dept||ne': [0, 1, 3, 0], 'maggie||per': [0, 1, 1, 4], 'korea||loc': [0, 1, 2, 3], 'mark r . levin||per': [0, 4, 1, 4], 'jews||misc': [0, 1, 1, 2], 'german||misc': [0, 1, 1, 2], 'carney||per': [0, 1, 1, 4], 'ivanka||per': [0, 1, 11, 4], 'fed||org': [0, 1, 1, 1], 'chemical||ne': [0, 1, 5, 0], 'bane||per': [0, 1, 1, 4], 'comments||ne': [0, 1, 4, 0], 'kent brockman||per': [0, 2, 1, 4], 'julia loffe||per': [0, 2, 1, 4], 'sets||ne': [0, 1, 2, 0], 'spacey||per': [0, 1, 1, 4], 'oda mae brown||per': [0, 3, 1, 4], 'definitely||ne': [0, 1, 3, 0], 'suggested||ne': [0, 1, 2, 0], 'croatia||loc': [0, 1, 2, 3], 'united states of west america||loc': [0, 5, 1, 3], 'united states of east america||loc': [0, 5, 1, 3], 'united states of flyover america||loc': [0, 5, 1, 3], 'wv||loc': [0, 1, 1, 3], 'project||ne': [0, 1, 6, 0], 'ces||org': [0, 1, 1, 1], 'project tango||misc': [0, 2, 1, 2], 'lenovo||org': [0, 1, 1, 1], 'rachael||per': [0, 1, 1, 4], 'matt pressberg||per': [0, 2, 1, 4], 'believes||ne': [0, 1, 1, 0], 'trump admin||org': [0, 2, 3, 1], 'san diego||loc': [0, 2, 1, 3], 'richard iii||per': [0, 2, 1, 4], 'roseneft||per': [0, 1, 1, 4], 'rick dearborn||per': [0, 2, 1, 4], 'michael cohen||per': [0, 2, 1, 4], 'low||ne': [0, 1, 2, 0], 'mike dean||per': [0, 2, 1, 4], 'liberty university||org': [0, 2, 1, 1], 'joe jonas||per': [0, 2, 1, 4], 'sophie turner||per': [0, 2, 1, 4], 'masvidal||per': [0, 1, 3, 4], 'whittaker||per': [0, 1, 1, 4], 'donald jr||per': [0, 2, 1, 4], 'launch||ne': [0, 1, 1, 0], 'missles||ne': [0, 1, 1, 0], 'naval academy||org': [0, 2, 1, 1], 'council on foreign relations||org': [0, 4, 1, 1], 'jorge||per': [0, 1, 1, 4], 'jacare souza||per': [0, 2, 1, 4], 'china||loc': [0, 1, 8, 3], 'demand||ne': [0, 1, 5, 0], 'zipcar||org': [0, 1, 1, 1], 'fan||ne': [0, 1, 1, 0], 'waitrose||loc': [0, 1, 1, 3], 'copella||misc': [0, 1, 1, 2], 'toast||ne': [0, 1, 1, 0], 'action||ne': [0, 1, 4, 0], 'linkin park||misc': [0, 2, 1, 2], 'sergey gorkov||per': [0, 2, 1, 4], 'gorkov||per': [0, 1, 1, 4], 'mccarthyites||misc': [0, 1, 1, 2], 'nyt||org': [0, 1, 1, 1], 'butt||ne': [0, 1, 1, 0], 'karen||per': [0, 1, 1, 4], 'justice dep||org': [0, 2, 1, 1], 'lorrcliff||per': [0, 1, 1, 4], 'clifford jr||per': [0, 2, 1, 4], 'lorraine||per': [0, 1, 1, 4], 'buzzfeed||org': [0, 1, 1, 1], 'birdsong||misc': [0, 1, 1, 2], 'isabelle||per': [0, 1, 1, 4], 'stephen||per': [0, 1, 1, 4], 'barrel||ne': [0, 1, 1, 0], 'gerrard||per': [0, 1, 2, 4], 'orlando bloom||per': [0, 2, 2, 4], 'lincoln||org': [0, 1, 1, 1], 'sam smith||per': [0, 2, 1, 4], 'deasy||per': [0, 1, 1, 4], 'lincoln||loc': [0, 1, 1, 3], 'gay||ne': [0, 1, 1, 0], 'kisleak||per': [0, 1, 1, 4], 'deli||misc': [0, 1, 1, 2], 'amirite||ne': [0, 1, 1, 0], 'rachel show||misc': [0, 2, 1, 2], 'ford||per': [0, 1, 1, 4], 'nixon||per': [0, 1, 1, 4], 'wiener||per': [0, 1, 1, 4], 'krystaltweets||per': [0, 1, 1, 4], 'bho||org': [0, 1, 1, 1], 'later||ne': [0, 1, 4, 0], 'kgb||org': [0, 1, 2, 1], 'xstrology||org': [0, 1, 1, 1], 'natmacfarlane||per': [0, 1, 1, 4], 'iran||loc': [0, 1, 2, 3], 'contra||misc': [0, 1, 1, 2], 'cher lloyd||per': [0, 2, 1, 4], 'daniel||per': [0, 1, 2, 4], 'john williams||per': [0, 2, 2, 4], 'trent reznor||per': [0, 2, 2, 4], 'atticus ross||per': [0, 2, 2, 4], 'gwtdt||misc': [0, 1, 2, 2], 'liverpool||misc': [0, 1, 1, 2], 'man utd||misc': [0, 2, 1, 2], 'dorchester||loc': [0, 1, 2, 3], 'danno||per': [0, 1, 1, 4], 'facebook||org': [0, 1, 3, 1], 'rep lueu||per': [0, 2, 1, 4], 'trumpnation||loc': [0, 1, 1, 3], 'leave||ne': [0, 1, 2, 0], 'family||ne': [0, 1, 22, 0], 'royal||ne': [0, 1, 2, 0], 'ebola||misc': [0, 1, 3, 2], 'william pooley||per': [0, 2, 1, 4], 'royal free hospital||loc': [0, 3, 1, 3], 'london||loc': [0, 1, 1, 3], 'respect||ne': [0, 1, 2, 0], 'band||ne': [0, 1, 1, 0], 'jeff session||per': [0, 2, 2, 4], 'attorney general||misc': [0, 2, 1, 2], 'department||ne': [0, 1, 1, 0], 'sierra leone||loc': [0, 2, 1, 3], 'department of health||org': [0, 3, 1, 1], 'aid||ne': [0, 1, 1, 0], 'jacques clouseu comey||per': [0, 3, 1, 4], 'drug||ne': [0, 1, 1, 0], 'will pooley||per': [0, 2, 1, 4], 'zmapp||misc': [0, 1, 1, 2], \"o'reilly||per\": [0, 1, 1, 4], 'imerikapotato||per': [0, 1, 1, 4], 'taylor swift||per': [0, 2, 1, 4], 'chicago tribune||org': [0, 2, 1, 1], 'barry pepper||per': [0, 2, 1, 4], 'kev||per': [0, 1, 1, 4], 'weapons||ne': [0, 1, 1, 0], 'jason mraz||per': [0, 2, 1, 4], 'foreign intelligence surveillance act||misc': [0, 4, 1, 2], 'corey carter||per': [0, 2, 1, 4], 'amazon||org': [0, 1, 1, 1], 'kindle||misc': [0, 1, 1, 2], 'mitt romney||per': [0, 2, 2, 4], 'rick santorum||per': [0, 2, 1, 4], 'iowa||loc': [0, 1, 1, 3], 'ric||per': [0, 1, 1, 4], 'chris||per': [0, 1, 2, 4], 'trump advisor||misc': [0, 2, 1, 2], 'continue||ne': [0, 1, 1, 0], 'gmail||misc': [0, 1, 2, 2], 'mattis||per': [0, 1, 1, 4], 'h . r mcmaster||per': [0, 4, 1, 4], 'nicki haley||per': [0, 2, 1, 4], 'graham||per': [0, 1, 2, 4], 'abigail||per': [0, 1, 1, 4], 'ian||per': [0, 1, 2, 4], 'andywaterman||per': [0, 1, 1, 4], 'louisville||loc': [0, 1, 1, 3], 'rouleurs||misc': [0, 1, 1, 2], 'business||ne': [0, 1, 5, 0], 'bill ayers||per': [0, 2, 1, 4], 'sonia||per': [0, 1, 1, 4], 'ns||org': [0, 1, 1, 1], 'death||ne': [0, 1, 3, 0], 'chaz||per': [0, 1, 2, 4], 'justin||per': [0, 1, 3, 4], 'selena||per': [0, 1, 2, 4], 'zayn||per': [0, 1, 2, 4], 'stella||per': [0, 1, 1, 4], 'natalie||per': [0, 1, 2, 4], 'andrew stone||per': [0, 2, 1, 4], 'x factor||misc': [0, 2, 1, 2], 'jesus||per': [0, 1, 2, 4], 'trump team||misc': [0, 2, 1, 2], 'new york||loc': [0, 2, 1, 3], 'katzs||misc': [0, 1, 1, 2], 'pastrami||misc': [0, 1, 1, 2], 'swiss cheese||misc': [0, 2, 1, 2], 'russian dressing||misc': [0, 2, 1, 2], 'istanbul||loc': [0, 1, 2, 3], 'nation||ne': [0, 1, 2, 0], 'trumpworld||misc': [0, 1, 1, 2], 'ronaldo||per': [0, 1, 1, 4], 'madrid||misc': [0, 1, 1, 2], 'questions||ne': [0, 1, 2, 0], 'jim||per': [0, 1, 1, 4], 'denies||ne': [0, 1, 2, 0], 'busy||ne': [0, 1, 1, 0], 'harry reid||per': [0, 2, 1, 4], 'german jews||misc': [0, 2, 1, 2], 'chris matthews||per': [0, 2, 1, 4], 'rosie||per': [0, 1, 1, 4], 'barcelona||misc': [0, 1, 1, 2], 'deulofeu||per': [0, 1, 1, 4], 'dongou||per': [0, 1, 1, 4], 'grimaldo||per': [0, 1, 1, 4], 'crimea||loc': [0, 1, 1, 3], 'ru||org': [0, 1, 1, 1], 'ricky davila||per': [0, 2, 1, 4], 'members||ne': [0, 1, 1, 0], 'andy carroll||per': [0, 2, 2, 4], 'crystal palace||misc': [0, 2, 2, 2], 'ritchie mcclaw||per': [0, 2, 2, 4], 'jefferson beauregard sessions||per': [0, 3, 1, 4], 'sandy hook||misc': [0, 2, 1, 2], 'gonçalo guedes||per': [0, 2, 1, 4], 'mccabe||per': [0, 1, 2, 4], 'amazon s 3||misc': [0, 3, 1, 2], 'tor||misc': [0, 1, 1, 2], 'tarzan||per': [0, 1, 1, 4], 'cheeta||per': [0, 1, 2, 4], 'united states naval academy||org': [0, 4, 1, 1], 'trumpers||per': [0, 1, 1, 4], 'staffers||ne': [0, 1, 1, 0], 'african leaders summit||misc': [0, 3, 2, 2], 'diego rolan||per': [0, 2, 1, 4], 'psg||misc': [0, 1, 2, 2], 'paul manaford||per': [0, 2, 1, 4], 'ray scollin||per': [0, 2, 1, 4], 'woolsey||per': [0, 1, 1, 4], 'nhs||org': [0, 1, 3, 1], 'whitehall||misc': [0, 1, 2, 2], 'copa||misc': [0, 1, 1, 2], 'messi||per': [0, 1, 1, 4], 'idiots||ne': [0, 1, 2, 0], 'trump jr||per': [0, 2, 1, 4], 'erik||per': [0, 1, 1, 4], 'epub||org': [0, 1, 3, 1], 'blink technologies inc||org': [0, 3, 1, 1], 'kids||ne': [0, 1, 2, 0], 'trumpikins||misc': [0, 1, 1, 2], 'mathews||per': [0, 1, 1, 4], 'market days||org': [0, 2, 1, 1], 'tour de chesapeake||org': [0, 3, 1, 1], 'trumpf||per': [0, 1, 1, 4], 'cpage||per': [0, 1, 1, 4], 'potus||per': [0, 1, 7, 4], 'barca||misc': [0, 1, 2, 2], 'navy||org': [0, 1, 1, 1], 'sent||ne': [0, 1, 2, 0], 'rus||loc': [0, 1, 1, 3], 'girls||ne': [0, 1, 2, 0], 'brooke||per': [0, 1, 1, 4], 'candy girls||misc': [0, 2, 2, 2], 'tussian||misc': [0, 1, 1, 2], 'charge||ne': [0, 1, 1, 0], 'shitting||ne': [0, 1, 1, 0], 'clinton fdn||org': [0, 2, 1, 1], 'wmd||org': [0, 1, 1, 1], 'rafa||per': [0, 1, 1, 4], 'nspcc||org': [0, 1, 1, 1], 'un||org': [0, 1, 2, 1], 'unesco||org': [0, 1, 1, 1], 'prez||ne': [0, 1, 1, 0], 'prez palace||loc': [0, 2, 1, 3], 'italian||misc': [0, 1, 1, 2], 'eamondelaney 10||per': [0, 2, 1, 4], 'steps||ne': [0, 1, 1, 0], 'pres||ne': [0, 1, 1, 0], 'fair||ne': [0, 1, 1, 0], 'dannysaint||per': [0, 1, 2, 4], 'per||ne': [0, 1, 2, 0], 'krokodil||misc': [0, 1, 1, 2], 'marketwatch||org': [0, 1, 1, 1], 'er||ne': [0, 1, 1, 0], 'washington times||org': [0, 2, 2, 1], 'nataliecooper||per': [0, 1, 1, 4], 'daisybruce||per': [0, 1, 1, 4], 'holocaust center||org': [0, 2, 1, 1], 'trump campaign||misc': [0, 2, 4, 2], 'kill||ne': [0, 1, 2, 0], 'gorka||per': [0, 1, 1, 4], 'steve bannon||per': [0, 2, 1, 4], 'jarod kushner||per': [0, 2, 1, 4], 'gary oldman||per': [0, 2, 1, 4], 'gary numan||per': [0, 2, 1, 4], 'peggy carter||per': [0, 2, 1, 4], 'pinkfloyd||misc': [0, 1, 3, 2], 'spotify||org': [0, 1, 1, 1], 'madrid||loc': [0, 1, 1, 3], 'steele dossier||misc': [0, 2, 1, 2], 'centre||ne': [0, 1, 1, 0], 'brighton centre||loc': [0, 2, 1, 3], 'president bannon||per': [0, 2, 1, 4], 'cruise||ne': [0, 1, 1, 0], 'tamerlan||per': [0, 1, 1, 4], 'drump||per': [0, 1, 1, 4], 'fernando torres||per': [0, 2, 1, 4], 'videos||ne': [0, 1, 1, 0], 'kylekulinski||per': [0, 1, 1, 4], 'kelly ann conway||per': [0, 3, 1, 4], 'gestapo||misc': [0, 1, 1, 2], 'wapost||org': [0, 1, 1, 1], 'newsmax||org': [0, 1, 1, 1], 'ambassador||ne': [0, 1, 1, 0], 'dnc||org': [0, 1, 2, 1], 'obama administration||org': [0, 2, 1, 1], 'hill||org': [0, 1, 1, 1], 'tweeted||ne': [0, 1, 1, 0], 'malcolmcoles||per': [0, 1, 1, 4], 'neave||per': [0, 1, 1, 4], 'takes||ne': [0, 1, 2, 0], 'sopa||misc': [0, 1, 1, 2], 'woman||ne': [0, 1, 2, 0], 'symantec||org': [0, 1, 1, 1], 'pcanywhere||misc': [0, 1, 1, 2], 'guys||ne': [0, 1, 3, 0], 'hackneycouncil labour||org': [0, 2, 1, 1], 'ken||per': [0, 1, 1, 4], 'exxon||org': [0, 1, 2, 1], 'nevada||loc': [0, 1, 1, 3], 'bt infinity homehub||misc': [0, 3, 1, 2], 'sid||per': [0, 1, 1, 4], 'john mayer||per': [0, 2, 1, 4], 'charles simmons daily||org': [0, 3, 1, 1], 'tinkle||misc': [0, 1, 1, 2], 'potus trump||per': [0, 2, 2, 4], 'pt citilink indonesia||org': [0, 3, 1, 1], 'citilink||org': [0, 1, 1, 1], 'trump org||org': [0, 2, 2, 1], 'shanghai||loc': [0, 1, 2, 3], 'beijing||loc': [0, 1, 2, 3], 'nra||org': [0, 1, 2, 1], 'philippines||loc': [0, 1, 4, 3], 'manila||loc': [0, 1, 2, 3], 'socks||ne': [0, 1, 5, 0], 'don jr||per': [0, 2, 6, 4], \"joey ' no socks ' cinque||per\": [0, 6, 3, 4], 'tsar-a-lago||loc': [0, 1, 4, 3], 'briankoppelman||per': [0, 1, 1, 4], 'jaketapper||per': [0, 1, 2, 4], 'jak||per': [0, 1, 1, 4], 'river rom||misc': [0, 2, 2, 2], 'river beam||misc': [0, 2, 2, 2], 'essex||loc': [0, 1, 2, 3], 'donnie||per': [0, 1, 2, 4], 'umple||loc': [0, 1, 1, 3], 'daily audio bible program||misc': [0, 4, 1, 2], 'latin america||loc': [0, 2, 1, 3], 'big mac||misc': [0, 2, 1, 2], 'mcdonalds||org': [0, 1, 1, 1], 'lawrence 23||per': [0, 2, 1, 4], 'north dakota||loc': [0, 2, 2, 3], 'nj||loc': [0, 1, 1, 3], 'pa||loc': [0, 1, 1, 3], 'mi||loc': [0, 1, 1, 3], 'la||loc': [0, 1, 1, 3], 'wa||loc': [0, 1, 1, 3], 'ca||loc': [0, 1, 1, 3], 'ma||loc': [0, 1, 1, 3], 'fl||loc': [0, 1, 1, 3], 'il||loc': [0, 1, 1, 3], 'tiffany||per': [0, 1, 1, 4], 'epshteyn||per': [0, 1, 1, 4], 'vodka||misc': [0, 1, 2, 2], 'caviar||misc': [0, 1, 1, 2], 'us government||org': [0, 2, 1, 1], 'wendyquent||per': [0, 1, 1, 4], 'strikes||ne': [0, 1, 3, 0], 'chavismo||per': [0, 1, 1, 4], 'mommy||ne': [0, 1, 1, 0], 'easter bunny||misc': [0, 2, 1, 2], 'village||ne': [0, 1, 1, 0], 'malaysia airlines||org': [0, 2, 5, 1], 'mas||org': [0, 1, 3, 1], 'north carolina state capitol||loc': [0, 4, 1, 3], 'zdnet||org': [0, 1, 1, 1], 'samsung galaxy||misc': [0, 2, 1, 2], 'dutch court||org': [0, 2, 1, 1], 'zackwhittaker||per': [0, 1, 1, 4], 'congressional||misc': [0, 1, 1, 2], 'jessicalowndes||per': [0, 1, 1, 4], 'sally hemings||per': [0, 2, 1, 4], 'chanel||org': [0, 1, 1, 1], 'cannes||org': [0, 1, 1, 1], 'state farm||org': [0, 2, 1, 1], 'base||ne': [0, 1, 3, 0], 'father||ne': [0, 1, 14, 0], 'controls||ne': [0, 1, 1, 0], 'malaysian airlines||org': [0, 2, 4, 1], 'scott||per': [0, 1, 2, 4], 'fault||ne': [0, 1, 1, 0], 'bhaschat||per': [0, 1, 1, 4], 'reuters||org': [0, 1, 1, 1], 'kingdom||ne': [0, 1, 1, 0], 'blaming||ne': [0, 1, 1, 0], 'incident||ne': [0, 1, 1, 0], 'tho||ne': [0, 1, 1, 0], 'celtics||misc': [0, 1, 2, 2], 'assad||per': [0, 1, 7, 4], 'turkey||loc': [0, 1, 1, 3], \"joey ' mo socks ' cinque||per\": [0, 6, 1, 4], 'complete||ne': [0, 1, 1, 0], 'scene||ne': [0, 1, 1, 0], 'cheeto||misc': [0, 1, 1, 2], 'teflon don 2||per': [0, 3, 1, 4], 'intelligence briefing||misc': [0, 2, 1, 2], 'state dept||org': [0, 2, 2, 1], 'nepotism||ne': [0, 1, 4, 0], 'west||loc': [0, 1, 1, 3], 'trump family||misc': [0, 2, 1, 2], 'mini||ne': [0, 1, 1, 0], 'palestine||loc': [0, 1, 2, 3], 'malaysia||loc': [0, 1, 1, 3], 'boston marathon||misc': [0, 2, 2, 2], 'russian military||org': [0, 2, 1, 1], 'english||misc': [0, 1, 1, 2], 'beavis||per': [0, 1, 3, 4], 'proven||ne': [0, 1, 1, 0], 'therickwilson||per': [0, 1, 1, 4], 'busted||ne': [0, 1, 1, 0], 'rico||misc': [0, 1, 2, 2], 'rayelle 73||per': [0, 2, 1, 4], 'merrick garland||per': [0, 2, 1, 4], 'president carter||per': [0, 2, 1, 4], 'bert lance||per': [0, 2, 1, 4], 'georgia||loc': [0, 1, 1, 3], 'kremlin||loc': [0, 1, 1, 3], 'bowie||per': [0, 1, 1, 4], 'space oddity||misc': [0, 2, 1, 2], 'turns||ne': [0, 1, 2, 0], 'ny board of elections||org': [0, 4, 1, 1], 'donnie jr||per': [0, 2, 1, 4], 'mayor of nyc||per': [0, 3, 1, 4], 'pooty||per': [0, 1, 2, 4], 'seen||ne': [0, 1, 1, 0], 'pamela anderson||per': [0, 2, 1, 4], 'assange||per': [0, 1, 1, 4], 'jakarta chemical attack||misc': [0, 3, 1, 2], 'dog||ne': [0, 1, 3, 0], 'daddy||ne': [0, 1, 4, 0], 'grizzly||ne': [0, 1, 1, 0], 'wwiii||misc': [0, 1, 2, 2], 'ivanks||per': [0, 1, 1, 4], 'committed||ne': [0, 1, 1, 0], 'ag||misc': [0, 1, 1, 2], 'turkey||misc': [0, 1, 1, 2], 'easter egg roll||misc': [0, 3, 3, 2], 'russian pysanky||misc': [0, 2, 1, 2], 'nuclear war||misc': [0, 2, 1, 2], 'dot||ne': [0, 1, 1, 0], 'cult||ne': [0, 1, 1, 0], 'panama||loc': [0, 1, 2, 3], 'canadian||misc': [0, 1, 2, 2], 'self||ne': [0, 1, 1, 0], 'george hamilton||per': [0, 2, 1, 4], 'jesu kristi||per': [0, 2, 1, 4], 'n . korea||loc': [0, 3, 1, 3], 'driving||ne': [0, 1, 1, 0], 'cadillac||misc': [0, 1, 1, 2], 'wilbur ross||per': [0, 2, 1, 4], 'peloponnesian||misc': [0, 1, 1, 2], 'sql||misc': [0, 1, 3, 2], 'staged||ne': [0, 1, 1, 0], 'mandalorian||misc': [0, 1, 1, 2], 'mandalorians||misc': [0, 1, 1, 2], 'defalt||per': [0, 1, 1, 4], 'op||per': [0, 1, 1, 4], 'vpn||misc': [0, 1, 1, 2], 'omb||org': [0, 1, 1, 1], 'mick mulvaney||per': [0, 2, 1, 4], 'social security||misc': [0, 2, 1, 2], 'medicare||misc': [0, 1, 1, 2], 'wsj||org': [0, 1, 1, 1], 'bernie||per': [0, 1, 2, 4], \"gov't||ne\": [0, 1, 1, 0], 'airport||ne': [0, 1, 1, 0], 'sec . of state||per': [0, 4, 1, 4], 'trumpino||per': [0, 1, 1, 4], 'lies||ne': [0, 1, 2, 0], 'don the con block||per': [0, 4, 1, 4], 'x-files||misc': [0, 1, 3, 2], 'schumer||per': [0, 1, 1, 4], 'nk||loc': [0, 1, 3, 3], 'komrade kushners||misc': [0, 2, 1, 2], 'gitmo||loc': [0, 1, 1, 3], 'president trump||per': [0, 2, 2, 4], 'haley||per': [0, 1, 2, 4], 'twins||misc': [0, 1, 1, 2], 'vikings||misc': [0, 1, 2, 2], 'sql event log||misc': [0, 3, 1, 2], 'use||ne': [0, 1, 1, 0], 'windows hello||misc': [0, 2, 1, 2], 'sql 10||misc': [0, 2, 1, 2], 'liberals||misc': [0, 1, 2, 2], 'mafia||misc': [0, 1, 1, 2], 'ivanka trump||per': [0, 2, 1, 4], 'einar selvik||misc': [0, 2, 1, 2], 'kiss||misc': [0, 1, 1, 2], 'rubio||per': [0, 1, 2, 4], 'buchenwald||loc': [0, 1, 2, 3], 'dora||loc': [0, 1, 1, 3], 'missile||ne': [0, 1, 2, 0], 'israeli||loc': [0, 1, 1, 3], 'golan heights||loc': [0, 2, 1, 3], 'human||ne': [0, 1, 3, 0], 'vic dept of human services||org': [0, 5, 1, 1], 'victoriapolice||org': [0, 1, 1, 1], 'rosie batty||per': [0, 2, 1, 4], 'simolove||per': [0, 1, 1, 4], 'inauguration||ne': [0, 1, 1, 0], 'indonesia parliament||org': [0, 2, 1, 1], 'joko widodo||per': [0, 2, 1, 4], 'govt assurance committee||org': [0, 3, 2, 1], 'ghanaparliament||org': [0, 1, 2, 1], 'starghana||org': [0, 1, 1, 1], 'kinnareads||org': [0, 1, 1, 1], 'bbcworld||org': [0, 1, 1, 1], 'herr trump||per': [0, 2, 1, 4], 'relations||ne': [0, 1, 1, 0], 'duterte||per': [0, 1, 2, 4], 'debate||ne': [0, 1, 1, 0], 'house judiciary committee||org': [0, 3, 1, 1], 'colbert report||misc': [0, 2, 1, 2], 'wi||loc': [0, 1, 1, 3], 'kabuki theater||misc': [0, 2, 1, 2], 'seattle||loc': [0, 1, 2, 3], 'nimby||misc': [0, 1, 1, 2], 'mar a lago||loc': [0, 3, 1, 3], 'isil||org': [0, 1, 3, 1], 'beautiful||ne': [0, 1, 2, 0], 'ks||loc': [0, 1, 1, 3], 'conference||ne': [0, 1, 1, 0], 'omar sharif||per': [0, 2, 1, 4], 'omar||per': [0, 1, 1, 4], 'estes||org': [0, 1, 1, 1], 'trump hotel collection||misc': [0, 3, 2, 2], 'doomed||ne': [0, 1, 2, 0], 'golf||misc': [0, 1, 2, 2], 'direction||ne': [0, 1, 1, 0], 'canada||loc': [0, 1, 3, 3], 'airbase||ne': [0, 1, 1, 0], 'presidents||ne': [0, 1, 2, 0], 'telegraph||org': [0, 1, 1, 1], 'foundation||ne': [0, 1, 4, 0], 'eric trump foundation||org': [0, 3, 2, 1], 'bevis||per': [0, 1, 1, 4], 'fredo||per': [0, 1, 1, 4], 'remarks||ne': [0, 1, 1, 0], 'giuliani||per': [0, 1, 1, 4], 'dad||ne': [0, 1, 1, 0], 'vern||per': [0, 1, 1, 4], 'muslim||misc': [0, 1, 2, 2], 'eric \" qusay \" trump||per': [0, 5, 1, 4], 'california||loc': [0, 1, 1, 3], 'jamali||per': [0, 1, 1, 4], 'marmel||per': [0, 1, 2, 4], 'karma||ne': [0, 1, 1, 0], 'mr . booker||per': [0, 3, 1, 4], 'washington||per': [0, 1, 3, 4], 'scott dworkin||per': [0, 2, 2, 4], 'lacedaemon||misc': [0, 1, 1, 2], 'tie||ne': [0, 1, 3, 0], 'uncle||ne': [0, 1, 1, 0], 'uncle puttie||per': [0, 2, 1, 4], 'fallout||ne': [0, 1, 1, 0], 'japan||loc': [0, 1, 1, 3], 'pacific||loc': [0, 1, 1, 3], 'west coast||loc': [0, 2, 1, 3], 'trick||ne': [0, 1, 1, 0], 'tax march||misc': [0, 2, 1, 2], 'allies||ne': [0, 1, 1, 0], 'comrade trump||per': [0, 2, 1, 4], 'rump||per': [0, 1, 1, 4], 'john mellencamp||per': [0, 2, 1, 4], 'daughter||ne': [0, 1, 1, 0], 'chaffetz||per': [0, 1, 1, 4], 'james barraford daily||org': [0, 3, 1, 1], 'ecoterror||misc': [0, 1, 1, 2], 'snl||misc': [0, 1, 2, 2], 'south park||misc': [0, 2, 1, 2], 'neocons||misc': [0, 1, 1, 2], 'message||ne': [0, 1, 2, 0], 'talks||ne': [0, 1, 2, 0], 'threaten||ne': [0, 1, 1, 0], 'falling||ne': [0, 1, 1, 0], 'train||ne': [0, 1, 1, 0], 'trumplethinskins||per': [0, 1, 1, 4], 'scary||ne': [0, 1, 1, 0], 'syrian chemical attack||misc': [0, 3, 1, 2], 'jfk||per': [0, 1, 1, 4], 'ahca||org': [0, 1, 1, 1], 'nh||loc': [0, 1, 1, 3], 'stefanmolyneux||per': [0, 1, 1, 4], 'realdonaldtrump||per': [0, 1, 1, 4], 'donaldjtrumpjr||per': [0, 1, 1, 4], 'secretary potemkin||per': [0, 2, 1, 4], 'yoshkumar||per': [0, 1, 1, 4], 'esports||misc': [0, 1, 1, 2], 'jab||ne': [0, 1, 1, 0], 'star tribune||org': [0, 2, 1, 1], 'evil||ne': [0, 1, 2, 0], 'syrian airstrike||misc': [0, 2, 1, 2], 'ahead||ne': [0, 1, 2, 0], 'reversal||ne': [0, 1, 1, 0], 'trump towers||loc': [0, 2, 1, 3], 'bout||ne': [0, 1, 1, 0], 'freedom of information act||misc': [0, 4, 1, 2], 'decisions||ne': [0, 1, 1, 0], 'vampire||ne': [0, 1, 1, 0], 'stock||ne': [0, 1, 1, 0], 'children||ne': [0, 1, 5, 0], 'soho||loc': [0, 1, 1, 3], 'son||ne': [0, 1, 1, 0], 'uruguay||loc': [0, 1, 1, 3], 'election day||misc': [0, 2, 1, 2], 'completely||ne': [0, 1, 1, 0], 'trumpy||per': [0, 1, 1, 4], 'us election||misc': [0, 2, 1, 2], 'erik prince||per': [0, 2, 2, 4], 'betsy devos||per': [0, 2, 2, 4], 'correction||ne': [0, 1, 1, 0], 'ulrike beudgen daily||org': [0, 3, 1, 1], 'golfing||ne': [0, 1, 1, 0], 'lord||ne': [0, 1, 1, 0], 'jeffrey lord||per': [0, 2, 1, 4], 'kim jong un||per': [0, 3, 1, 4], 'feather||ne': [0, 1, 1, 0], 'adolph trump||per': [0, 2, 1, 4], 'americas||loc': [0, 1, 1, 3], 'hillsboro||loc': [0, 1, 1, 3], 'minister||ne': [0, 1, 1, 0], 'brothers||ne': [0, 1, 1, 0], 'menendez||per': [0, 1, 1, 4], 'gao||org': [0, 1, 2, 1], 'shawn||per': [0, 1, 1, 4], 'jackie||per': [0, 1, 1, 4], 'blackwater||org': [0, 1, 1, 1], 'seychelles||loc': [0, 1, 1, 3], 'gulf of tonkin||loc': [0, 3, 1, 3], 'statements||ne': [0, 1, 2, 0], 'candidate||ne': [0, 1, 1, 0], 'democrat||misc': [0, 1, 1, 2], 'planes||ne': [0, 1, 1, 0], 'dictators||ne': [0, 1, 1, 0], 'rise||ne': [0, 1, 1, 0], 'anti||ne': [0, 1, 1, 0], 'jewish||misc': [0, 1, 1, 2], 'spectrum||org': [0, 1, 1, 1], 'cowtown||loc': [0, 1, 1, 3], 'empire||ne': [0, 1, 1, 0], 'aaron burr||per': [0, 2, 1, 4], 'christ||per': [0, 1, 1, 4], 'obamacare||misc': [0, 1, 2, 2], 'mexico||loc': [0, 1, 2, 3], 'don the con||per': [0, 3, 1, 4], 'asian||misc': [0, 1, 1, 2], 'feels||ne': [0, 1, 1, 0], 'squirrel||misc': [0, 1, 1, 2], 'killed||ne': [0, 1, 4, 0], 'russian easter||misc': [0, 2, 1, 2], 'ceo||misc': [0, 1, 1, 2], 'eo||org': [0, 1, 2, 1], 'dow||org': [0, 1, 1, 1], 'board||ne': [0, 1, 1, 0], 'gif||ne': [0, 1, 1, 0], 'ww3||misc': [0, 1, 1, 2], 'pay||ne': [0, 1, 1, 0], 'skippy||per': [0, 1, 1, 4], 'medvedev||per': [0, 1, 1, 4], 'lavrov||per': [0, 1, 1, 4], 'hamilton||per': [0, 1, 2, 4], 'airfield||ne': [0, 1, 1, 0], 'scaramucci||per': [0, 1, 1, 4], 'alexander hamilton||per': [0, 2, 1, 4], 'marketing||ne': [0, 1, 1, 0], 'quinn cummings||per': [0, 2, 2, 4], 'quinncy||per': [0, 1, 2, 4], 'amaliada||per': [0, 1, 1, 4], 'dremmelqueen||per': [0, 1, 1, 4], 'patton||per': [0, 1, 1, 4], 'bashar-al assad||per': [0, 2, 1, 4], 'russian rogues gallery||org': [0, 3, 1, 1], 'amb kislyak||per': [0, 2, 1, 4], 'syracusans||misc': [0, 1, 1, 2], 'plan||ne': [0, 1, 3, 0], 'constitution||misc': [0, 1, 2, 2], 'trumpcare||misc': [0, 1, 1, 2], 'nsc||org': [0, 1, 1, 1], 'peace agreement||misc': [0, 2, 1, 2], 'throwing||ne': [0, 1, 1, 0], 'universal healthcare||misc': [0, 2, 2, 2], 'montenegro||loc': [0, 1, 2, 3], 'nato||org': [0, 1, 1, 1], 'geppetto||per': [0, 1, 1, 4], 'haiti||loc': [0, 1, 1, 3], 'honduras||loc': [0, 1, 1, 3], 'afghanistan||loc': [0, 1, 1, 3], 'yemen||loc': [0, 1, 1, 3], 'wont||ne': [0, 1, 2, 0], 'feed||ne': [0, 1, 1, 0], 'bernie sanders||per': [0, 2, 1, 4], 's koreans||misc': [0, 2, 1, 2], 'suffering||ne': [0, 1, 1, 0], 'maduro||per': [0, 1, 1, 4], 'venezuelan||misc': [0, 1, 1, 2], 'rex||per': [0, 1, 1, 4], 'everyday||ne': [0, 1, 1, 0], 'mr trump||per': [0, 2, 1, 4], 'lawn||ne': [0, 1, 1, 0], 'kansas dems||misc': [0, 2, 1, 2], 'gotv||org': [0, 1, 1, 1], 'ks04||misc': [0, 1, 1, 2], 'blue lives matter||misc': [0, 3, 1, 2], 'russian op||org': [0, 2, 1, 1], 'maga||org': [0, 1, 1, 1], 'syria strike||misc': [0, 2, 1, 2], 'secretary tillerson||per': [0, 2, 1, 4], 'fm lavrov||per': [0, 2, 1, 4], 'bitcoin||org': [0, 1, 2, 1], 'planet||ne': [0, 1, 1, 0], 'yates||per': [0, 1, 1, 4], 'los angeles times||org': [0, 3, 1, 1], 'innocent||ne': [0, 1, 1, 0], 'luck||ne': [0, 1, 1, 0], 'statement||ne': [0, 1, 2, 0], 'govt accountability office||org': [0, 3, 1, 1], 'u . s . a||loc': [0, 5, 1, 3], 'balkans||loc': [0, 1, 1, 3], 'wh bj||loc': [0, 2, 1, 3], 'reach||ne': [0, 1, 1, 0], 'trump transition team||org': [0, 3, 1, 1], 'fort lee||loc': [0, 2, 1, 3], 'repeat||ne': [0, 1, 1, 0], 'chance||ne': [0, 1, 1, 0], 'rump||ne': [0, 1, 1, 0], 'satan||misc': [0, 1, 1, 2], 'chinese||misc': [0, 1, 1, 2], 'melania||per': [0, 1, 1, 4], 'east coast||loc': [0, 2, 1, 3], 'kardashians||per': [0, 1, 1, 4], 'pepsi||misc': [0, 1, 1, 2], 'skittles||misc': [0, 1, 1, 2], 'wld||ne': [0, 1, 1, 0], 'teapainusa||org': [0, 1, 1, 1], 'organization||ne': [0, 1, 1, 0], 'usay||per': [0, 1, 1, 4], 'qusay trump||per': [0, 2, 1, 4], 'trump organization||org': [0, 2, 1, 1], 'trump ent||org': [0, 2, 1, 1], 'sea||ne': [0, 1, 1, 0], 'kaspersky||per': [0, 1, 1, 4], 'presidential tax transparency act||misc': [0, 4, 1, 2], 'kmiz||org': [0, 1, 2, 1], 'president||per': [0, 1, 1, 4], 'ca republicans||misc': [0, 2, 1, 2], 'nerve||ne': [0, 1, 1, 0], 'rexypoo||per': [0, 1, 1, 4], 'ru||loc': [0, 1, 1, 3], 'mar-a-lago||loc': [0, 1, 1, 3], 'charter||ne': [0, 1, 1, 0], 'romania||loc': [0, 1, 1, 3], 'serbia||loc': [0, 1, 1, 3], 'sweden||loc': [0, 1, 1, 3], 'switzerland||loc': [0, 1, 1, 3], 'bahamas||loc': [0, 1, 1, 3], 'costarica||loc': [0, 1, 1, 3], 'universal health care||misc': [0, 3, 1, 2], 'faces||ne': [0, 1, 1, 0], 'drpeterthraft||per': [0, 1, 2, 4], 'potterwatch||org': [0, 1, 1, 1], 'ursula le guin||per': [0, 3, 2, 4], 'dispossessed||misc': [0, 1, 2, 2], 'narsingh||per': [0, 1, 1, 4], 'tomi lahren||per': [0, 2, 1, 4], 'jamesakanoah||per': [0, 1, 1, 4], 'gingrich||per': [0, 1, 1, 4], 'romney||per': [0, 1, 1, 4], 'hulk hogan||per': [0, 2, 1, 4], 'hulk||per': [0, 1, 2, 4], 'rent-a-center||org': [0, 1, 1, 1], 'downfall||ne': [0, 1, 1, 0], 'fix||ne': [0, 1, 1, 0], 'vox||org': [0, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "print(candidateBase_dict_alt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37h_Y1iM1NJm"
      },
      "outputs": [],
      "source": [
        "# #softknn TUPLET MINING\n",
        "# printonce=0\n",
        "# candidate_index_dict = {}\n",
        "# index_candidate_dict = {}\n",
        "\n",
        "# for ind, elem in enumerate(list(candidate_embedding_dict.keys())):\n",
        "#     candidate_index_dict[elem] = ind\n",
        "#     index_candidate_dict[ind] = elem\n",
        "\n",
        "# datalist=[] #schema: anchor, positive, n-negatives\n",
        "# for candidate_tup in candidate_embedding_dict.keys():\n",
        "#     if(len(candidate_embedding_dict[candidate_tup])>1):\n",
        "#         candidate, candidate_type = candidate_tup[0], candidate_tup[1]\n",
        "#         mention_embeddings_list = candidate_embedding_dict[candidate_tup]\n",
        "#         if(len(mention_embeddings_list)>300):\n",
        "#             mention_index_random = random.sample(list(range(len(mention_embeddings_list))), 300)\n",
        "#         else:\n",
        "#             mention_index_random = list(range(len(mention_embeddings_list)))\n",
        "        \n",
        "#         for ind in range(len(mention_embeddings_list)):\n",
        "#             negative_candidates_list=[]\n",
        "#             for entity_type in entity_types_dict:\n",
        "#                 if(candidate_type!=entity_type):\n",
        "#                     if(candidate in type_candidate_dict[entity_type]):\n",
        "#                         print('=>',candidate,candidate_type,entity_type)\n",
        "#                         neg_candidate_tup = (candidate,entity_type)\n",
        "#                     else:\n",
        "#                         negative_candidate = random.choice(list(type_candidate_dict[entity_type]))\n",
        "#                         neg_candidate_tup = (negative_candidate,entity_type)\n",
        "#                     negative_candidates_list.append(candidate_index_dict[neg_candidate_tup])\n",
        "#             tuplet = tuple([ind,candidate_index_dict[candidate_tup]]+negative_candidates_list)\n",
        "#             if(printonce<1):\n",
        "#                 print(tuplet)\n",
        "#                 printonce+=1\n",
        "#             datalist.append(tuplet)\n",
        "# print('dataset length is ',len(datalist))\n",
        "# shuffle(datalist)\n",
        "# print('dataset length is ',len(datalist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlDQucSgULYi"
      },
      "outputs": [],
      "source": [
        "# #N+1 TUPLET MINING\n",
        "# datalist=[] #schema: anchor, positive, n-negatives\n",
        "# for candidate_tup in candidate_embedding_dict.keys():\n",
        "#     if(len(candidate_embedding_dict[candidate_tup])>1):\n",
        "#         candidate, candidate_type = candidate_tup[0], candidate_tup[1]\n",
        "#         mention_embeddings_list = candidate_embedding_dict[candidate_tup]\n",
        "#         if(len(mention_embeddings_list)>300):\n",
        "#             mention_embeddings_list_random = random.sample(mention_embeddings_list, 300)\n",
        "#         else:\n",
        "#             mention_embeddings_list_random = mention_embeddings_list\n",
        "\n",
        "#         tuplets_size = 1\n",
        "#         negatives_arr = []\n",
        "#         for entity_type in entity_types_dict:\n",
        "#             if(candidate_type!=entity_type):\n",
        "#                 if(candidate in type_candidate_dict[entity_type]):\n",
        "#                     print('=>',candidate,candidate_type,entity_type)\n",
        "#                     neg_candidate_tup = (candidate,entity_type)\n",
        "#                 else:\n",
        "#                     negative_candidate = random.choice(list(type_candidate_dict[entity_type]))\n",
        "#                     neg_candidate_tup = (negative_candidate,entity_type)\n",
        "#                 negative_embedding_list = candidate_embedding_dict[neg_candidate_tup]\n",
        "\n",
        "#                 if(len(negative_embedding_list)>350):\n",
        "#                     negative_embedding_list_random = random.sample(negative_embedding_list, 350)\n",
        "#                 else:\n",
        "#                     negative_embedding_list_random = negative_embedding_list\n",
        "#                 tuplets_size *= len(negative_embedding_list_random)\n",
        "#                 negatives_arr.append(negative_embedding_list_random)\n",
        "        \n",
        "#         limit = min(500,tuplets_size)\n",
        "#         negatives_list = []\n",
        "#         while(limit>0):\n",
        "#             inner=[]\n",
        "#             for i in range(4):\n",
        "#                 inner.append(random.choice(negatives_arr[i]))\n",
        "#             negatives_list.append(inner)\n",
        "#             limit-=1\n",
        "\n",
        "#         for ind1, elem in enumerate(mention_embeddings_list_random):\n",
        "#             for ind2, elem in enumerate(mention_embeddings_list_random):\n",
        "#                 if(ind1!=ind2):\n",
        "#                     for neg_tuplet in negatives_list:\n",
        "#                         tuplet = tuple([mention_embeddings_list_random[ind1],mention_embeddings_list_random[ind2]]+ neg_tuplet)\n",
        "#                         datalist.append(tuplet)\n",
        "\n",
        "# print('dataset length is ',len(datalist))\n",
        "# shuffle(datalist)\n",
        "# print('dataset length is ',len(datalist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UormWm1mbmf",
        "outputId": "bd9eb367-497e-454a-aaa3-797310b5ccd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> us loc ne\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> dems misc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> white house loc org\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> us ne loc\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> wh loc org\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> pepsi org misc\n",
            "=> ahca misc org\n",
            "=> ahca misc org\n",
            "=> left ne misc\n",
            "=> left ne misc\n",
            "=> left ne misc\n",
            "=> left ne misc\n",
            "=> left ne misc\n",
            "=> left ne misc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> wh org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> white house org loc\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> washington loc per\n",
            "=> left misc ne\n",
            "=> left misc ne\n",
            "=> left misc ne\n",
            "=> left misc ne\n",
            "=> left misc ne\n",
            "=> left misc ne\n",
            "=> left misc ne\n",
            "=> left misc ne\n",
            "=> left misc ne\n",
            "=> left misc ne\n",
            "=> left misc ne\n",
            "=> left misc ne\n",
            "=> navy ne org\n",
            "=> navy ne org\n",
            "=> mccain per org\n",
            "=> mccain per org\n",
            "=> mccain per org\n",
            "=> mccain per org\n",
            "=> mccain per org\n",
            "=> mccain per org\n",
            "=> washington per loc\n",
            "=> washington per loc\n",
            "=> washington per loc\n",
            "=> washington per loc\n",
            "=> washington per loc\n",
            "=> washington per loc\n",
            "dataset length is  14632373\n",
            "dataset length is  14632373\n"
          ]
        }
      ],
      "source": [
        "#TRIPLET MINING\n",
        "\n",
        "datalist=[] #schema: anchor, positive, negative\n",
        "for candidate_tup in candidate_embedding_dict.keys():\n",
        "    if(len(candidate_embedding_dict[candidate_tup])>1):\n",
        "        candidate, candidate_type = candidate_tup[0], candidate_tup[1]\n",
        "        mention_embeddings_list = candidate_embedding_dict[candidate_tup]\n",
        "        if(len(mention_embeddings_list)>350):\n",
        "            mention_embeddings_list_random = random.sample(mention_embeddings_list, 350)\n",
        "        else:\n",
        "            mention_embeddings_list_random = mention_embeddings_list\n",
        "        \n",
        "        for ind1, elem in enumerate(mention_embeddings_list_random):\n",
        "            for ind2, elem in enumerate(mention_embeddings_list_random):\n",
        "                if(ind1!=ind2):\n",
        "                    for entity_type in entity_types_dict:\n",
        "                        if(candidate_type!=entity_type):\n",
        "                            if(candidate in type_candidate_dict[entity_type]):\n",
        "                                print('=>',candidate,candidate_type,entity_type)\n",
        "                                neg_candidate_tup = (candidate,entity_type)\n",
        "                            else:\n",
        "                                negative_candidate = random.choice(list(type_candidate_dict[entity_type]))\n",
        "                                neg_candidate_tup = (negative_candidate,entity_type)\n",
        "                            negative_embedding_list = candidate_embedding_dict[neg_candidate_tup]\n",
        "\n",
        "                            if(len(negative_embedding_list)>350):\n",
        "                                # negative_embedding_list_random = random.shuffle(negative_embedding_list)\n",
        "                                negative_embedding_list_random = random.sample(negative_embedding_list, 350)\n",
        "                            else:\n",
        "                                negative_embedding_list_random = negative_embedding_list\n",
        "                            \n",
        "                            #For triplets\n",
        "                            interlist = [(mention_embeddings_list_random[ind1],mention_embeddings_list_random[ind2],negative_elem) for negative_elem in negative_embedding_list_random]\n",
        "                            datalist.extend(interlist)\n",
        "print('dataset length is ',len(datalist))\n",
        "shuffle(datalist)\n",
        "print('dataset length is ',len(datalist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTlGFN2zUgsh"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "learning_rate = 0.001 #0.001\n",
        "num_epochs = 50\n",
        "patience = 8\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqSqRAJo3Um-"
      },
      "outputs": [],
      "source": [
        "class PhraseEmbeddingDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, input):\n",
        "\n",
        "        self.input = input\n",
        "        #input schema is a triplet of anchor|positive|negative examples\n",
        "        print(type(self.input))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = self.input[idx]\n",
        "        # y = self.output[idx]\n",
        "        # return X,y\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3X828UaLfTq",
        "outputId": "78382fc5-8848-44fb-c10a-13e7e8356b84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "Training set: 10974279\n",
            "Validation set: 3658094\n"
          ]
        }
      ],
      "source": [
        "full_dataset = PhraseEmbeddingDataset(datalist)\n",
        "train_size = int(0.75 * len(full_dataset))\n",
        "validation_size = len(full_dataset) - train_size\n",
        "print('Training set:', train_size)\n",
        "print('Validation set:', validation_size)\n",
        "\n",
        "# print(type(training_set))\n",
        "val_batch=int(validation_size/11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TA9vkk_ewmdW"
      },
      "outputs": [],
      "source": [
        "training_set, validation_set = torch.utils.data.random_split(full_dataset, [train_size, validation_size])\n",
        "\n",
        "training_generator = torch.utils.data.DataLoader(training_set, batch_size=2048, shuffle=False)# 512 for soft-knn and 2048 for triplet\n",
        "validation_generator = torch.utils.data.DataLoader(validation_set, batch_size=val_batch, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7JYfopWPAOP"
      },
      "outputs": [],
      "source": [
        "def save_ckp(state, is_best, checkpoint_dir):\n",
        "    # f_path = checkpoint_dir + '/checkpoint.pt' \n",
        "    f_path = checkpoint_dir + '/checkpoint_model300.pt'\n",
        "    # f_path = checkpoint_dir + '/checkpoint_model300_softknn.pt'\n",
        "    torch.save(state, f_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3vb4DntcFbQ",
        "outputId": "2003dfcd-9cc9-4823-f4c3-d937c874f5e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768 300\n"
          ]
        }
      ],
      "source": [
        "# # soft knn\n",
        "# candidate_tup = index_candidate_dict[datalist[1430][1]]\n",
        "# embeddingSize = list(candidate_embedding_dict[candidate_tup][datalist[1430][0]].shape)[0]\n",
        "\n",
        "# triplet\n",
        "embeddingSize = datalist[1430][0].shape[0]\n",
        "output_embedding_size = 300\n",
        "print(embeddingSize,output_embedding_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc0WRh-yhWrU"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_uniform_(m.weight.data,nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.BatchNorm1d):\n",
        "        nn.init.constant_(m.weight.data, 1)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        nn.init.kaiming_uniform_(m.weight.data)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dmz6tPuP52R"
      },
      "outputs": [],
      "source": [
        "# Initialize network\n",
        "phraseEmbeddingModel = PhraseEmbedding(embeddingSize, output_embedding_size, device).to(device)\n",
        "# phraseEmbeddingModel.apply(initialize_weights)\n",
        "\n",
        "#Loss and Optimizer\n",
        "optimizer = optim.Adam(phraseEmbeddingModel.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
        "criterion = TripletLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MskESAKT7p3y"
      },
      "outputs": [],
      "source": [
        "# phraseEmbeddingModel = PhraseEmbeddingI(embeddingSize, output_embedding_size, device,candidate_embedding_dict,index_candidate_dict).to(device)\n",
        "\n",
        "# #Loss and Optimizer\n",
        "# optimizer = optim.Adam(phraseEmbeddingModel.parameters(), lr=learning_rate, weight_decay=0.0005)\n",
        "# criterion = SoftKNNLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyyjJ1lpaITg"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir='entityEmbedding/model_checkpoints_ner'\n",
        "ckp_path = \"entityEmbedding/model_checkpoints_ner/checkpoint_model300.pt\" #300\n",
        "# ckp_path = \"entityEmbedding/model_checkpoints_ner/checkpoint_model300_softknn.pt\" #300\n",
        "\n",
        "# if(path.exists(ckp_path)):\n",
        "#     # load the saved checkpoint\n",
        "#     phraseEmbeddingModel, optimizer, start_epoch = load_ckp(ckp_path, phraseEmbeddingModel, optimizer)\n",
        "\n",
        "#     print(\"starting with model at epoch:\", start_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO4FgsQJQ5vp",
        "outputId": "402b52c2-0e72-41bb-aa2a-b35b507dcd2f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 1  Training Loss: 0.014150862475149132\n",
            "\n",
            "Epoch 1  Validation Loss: 0.006315389351749962\n",
            "=====================================================================\n",
            "\n",
            "saving this checkpoint\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 2  Training Loss: 0.005428125148264225\n",
            "\n",
            "Epoch 2  Validation Loss: 0.0031699858690527353\n",
            "=====================================================================\n",
            "\n",
            "saving this checkpoint\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 3  Training Loss: 0.0038540469251013842\n",
            "\n",
            "Epoch 3  Validation Loss: 0.0030689049427482214\n",
            "=====================================================================\n",
            "\n",
            "saving this checkpoint\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 4  Training Loss: 0.003507194656971338\n",
            "\n",
            "Epoch 4  Validation Loss: 0.002983760977671905\n",
            "=====================================================================\n",
            "\n",
            "saving this checkpoint\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 5  Training Loss: 0.0033275638045506756\n",
            "\n",
            "Epoch 5  Validation Loss: 0.002321392572908239\n",
            "=====================================================================\n",
            "\n",
            "saving this checkpoint\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 6  Training Loss: 0.0032001936546549267\n",
            "\n",
            "Epoch 6  Validation Loss: 0.002383294684643095\n",
            "=====================================================================\n",
            "\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 7  Training Loss: 0.003093651891434032\n",
            "\n",
            "Epoch 7  Validation Loss: 0.005676613231612878\n",
            "=====================================================================\n",
            "\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 8  Training Loss: 0.003092365155336615\n",
            "\n",
            "Epoch 8  Validation Loss: 0.00228909849697216\n",
            "=====================================================================\n",
            "\n",
            "saving this checkpoint\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 9  Training Loss: 0.0030330983352690817\n",
            "\n",
            "Epoch 9  Validation Loss: 0.005826832557266409\n",
            "=====================================================================\n",
            "\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 10  Training Loss: 0.0029852424198337545\n",
            "\n",
            "Epoch 10  Validation Loss: 0.0027596243360841818\n",
            "=====================================================================\n",
            "\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 11  Training Loss: 0.00297733285292037\n",
            "\n",
            "Epoch 11  Validation Loss: 0.0025398948610844936\n",
            "=====================================================================\n",
            "\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 12  Training Loss: 0.00293235845408194\n",
            "\n",
            "Epoch 12  Validation Loss: 0.0033541639462452044\n",
            "=====================================================================\n",
            "\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 13  Training Loss: 0.002903675023823654\n",
            "\n",
            "Epoch 13  Validation Loss: 0.004783492196689953\n",
            "=====================================================================\n",
            "\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 14  Training Loss: 0.0029222382873862933\n",
            "\n",
            "Epoch 14  Validation Loss: 0.002181947569955479\n",
            "=====================================================================\n",
            "\n",
            "saving this checkpoint\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 15  Training Loss: 0.0028762051043601856\n",
            "\n",
            "Epoch 15  Validation Loss: 0.0025347664698281073\n",
            "=====================================================================\n",
            "\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 16  Training Loss: 0.0028542717116836923\n",
            "\n",
            "Epoch 16  Validation Loss: 0.002493366493250836\n",
            "=====================================================================\n",
            "\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 17  Training Loss: 0.002883525834038501\n",
            "\n",
            "Epoch 17  Validation Loss: 0.0021589599041776223\n",
            "=====================================================================\n",
            "\n",
            "saving this checkpoint\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 18  Training Loss: 0.0028636041489666295\n",
            "\n",
            "Epoch 18  Validation Loss: 0.002218139125034213\n",
            "=====================================================================\n",
            "\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 19  Training Loss: 0.002843867105285961\n",
            "\n",
            "Epoch 19  Validation Loss: 0.0024125091308219867\n",
            "=====================================================================\n",
            "\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 20  Training Loss: 0.0027793181362390875\n",
            "\n",
            "Epoch 20  Validation Loss: 0.002419187348674644\n",
            "=====================================================================\n",
            "\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 21  Training Loss: 0.002822942110892496\n",
            "\n",
            "Epoch 21  Validation Loss: 0.002819333860481327\n",
            "=====================================================================\n",
            "\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 22  Training Loss: 0.002801992025738678\n",
            "\n",
            "Epoch 22  Validation Loss: 0.0026162163439122114\n",
            "=====================================================================\n",
            "\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 23  Training Loss: 0.0028224915909286492\n",
            "\n",
            "Epoch 23  Validation Loss: 0.0021756104701621966\n",
            "=====================================================================\n",
            "\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 24  Training Loss: 0.0027591669882261367\n",
            "\n",
            "Epoch 24  Validation Loss: 0.002300030424852263\n",
            "=====================================================================\n",
            "\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 25  Training Loss: 0.002765514762254206\n",
            "\n",
            "Epoch 25  Validation Loss: 0.0021747873503376136\n",
            "=====================================================================\n",
            "\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "\n",
            "Epoch 26  Training Loss: 0.0028375087611637573\n",
            "\n",
            "Epoch 26  Validation Loss: 0.0023295864547518167\n",
            "=====================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train Network\n",
        "history_training= []\n",
        "history_validation = []\n",
        "best_loss = np.float('inf')\n",
        "best_checkpoint = {}\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    training_batch_loss=[]\n",
        "    mbcount=0\n",
        "    for batch_idx, batch_data in enumerate(training_generator):\n",
        "        # print(type(data),len(data),len(data[0]),len(data[1]),len(data[2]))\n",
        "        optimizer.zero_grad()\n",
        "        out = phraseEmbeddingModel(batch_data)\n",
        "        # print('network output type:',type(out))\n",
        "        loss = criterion(out)\n",
        "        # print('mini batch loss:',loss.item())\n",
        "        training_batch_loss.append(loss.item())\n",
        "         \n",
        "         \n",
        "\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(phraseEmbeddingModel.parameters(), max_norm=2.0, norm_type=2)\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "        mbcount+=1\n",
        "        if(mbcount%1000==0):\n",
        "            print(mbcount//1000)\n",
        "    combined_training_loss = np.mean(training_batch_loss)\n",
        "    print('\\nEpoch',str(epoch+1),' Training Loss:', combined_training_loss)\n",
        "    history_training.append(combined_training_loss)\n",
        "\n",
        "    #Validation: DO NOT BACKPROPAGATE HERE\n",
        "    validation_batch_loss = []\n",
        "    print_only_one=True\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data in enumerate(validation_generator):\n",
        "            # if(print_only_one):\n",
        "                # print(len(data[0]),len(data[1]))\n",
        "                # print(type(data))\n",
        "                # print_only_one=False\n",
        "            out = phraseEmbeddingModel(data)\n",
        "            loss = criterion(out)\n",
        "            validation_batch_loss.append(loss.item())\n",
        "            # print(validation_batch_loss)\n",
        "    combined_validation_loss= np.mean(validation_batch_loss)\n",
        "    history_validation.append(combined_validation_loss)\n",
        "    # if(((epoch+1)%10==0)|(epoch == (num_epochs-1))):\n",
        "    print('\\nEpoch',str(epoch+1),' Validation Loss:',combined_validation_loss)\n",
        "    print('=====================================================================\\n')\n",
        "    \n",
        "    if(combined_validation_loss<best_loss):\n",
        "        best_loss = combined_validation_loss\n",
        "        print('saving this checkpoint')\n",
        "        best_checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': phraseEmbeddingModel.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "        no_improvement_counter=0\n",
        "    else:\n",
        "        no_improvement_counter+=1\n",
        "        if(no_improvement_counter>patience):\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0YGzUWQ12A1"
      },
      "outputs": [],
      "source": [
        "save_ckp(best_checkpoint, True, checkpoint_dir) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjyU4EUATYTr"
      },
      "outputs": [],
      "source": [
        "# # tensor = -1*torch.Tensor([3,2,1])\n",
        "# # sum = torch.sum(tensor) \n",
        "# # sum_int = int(sum.item())\n",
        "# # print(tensor, type(sum), sum_int)\n",
        "\n",
        "# def nxn_cos_sim(A, B, dim=1, eps=1e-8):\n",
        "#       numerator = A @ B.T\n",
        "#       A_l2 = torch.mul(A, A).sum(axis=dim)\n",
        "#       B_l2 = torch.mul(B, B).sum(axis=dim)\n",
        "#       denominator = torch.max(torch.sqrt(torch.outer(A_l2, B_l2)), torch.tensor(eps))\n",
        "#       return torch.div(numerator, denominator)\n",
        "\n",
        "# example_2D_list1 = [[0.2423,-0.6679,0.8277],[0.2423,-0.6679,0.8277],[0.2423,-0.6679,0.8277]]\n",
        "# example_2D_Tensor1 = torch.tensor(example_2D_list1)\n",
        "\n",
        "# example_2D_list2 = [[0.2245,-2.2268,0.4577],[0.2245,-2.2268,0.3295],[0.2245,-2.2268,0.4577]]\n",
        "# example_2D_Tensor2 = torch.tensor(example_2D_list2)\n",
        "\n",
        "\n",
        "# sim_matrix = nxn_cos_sim(example_2D_Tensor1,example_2D_Tensor2)\n",
        "# print(sim_matrix)\n",
        "\n",
        "# for i in range(sim_matrix.size()[0]):\n",
        "#     print(i,sim_matrix[i])\n",
        "#     exp_tensor = torch.exp(sim_matrix[i])\n",
        "#     print(exp_tensor)\n",
        "#     sum_tensor = torch.sum(exp_tensor)\n",
        "#     print(sum_tensor)\n",
        "#     weights = torch.div(exp_tensor,sum_tensor)\n",
        "#     print('weights:',weights)\n",
        "#     print(weights[:,None]*example_2D_Tensor2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gcq0b510200"
      },
      "source": [
        "## **Training the Entity Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vybekKdR3jVO"
      },
      "outputs": [],
      "source": [
        "trainset_ec, tokenizedtestset_ec, tweet_to_sentences_w_annotation_ec = preprocess('deduplicated_test_WTypes.csv')\n",
        "candidateBaseHeaders_alt=['candidate', 'batch', 'length','cumulative','class']\n",
        "\n",
        "predictions=[]\n",
        "tokenized_sentences=[]\n",
        "count=0\n",
        "with torch.no_grad():\n",
        "    for train_record in trainset_ec:\n",
        "        \n",
        "        sentence = normalizeTweet(train_record)\n",
        "        tweetWordList = sentence.split()\n",
        "        enumerated_tweetWordList=[(token,idx) for idx,token in enumerate(tweetWordList)]\n",
        "\n",
        "        tokenized_input=tokenizer(sentence)\n",
        "        initial_input_ids = torch.tensor([tokenizer.encode(sentence)])\n",
        "\n",
        "        initial_input_ids = initial_input_ids[:,:128]\n",
        "        token_dict = {x : tokenizer.encode(x, add_special_tokens=False) for x in sentence.split()}\n",
        "\n",
        "        input_ids = initial_input_ids.to(device)\n",
        "        tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
        "\n",
        "        output = alt_model(input_ids)\n",
        "        \n",
        "        token_embeddings=output.hidden_states[-1].squeeze()[1:-1] # we dont need embeddings for CLS and EOS\n",
        "\n",
        "        prediction = (torch.argmax(output.logits, axis=2))\n",
        "        prediction = prediction.cpu().numpy().reshape(-1)\n",
        "        # prediction_labels=[label_list[l].split('-')[0] for l in prediction]\n",
        "        prediction_labels=[label_list[l] for l in prediction]\n",
        "        # prediction_labels=collate_token_labels(token_dict, prediction_labels[1:-1])\n",
        "        prediction_labels, entity_aware_embeddings = collate_token_label_embedding(tweetWordList, token_dict, prediction_labels[1:-1], token_embeddings)\n",
        "\n",
        "        # print(len(enumerated_tweetWordList),len(token_dict.keys()),len(entity_aware_embeddings),len(prediction_labels))\n",
        "\n",
        "        assert len(enumerated_tweetWordList)==len(entity_aware_embeddings)\n",
        "        assert len(prediction_labels)==len(enumerated_tweetWordList)\n",
        "\n",
        "        predictions.append(prediction_labels)\n",
        "        tokenized_sentences.append((tweetWordList,entity_aware_embeddings))\n",
        "        count+=1\n",
        "\n",
        "print(len(predictions),len(tokenized_sentences))\n",
        "\n",
        "local_ner_arrays=[]\n",
        "for n, sentence_tup in enumerate(tokenized_sentences):  \n",
        "    sentence = sentence_tup[0]\n",
        "    assert (len(sentence)==len(predictions[n]))\n",
        "    word_tag_tuples=zip(sentence,predictions[n])\n",
        "    entities_from_sentence=get_entities(word_tag_tuples)\n",
        "    local_ner_arrays.append(entities_from_sentence)\n",
        "print('tally:',len(tokenized_sentences),len(local_ner_arrays))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uz-gnTm84tAV"
      },
      "outputs": [],
      "source": [
        "phraseEmbeddingModel = PhraseEmbedding(768, output_embedding_size, device).to(device) #triplet\n",
        "# # phraseEmbeddingModel = PhraseEmbeddingI(768, output_embedding_size, device).to(device) #soft-knn\n",
        "# phraseEmbeddingModel.apply(initialize_weights)\n",
        "\n",
        "# #Loss and Optimizer\n",
        "optimizer = optim.Adam(phraseEmbeddingModel.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
        "\n",
        "# # define checkpoint saved path for entity phrase embedder\n",
        "ckp_path = \"entityEmbedding/model_checkpoints_ner/checkpoint_model300.pt\" #300 triplet\n",
        "# # ckp_path = \"entityEmbedding/model_checkpoints_ner/checkpoint_model300_softknn.pt\" #300 tuplet\n",
        "\n",
        "if(path.exists(ckp_path)):\n",
        "    # load the saved checkpoint\n",
        "    entityPhraseEmbedder, optimizer, start_epoch = load_ckp(ckp_path, phraseEmbeddingModel, optimizer)\n",
        "    print(\"starting with model at epoch:\", start_epoch)\n",
        "\n",
        "#comment this out if collecting samples for training the entity phrase embedder\n",
        "entityPhraseEmbedder.eval()\n",
        "\n",
        "candidate_embedding_dict = defaultdict(list)\n",
        "candidateBase_dict_alt_ec = {} #<batch, length, cumulative, class>\n",
        "non_entity_count = 0\n",
        "entity_count = 0\n",
        "for tweetID in tweet_to_sentences_w_annotation_ec.keys():\n",
        "    annotated_token_list = []\n",
        "    annotated_mention_list=tweet_to_sentences_w_annotation_ec[tweetID][1]\n",
        "    tweet_token_list=[]\n",
        "    token_embedding_list=[]\n",
        "    local_mentions_list=[]\n",
        "    idRange=tweet_to_sentences_w_annotation_ec[tweetID][0]\n",
        "\n",
        "    for sentID in range(idRange[0],idRange[1]):\n",
        "        tweet_token_list+=tokenized_sentences[sentID][0]\n",
        "        token_embedding_list+=tokenized_sentences[sentID][1]\n",
        "        local_mentions_list+=local_ner_arrays[sentID]\n",
        "    \n",
        "    assert len(tweet_token_list)==len(token_embedding_list)\n",
        "    print(tweetID, tweet_token_list)\n",
        "    print('annotated_mention_list:',annotated_mention_list)\n",
        "\n",
        "    \n",
        "    annotated_candidates = set([mention_tup[0].lower().strip() for mention_tup in annotated_mention_list])\n",
        "    for mention_tup in annotated_mention_list:\n",
        "        annotated_token_list+= mention_tup[0].lower().strip().split()\n",
        "    annotated_token_list = set(annotated_token_list)\n",
        "\n",
        "    #------------------------ negative candidate mining ------------------------\n",
        "    non_entity_list = list(set([elem.strip().lower() for elem in tweet_token_list]).intersection(canonical_ne_list)-annotated_candidates)\n",
        "\n",
        "    \n",
        "    if(non_entity_list):\n",
        "        print('non_entity_list:',non_entity_list)\n",
        "    \n",
        "    tweet_token_ind = 0\n",
        "    while((len(non_entity_list)>0)&(tweet_token_ind < len(tweet_token_list))):\n",
        "        #must pop from the left\n",
        "        non_entity_candidate = non_entity_list.pop(0)\n",
        "        non_entity_candidate, nonentity_type = non_entity_candidate.lower(),'ne'\n",
        "        non_entity_candidate_tokens = non_entity_candidate.split()\n",
        "        while(tweet_token_ind < len(tweet_token_list)):\n",
        "            if((' '.join(tweet_token_list[tweet_token_ind:tweet_token_ind+len(non_entity_candidate_tokens)])).strip().lower()!=non_entity_candidate):\n",
        "                # print(tweet_token_ind)\n",
        "                tweet_token_ind+=1\n",
        "            else:\n",
        "                ne_candidate=(' '.join(tweet_token_list[tweet_token_ind:tweet_token_ind+len(non_entity_candidate_tokens)])).strip().lower()\n",
        "                ne_candidate_token_embeddings = torch.stack(token_embedding_list[tweet_token_ind:tweet_token_ind+len(non_entity_candidate_tokens)]) #2d tensor of ne candidate token embeddings\n",
        "                \n",
        "                tensor_inter = torch.mean(ne_candidate_token_embeddings,dim=0)\n",
        "                tensor_inter_norm = torch.norm(tensor_inter, p=2,dim=0)\n",
        "                ne_candidate_tokens_avg_embedding = tensor_inter/tensor_inter_norm\n",
        "\n",
        "                \n",
        "\n",
        "                # print(ne_candidate, ne_candidate_tokens_avg_embedding.shape)\n",
        "                if((non_entity_candidate, nonentity_type) not in candidate_embedding_dict):\n",
        "                    non_entity_count+=1\n",
        "                    candidateBase_dict_alt_ec[non_entity_candidate+'||'+nonentity_type] = [0,len(non_entity_candidate_tokens),1,entity_types_dict[nonentity_type]]\n",
        "                else:\n",
        "                    candidateBase_dict_alt_ec[non_entity_candidate+'||'+nonentity_type][2] += 1\n",
        "                \n",
        "\n",
        "                #---------------------- When collecting mention phrase embeddings to train the entity classifier ----------------------\n",
        "                # !! must unsqueeze at test time with embedder else batchnorm throws error\n",
        "                ne_candidate_tokens_avg_embedding = ne_candidate_tokens_avg_embedding.unsqueeze(0)\n",
        "                assert torch.isnan(ne_candidate_tokens_avg_embedding).any() == False\n",
        "                ne_candidate_phrase_embedding = (entityPhraseEmbedder.getEmbedding(ne_candidate_tokens_avg_embedding)).squeeze(0)\n",
        "                assert torch.isnan(ne_candidate_phrase_embedding).any() == False\n",
        "                # print(ne_candidate_tokens_avg_embedding.shape, ne_candidate_phrase_embedding.shape)\n",
        "                candidate_embedding_dict[(non_entity_candidate, nonentity_type)].append(ne_candidate_phrase_embedding)\n",
        "\n",
        "                tweet_token_ind+=len(non_entity_candidate_tokens)\n",
        "                break\n",
        "    #------------------------ negative candidate mining ------------------------\n",
        "\n",
        "    #------------------------ positive candidate mining ------------------------\n",
        "    tweet_token_ind = 0\n",
        "    while((len(annotated_mention_list)>0)&(tweet_token_ind < len(tweet_token_list))):\n",
        "        #must pop from the left\n",
        "        annotated_candidate_tuple = annotated_mention_list.pop(0)\n",
        "        annotated_candidate, entity_type = annotated_candidate_tuple[0].lower(),annotated_candidate_tuple[1].lower()\n",
        "        candidate_tokens = annotated_candidate.split()\n",
        "\n",
        "        print(annotated_candidate)\n",
        "        while((' '.join(tweet_token_list[tweet_token_ind:tweet_token_ind+len(candidate_tokens)])).strip().lower()!=annotated_candidate):\n",
        "            tweet_token_ind+=1\n",
        "        candidate=(' '.join(tweet_token_list[tweet_token_ind:tweet_token_ind+len(candidate_tokens)])).strip().lower()\n",
        "        candidate_token_embeddings = torch.stack(token_embedding_list[tweet_token_ind:tweet_token_ind+len(candidate_tokens)]) #2d tensor of candidate token embeddings\n",
        "        tensor_inter = torch.mean(candidate_token_embeddings,dim=0)\n",
        "        tensor_inter_norm = torch.norm(tensor_inter, p=2,dim=0)\n",
        "        candidate_tokens_avg_embedding = tensor_inter/tensor_inter_norm\n",
        "        # print(candidate,annotated_candidate,candidate_token_embeddings.shape)\n",
        "\n",
        "        if((annotated_candidate, entity_type) not in candidate_embedding_dict):\n",
        "            entity_count+=1\n",
        "            candidateBase_dict_alt_ec[annotated_candidate+'||'+entity_type] = [0,len(candidate_tokens),1,entity_types_dict[entity_type]]\n",
        "        else:\n",
        "            candidateBase_dict_alt_ec[annotated_candidate+'||'+entity_type][2] += 1\n",
        "\n",
        "        #---------------------- When collecting mention phrase embeddings to train the entity classifier ----------------------\n",
        "        # !! must unsqueeze at test time with embedder else batchnorm throws error\n",
        "        candidate_tokens_avg_embedding = candidate_tokens_avg_embedding.unsqueeze(0)\n",
        "        assert torch.isnan(candidate_tokens_avg_embedding).any() == False\n",
        "        candidate_phrase_embedding = (entityPhraseEmbedder.getEmbedding(candidate_tokens_avg_embedding)).squeeze(0)\n",
        "        assert torch.isnan(candidate_phrase_embedding).any() == False\n",
        "        # print(candidate_tokens_avg_embedding.shape, candidate_phrase_embedding.shape)\n",
        "        candidate_embedding_dict[(annotated_candidate, entity_type)].append(candidate_phrase_embedding)\n",
        "\n",
        "        tweet_token_ind+=len(candidate_tokens)\n",
        "    #------------------------ positive candidate mining ------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-El0QCwZvRa8"
      },
      "outputs": [],
      "source": [
        "print(len(candidateBase_dict_alt_ec))\n",
        "print(candidateBase_dict_alt_ec.keys())\n",
        "# candidateBaseHeaders_alt\n",
        "candidate_featureBase_DF_alt = pd.DataFrame.from_dict(candidateBase_dict_alt_ec, orient='index')\n",
        "candidate_featureBase_DF_alt.columns = candidateBaseHeaders_alt[1:]\n",
        "candidate_featureBase_DF_alt.index.name = candidateBaseHeaders_alt[0]\n",
        "candidate_featureBase_DF_alt  = candidate_featureBase_DF_alt.reset_index(drop=False)\n",
        "print(candidate_featureBase_DF_alt.columns.tolist())\n",
        "print(len(candidateBase_dict_alt_ec),len(candidate_embedding_dict))\n",
        "print(candidate_featureBase_DF_alt.head())\n",
        "\n",
        "entity_types = set(candidate_featureBase_DF_alt['class'].tolist())\n",
        "for entity_type in entity_types:\n",
        "    print(len(candidate_featureBase_DF_alt[candidate_featureBase_DF_alt['class']==entity_type]))\n",
        "\n",
        "print('=============')\n",
        "\n",
        "\n",
        "# entity_types = set(candidate_featureBase_DF_alt_filtered['class'].tolist())\n",
        "# for entity_type in entity_types:\n",
        "#     print(len(candidate_featureBase_DF_alt_filtered[candidate_featureBase_DF_alt_filtered['class']==entity_type]))\n",
        "# print(len(candidate_featureBase_DF_alt_filtered))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xT0n8825I_v2"
      },
      "outputs": [],
      "source": [
        "entity_classifier_alt = EntityClassifierAlt(True, device, candidate_featureBase_DF_alt, candidate_embedding_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wbn1mwrwIZX"
      },
      "outputs": [],
      "source": [
        "# p= 0.8297872340425532\n",
        "# r= 0.6933962264150944\n",
        "\n",
        "# f=2*p*r/(p+r)\n",
        "# print(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQy_LjrMrhfw"
      },
      "outputs": [],
      "source": [
        "# import torch.nn.functional as F\n",
        "# data1=np.array([0.0,0.0,0.0])\n",
        "# x_data1 = torch.tensor(data1)\n",
        "\n",
        "# tensor_inter_norm = torch.norm(x_data1, p=2,dim=0)\n",
        "# print(tensor_inter_norm)\n",
        "# updated_norm = torch.add(tensor_inter_norm, 1e-6)\n",
        "# print(x_data1/tensor_inter_norm)\n",
        "# print(x_data1/updated_norm)\n",
        "\n",
        "# data2=np.array([2.0,3.0,4.0])\n",
        "# x_data2 = torch.tensor(data2)\n",
        "\n",
        "# diff = x_data1-x_data2\n",
        "# print(x_data1.shape,x_data2.shape,diff.shape)\n",
        "# print(diff)\n",
        "# losses=torch.relu(diff)\n",
        "# print(losses)\n",
        "# print(losses.mean())\n",
        "# print('=====')\n",
        "# # print(x_data.shape)\n",
        "# # stacked=torch.stack([x_data1,x_data2])\n",
        "# # print(stacked.shape)\n",
        "# tensorlist = [x_data1,x_data2]\n",
        "# # mean = torch.mean(torch.stack(tensorlist), axis=1)\n",
        "# # sd = torch.std(torch.stack(tensorlist), axis=1)\n",
        "# # print('mean:', mean)\n",
        "# # print('sd:' , sd)\n",
        "# for tensor in tensorlist:\n",
        "#     print(tensor)\n",
        "#     tensor_norm = torch.norm(tensor, p=2,dim=0)\n",
        "#     print(tensor_norm)\n",
        "#     print(tensor/tensor_norm)\n",
        "#     print('----')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6a02VCgGRl9"
      },
      "source": [
        "## **Phase I: Local NER to collect entity candidates and Token Contextual Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzwyqfxcHEF2"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import re\n",
        "import emoji\n",
        "from emoji import demojize\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas  as pd\n",
        "from itertools import groupby\n",
        "from operator import itemgetter\n",
        "from collections import Iterable, OrderedDict\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import gutenberg\n",
        "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "#from datasketch import MinHash, MinHashLSH\n",
        "# import NE_candidate_module as ne\n",
        "# import Mention\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "import copy\n",
        "import trie as trie\n",
        "import ast\n",
        "\n",
        "from datasets import load_dataset, load_metric, ClassLabel, Sequence\n",
        "import random\n",
        "import torch\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, set_seed\n",
        "import copy\n",
        "\n",
        "# import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "# import matplotlib.pyplot as plt\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "cachedStopWords = stopwords.words(\"english\")\n",
        "tempList=[\"i\",\"and\",\"or\",\"other\",\"since\",\"hence\",\"onto\",\"another\",\"across\",\"unlike\",\"anytime\",\"were\",\"you\",\"then\",\"still\",\"till\",\"nor\",\"perhaps\",\"probably\",\"otherwise\",\"until\",\"sometimes\",\"sometime\",\"seem\",\"cannot\",\"seems\",\"because\",\"can\",\"like\",\"into\",\"able\",\"unable\",\"either\",\"neither\",\"if\",\"we\",\"it\",\"else\",\"elsewhere\",\"how\",\"not\",\"what\",\"who\",\"when\",\"where\",\"who's\",\"who’s\",\"let\",\"today\",\"tomorrow\",\"tonight\",\"let's\",\"let’s\",\"lets\",\"know\",\"make\",\"oh\",\"via\",\"i\",\"yet\",\"must\",\"mustnt\",\"mustn't\",\"mustn’t\",\"i'll\",\"i’ll\",\"you'll\",\"you’ll\",\"we'll\",\"we’ll\",\"done\",\"doesnt\",\"doesn't\",\"doesn’t\",\"dont\",\"don't\",\"don’t\",\"did\",\"didnt\",\"didn't\",\"didn’t\",\"much\",\"without\",\"could\",\"couldn't\",\"couldn’t\",\"would\",\"wouldn't\",\"wouldn’t\",\"should\",\"shouldn't\",\"souldn’t\",\"shall\",\"isn't\",\"isn’t\",\"hasn't\",\"hasn’t\",\"wasn't\",\"wasn’t\",\"also\",\"let's\",\"let’s\",\"let\",\"well\",\"just\",\"everyone\",\"anyone\",\"noone\",\"none\",\"someone\",\"theres\",\"there's\",\"there’s\",\"everybody\",\"nobody\",\"somebody\",\"anything\",\"else\",\"elsewhere\",\"something\",\"nothing\",\"everything\",\"i'd\",\"i’d\",\"i’m\",\"won't\",\"won’t\",\"i’ve\",\"i've\",\"they're\",\"they’re\",\"we’re\",\"we're\",\"we'll\",\"we’ll\",\"we’ve\",\"we've\",\"they’ve\",\"they've\",\"they’d\",\"they'd\",\"they’ll\",\"they'll\",\"again\",\"you're\",\"you’re\",\"you've\",\"you’ve\",\"thats\",\"that's\",'that’s','here’s',\"here's\",\"what's\",\"what’s\",\"i’m\",\"i'm\",\"a\",\"so\",\"except\",\"arn't\",\"aren't\",\"arent\",\"this\",\"when\",\"it\",\"it’s\",\"it's\",\"he's\",\"she's\",\"she'd\",\"he'd\",\"he'll\",\"she'll\",\"she’ll\",\"many\",\"can't\",\"cant\",\"can’t\",\"even\",\"yes\",\"no\",\"these\",\"here\",\"there\",\"to\",\"maybe\",\"<hashtag>\",\"<hashtag>.\",\"ever\",\"every\",\"never\",\"there's\",\"there’s\",\"whenever\",\"wherever\",\"however\",\"whatever\",\"always\",\"although\"]\n",
        "for item in tempList:\n",
        "    if item not in cachedStopWords:\n",
        "        cachedStopWords.append(item)\n",
        "cachedStopWords.remove(\"don\")\n",
        "# cachedStopWords.remove(\"your\")\n",
        "# cachedStopWords.remove(\"up\")\n",
        "\n",
        "cachedTitles = [\"mr.\",\"mr\",\"mrs.\",\"mrs\",\"miss\",\"ms\",\"sen.\",\"dr\",\"dr.\",\"prof.\",\"president\",\"congressman\"]\n",
        "prep_list=[\"of\",\"v.\"]  #includes common conjunction as well\n",
        "# prep_list=[]\n",
        "# article_list=[]\n",
        "article_list=[\"a\",\"an\",\"the\"]\n",
        "conjoiner=[\"de\"]\n",
        "day_list=[\"sunday\",\"monday\",\"tuesday\",\"wednesday\",\"thursday\",\"friday\",\"saturday\",\"mon\",\"tues\",\"wed\",\"thurs\",\"fri\",\"sat\",\"sun\"]\n",
        "month_list=[\"january\",\"february\",\"march\",\"april\",\"may\",\"june\",\"july\",\"august\",\"september\",\"october\",\"november\",\"december\",\"jan\",\"feb\",\"mar\",\"apr\",\"may\",\"jun\",\"jul\",\"aug\",\"sep\",\"oct\",\"nov\",\"dec\"]\n",
        "chat_word_list=[\"nope\",\"gee\",\"hmm\",\"httpurl\",\"n't\",\"pls\",\"bye\",\"€\",\"vs\",\"ouch\",\"am\",\"pm\",\"omw\",\"cbb\",\"tmi\",\"http\",\"https\",\"tv\",\"tmw\",\"og\",\"psst\",\"b.s\",\"thanku\",\"em\",\"ip\",\"qft\",\"ima\",\"icymi\",\"bdsm\",\"ah\",\"ive\",\"qt\",\"dj\",\"dm\",\"pts\",\"pt\",\"yrs\",\"congrat\",\"haueheuaeh\",\"ahushaush\",\"jr\",\"please\",\"retweet\",\"2mrw\",\"2moro\",\"4get\",\"ooh\",\"reppin\",\"idk\",\"oops\",\"yup\",\"stfu\",\"uhh\",\"2b\",\"dear\",\"yay\",\"btw\",\"ahhh\",\"b4\",\"ugh\",\"ty\",\"cuz\",\"coz\",\"sorry\",\"yea\",\"asap\",\"ur\",\"bs\",\"rt\",\"lmfao\",\"lfmao\",\"slfmao\",\"u\",\"r\",\"nah\",\"umm\",\"ummm\",\"thank\",\"thanks\",\"congrats\",\"whoa\",\"rofl\",\"ha\",\"ok\",\"okay\",\"hey\",\"hi\",\"huh\",\"ya\",\"yep\",\"yeah\",\"fyi\",\"duh\",\"damn\",\"lol\",\"omg\",\"congratulations\",\"fucking\",\"fuck\",\"f*ck\",\"wtf\",\"wth\",\"aka\",\"wtaf\",\"xoxo\",\"rofl\",\"imo\",\"wow\",\"fck\",\"haha\",\"hehe\",\"hoho\"]\n",
        "string.punctuation=string.punctuation+'…‘’'\n",
        "\n",
        "\n",
        "class LocalNERModule():\n",
        "    def __init__(self, sentenceTokenizer, nerTokenizer, nerEngine, device):\n",
        "        self.counter=0\n",
        "\n",
        "        if(sentenceTokenizer):\n",
        "            self.my_sentence_tokenizer = sentenceTokenizer\n",
        "        else:\n",
        "            nltk.download('gutenberg')\n",
        "            gutenberg_text = \"\"\n",
        "            for file_id in gutenberg.fileids():\n",
        "                gutenberg_text += gutenberg.raw(file_id)\n",
        "            tokenizer_trainer = PunktTrainer()\n",
        "            tokenizer_trainer.INCLUDE_ALL_COLLOCS = True\n",
        "            tokenizer_trainer.train(gutenberg_text)\n",
        "\n",
        "            self.my_sentence_tokenizer = PunktSentenceTokenizer(tokenizer_trainer.get_params())\n",
        "            self.my_sentence_tokenizer._params.abbrev_types.add('dr')\n",
        "            self.my_sentence_tokenizer._params.abbrev_types.add('c.j')\n",
        "            self.my_sentence_tokenizer._params.abbrev_types.add('u.s')\n",
        "            self.my_sentence_tokenizer._params.abbrev_types.add('u.s.a')\n",
        "            self.my_sentence_tokenizer._params.abbrev_types.add('ret')\n",
        "            self.my_sentence_tokenizer._params.abbrev_types.add('rep')\n",
        "            self.my_sentence_tokenizer._params.abbrev_types.add('mr')\n",
        "            self.my_sentence_tokenizer._params.abbrev_types.add('ms')\n",
        "            self.my_sentence_tokenizer._params.abbrev_types.add('mrs')\n",
        "            self.my_sentence_tokenizer._params.abbrev_types.add('v')\n",
        "            self.my_sentence_tokenizer._params.abbrev_types.add('vs')\n",
        "\n",
        "        self.quickRegex=re.compile(\"[a-z]+\")\n",
        "\n",
        "        self.tweet_to_sentences_w_annotation = {}\n",
        "        self.device = device\n",
        "        self.apostrophe_list =[\"'s\",'’s','s']\n",
        "        # self.label_list = ['O','B','I']\n",
        "        self.label_list = ['O','B-ORG','I-ORG','B-MISC','I-MISC','B-LOC','I-LOC','B-PER','I-PER']\n",
        "\n",
        "        self.tweetTokenizer = TweetTokenizer()\n",
        "\n",
        "        self.contextual_embeddings = {}\n",
        "\n",
        "        print('Starting Local NER Engine!')\n",
        "        self.expanded_label_dict={0:'O', 1:'B-corporation', 2:'I-corporation', 3:'B-creative-work', 4:'I-creative-work', 5:'B-group', 6:'I-group', 7:'B-location', 8:'I-location', 9:'B-person', 10:'I-person', 11:'B-product', 12:'I-product'}\n",
        "        self.BIO_dict={'O':0,'B':1,'I':2}\n",
        "        self.BIO_type_dict={'O':0, 'B-ORG':1, 'I-ORG':2, 'B-MISC':3, 'I-MISC':4, 'B-LOC':5, 'I-LOC':6, 'B-PER':7, 'I-PER':8}\n",
        "        self.label_map_dict={'O':'O', 'B-corporation':'B-ORG', 'I-corporation':'I-ORG', 'B-creative-work':'B-MISC', 'I-creative-work':'I-MISC', 'B-group':'B-MISC', 'I-group':'I-MISC', 'B-location':'B-LOC', 'I-location':'I-LOC', 'B-person':'B-PER', 'I-person':'I-PER', 'B-product':'B-MISC', 'I-product':'I-MISC'}\n",
        "\n",
        "\n",
        "        if((nerTokenizer is not None)&(nerEngine is not None)):\n",
        "            self.nerTokenizer = nerTokenizer\n",
        "            self.localNEREngine = nerEngine\n",
        "        else:\n",
        "            self.train_engine()\n",
        "\n",
        "    def train_engine(self):\n",
        "        task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
        "        model_checkpoint = \"vinai/bertweet-base\"\n",
        "        batch_size = 16\n",
        "        # set_seed(42)\n",
        "        datasets = load_dataset(\"wnut_17\")\n",
        "        self.nerTokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False, normalization=True)\n",
        "        label_all_tokens = True\n",
        "        tokenized_datasets = datasets.map(self.tokenize_and_align_labels)\n",
        "        data_collator = DataCollatorForTokenClassification(self.nerTokenizer)\n",
        "        self.metric = load_metric(\"seqeval\")\n",
        "        self.localNEREngine = AutoModelForTokenClassification.from_pretrained(\"vinai/bertweet-base\", output_hidden_states=True, num_labels=len(self.label_list))\n",
        "        alt_training_args = TrainingArguments(\n",
        "            f\"test-{task}\",\n",
        "            evaluation_strategy = \"epoch\",\n",
        "            learning_rate=1e-5,\n",
        "            per_device_train_batch_size=batch_size,\n",
        "            per_device_eval_batch_size=batch_size,\n",
        "            num_train_epochs=3,\n",
        "            weight_decay=0.01,\n",
        "        )\n",
        "        alt_trainer = Trainer(\n",
        "        self.localNEREngine,\n",
        "        alt_training_args,\n",
        "        train_dataset=tokenized_datasets[\"train\"],\n",
        "        eval_dataset=tokenized_datasets[\"validation\"],\n",
        "        data_collator=data_collator,\n",
        "        tokenizer=self.nerTokenizer,\n",
        "        compute_metrics=self.compute_metrics\n",
        "        )\n",
        "        alt_trainer.train()\n",
        "\n",
        "        # tokenizer.save_pretrained('test-ner/')\n",
        "        # alt_model.save_pretrained('test-ner/')\n",
        "\n",
        "    def tokenize_and_align_labels(self,example):\n",
        "        \n",
        "        tokenized_ds_input = self.nerTokenizer(example[\"tokens\"], is_split_into_words=True)\n",
        "        inputId_to_token_dict={}\n",
        "        for index, token in enumerate(example[\"tokens\"]):\n",
        "            values=self.nerTokenizer.encode(token, add_special_tokens=False, truncation=True)\n",
        "            for value in values:\n",
        "                try:\n",
        "                    inputId_to_token_dict[value].append(index)\n",
        "                except KeyError:\n",
        "                    inputId_to_token_dict[value]=[index]\n",
        "        labels=[]\n",
        "        for inputID in tokenized_ds_input['input_ids']:\n",
        "            try:\n",
        "                index_list=copy.deepcopy(inputId_to_token_dict[inputID])\n",
        "                index_to_address=index_list.pop(0)\n",
        "\n",
        "                label = self.BIO_type_dict[self.label_map_dict[self.expanded_label_dict[example['ner_tags'][index_to_address]]]]\n",
        "                # label = example['ner_tags'][index_to_address]\n",
        "\n",
        "                labels.append(label)\n",
        "                inputId_to_token_dict[inputID]=index_list\n",
        "            except KeyError:\n",
        "                labels.append(-100)\n",
        "\n",
        "        assert (len(tokenized_ds_input['input_ids']) == len(labels))\n",
        "        tokenized_ds_input['labels']=labels\n",
        "        \n",
        "        return tokenized_ds_input\n",
        "\n",
        "    def compute_metrics(self, p):\n",
        "        # print(p.shape)\n",
        "        output, labels = p\n",
        "\n",
        "        # print(len(predictions))\n",
        "        # print(predictions[0].shape)\n",
        "        # for elem in predictions[1]:\n",
        "        #   print(elem.shape)\n",
        "\n",
        "        predictions, _ = output\n",
        "        \n",
        "        predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "        # Remove ignored index (special tokens)\n",
        "        true_predictions = [\n",
        "            [self.label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "            for prediction, label in zip(predictions, labels)\n",
        "        ]\n",
        "        true_labels = [\n",
        "            [self.label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "            for prediction, label in zip(predictions, labels)\n",
        "        ]\n",
        "\n",
        "        results = self.metric.compute(predictions=true_predictions, references=true_labels)\n",
        "        return {\n",
        "            \"precision\": results[\"overall_precision\"],\n",
        "            \"recall\": results[\"overall_recall\"],\n",
        "            \"f1\": results[\"overall_f1\"],\n",
        "            \"accuracy\": results[\"overall_accuracy\"],\n",
        "        }\n",
        "\n",
        "    def is_float(self,string):\n",
        "        try:\n",
        "            f=float(string)\n",
        "            if(f==0.0):\n",
        "              return True\n",
        "            else:\n",
        "              return ((f) and (string.count(\".\")==1))\n",
        "      #return True# True if string is a number with a dot\n",
        "        except ValueError:  # if string is not a number\n",
        "          return False\n",
        "\n",
        "    def collate_token_label_embedding(self, tweetWordList, token_dict, prediction_labels, entity_embeddings):\n",
        "        counter=0\n",
        "        collated_labels=[]\n",
        "        collated_entity_embeddings=[]\n",
        "        for word in tweetWordList:\n",
        "            vals=token_dict[word]\n",
        "            # print(word,vals)\n",
        "            if(counter<len(prediction_labels)):\n",
        "                labels=prediction_labels[counter:counter+len(vals)]\n",
        "                token_entity_embeddings=entity_embeddings[counter:counter+len(vals)]\n",
        "        #         print(token_entity_embeddings.shape)\n",
        "                mean_tensor = torch.mean(token_entity_embeddings,dim=0)\n",
        "                mean_tensor[torch.isnan(mean_tensor)] = 0\n",
        "                collated_entity_embeddings.append(mean_tensor)\n",
        "        #         print(collated_entity_embeddings)\n",
        "                if('I-PER' in labels):\n",
        "                    collated_labels.append('I-PER')\n",
        "                elif('I-LOC' in labels):\n",
        "                    collated_labels.append('I-LOC')\n",
        "                elif('I-ORG' in labels):\n",
        "                    collated_labels.append('I-ORG')\n",
        "                elif('I-MISC' in labels):\n",
        "                    collated_labels.append('I-MISC')\n",
        "                elif('B-PER' in labels):\n",
        "                    collated_labels.append('B-PER')\n",
        "                elif('B-LOC' in labels):\n",
        "                    collated_labels.append('B-LOC')\n",
        "                elif('B-ORG' in labels):\n",
        "                    collated_labels.append('B-ORG')\n",
        "                elif('B-MISC' in labels):\n",
        "                    collated_labels.append('B-MISC')\n",
        "                else:\n",
        "                    collated_labels.append('O')\n",
        "                counter+=len(vals)\n",
        "            else:\n",
        "                collated_labels.append('O')\n",
        "                collated_entity_embeddings.append(torch.zeros(768).to(self.device))\n",
        "        assert len(collated_labels)==len(collated_entity_embeddings)\n",
        "        return collated_labels,collated_entity_embeddings\n",
        "\n",
        "\n",
        "    def get_entities(self, word_tag_tuples):\n",
        "        mentions=[]\n",
        "        candidateMention=''\n",
        "        positions=[]\n",
        "        type_tag=''\n",
        "        \n",
        "        #emoji.get_emoji_regexp().sub(u'', candidateMention)\n",
        "        for index, tup in enumerate(word_tag_tuples):\n",
        "            candidate=tup[0]\n",
        "            tag=tup[1]\n",
        "            if(tag=='O'):\n",
        "                if(candidateMention):\n",
        "                    if((not candidateMention.strip().startswith('#'))&(not candidateMention.strip().startswith('@'))&(not candidateMention.strip().startswith('https:'))):\n",
        "                        mention_to_add=emoji.get_emoji_regexp().sub(u'', candidateMention).strip(string.punctuation).lower().strip()\n",
        "                        if mention_to_add.endswith(\"'s\"):\n",
        "                            li = mention_to_add.rsplit(\"'s\", 1)\n",
        "                            mention_to_add=''.join(li)\n",
        "                        elif mention_to_add.endswith(\"’s\"):\n",
        "                            li = mention_to_add.rsplit(\"’s\", 1)\n",
        "                            mention_to_add=''.join(li)\n",
        "                        else:\n",
        "                            mention_to_add=mention_to_add\n",
        "                        if(mention_to_add!=''):\n",
        "                            try:\n",
        "                                assert len(mention_to_add.split()) == len(positions)\n",
        "                                mentions.append((mention_to_add,type_tag,positions))\n",
        "                            except AssertionError:\n",
        "                                print(word_tag_tuples)\n",
        "                                print(mention_to_add,type_tag,positions)\n",
        "                                return\n",
        "                candidateMention=''\n",
        "                positions=[]\n",
        "                type_tag=''\n",
        "            else:\n",
        "                boundary_tag = tag.split('-')[0]\n",
        "                type_tag = tag.split('-')[1]\n",
        "                if (boundary_tag=='B'):\n",
        "                    if((not candidateMention.strip().startswith('#'))&(not candidateMention.strip().startswith('@'))&(not candidateMention.strip().startswith('https:'))):\n",
        "                        mention_to_add=emoji.get_emoji_regexp().sub(u'', candidateMention).strip(string.punctuation).lower().strip()\n",
        "                        if mention_to_add.endswith(\"'s\"):\n",
        "                            li = mention_to_add.rsplit(\"'s\", 1)\n",
        "                            mention_to_add=''.join(li)\n",
        "                        elif mention_to_add.endswith(\"’s\"):\n",
        "                            li = mention_to_add.rsplit(\"’s\", 1)\n",
        "                            mention_to_add=''.join(li)\n",
        "                        else:\n",
        "                            mention_to_add=mention_to_add\n",
        "                        if(mention_to_add!=''):\n",
        "                            try:\n",
        "                                assert len(mention_to_add.split()) == len(positions)\n",
        "                                mentions.append((mention_to_add,type_tag,positions))\n",
        "                            except AssertionError:\n",
        "                                print(word_tag_tuples)\n",
        "                                print(mention_to_add,type_tag,positions)\n",
        "                                return\n",
        "                    if((candidate.strip() not in string.punctuation)&(emoji.get_emoji_regexp().sub(u'', candidate).strip(string.punctuation).lower().strip()!='')&(candidate.strip().strip(string.punctuation) not in self.apostrophe_list)):\n",
        "                        candidateMention=candidate\n",
        "                        positions=[index]\n",
        "                else:\n",
        "                    if((candidate.strip() not in string.punctuation)&(emoji.get_emoji_regexp().sub(u'', candidate).strip(string.punctuation).lower().strip()!='')&(candidate.strip().strip(string.punctuation) not in self.apostrophe_list)):\n",
        "                        candidateMention+=\" \"+candidate\n",
        "                        positions.append(index)\n",
        "            # if (tag=='B'):\n",
        "            #     if((not candidateMention.strip().startswith('#'))&(not candidateMention.strip().startswith('@'))):\n",
        "            #         mention_to_add=emoji.get_emoji_regexp().sub(u'', candidateMention).strip(string.punctuation).lower().strip()\n",
        "            #         if(mention_to_add):\n",
        "            #             mentions.append(mention_to_add)\n",
        "            #     candidateMention=candidate\n",
        "            # else:\n",
        "            #     candidateMention+=\" \"+candidate\n",
        "        if(emoji.get_emoji_regexp().sub(u'', candidateMention).strip(string.punctuation).strip()):\n",
        "            if((not candidateMention.strip().startswith('#'))&(not candidateMention.strip().startswith('@'))&(not candidateMention.strip().startswith('https:'))&(candidate.strip().strip(string.punctuation) not in self.apostrophe_list)):\n",
        "                mention_to_add=emoji.get_emoji_regexp().sub(u'', candidateMention).strip(string.punctuation).lower().strip()\n",
        "                if(mention_to_add!=''):\n",
        "                    try:\n",
        "                        assert len(mention_to_add.split()) == len(positions)\n",
        "                        mentions.append((mention_to_add,type_tag,positions))\n",
        "                    except AssertionError:\n",
        "                        print(word_tag_tuples)\n",
        "                        print(mention_to_add,type_tag,positions)\n",
        "                        return\n",
        "            # mentions.append(emoji.get_emoji_regexp().sub(u'', candidateMention).strip(string.punctuation).lower().strip())\n",
        "        # print('extracted mentions:', mentions)\n",
        "        return mentions\n",
        "\n",
        "    def normalize_to_sentences(self, text):\n",
        "        tweetSentences=list(filter (lambda sentence: len(sentence)>1, text.split('\\n')))\n",
        "        tweetSentenceList_inter=self.custom_flatten(list(map(lambda sentText: self.my_sentence_tokenizer.tokenize(sentText.lstrip().rstrip()),tweetSentences)),[])\n",
        "        tweetSentenceList=list(filter (lambda sentence: len(sentence)>1, tweetSentenceList_inter))\n",
        "        return tweetSentenceList\n",
        "\n",
        "    def custom_flatten(self, mylist, outlist, ignore_types=(str, bytes, int)):\n",
        "        \n",
        "        if (mylist !=[]):\n",
        "            for item in mylist:\n",
        "                #print not isinstance(item, ne.NE_candidate)\n",
        "                if isinstance(item, list) and not isinstance(item, ignore_types):\n",
        "                    self.custom_flatten(item, outlist)\n",
        "                else:\n",
        "                    item=item.strip(' \\t\\n\\r')\n",
        "                    outlist.append(item)\n",
        "        return outlist\n",
        "\n",
        "    def getWords(self, sentence):\n",
        "        tempList=[]\n",
        "        tempWordList=sentence.split()\n",
        "        p_dots= re.compile(r'[.]{2,}')\n",
        "        #print(tempWordList)\n",
        "        for word in tempWordList:\n",
        "            temp=[]\n",
        "\n",
        "            if \"(\" in word:\n",
        "                temp=list(filter(lambda elem: elem!='',word.split(\"(\")))\n",
        "                if(temp):\n",
        "                    temp=list(map(lambda elem: '('+elem, temp))\n",
        "            elif \")\" in word:\n",
        "                temp=list(filter(lambda elem: elem!='',word.split(\")\")))\n",
        "                if(temp):\n",
        "                    temp=list(map(lambda elem: elem+')', temp))\n",
        "                # temp.append(temp1[-1])\n",
        "    #         elif ((\"-\" in word)&(not word.endswith(\"-\"))):\n",
        "    #             temp1=list(filter(lambda elem: elem!='',word.split(\"-\")))\n",
        "    #             if(temp1):\n",
        "    #                 temp=list(map(lambda elem: elem+'-', temp1[:-1]))\n",
        "    #             temp.append(temp1[-1])\n",
        "            elif ((\"?\" in word)&(not word.endswith(\"?\"))):\n",
        "                temp1=list(filter(lambda elem: elem!='',word.split(\"?\")))\n",
        "                if(temp1):\n",
        "                    temp=list(map(lambda elem: elem+'?', temp1[:-1]))\n",
        "                temp.append(temp1[-1])\n",
        "            elif ((\":\" in word)&(not word.endswith(\":\"))):\n",
        "                temp1=list(filter(lambda elem: elem!='',word.split(\":\")))\n",
        "                if(temp1):\n",
        "                    temp=list(map(lambda elem: elem+':', temp1[:-1]))\n",
        "                temp.append(temp1[-1])\n",
        "            elif ((\",\" in word)&(not word.endswith(\",\"))):\n",
        "                #temp=list(filter(lambda elem: elem!='',word.split(\",\")))\n",
        "                temp1=list(filter(lambda elem: elem!='',word.split(\",\")))\n",
        "                if(temp1):\n",
        "                    temp=list(map(lambda elem: elem+',', temp1[:-1]))\n",
        "                temp.append(temp1[-1])\n",
        "            elif ((\"/\" in word)&(not word.endswith(\"/\"))):\n",
        "                temp1=list(filter(lambda elem: elem!='',word.split(\"/\")))\n",
        "                if(temp1):\n",
        "                    temp=list(map(lambda elem: elem+'/', temp1[:-1]))\n",
        "                temp.append(temp1[-1])\n",
        "            elif (list(p_dots.finditer(word))):\n",
        "                matched_spans= list(p_dots.finditer(word)) \n",
        "                temp=[]\n",
        "                next_string_start=0\n",
        "                for matched_span in matched_spans:\n",
        "                    matched_start=matched_span.span()[0]\n",
        "                    this_excerpt=word[next_string_start:matched_start]\n",
        "                    if(this_excerpt):\n",
        "                        temp.append(this_excerpt)\n",
        "                    next_string_start=matched_span.span()[1]\n",
        "                if(next_string_start<len(word)):\n",
        "                    last_excerpt=word[next_string_start:]\n",
        "                    if(last_excerpt):\n",
        "                        temp.append(last_excerpt)\n",
        "            elif \"…\" in word:\n",
        "                temp=list(filter(lambda elem: elem!='',word.split(\"…\")))\n",
        "                if(temp):\n",
        "                    if(word.endswith(\"…\")):\n",
        "                        temp=list(map(lambda elem: elem+'…', temp))\n",
        "                    else:\n",
        "                        temp=list(map(lambda elem: elem+'…', temp[:-1]))+[temp[-1]]\n",
        "            else:\n",
        "                #if word not in string.punctuation:\n",
        "                temp=[word]\n",
        "            if(temp):\n",
        "                tempList.append(temp)\n",
        "        tweetWordList=self.custom_flatten(tempList,[])\n",
        "        return tweetWordList\n",
        "\n",
        "    def rreplace(self,s, old, new, occurrence):\n",
        "        if s.endswith(old):\n",
        "            li = s.rsplit(old, occurrence)\n",
        "            return new.join(li)\n",
        "        else:\n",
        "            return s\n",
        "\n",
        "    def remAmpersand(self,candidateStr):\n",
        "        candidateStr=candidateStr.replace('&amp;','')\n",
        "        return candidateStr\n",
        "\n",
        "    def normalizeToken(self,token):\n",
        "        lowercased_token = token.lower()\n",
        "        if token.startswith(\"@\"):\n",
        "            return \"@USER\"\n",
        "        elif lowercased_token.startswith(\"http\") or lowercased_token.startswith(\"www\"):\n",
        "            return \"HTTPURL\"\n",
        "        elif len(token) == 1:\n",
        "            return demojize(token)\n",
        "        else:\n",
        "            if token == \"’\":\n",
        "                return \"'\"\n",
        "            elif token == \"…\":\n",
        "                return \"...\"\n",
        "            else:\n",
        "                return token\n",
        "\n",
        "    def normalizeTweet(self, tweet):\n",
        "        tokens = self.tweetTokenizer.tokenize(tweet.replace(\"’\", \"'\").replace(\"…\", \"...\"))\n",
        "        normTweet = \" \".join([self.normalizeToken(token) for token in tokens])\n",
        "\n",
        "        normTweet = normTweet.replace(\"cannot \", \"can not \").replace(\"n't \", \" n't \").replace(\"n 't \", \" n't \").replace(\"ca n't\", \"can't\").replace(\"ai n't\", \"ain't\")\n",
        "        normTweet = normTweet.replace(\"'m \", \" 'm \").replace(\"'re \", \" 're \").replace(\"'s \", \" 's \").replace(\"'ll \", \" 'll \").replace(\"'d \", \" 'd \").replace(\"'ve \", \" 've \")\n",
        "        normTweet = normTweet.replace(\" p . m .\", \"  p.m.\") .replace(\" p . m \", \" p.m \").replace(\" a . m .\", \" a.m.\").replace(\" a . m \", \" a.m \")\n",
        "\n",
        "        normTweet = re.sub(r\",([0-9]{2,4}) , ([0-9]{2,4})\", r\",\\1,\\2\", normTweet)\n",
        "        normTweet = re.sub(r\"([0-9]{1,3}) / ([0-9]{2,4})\", r\"\\1/\\2\", normTweet)\n",
        "        normTweet = re.sub(r\"([0-9]{1,3})- ([0-9]{2,4})\", r\"\\1-\\2\", normTweet)\n",
        "        \n",
        "        return normTweet\n",
        "\n",
        "    #removing commonly used expletives, enunciated chat words and other common words (like days of the week, common expressions)\n",
        "    def slang_remove(self,ne_phrase):\n",
        "        phrase=ne_phrase.strip().strip(string.punctuation).lower()\n",
        "        p1= re.compile(r'([A-Za-z]+)\\1\\1{1,}')\n",
        "        match_lst = p1.findall(phrase)\n",
        "        if phrase in article_list:\n",
        "            return True\n",
        "        elif phrase in day_list:\n",
        "            return True\n",
        "        elif phrase in month_list:\n",
        "            return True\n",
        "        elif match_lst:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def all_slang(self, ne_phrase):\n",
        "        ne_words=ne_phrase.split()\n",
        "        combined=[]+cachedStopWords+cachedTitles+chat_word_list+day_list\n",
        "        is_invalid=0\n",
        "\n",
        "        for word in ne_words:\n",
        "            if(word.strip().strip(string.punctuation).lower() in combined):\n",
        "                is_invalid+=1\n",
        "        if(is_invalid==len(ne_words)):\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def start_end_token_check(self, ne_candidate):\n",
        "        positions = ne_candidate[2]\n",
        "        entity_type = ne_candidate[1]\n",
        "        ne_words=ne_candidate[0].split()\n",
        "        combined=[]+cachedStopWords+cachedTitles+chat_word_list+day_list+prep_list+article_list\n",
        "        # print(combined)\n",
        "        # print(ne_words)\n",
        "        start_word = ne_words[0].strip().strip(string.punctuation).lower()\n",
        "        end_word = ne_words[-1].strip().strip(string.punctuation).lower()\n",
        "        while((len(ne_words)>1)&((start_word in combined)|(end_word in combined))):\n",
        "            if(start_word in combined):\n",
        "                ne_words.pop(0)\n",
        "                positions.pop(0)\n",
        "            if(end_word in combined):\n",
        "                ne_words.pop()\n",
        "                positions.pop()\n",
        "            if(len(ne_words)>1):\n",
        "                start_word = ne_words[0].strip().strip(string.punctuation).lower()\n",
        "                end_word = ne_words[-1].strip().strip(string.punctuation).lower()\n",
        "        ne_phrase = (' '.join(ne_words)).strip()\n",
        "        # print(ne_phrase)\n",
        "        return (ne_phrase,entity_type,positions)\n",
        "\n",
        "    def set_stopword_exceptions(self,words):\n",
        "        combined=cachedStopWords+prep_list+article_list+day_list\n",
        "        for word in words:\n",
        "            if word in combined:\n",
        "                self.swSet.add(word)\n",
        "\n",
        "    def extract(self, batch, batch_number):\n",
        "        print(\"Running Local NER now\")\n",
        "        time_in=time.time()\n",
        "        self.batch=batch\n",
        "        self.df_out= pd.DataFrame(columns=('tweetID', 'sentID', 'TweetSentence','tweetwordList', 'phase1Candidates','start_time','entry_batch'))\n",
        "        df_holder=[]\n",
        "        self.swSet= set()\n",
        "\n",
        "        if(self.counter==0):\n",
        "            #self.df_out= pd.DataFrame(columns=('tweetID', 'sentID', 'hashtags', 'user', 'TweetSentence', 'phase1Candidates','correct_candidates_tweet'))\n",
        "            #dict1 = {'tweetID':0, 'sentID':0, 'hashtags':'first', 'user':'user', 'TweetSentence':'sentence', 'phase1Candidates':'phase1Out','start_time':'now','entry_batch':'batch_number'}\n",
        "            self.CTrie=trie.Trie(\"ROOT\")\n",
        "            self.phase2stopWordList=[]\n",
        "            self.sentenceID = 0\n",
        "            self.f=0\n",
        "            self.phaseIpredictions=[]\n",
        "\n",
        "        for row in self.batch.itertuples():\n",
        "\n",
        "            now = datetime.datetime.now()\n",
        "            tweetID=str(row.Index)\n",
        "            text=str(row.TweetText)\n",
        "            row_sentences = self.normalize_to_sentences(text)\n",
        "\n",
        "            annnotated_mentions=[]\n",
        "\n",
        "            #Comment out when no annotations available\n",
        "            annnotated_mentions=[]\n",
        "            annotations = str(row.mentions_other).strip()\n",
        "            print(tweetID, annotations)\n",
        "            if(annotations):\n",
        "                for sentence_level in annotations.split(';'):\n",
        "                    sentence_level=sentence_level.strip()\n",
        "                    if(sentence_level):\n",
        "                        for elem in sentence_level.split(','):\n",
        "                            elem = elem.strip()\n",
        "                            if(elem):\n",
        "                                mention_record = elem.split('|')\n",
        "                                if(mention_record):\n",
        "                                    mention, entity_type =  mention_record[0], mention_record[1].lower()\n",
        "                                    if(mention):\n",
        "                                        if((mention !='')&(mention !='nan')):\n",
        "                                            mention = mention.lower().strip(string.punctuation).strip()\n",
        "                                            if(mention.startswith('the ')):\n",
        "                                                mention = mention[4:]\n",
        "                                                mention = mention.lower().strip(string.punctuation).strip()\n",
        "                                            annnotated_mentions.append((mention, entity_type))\n",
        "\n",
        "            self.tweet_to_sentences_w_annotation[tweetID]=((self.sentenceID,self.sentenceID+len(row_sentences)),annnotated_mentions)\n",
        "            self.sentenceID+=len(row_sentences)\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for sen_index, sentence in enumerate(row_sentences):\n",
        "\n",
        "                    # print('tuple index:',tweetID,sen_index)\n",
        "                    phase1Out=\"\"\n",
        "                    sentence = self.normalizeTweet(sentence)\n",
        "                    # tweetWordList=self.getWords(sentence)\n",
        "                    tweetWordList = sentence.split()\n",
        "                    tweetWordList = list(filter(lambda element: not element.startswith('http://'), tweetWordList))\n",
        "                    sentence=(' '.join(tweetWordList)).strip()\n",
        "                    enumerated_tweetWordList=[(token,idx) for idx,token in enumerate(tweetWordList)]\n",
        "\n",
        "                    entities_from_sentence=[] #with positions\n",
        "                    entity_predictions=[]\n",
        "                    entity_aware_embeddings=[]\n",
        "\n",
        "                    if(len(tweetWordList)>0):\n",
        "\n",
        "                        # print(test_record)\n",
        "                        # tokenized_input=tokenizer(test_record)\n",
        "                        # initial_input_ids = torch.tensor([tokenizer.encode(test_record)])\n",
        "                        # token_dict = {x : tokenizer.encode(x, add_special_tokens=False) for x in test_record.split()}\n",
        "                        # input_ids = initial_input_ids.to(device)\n",
        "                        # tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
        "\n",
        "                        tokenized_input= self.nerTokenizer(sentence)\n",
        "                        initial_input_ids = torch.tensor([self.nerTokenizer.encode(sentence)])\n",
        "                        # num_tokens = initial_input_ids.shape[1]\n",
        "\n",
        "                        initial_input_ids = initial_input_ids[:,:128]\n",
        "                        token_dict = {x : self.nerTokenizer.encode(x, add_special_tokens=False) for x in sentence.split()} #token, add_special_tokens=False, truncation=True\n",
        "                        input_ids = initial_input_ids.to(self.device)\n",
        "                        tokens = self.nerTokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
        "\n",
        "                        output = self.localNEREngine(input_ids)\n",
        "                        token_embeddings=output.hidden_states[-1].squeeze()[1:-1] # we dont need embeddings for CLS and EOS\n",
        "\n",
        "                        assert torch.isnan(token_embeddings).any() == False\n",
        "\n",
        "                        prediction = (torch.argmax(output.logits, axis=2))\n",
        "                        prediction = prediction.cpu().numpy().reshape(-1)\n",
        "\n",
        "                        # prediction_labels=[self.label_list[l].split('-')[0] for l in prediction]\n",
        "                        prediction_labels=[self.label_list[l] for l in prediction]\n",
        "\n",
        "                        prediction_labels, entity_aware_embeddings=self.collate_token_label_embedding(tweetWordList, token_dict, prediction_labels[1:-1],token_embeddings)\n",
        "\n",
        "                        assert len(enumerated_tweetWordList)==len(entity_aware_embeddings)\n",
        "                        assert len(prediction_labels)==len(enumerated_tweetWordList)\n",
        "\n",
        "                        word_tag_tuples=list(zip(tweetWordList,prediction_labels))\n",
        "                        print(list(word_tag_tuples))\n",
        "                        entities_from_sentence=self.get_entities(word_tag_tuples)\n",
        "                        print('entities_from_sentence:',entities_from_sentence)\n",
        "\n",
        "                        if(self.f<5):\n",
        "                            print(len(tweetWordList),initial_input_ids.shape,len(prediction[1:-1]))\n",
        "                            print(tweetWordList)\n",
        "                            print(token_dict)\n",
        "                            print(initial_input_ids)\n",
        "                            print(input_ids)\n",
        "                            print(prediction_labels)\n",
        "                            print('entities_from_sentence:',entities_from_sentence)\n",
        "                            print('======')\n",
        "                            self.f+=1\n",
        "\n",
        "                    just_candidates=[]\n",
        "\n",
        "                    # place some necessary filters\n",
        "                    entities_from_sentence= list(filter(lambda element: not self.slang_remove(element[0]), entities_from_sentence))\n",
        "                    entities_from_sentence= list(map(lambda element: self.start_end_token_check(element), entities_from_sentence))\n",
        "                    entities_from_sentence= list(filter(lambda element: not self.all_slang(element[0]), entities_from_sentence))\n",
        "                    entities_from_sentence= list(filter(lambda element: len(element[0])>1, entities_from_sentence))\n",
        "                    entities_from_sentence= list(filter(lambda element: element[0]!='', entities_from_sentence))\n",
        "\n",
        "                    \n",
        "\n",
        "                    for candidateTuple in entities_from_sentence:\n",
        "                        #self.insert_dict (candidate,self.NE_container,candidateBase,index,candidate.sen_index,batch_number)\n",
        "                        candidateText, entity_type, positions = candidateTuple\n",
        "\n",
        "                        entity_predictions.append((candidateText, entity_type))\n",
        "\n",
        "                        candidateText=(((candidateText.lstrip(string.punctuation)).rstrip(string.punctuation)).strip(' \\t\\n\\r')).lower()\n",
        "                        candidateText=(self.remAmpersand(candidateText).lstrip('“‘’”')).rstrip('“‘’”')\n",
        "                        candidateText= self.rreplace(self.rreplace(self.rreplace(candidateText,\"'s\",\"\",1),\"’s\",\"\",1),\"’s\",\"\",1)\n",
        "                        candidateText= candidateText.strip()\n",
        "                        self.set_stopword_exceptions(candidateText.split())\n",
        "                        just_candidates.append(candidateText)\n",
        "                        # if(index==9423):\n",
        "                        #     print(candidateText)\n",
        "                        position = '*'+'*'.join(str(v) for v in positions)\n",
        "                        position=position+'*'\n",
        "\n",
        "                        phase1Out+=(((candidateText).lstrip(string.punctuation)).strip())+'::'+str(position)+\"::\"+entity_type+\"||\"\n",
        "\n",
        "                        combined=[]+cachedStopWords+cachedTitles+prep_list+chat_word_list+article_list+day_list\n",
        "                        if not ((candidateText in combined)|(len(candidateText)<=1)|(candidateText.isdigit())|(self.is_float(candidateText))):\n",
        "                            if(self.quickRegex.match(candidateText)):\n",
        "                                self.CTrie.__setitem__(candidateText.split(),len(candidateText.split()),[],batch_number)\n",
        "                    \n",
        "                    print('candidate_strings_from_sentence:',just_candidates)\n",
        "                    self.phaseIpredictions.append(entity_predictions)\n",
        "                    #storing the outputs and token embeddings in dataframe tweetID,sen_index\n",
        "                    dict1 = {'tweetID':str(tweetID), 'sentID':str(sen_index), 'TweetSentence':sentence, 'tweetwordList': enumerated_tweetWordList,'phase1Candidates': just_candidates ,'phase1CandidatesWPositions':phase1Out,\n",
        "                             'contextual_embeddings':entity_aware_embeddings,\n",
        "                             'start_time':now,'entry_batch':batch_number}\n",
        "                    df_holder.append(dict1)\n",
        "                    # self.contextual_embeddings[(tweetID,sen_index)] = entity_aware_embeddings\n",
        "\n",
        "        time_out=time.time()\n",
        "        self.append_rows(df_holder)\n",
        "        self.phase2stopWordList=list(set(self.phase2stopWordList)|self.swSet)\n",
        "        self.counter=self.counter+1\n",
        "        \n",
        "        #return (copy.deepcopy(self.df_out),copy.deepcopy(freqs),time_in,time_out)\n",
        "        return (self.df_out,self.contextual_embeddings,self.CTrie,time_in,time_out,self.phase2stopWordList,self.tweet_to_sentences_w_annotation)\n",
        "\n",
        "    def append_rows(self,df_holder):\n",
        "    \n",
        "        df = pd.DataFrame(df_holder)\n",
        "        self.df_out=self.df_out.append(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_4GphEbGUen"
      },
      "source": [
        "## **Phase II: Global NER with Phrase Embedder to collect the Entity Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBKfLqJPHLcw"
      },
      "outputs": [],
      "source": [
        "# coding: utf-8\n",
        "from nltk.corpus import stopwords\n",
        "import pandas  as pd\n",
        "# import NE_candidate_module as ne\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import string\n",
        "import copy\n",
        "import numpy\n",
        "import math\n",
        "from itertools import groupby\n",
        "from operator import itemgetter\n",
        "from collections import Iterable, OrderedDict\n",
        "from scipy import stats\n",
        "import emoji\n",
        "import statistics\n",
        "import pandas as pd\n",
        "import time\n",
        "import datetime\n",
        "import trie as trie\n",
        "import re\n",
        "import ast\n",
        "import pickle\n",
        "import itertools\n",
        "from scipy import spatial\n",
        "\n",
        "# from sklearn.preprocessing import PolynomialFeatures\n",
        "# from sklearn import linear_model\n",
        "# from sklearn.cluster import KMeans, MeanShift\n",
        "# from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "# Clustering imports\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "import scipy.cluster.hierarchy as shc\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "import torch\n",
        "\n",
        "#CLASSIFIER CLASS\n",
        "# import SVM as svm\n",
        "# import entityClassifier as entityClassifier\n",
        "\n",
        "cachedStopWords = stopwords.words(\"english\")\n",
        "tempList=[\"i\",\"and\",\"or\",\"since\",\"hence\",\"onto\",\"other\",\"another\",\"across\",\"unlike\",\"anytime\",\"were\",\"you\",\"then\",\"still\",\"till\",\"nor\",\"perhaps\",\"probably\",\"otherwise\",\"until\",\"sometimes\",\"sometime\",\"seem\",\"cannot\",\"seems\",\"because\",\"can\",\"like\",\"into\",\"able\",\"unable\",\"either\",\"neither\",\"if\",\"we\",\"it\",\"else\",\"elsewhere\",\"how\",\"not\",\"what\",\"who\",\"when\",\"where\",\"who's\",\"who’s\",\"let\",\"today\",\"tomorrow\",\"tonight\",\"let's\",\"let’s\",\"lets\",\"know\",\"make\",\"oh\",\"via\",\"i\",\"yet\",\"must\",\"mustnt\",\"mustn't\",\"mustn’t\",\"i'll\",\"i’ll\",\"you'll\",\"you’ll\",\"we'll\",\"we’ll\",\"done\",\"doesnt\",\"doesn't\",\"doesn’t\",\"dont\",\"don't\",\"don’t\",\"did\",\"didnt\",\"didn't\",\"didn’t\",\"much\",\"without\",\"could\",\"couldn't\",\"couldn’t\",\"would\",\"wouldn't\",\"wouldn’t\",\"should\",\"shouldn't\",\"souldn’t\",\"shall\",\"isn't\",\"isn’t\",\"hasn't\",\"hasn’t\",\"wasn't\",\"wasn’t\",\"also\",\"let's\",\"let’s\",\"let\",\"well\",\"just\",\"everyone\",\"anyone\",\"noone\",\"none\",\"someone\",\"theres\",\"there's\",\"there’s\",\"everybody\",\"nobody\",\"somebody\",\"anything\",\"else\",\"elsewhere\",\"something\",\"nothing\",\"everything\",\"i'd\",\"i’d\",\"i’m\",\"won't\",\"won’t\",\"i’ve\",\"i've\",\"they're\",\"they’re\",\"we’re\",\"we're\",\"we'll\",\"we’ll\",\"we’ve\",\"we've\",\"they’ve\",\"they've\",\"they’d\",\"they'd\",\"they’ll\",\"they'll\",\"again\",\"you're\",\"you’re\",\"you've\",\"you’ve\",\"thats\",\"that's\",'that’s','here’s',\"here's\",\"what's\",\"what’s\",\"i’m\",\"i'm\",\"a\",\"so\",\"except\",\"arn't\",\"aren't\",\"arent\",\"this\",\"when\",\"it\",\"it’s\",\"it's\",\"he's\",\"she's\",\"she'd\",\"he'd\",\"he'll\",\"she'll\",\"she’ll\",\"many\",\"can't\",\"cant\",\"can’t\",\"even\",\"yes\",\"no\",\"these\",\"here\",\"there\",\"to\",\"maybe\",\"<hashtag>\",\"<hashtag>.\",\"ever\",\"every\",\"never\",\"there's\",\"there’s\",\"whenever\",\"wherever\",\"however\",\"whatever\",\"always\",\"although\"]\n",
        "for item in tempList:\n",
        "    if item not in cachedStopWords:\n",
        "        cachedStopWords.append(item)\n",
        "cachedStopWords.remove(\"don\")\n",
        "# cachedStopWords.remove(\"your\")\n",
        "# cachedStopWords.remove(\"us\")\n",
        "cachedTitles = [\"mr.\",\"mr\",\"mrs.\",\"mrs\",\"miss\",\"ms\",\"sen.\",\"dr\",\"dr.\",\"prof.\",\"president\",\"congressman\"]\n",
        "prep_list=[\"of\",\"&;\",\"v.\"] #includes common conjunction as well\n",
        "# prep_list=[]\n",
        "# article_list=[]\n",
        "article_list=[\"a\",\"an\",\"the\"]\n",
        "conjoiner=[\"de\"]\n",
        "day_list=[\"sunday\",\"monday\",\"tuesday\",\"wednesday\",\"thursday\",\"friday\",\"saturday\",\"mon\",\"tues\",\"wed\",\"thurs\",\"fri\",\"sat\",\"sun\"]\n",
        "month_list=[\"january\",\"february\",\"march\",\"april\",\"may\",\"june\",\"july\",\"august\",\"september\",\"october\",\"november\",\"december\",\"jan\",\"feb\",\"mar\",\"apr\",\"may\",\"jun\",\"jul\",\"aug\",\"sep\",\"oct\",\"nov\",\"dec\"]\n",
        "chat_word_list=[\"nope\",\"httpurl\",\"n't\",\"&amp;\",\"gee\",\"€\",\"hmm\",\"bye\",\"pls\",\"please\",\"yrs\",\"4get\",\"cbb\",\"tmi\",\"ooh\",\"ouch\",\"am\",\"tv\",\"ima\",\"tmw\",\"og\",\"psst\",\"b.s\",\"thanku\",\"em\",\"qft\",\"ip\",\"icymi\",\"bdsm\",\"ah\",\"http\",\"https\",\"pm\",\"omw\",\"pts\",\"pt\",\"ive\",\"reppin\",\"idk\",\"oops\",\"yup\",\"stfu\",\"uhh\",\"2b\",\"dear\",\"yay\",\"btw\",\"ahhh\",\"b4\",\"ugh\",\"ty\",\"cuz\",\"coz\",\"sorry\",\"yea\",\"asap\",\"ur\",\"bs\",\"rt\",\"lmfao\",\"lfmao\",\"slfmao\",\"u\",\"r\",\"nah\",\"umm\",\"ummm\",\"thank\",\"thanks\",\"congrats\",\"whoa\",\"rofl\",\"ha\",\"ok\",\"okay\",\"hey\",\"hi\",\"huh\",\"ya\",\"yep\",\"yeah\",\"fyi\",\"duh\",\"damn\",\"lol\",\"omg\",\"congratulations\",\"fucking\",\"fuck\",\"f*ck\",\"wtf\",\"wth\",\"aka\",\"wtaf\",\"xoxo\",\"rofl\",\"imo\",\"wow\",\"fck\",\"haha\",\"hehe\",\"hoho\"]\n",
        "string.punctuation=string.punctuation+'…‘’'\n",
        "punct = string.punctuation\n",
        "punct=punct.replace(\".\",\"\",1)\n",
        "# print(punct)\n",
        "\n",
        "\n",
        "\n",
        "class GlobalNERModule():\n",
        "\n",
        "\n",
        "    def executor(self,max_batch_value,TweetBase,CTrie,phase2stopwordList,z_score_threshold,reintroduction_threshold,raw_tweets_for_others):\n",
        "\n",
        "\n",
        "        # SET CB\n",
        "        # print(phase2stopwordList)\n",
        "        candidate_featureBase_DF,data_frame_holder,phase2_candidates_holder,phase2_unnormalized_candidates_holder = self.set_cb(TweetBase,CTrie,phase2stopwordList,z_score_threshold,reintroduction_threshold)\n",
        "        candidate_df = candidate_featureBase_DF[['candidate','class']]\n",
        "        for index, row in candidate_df.iterrows():\n",
        "            print(row['candidate']+' : '+str(row['class']))\n",
        "        candidate_df.to_csv(\"candidate_records.csv\", sep=',', encoding='utf-8',index=False)\n",
        "\n",
        "\n",
        "        # # SET TF \n",
        "        ner_arrays = self.set_tf(data_frame_holder, candidate_featureBase_DF,phase2_candidates_holder,phase2_unnormalized_candidates_holder)\n",
        "\n",
        "        # self.calculate_tp_fp_f1(z_score_threshold,untrashed_tweets,raw_tweets_for_others)\n",
        "\n",
        "        # # return candidate_featureBase_DF, self.complete_tweet_dataframe_grouped_df_sorted,time_out \n",
        "        return ner_arrays\n",
        "\n",
        "\n",
        "    def __init__(self,entity_phrase_embedder,device,filename):\n",
        "        self.counter=0\n",
        "        self.decay_factor=2**(-1/2)\n",
        "        self.decay_base_staggering=2\n",
        "        self.true_positive_count=0\n",
        "        self.false_positive_count=0\n",
        "        self.false_negative_count=0\n",
        "        self.device=device\n",
        "        self.save_file= filename\n",
        "\n",
        "        self.entity_phrase_embedder = entity_phrase_embedder\n",
        "\n",
        "        # context_feature_list=['cf_'+str(i) for i in range(768)]\n",
        "        context_feature_list=['cf_'+str(i) for i in range(300)]\n",
        "        self.candidateBaseHeaders=['candidate', 'batch', 'length','cap','substring-cap','s-o-sCap','all-cap','non-cap','non-discriminative']+context_feature_list+['cumulative']\n",
        "        self.candidateBaseHeaders_alt=['candidate', 'batch', 'length','cumulative','class']\n",
        "        self.complete_tweet_dataframe_grouped_df_sorted=pd.DataFrame([], columns=['tweetID', 'TweetSentence', 'ambiguous_candidates', 'annotation', 'candidates_with_label', 'completeness', 'current_minus_entry', 'entry_batch', 'hashtags', 'index', 'only_good_candidates', 'output_mentions', 'phase1Candidates', 'sentID', 'stanford_candidates', 'user'])\n",
        "\n",
        "\n",
        "    def classify_candidate_base(self,z_score_threshold,candidate_featureBase_DF):\n",
        "\n",
        "        # zscore_array1=stats.zscore(candidate_featureBase_DF['cumulative'])\n",
        "\n",
        "        # candidate_featureBase_DF['Z_ScoreUnweighted']=zscore_array1\n",
        "        # cumulative_threshold=1.0 #set threshold here\n",
        "        # z_score_threshold=candidate_featureBase_DF[candidate_featureBase_DF['cumulative']==cumulative_threshold].Z_ScoreUnweighted.tolist()[0]\n",
        "        # print(cumulative_threshold,z_score_threshold)\n",
        "        # #candidate_featureBase_DF.to_csv(\"cf_new_with_z_score.csv\", sep=',', encoding='utf-8')\n",
        "\n",
        "        # #multi-word infrequent candidates ---> to be used for recall correction\n",
        "        # infrequent_candidates=candidate_featureBase_DF[(candidate_featureBase_DF['Z_ScoreUnweighted'] < z_score_threshold) & (candidate_featureBase_DF.length>1)].candidate.tolist()\n",
        "        # candidate_featureBase_DF = candidate_featureBase_DF[candidate_featureBase_DF['Z_ScoreUnweighted'] >= z_score_threshold]\n",
        "        return self.entity_classifier_alt.run(candidate_featureBase_DF,self.candidateEmbeddingDict)\n",
        "\n",
        "    # recall_correction\n",
        "    def set_partition_dict(self,candidate_featureBase_DF,infrequent_candidates):\n",
        "\n",
        "        #print(list(self.partition_dict.keys()))\n",
        "        ambiguous_bad_candidates=candidate_featureBase_DF[(((candidate_featureBase_DF.status==\"a\")|(candidate_featureBase_DF.status==\"b\"))&(candidate_featureBase_DF.length.astype(int)>1))]\n",
        "        good_candidates=candidate_featureBase_DF[(candidate_featureBase_DF.status==\"g\")].candidate.tolist()\n",
        "        flag1=False\n",
        "        flag2=False\n",
        "        if(len(ambiguous_bad_candidates)>0):\n",
        "            # ambiguous_bad_candidates['max_column'] =ambiguous_bad_candidates[['cap','substring-cap','s-o-sCap','all-cap','non-cap','non-discriminative']].idxmax(axis=1) \n",
        "            # ambiguous_bad_candidates_wFilter= ambiguous_bad_candidates[ambiguous_bad_candidates.max_column=='substring-cap']\n",
        "\n",
        "            #good_candidates=candidate_featureBase_DF[(candidate_featureBase_DF.status==\"g\")].candidate.tolist()\n",
        "            #print(ambiguous_bad_candidates_wFilter.candidate.tolist())\n",
        "\n",
        "            # for candidate in ambiguous_bad_candidates_wFilter.candidate.tolist():\n",
        "            for candidate in ambiguous_bad_candidates.candidate.tolist():\n",
        "                \n",
        "                #print(candidate)\n",
        "                if candidate not in self.partition_dict.keys():\n",
        "\n",
        "                    substring_candidates=self.get_substring_candidates(candidate.split(),good_candidates)\n",
        "                    if(len(substring_candidates)>0):\n",
        "                        self.partition_dict[candidate]=substring_candidates\n",
        "\n",
        "            flag1= True\n",
        "        if(len(infrequent_candidates)>0):\n",
        "            #print(len(ambiguous_bad_candidates_wFilter.candidate.tolist()))\n",
        "\n",
        "            for candidate in infrequent_candidates:\n",
        "                #print(candidate)\n",
        "                if candidate not in self.partition_dict.keys():\n",
        "                    substring_candidates=self.get_substring_candidates(candidate.split(),good_candidates)\n",
        "                    if(len(substring_candidates)>0):\n",
        "                        self.partition_dict[candidate]=substring_candidates\n",
        "            flag2= True\n",
        "        print(list(self.partition_dict.keys()))\n",
        "        return (flag1|flag2)\n",
        "\n",
        "    def update_Candidatedict(self,candidate,cluster_id,contextual_embedding_vector):\n",
        "        \n",
        "        alt_feature_list=[] # this is for the reduced CandidateBase for the Alt_Classifier\n",
        "        candidate_name = candidate+'||'+cluster_id\n",
        "\n",
        "        if(candidate_name in self.CandidateBase_dict_alt.keys()):\n",
        "            # feature_list=self.CandidateBase_dict[normalized_candidate]\n",
        "            alt_feature_list=self.CandidateBase_dict_alt[candidate_name]\n",
        "        else:\n",
        "            alt_feature_list=[0]*4\n",
        "            alt_feature_list[0]=self.counter\n",
        "            alt_feature_list[1]=len(candidate.split())\n",
        "            alt_feature_list[2]=0\n",
        "            alt_feature_list[3]=-1\n",
        "\n",
        "        alt_feature_list[2]+=1 #increase cumulative frequency\n",
        "        self.CandidateBase_dict_alt[candidate_name]=alt_feature_list\n",
        "\n",
        "        if((candidate,cluster_id) in self.candidateEmbeddingDict.keys()):\n",
        "            self.candidateEmbeddingDict[(candidate,cluster_id)].append(contextual_embedding_vector)\n",
        "        else:\n",
        "            self.candidateEmbeddingDict[(candidate,cluster_id)]=[contextual_embedding_vector]\n",
        "        return\n",
        "\n",
        "    def get_candidate_clusters(self, candidate, input_arr):\n",
        "        if(len(input_arr)>1):\n",
        "            print(candidate)\n",
        "            # X = np.nan_to_num(np.array(input_arr))\n",
        "            X = np.array(input_arr)\n",
        "            # print(X)\n",
        "            # clusterer = AgglomerativeClustering(n_clusters=5, affinity=\"cosine\", linkage=\"single\") #total 5 entity type clusters can be formed\n",
        "            # cluster_labels = clusterer.fit_predict(X)\n",
        "\n",
        "            # clusterer = AgglomerativeClustering(n_clusters=None, affinity='cosine', linkage='complete', compute_full_tree=True, distance_threshold=1.0)\n",
        "            clusterer = AgglomerativeClustering(n_clusters=None, affinity='cosine', linkage='average', compute_full_tree=True, distance_threshold=0.999)\n",
        "            # clusterer = AgglomerativeClustering(n_clusters=None, affinity='cosine', linkage='single', compute_full_tree=True, distance_threshold=1.0)\n",
        "\n",
        "            # clusterer = AgglomerativeClustering(n_clusters=None, affinity='euclidean', linkage='ward', compute_full_tree=True, distance_threshold=1.0)\n",
        "\n",
        "            cluster_labels = clusterer.fit_predict(X)\n",
        "            # print(\"Number of clusters for \"+candidate+\" : \"+str(1+np.amax(cluster_labels)))\n",
        "\n",
        "            # range_n_clusters = [1, 2, 3, 4, 5]\n",
        "            # max_silhouette = float('-inf')\n",
        "            # for n_clusters in range_n_clusters:\n",
        "            #     if(n_clusters <= len(X)):\n",
        "            #         clusterer = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "            #         labels = clusterer.fit_predict(X)\n",
        "            #         silhouette = silhouette_score(X, cluster_labels)\n",
        "            #         if(silhouette>max_silhouette):\n",
        "            #             max_silhouette = silhouette\n",
        "            #             cluster_labels = labels\n",
        "        else:\n",
        "            cluster_labels = np.array([0])\n",
        "\n",
        "        # print(cluster_labels)\n",
        "        return cluster_labels\n",
        "    \n",
        "    def set_cb(self,TweetBase,CTrie,phase2stopwordList,z_score_threshold,reintroduction_threshold):\n",
        "\n",
        "        #input new_tweets, z_score, Updated candidatebase of phase1\n",
        "        #output candidate_featureBase_DF, Incomplete_tweets\n",
        "        data_frame_holder=pd.DataFrame([], columns=['index','entry_batch','tweetID', 'sentID', 'TweetSentence','phase1Candidates', '2nd Iteration Candidates', '2nd Iteration Candidates Unnormalized'])\n",
        "        phase2_candidates_holder=[]\n",
        "        phase2_unnormalized_candidates_holder=[]\n",
        "        df_holder=[]\n",
        "\n",
        "        df_holder_extracted,phase2_candidates_holder_extracted,phase2_unnormalized_candidates_holder_extracted= self.extract(TweetBase,CTrie,phase2stopwordList,0)\n",
        "        phase2_candidates_holder.extend(phase2_candidates_holder_extracted)\n",
        "        phase2_unnormalized_candidates_holder.extend(phase2_unnormalized_candidates_holder_extracted)\n",
        "        df_holder.extend(df_holder_extracted)\n",
        "\n",
        "        data_frame_holder = pd.DataFrame(df_holder)\n",
        "\n",
        "        #perform clustering over mentions of each candidate in self.candidateEmbeddingPool\n",
        "        for candidate in self.candidateEmbeddingPool.keys():\n",
        "            labels = self.get_candidate_clusters(candidate, self.candidateEmbeddingPool[candidate])\n",
        "            for ind,int_label in enumerate(labels):\n",
        "                # print(self.candidateEmbedding_records[candidate][ind])\n",
        "                label = str(int_label)\n",
        "                mention_embedding_vector = self.candidateEmbedding_records[candidate][ind][0]\n",
        "                assert self.candidateEmbeddingPool[candidate][ind] == mention_embedding_vector.tolist()\n",
        "                self.candidateEmbedding_records[candidate][ind] += (label,)\n",
        "                # print(self.candidateEmbedding_records[candidate][ind])\n",
        "                self.update_Candidatedict(candidate,label,mention_embedding_vector)\n",
        "\n",
        "        # #self.CandidateBase_dict_alt and self.candidateEmbeddingDict are formed after candidate clusters have been separated\n",
        "        candidate_featureBase_DF_alt = pd.DataFrame.from_dict(self.CandidateBase_dict_alt, orient='index')\n",
        "\n",
        "        candidate_featureBase_DF_alt.columns = self.candidateBaseHeaders_alt[1:]\n",
        "        candidate_featureBase_DF_alt.index.name = self.candidateBaseHeaders_alt[0]\n",
        "        candidate_featureBase_DF_alt  = candidate_featureBase_DF_alt.reset_index(drop=False)\n",
        "\n",
        "        # print(candidate_featureBase_DF_alt.head(5))\n",
        "        # for elem in list(self.candidateEmbeddingDict.keys())[:5]:\n",
        "        #     print(elem, len(self.candidateEmbeddingDict[elem]))\n",
        "\n",
        "        #initialize and classify\n",
        "        self.entity_classifier_alt = EntityClassifierAlt(False,self.device,None,None)\n",
        "        candidate_featureBase_DF= self.classify_candidate_base(z_score_threshold,candidate_featureBase_DF_alt)\n",
        "\n",
        "        return candidate_featureBase_DF,data_frame_holder,phase2_candidates_holder,phase2_unnormalized_candidates_holder\n",
        "\n",
        "    def set_tf(self,data_frame_holder, candidate_featureBase_DF, phase2_candidates_holder,phase2_unnormalized_candidates_holder):\n",
        "        entity_mentions_holder = []\n",
        "        for phase2_mentions in phase2_candidates_holder:\n",
        "            row_entity_mentions=[]\n",
        "            for mention in phase2_mentions:\n",
        "                # print(mention)\n",
        "                mention_record = mention.split('||')\n",
        "                candidate, mention_id = mention_record[0], int(mention_record[1])\n",
        "                # print(self.candidateEmbedding_records[candidate][mention_id])\n",
        "                cluster_id = self.candidateEmbedding_records[candidate][mention_id][1]\n",
        "                class_value = candidate_featureBase_DF[candidate_featureBase_DF['candidate'] == candidate+'||'+cluster_id]['class'].tolist()[0]\n",
        "                class_label = self.entity_classifier_alt.entity_types[class_value]\n",
        "                if(class_label!='ne'):\n",
        "                    row_entity_mentions.append((candidate,class_label))\n",
        "            entity_mentions_holder.append(row_entity_mentions)\n",
        "        data_frame_holder[\"only_good_candidates\"]=entity_mentions_holder\n",
        "        return entity_mentions_holder\n",
        "\n",
        "    def get_incomplete_tf(self,untrashed_tweets):\n",
        "        return untrashed_tweets[untrashed_tweets.completeness==False]\n",
        "\n",
        "    def get_complete_tf(self,untrashed_tweets):\n",
        "        return untrashed_tweets[untrashed_tweets.completeness==True]\n",
        "\n",
        "    def compute_seen_tweets_so_far(self,start_batch,end_batch):\n",
        "        if(start_batch==end_batch):\n",
        "            sliced_seen_tweets=self.number_of_seen_tweets_per_batch[start_batch]\n",
        "\n",
        "\n",
        "        sliced_seen_tweets=self.number_of_seen_tweets_per_batch[start_batch:]\n",
        "\n",
        "\n",
        "        counter=0\n",
        "        for elem in sliced_seen_tweets:\n",
        "            counter=counter+elem\n",
        "\n",
        "        return counter\n",
        "\n",
        "\n",
        "    def rreplace(self,s, old, new, occurrence):\n",
        "        if s.endswith(old):\n",
        "            li = s.rsplit(old, occurrence)\n",
        "            return new.join(li)\n",
        "        else:\n",
        "            return s\n",
        "    #ME_EXTR=Mention.Mention_Extraction()\n",
        "\n",
        "\n",
        "\n",
        "    def set_column_for_candidates_in_incomplete_tweets(self,candidate_featureBase_DF,input_to_eval):\n",
        "\n",
        "        incomplete_candidates= input_to_eval['2nd Iteration Candidates'].tolist()\n",
        "\n",
        "        candidate_featureBase_DF= candidate_featureBase_DF.set_index('candidate')\n",
        "\n",
        "        candidate_with_label_holder=[]\n",
        "        one_level=[]\n",
        "        \n",
        "\n",
        "        for sentence_level_candidates in incomplete_candidates:\n",
        "\n",
        "            one_level.clear()\n",
        "\n",
        "            for candidate in sentence_level_candidates:\n",
        "                if candidate.lower() in candidate_featureBase_DF.index:\n",
        "                    # label=candidate_featureBase_DF.get_value(candidate.lower(),'status')\n",
        "                    label=candidate_featureBase_DF.at[candidate.lower(),'status']\n",
        "                    one_level.append((candidate,label))\n",
        "                else:\n",
        "                    one_level.append((candidate,\"na\"))\n",
        "\n",
        "            candidate_with_label_holder.append(copy.deepcopy(one_level))\n",
        "\n",
        "\n",
        "        input_to_eval[\"candidates_with_label\"]=candidate_with_label_holder\n",
        "        debug_candidates_label_list= input_to_eval['candidates_with_label'].tolist()\n",
        "        candidates_filtered_g_labeled=[]\n",
        "        row_level_candidates=[]\n",
        "        index_outer=0\n",
        "\n",
        "        candidates_filtered_a_labeled=[]\n",
        "        row_level_a_candidates=[]\n",
        "\n",
        "        for sentence_level in debug_candidates_label_list:\n",
        "\n",
        "            # sentence_level_candidates_unnormalized= incomplete_candidates_unnormalized[index_outer]\n",
        "            row_level_candidates.clear()\n",
        "            row_level_a_candidates.clear()\n",
        "            for candidate in sentence_level:\n",
        "                if(candidate[1]==\"g\"):\n",
        "                    candidate_str = self.erode_article(candidate[0])\n",
        "                    row_level_candidates.append(candidate_str)\n",
        "                if(((candidate[1]==\"b\")|(candidate[1]==\"a\"))&(candidate[0]==\"US\")):\n",
        "                    # print('here')\n",
        "                    row_level_candidates.append(candidate[0])\n",
        "                if(candidate[1]==\"a\"):\n",
        "                    row_level_a_candidates.append(candidate[0])\n",
        "\n",
        "            candidates_filtered_g_labeled.append(copy.deepcopy(row_level_candidates))\n",
        "            candidates_filtered_a_labeled.append(copy.deepcopy(row_level_a_candidates))\n",
        "            index_outer+=1\n",
        "\n",
        "\n",
        "        input_to_eval[\"only_good_candidates\"]=candidates_filtered_g_labeled\n",
        "        input_to_eval[\"ambiguous_candidates\"]=candidates_filtered_a_labeled\n",
        "\n",
        "\n",
        "\n",
        "    def calculate_tp_fp_f1(self,z_score_threshold,input_to_eval,raw_tweets_for_others):\n",
        "\n",
        "        input_to_eval_grouped_df= (input_to_eval.groupby('tweetID', as_index=False).aggregate(lambda x: x.tolist()))\n",
        "        input_to_eval_grouped_df['tweetID']=input_to_eval_grouped_df['tweetID'].astype(int)\n",
        "        input_to_eval_df_sorted=(input_to_eval_grouped_df.sort_values(by='tweetID', ascending=True)).reset_index(drop=True)\n",
        "\n",
        "        print(len(input_to_eval_df_sorted),len(raw_tweets_for_others))\n",
        "        \n",
        "        print(set(input_to_eval_df_sorted['tweetID'].values.tolist())-set(raw_tweets_for_others['ID'].values.tolist()))\n",
        "\n",
        "        input_to_eval_df_sorted['annotation']=input_to_eval_df_sorted['tweetID'].apply(lambda x: raw_tweets_for_others[raw_tweets_for_others['ID']==x]['mentions_other'].iloc[0])\n",
        "        # input_to_eval_df_sorted['annotation']=input_to_eval_df_sorted['tweetID'].apply(lambda x: raw_tweets_for_others[raw_tweets_for_others['ID']==x]['mentions_limited_types'].iloc[0])\n",
        "        # input_to_eval_df_sorted['annotation']=input_to_eval_df_sorted['tweetID'].apply(lambda x: raw_tweets_for_others[raw_tweets_for_others['ID']==x]['annotation_limited types'].iloc[0])\n",
        "\n",
        "        column_candidates_holder = input_to_eval_df_sorted['only_good_candidates'].tolist()\n",
        "        # column_candidates_holder = input_to_eval_df_sorted['phase1Candidates'].tolist()\n",
        "\n",
        "        file1 = open(self.save_file+\".txt\", \"w\")\n",
        "        \n",
        "\n",
        "        column_annot_holder= input_to_eval_df_sorted['annotation'].tolist()\n",
        "        \n",
        "        output_str=''\n",
        "        # print(column_candidates_holder)\n",
        "\n",
        "        true_positive_count=0\n",
        "        false_positive_count=0\n",
        "        false_negative_count=0\n",
        "        ambigious_not_in_annotation=0\n",
        "        total_mentions=0\n",
        "        total_annotation=0\n",
        "\n",
        "        all_annotations=[]\n",
        "        all_mentions=[]\n",
        "\n",
        "        true_positive_holder = []\n",
        "        false_negative_holder=[]\n",
        "        false_positive_holder=[]\n",
        "        total_mention_holder=[]\n",
        "        ambigious_not_in_annotation_holder=[]\n",
        "        f_measure_holder=[]\n",
        "\n",
        "        quickRegex=re.compile(\"[a-z]+\")\n",
        "\n",
        "        print('=========================BERTNER_candidates')\n",
        "\n",
        "        for idx in range(len(column_annot_holder)):\n",
        "            unrecovered_annotated_mention_list=[]\n",
        "            tp_counter_inner=0\n",
        "            fp_counter_inner=0\n",
        "            fn_counter_inner=0\n",
        "\n",
        "            annotated_mention_list=[]\n",
        "            output_mentions_list=[]\n",
        "            tweet_level_candidate_list=str(column_annot_holder[idx]).split(';')\n",
        "            for tweet_level_candidates in tweet_level_candidate_list:\n",
        "                sentence_level_cand_list= tweet_level_candidates.split(',')\n",
        "                annotated_mention_list.extend(sentence_level_cand_list)\n",
        "            annotated_mention_list=list(map(lambda element: element.lower().strip(),annotated_mention_list))\n",
        "            annotated_mention_list=list(filter(lambda element: quickRegex.match(element), annotated_mention_list))\n",
        "            annotated_mention_list=list(filter(lambda element: ((element !='')&(element !='nan')), annotated_mention_list))\n",
        "\n",
        "            for lst in column_candidates_holder[idx]:\n",
        "                output_mentions_list.extend(lst)\n",
        "\n",
        "            output_mentions_list=list(filter(lambda element: (element !=''), output_mentions_list))\n",
        "            output_mentions_list=list(map(lambda element: element.lower(), output_mentions_list))\n",
        "            total_annotation+=len(annotated_mention_list)\n",
        "\n",
        "            print(idx, annotated_mention_list,output_mentions_list)\n",
        "            output_str+=','.join(output_mentions_list)+'\\n'\n",
        "\n",
        "            all_annotations.extend(annotated_mention_list)\n",
        "            all_mentions.extend(output_mentions_list)\n",
        "\n",
        "            total_mentions+=len(output_mentions_list)\n",
        "            all_postitive_counter_inner=len(output_mentions_list)\n",
        "\n",
        "            while(annotated_mention_list):\n",
        "                if(len(output_mentions_list)):\n",
        "                    annotated_candidate= self.normalize(annotated_mention_list.pop())\n",
        "                    if(annotated_candidate in output_mentions_list):\n",
        "                        output_mentions_list.pop(output_mentions_list.index(annotated_candidate))\n",
        "                        tp_counter_inner+=1\n",
        "                    else:\n",
        "                        unrecovered_annotated_mention_list.append(annotated_candidate)\n",
        "                else:\n",
        "                    unrecovered_annotated_mention_list.extend(annotated_mention_list)\n",
        "                    break\n",
        "\n",
        "            # unrecovered_annotated_mention_list_outer.extend(unrecovered_annotated_mention_list)\n",
        "            fn_counter_inner=len(unrecovered_annotated_mention_list)\n",
        "            fp_counter_inner=all_postitive_counter_inner- tp_counter_inner\n",
        "\n",
        "            # print(tp_counter_inner,fp_counter_inner,fn_counter_inner)\n",
        "\n",
        "            self.true_positive_count+=tp_counter_inner\n",
        "            self.false_positive_count+=fp_counter_inner\n",
        "            self.false_negative_count+=fn_counter_inner\n",
        "\n",
        "        print('TP||||FP||||FN')\n",
        "        print(self.true_positive_count,self.false_positive_count,self.false_negative_count,total_mentions,total_annotation)\n",
        "\n",
        "        precision=(self.true_positive_count)/(self.true_positive_count+self.false_positive_count)\n",
        "        recall=(self.true_positive_count)/(self.true_positive_count+self.false_negative_count)\n",
        "        f_measure=2*(precision*recall)/(precision+recall)\n",
        "\n",
        "        # all_annotations=set(all_annotations)\n",
        "        # all_mentions=set(all_mentions)\n",
        "        \n",
        "        # true_positive_count= len(all_annotations.intersection(all_mentions))\n",
        "        # false_positive_count=len(all_mentions-all_annotations)\n",
        "        # false_negative_count=len(all_annotations-all_mentions)\n",
        "        # total_mentions=len(all_mentions)\n",
        "        # total_annotation=len(all_annotations)\n",
        "\n",
        "\n",
        "        # print(true_positive_count,false_positive_count,false_negative_count,total_mentions,total_annotation)\n",
        "\n",
        "        # precision=(true_positive_count)/(true_positive_count+false_positive_count)\n",
        "        # recall=(true_positive_count)/(true_positive_count+false_negative_count)\n",
        "        # f_measure=2*(precision*recall)/(precision+recall)\n",
        "\n",
        "        file1.write(output_str)\n",
        "        file1.close()\n",
        "\n",
        "\n",
        "\n",
        "        self.accuracy_vals=(z_score_threshold,f_measure,precision,recall)\n",
        "\n",
        "        print('Precision:',precision)\n",
        "        print('Recall:',recall)\n",
        "        print('F1:',f_measure)\n",
        "\n",
        "        # print('z_score:', z_score_threshold , 'precision: ',precision,'recall: ',recall,'f measure: ',f_measure)\n",
        "        # print('trupe positive: ',tp_count, 'false positive: ',fp_count,'false negative: ', fn_count,'total mentions: ', tm_count)\n",
        "\n",
        "        return input_to_eval\n",
        "\n",
        "\n",
        "    def recall_correction(self,candidate_featureBase_DF,phase2_candidates_holder,phase2_unnormalized_candidates_holder,data_frame_holder):\n",
        "\n",
        "        corrected_phase2_candidates_holder=[]\n",
        "        index_outer=0\n",
        "        for candidates in phase2_candidates_holder:\n",
        "            unnormalized_candidates=phase2_unnormalized_candidates_holder[index_outer]\n",
        "            corrected_phase2_candidates=[]\n",
        "            for idx, candidate in enumerate(candidates):\n",
        "                unnormalized_candidate=unnormalized_candidates[idx]\n",
        "                # if((candidate in self.partition_dict.keys())&((candidate in self.infrequent_candidates)|(candidate in self.bad_candidates))):\n",
        "                if((candidate in self.partition_dict.keys())&((candidate in self.infrequent_candidates)|(candidate in self.bad_candidates)|(candidate in self.ambiguous_candidates))):   #do this only for 3K tweets\n",
        "                    #print(candidate, self.partition_dict[candidate])\n",
        "                    corrected_phase2_candidates.extend(self.partition_dict[candidate])\n",
        "                else:\n",
        "                    if(((candidate in self.bad_candidates)|(candidate in self.ambiguous_candidates))&(candidate=='us')&(unnormalized_candidate=='US')):\n",
        "                        # print(index_outer)\n",
        "                        candidate=unnormalized_candidate\n",
        "                    # if((len(candidate.strip().strip(string.punctuation).split())>1)&(candidate.strip().strip(string.punctuation).split()[0].lower() in ['a','an','the'])):\n",
        "                    #     candidate = (' '.join(candidate.strip().strip(string.punctuation).split()[1:])).strip()\n",
        "                    corrected_phase2_candidates.append(candidate)\n",
        "            corrected_phase2_candidates_holder.append(copy.deepcopy(corrected_phase2_candidates))\n",
        "            index_outer+=1\n",
        "\n",
        "        \n",
        "        #print(corrected_phase2_candidates_holder)\n",
        "        data_frame_holder['2nd Iteration Candidates']=corrected_phase2_candidates_holder\n",
        "\n",
        "        return corrected_phase2_candidates_holder,data_frame_holder                  \n",
        "\n",
        "\n",
        "    def erode_article(self, entity_string):\n",
        "        if((len(entity_string.strip().strip(string.punctuation).split())>1)&(entity_string.lower().strip().strip(string.punctuation).split()[0] in ['a','an','the'])):\n",
        "            # print(entity_string)\n",
        "            entity_string = ' '.join(entity_string.strip().strip(string.punctuation).split()[1:])\n",
        "            # print(entity_string)\n",
        "        return entity_string.strip()\n",
        "\n",
        "\n",
        "    def set_completeness_in_tweet_frame(self,data_frame_holder,candidate_featureBase_DF,phase2_candidates_holder,phase2_unnormalized_candidates_holder,correction_flag):\n",
        "        #print(candidate_featureBase_DF.head())\n",
        "        good_candidates=candidate_featureBase_DF[candidate_featureBase_DF.status==\"g\"].candidate.tolist()\n",
        "        bad_candidates=candidate_featureBase_DF[candidate_featureBase_DF.status==\"b\"].candidate.tolist()\n",
        "\n",
        "        merged_g_b= bad_candidates+good_candidates\n",
        "\n",
        "        #candidate_featureBase_DF.to_csv(\"cf_before_labeling_comp.csv\", sep=',', encoding='utf-8')\n",
        "        ambiguous_candidates=candidate_featureBase_DF[candidate_featureBase_DF.status==\"a\"].candidate.tolist()\n",
        "\n",
        "        if(correction_flag):\n",
        "            phase2_candidates_holder,data_frame_holder=self.recall_correction(candidate_featureBase_DF,phase2_candidates_holder,phase2_unnormalized_candidates_holder,data_frame_holder)\n",
        "\n",
        "         \n",
        "\n",
        "        \n",
        "        truth_vals=[False if any(x not in merged_g_b for x in list1) else True for list1 in phase2_candidates_holder]\n",
        "\n",
        "        intermediate_output_mentions=[list(filter(lambda candidate: ((candidate in good_candidates))|(candidate=='US'), list1)) for list1 in phase2_candidates_holder]\n",
        "\n",
        "        output_mentions=[list(map(lambda candidate: self.erode_article(candidate), list1)) for list1 in intermediate_output_mentions]\n",
        "\n",
        "        # truth_vals=[False if any(x in ambiguous_candidates for x in list1) else True for list1 in phase2_candidates_holder]\n",
        "        completeness_series = pd.Series( (v for v in truth_vals) )\n",
        "        output_mentions_series = pd.Series( (v for v in output_mentions) )\n",
        "\n",
        "\n",
        "        data_frame_holder['output_mentions']=output_mentions_series\n",
        "        data_frame_holder['completeness']=completeness_series\n",
        "        data_frame_holder[\"current_minus_entry\"]=self.counter-data_frame_holder['entry_batch']\n",
        "\n",
        "        return data_frame_holder\n",
        "\n",
        "\n",
        "\n",
        "    def normalize(self,word):\n",
        "        strip_op=word\n",
        "        strip_op=(((strip_op.lstrip(string.punctuation)).rstrip(string.punctuation)).strip()).lower()\n",
        "        strip_op=(strip_op.lstrip('“‘’”')).rstrip('“‘’”')\n",
        "        strip_op=(((strip_op.lstrip(string.punctuation)).rstrip(string.punctuation)).strip()).lower()\n",
        "        #strip_op= self.rreplace(self.rreplace(self.rreplace(strip_op,\"'s\",\"\",1),\"’s\",\"\",1),\"’s\",\"\",1)\n",
        "        if strip_op.endswith(\"'s\"):\n",
        "            li = strip_op.rsplit(\"'s\", 1)\n",
        "            return ''.join(li)\n",
        "        elif strip_op.endswith(\"’s\"):\n",
        "            li = strip_op.rsplit(\"’s\", 1)\n",
        "            return ''.join(li)\n",
        "        else:\n",
        "            return strip_op\n",
        "        #return strip_op\n",
        "\n",
        "    \n",
        "    def isSubstring(self,to_increase_element,id_to_incr,comparison_holder,phase1_holder_holder_copy):\n",
        "        combined_list=comparison_holder[id_to_incr]+phase1_holder_holder_copy[id_to_incr]\n",
        "\n",
        "        for idx,val in enumerate(comparison_holder[id_to_incr]):\n",
        "            if((to_increase_element[0] in val[0]) and to_increase_element[0] != val[0]):\n",
        "                if((to_increase_element[5] in val[5]) and to_increase_element[5] != val[5]):\n",
        "                    return True\n",
        "        for idx,val in enumerate(phase1_holder_holder_copy[id_to_incr]):\n",
        "            if((to_increase_element[0] in val[0]) and to_increase_element[0] != val[0]):\n",
        "                if((to_increase_element[5] in val[2]) and to_increase_element[5] != val[2]):\n",
        "                    return True   \n",
        "                \n",
        "        return False\n",
        "\n",
        "\n",
        "    def calculate_pmi(self,big,x1,x2,total):\n",
        "        big__= float(big/total)\n",
        "        x1__=float(x1/total)\n",
        "        x2__=float(x2/total)\n",
        "        pmi= math.log(big__/(x1__*x2__),2.71828182845)\n",
        "        pklv=big__*pmi\n",
        "        #return (1/(1+math.exp(-1*pmi)))\n",
        "        npmi= pmi/(-1.0*(math.log(big__,2.71828182845)))\n",
        "        return npmi,pklv\n",
        "        #return pklv\n",
        "\n",
        "    def multiSlice(self,s,cutpoints,good_candidates):\n",
        "        k = len(cutpoints)\n",
        "        multislices=[]\n",
        "        if k == 0:\n",
        "            curr_candidate=self.normalize(' '.join(s))\n",
        "\n",
        "            if(curr_candidate in good_candidates):\n",
        "                multislices = [curr_candidate]        \n",
        "        else:\n",
        "            \n",
        "            curr_candidate=self.normalize(' '.join(s[:cutpoints[0]]))\n",
        "            alt_list=[curr_candidate]\n",
        "            \n",
        "            if(curr_candidate in good_candidates):\n",
        "                multislices = [curr_candidate]\n",
        "\n",
        "            alt_list.extend(self.normalize(' '.join(s[cutpoints[i]:cutpoints[i+1]])) for i in range(k-1))\n",
        "            multislices.extend(self.normalize(' '.join(s[cutpoints[i]:cutpoints[i+1]])) for i in range(k-1) if self.normalize(' '.join(s[cutpoints[i]:cutpoints[i+1]])) in good_candidates)\n",
        "\n",
        "            curr_candidate=self.normalize(' '.join(s[cutpoints[k-1]:]))\n",
        "            alt_list.append(curr_candidate)\n",
        "            \n",
        "            if(curr_candidate in good_candidates):\n",
        "                multislices.append(curr_candidate)\n",
        "            # print('::',alt_list)\n",
        "        return multislices\n",
        "\n",
        "\n",
        "\n",
        "    def get_substring_candidates(self,candidate_words,good_candidates):\n",
        "        n = len(candidate_words)\n",
        "        all_partitions=[]\n",
        "        all_partitions_length=[]\n",
        "        cuts = list(range(1,n))\n",
        "        for k in range(n):\n",
        "            # all_partitions_inner=[]\n",
        "            partition_list=[]\n",
        "            partition_length_list=[]\n",
        "            for cutpoints in itertools.combinations(cuts,k):\n",
        "                ret_list=self.multiSlice(candidate_words,cutpoints,good_candidates)\n",
        "                if(ret_list):\n",
        "                    partition_length=sum([len(elem.split()) for elem in ret_list])\n",
        "                    # print('==',ret_list,partition_length)\n",
        "                    if(partition_length==len(candidate_words)):\n",
        "                        return ret_list\n",
        "                    partition_list.append(ret_list)\n",
        "                    partition_length_list.append(partition_length)\n",
        "                    # yield ret_list\n",
        "            # print('------')\n",
        "            if(partition_length_list):\n",
        "                max_index=partition_length_list.index(max(partition_length_list))\n",
        "                all_partitions.append(partition_list[max_index])\n",
        "                all_partitions_length.append(partition_length_list[max_index])\n",
        "        # print(all_partitions)\n",
        "        if(all_partitions_length):\n",
        "            max_index=all_partitions_length.index(max(all_partitions_length))\n",
        "            # print(all_partitions[max_index])\n",
        "            return all_partitions[max_index]\n",
        "        else:\n",
        "            return []\n",
        "    \n",
        "\n",
        "    def verify(self, subsequence, CTrie):\n",
        "        return CTrie.__contains__(subsequence)\n",
        "\n",
        "\n",
        "\n",
        "    def check_sequence(self, sequence, l, CTrie):\n",
        "        result=[]\n",
        "        subsequence_length=l\n",
        "        while(subsequence_length>0):\n",
        "            shift=len(sequence)-subsequence_length\n",
        "            verified_subsequence=[]\n",
        "            verified=False\n",
        "            for i in range(0,shift+1):\n",
        "                list1=sequence[i:(i+subsequence_length)]\n",
        "                text=' '.join(str(e[0]) for e in list1)\n",
        "                subsequence=(self.normalize(text)).split()\n",
        "                #print(\"search for\", subsequence)\n",
        "                if self.verify(subsequence, CTrie):\n",
        "                    verified_subsequence.append(i)\n",
        "                    verified_subsequence.append(i+subsequence_length)\n",
        "                    #print(subsequence)\n",
        "                    #print(subsequence,[(verified_subsequence[0]-0),(int(sequence[-1][1])-verified_subsequence[1])])\n",
        "                    verified=True\n",
        "                    break\n",
        "            if(verified):\n",
        "                result.append(sequence[verified_subsequence[0]:verified_subsequence[1]])\n",
        "                if(verified_subsequence[0]-0)>0:\n",
        "                    subequence_to_check=sequence[0:verified_subsequence[0]]\n",
        "                    #since tokens before the starting position of the verified subsequence have already been checked for subsequences of this length\n",
        "                    partition_length=min(len(subequence_to_check),(subsequence_length-1))\n",
        "                    #print(subequence_to_check)\n",
        "                    lst=self.check_sequence(subequence_to_check,partition_length, CTrie)\n",
        "                    if(lst):\n",
        "                        result.extend(lst)\n",
        "                if(int(sequence[-1][1])-verified_subsequence[1])>0:\n",
        "                    subequence_to_check=sequence[(verified_subsequence[1]):]\n",
        "                    #since tokens following the end position of the verified subsequence have not been checked for subsequences of this length\n",
        "                    partition_length=min(len(subequence_to_check),(subsequence_length))\n",
        "                    #print(subequence_to_check)\n",
        "                    lst=self.check_sequence(subequence_to_check,partition_length, CTrie)\n",
        "                    if(lst):\n",
        "                        result.extend(lst)\n",
        "                return result\n",
        "            else:\n",
        "                subsequence_length-=1\n",
        "        return result\n",
        "\n",
        "    # def flatten(self,mylist, outlist,ignore_types=(str, bytes, int, ne.NE_candidate)):\n",
        "    def flatten(self,mylist, outlist,ignore_types=(str, bytes, int)):\n",
        "    \n",
        "        if mylist !=[]:\n",
        "            for item in mylist:\n",
        "                #print not isinstance(item, ne.NE_candidate)\n",
        "                if isinstance(item, list) and not isinstance(item, ignore_types):\n",
        "                    self.flatten(item, outlist)\n",
        "                else:\n",
        "                    # if isinstance(item,ne.NE_candidate):\n",
        "                    #     item.phraseText=item.phraseText.strip(' \\t\\n\\r')\n",
        "                    #     item.reset_length()\n",
        "                    # else:\n",
        "                    if type(item)!= int:\n",
        "                        item=item.strip(' \\t\\n\\r')\n",
        "                    outlist.append(item)\n",
        "        return outlist\n",
        "\n",
        "\n",
        "    def getWords(self, sentence):\n",
        "        tempList=[]\n",
        "        tempWordList=sentence.split()\n",
        "        p_dots= re.compile(r'[.]{2,}')\n",
        "        #print(tempWordList)\n",
        "        for word in tempWordList:\n",
        "            temp=[]\n",
        "            \n",
        "            if \"(\" in word:\n",
        "                temp=list(filter(lambda elem: elem!='',word.split(\"(\")))\n",
        "                if(temp):\n",
        "                    temp=list(map(lambda elem: '('+elem, temp))\n",
        "            elif \")\" in word:\n",
        "                temp=list(filter(lambda elem: elem!='',word.split(\")\")))\n",
        "                if(temp):\n",
        "                    temp=list(map(lambda elem: elem+')', temp))\n",
        "                # temp.append(temp1[-1])\n",
        "            # elif ((\"-\" in word)&(not word.endswith(\"-\"))):\n",
        "            #     temp1=list(filter(lambda elem: elem!='',word.split(\"-\")))\n",
        "            #     if(temp1):\n",
        "            #         temp=list(map(lambda elem: elem+'-', temp1[:-1]))\n",
        "            #     temp.append(temp1[-1])\n",
        "            elif ((\"?\" in word)&(not word.endswith(\"?\"))):\n",
        "                temp1=list(filter(lambda elem: elem!='',word.split(\"?\")))\n",
        "                if(temp1):\n",
        "                    temp=list(map(lambda elem: elem+'?', temp1[:-1]))\n",
        "                temp.append(temp1[-1])\n",
        "            elif ((\":\" in word)&(not word.endswith(\":\"))):\n",
        "                temp1=list(filter(lambda elem: elem!='',word.split(\":\")))\n",
        "                if(temp1):\n",
        "                    temp=list(map(lambda elem: elem+':', temp1[:-1]))\n",
        "                temp.append(temp1[-1])\n",
        "            elif ((\",\" in word)&(not word.endswith(\",\"))):\n",
        "                #temp=list(filter(lambda elem: elem!='',word.split(\",\")))\n",
        "                temp1=list(filter(lambda elem: elem!='',word.split(\",\")))\n",
        "                if(temp1):\n",
        "                    temp=list(map(lambda elem: elem+',', temp1[:-1]))\n",
        "                temp.append(temp1[-1])\n",
        "            elif ((\"/\" in word)&(not word.endswith(\"/\"))):\n",
        "                temp1=list(filter(lambda elem: elem!='',word.split(\"/\")))\n",
        "                if(temp1):\n",
        "                    temp=list(map(lambda elem: elem+'/', temp1[:-1]))\n",
        "                temp.append(temp1[-1])\n",
        "                #print(index, temp)\n",
        "            # elif \"...\" in word:\n",
        "            #     #print(\"here\")\n",
        "            #     temp=list(filter(lambda elem: elem!='',word.split(\"...\")))\n",
        "            #     if(temp):\n",
        "            #         if(word.endswith(\"...\")):\n",
        "            #             temp=list(map(lambda elem: elem+'...', temp))\n",
        "            #         else:\n",
        "            #            temp=list(map(lambda elem: elem+'...', temp[:-1]))+[temp[-1]]\n",
        "            #     # temp.append(temp1[-1])\n",
        "            # elif \"..\" in word:\n",
        "            #     temp=list(filter(lambda elem: elem!='',word.split(\"..\")))\n",
        "            #     if(temp):\n",
        "            #         if(word.endswith(\"..\")):\n",
        "            #             temp=list(map(lambda elem: elem+'..', temp))\n",
        "            #         else:\n",
        "            #             temp=list(map(lambda elem: elem+'..', temp[:-1]))+[temp[-1]]\n",
        "            #     #temp.append(temp1[-1])\n",
        "            elif (list(p_dots.finditer(word))):\n",
        "                matched_spans= list(p_dots.finditer(word)) \n",
        "                temp=[]\n",
        "                next_string_start=0\n",
        "                for matched_span in matched_spans:\n",
        "                    matched_start=matched_span.span()[0]\n",
        "                    this_excerpt=word[next_string_start:matched_start]\n",
        "                    if(this_excerpt):\n",
        "                        temp.append(this_excerpt)\n",
        "                    next_string_start=matched_span.span()[1]\n",
        "                if(next_string_start<len(word)):\n",
        "                    last_excerpt=word[next_string_start:]\n",
        "                    if(last_excerpt):\n",
        "                        temp.append(last_excerpt)\n",
        "            elif \"…\" in word:\n",
        "                temp=list(filter(lambda elem: elem!='',word.split(\"…\")))\n",
        "                if(temp):\n",
        "                    if(word.endswith(\"…\")):\n",
        "                        temp=list(map(lambda elem: elem+'…', temp))\n",
        "                    else:\n",
        "                        temp=list(map(lambda elem: elem+'…', temp[:-1]))+[temp[-1]]\n",
        "            else:\n",
        "                #if word not in string.punctuation:\n",
        "                temp=[word]\n",
        "            if(temp):\n",
        "                tempList.append(temp)\n",
        "        tweetWordList=self.flatten(tempList,[])\n",
        "        return tweetWordList\n",
        "\n",
        "    def get_Candidates(self, sequence, CTrie,flag):\n",
        "        #flag: debug_flag\n",
        "        candidateList=[]\n",
        "        left=0\n",
        "        start_node=CTrie\n",
        "        last_cand=\"NAN\"\n",
        "        last_cand_substr=\"\"\n",
        "        reset=False\n",
        "        right=0\n",
        "        while (right < len(sequence)):\n",
        "            # if(flag):\n",
        "            #     print(right)\n",
        "            if(reset):\n",
        "                start_node=CTrie\n",
        "                last_cand_substr=\"\"\n",
        "                left=right\n",
        "            curr_text=sequence[right][0]\n",
        "            curr_pos=[sequence[right][1]]\n",
        "            #normalized curr_text\n",
        "            curr=self.normalize(sequence[right][0])\n",
        "            cand_str=self.normalize(last_cand_substr+\" \"+curr)\n",
        "            cand_str_wPunct=(last_cand_substr+\" \"+curr_text).lower()\n",
        "            last_cand_sequence=sequence[left:(right+1)]\n",
        "            last_cand_text=' '.join(str(e[0]) for e in last_cand_sequence)\n",
        "            last_cand_text_norm=self.normalize(' '.join(str(e[0]) for e in last_cand_sequence))\n",
        "            if(flag):\n",
        "                print(\"==>\",cand_str,last_cand_text_norm)\n",
        "            if((cand_str==last_cand_text_norm)&((curr in start_node.path.keys())|(curr_text.lower() in start_node.path.keys()))):\n",
        "            #if (((curr in start_node.path.keys())&(cand_str==last_cand_text_norm))|(curr_text.lower() in start_node.path.keys())):\n",
        "                if flag:\n",
        "                    print(\"=>\",cand_str,last_cand_text)\n",
        "                reset=False\n",
        "                if (curr_text.lower() in start_node.path.keys()):\n",
        "                    if (start_node.path[curr_text.lower()].value_valid):\n",
        "                        last_cand_pos=[e[1] for e in last_cand_sequence]\n",
        "                        last_cand_batch=start_node.path[curr_text.lower()].feature_list[-1]\n",
        "                        last_cand=last_cand_text\n",
        "                    elif(curr in start_node.path.keys()):\n",
        "                        if ((start_node.path[curr].value_valid)):\n",
        "                            last_cand_pos=[e[1] for e in last_cand_sequence]\n",
        "                            last_cand=last_cand_text\n",
        "                            last_cand_batch=start_node.path[curr].feature_list[-1]\n",
        "                        else:\n",
        "                            if((right==(len(sequence)-1))&(last_cand==\"NAN\")&(left<right)):\n",
        "                                #print(\"hehe\",cand_str)\n",
        "                                right=left\n",
        "                                reset=True\n",
        "                    else:\n",
        "                        if((right==(len(sequence)-1))&(last_cand==\"NAN\")&(left<right)):\n",
        "                            #print(\"hehe\",cand_str)\n",
        "                            right=left\n",
        "                            reset=True\n",
        "                elif ((start_node.path[curr].value_valid)&(cand_str==last_cand_text_norm)):\n",
        "                    # if flag:\n",
        "                    #     print(\"==\",last_cand_text)\n",
        "                    last_cand_pos=[e[1] for e in last_cand_sequence]\n",
        "                    last_cand=last_cand_text\n",
        "                    last_cand_batch=start_node.path[curr].feature_list[-1]\n",
        "                else:\n",
        "                    if((right==(len(sequence)-1))&(last_cand==\"NAN\")&(left<right)):\n",
        "                        #print(\"hehe\",cand_str)\n",
        "                        right=left\n",
        "                        reset=True\n",
        "                if((curr_text.lower() in start_node.path.keys())&(cand_str==last_cand_text_norm)):\n",
        "                    start_node=start_node.path[curr_text.lower()]\n",
        "                    last_cand_substr=cand_str_wPunct\n",
        "                else:\n",
        "                    start_node=start_node.path[curr]\n",
        "                    last_cand_substr=cand_str\n",
        "            else:\n",
        "                #print(\"=>\",cand_str,last_cand_text)\n",
        "                if(last_cand!=\"NAN\"):\n",
        "                    candidateList.append((last_cand,last_cand_pos,last_cand_batch))\n",
        "                    last_cand=\"NAN\"\n",
        "                    if(start_node!=CTrie):\n",
        "                        start_node=CTrie\n",
        "                        last_cand_substr=\"\"\n",
        "                        if curr in start_node.path.keys():\n",
        "                            # if(flag):\n",
        "                            #     print(\"here\",curr)\n",
        "                            reset=False\n",
        "                            if start_node.path[curr].value_valid:\n",
        "                                last_cand_text=curr_text\n",
        "                                last_cand_pos=curr_pos\n",
        "                                last_cand=last_cand_text\n",
        "                                last_cand_batch=start_node.path[curr].feature_list[-1]\n",
        "                            left=right\n",
        "                            start_node=start_node.path[curr]\n",
        "                            last_cand_substr=curr\n",
        "                        else:\n",
        "                            reset=True\n",
        "                    else:\n",
        "                        reset=True\n",
        "                else:\n",
        "                    if(left<right):\n",
        "                        # if(flag):\n",
        "                        #     print(sequence[(left+1):(right+1)])\n",
        "                        #candidateList.extend(self.get_Candidates(sequence[(left+1):(right+1)], CTrie, flag))\n",
        "                        right=left\n",
        "                        # if(flag):\n",
        "                        #     print(\"++\",right)\n",
        "                    reset=True\n",
        "            right+=1\n",
        "        # if(flag):\n",
        "        #     print(last_cand)\n",
        "        if(last_cand!=\"NAN\"):\n",
        "            candidateList.append((last_cand,last_cand_pos,last_cand_batch))\n",
        "        return candidateList\n",
        "\n",
        "\n",
        "    def append_rows(self,df_holder):\n",
        "    \n",
        "        df = pd.DataFrame(df_holder)\n",
        "        #self.data_frame_holder=self.data_frame_holder.append(df,ignore_index=True)\n",
        "        #self.data_frame_holder=self.data_frame_holder.reset_index(drop=True)\n",
        "        return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def join_token_tuples(self,list_of_tuples):\n",
        "        #print(string.punctuation)\n",
        "        combined_str=(' '.join(tuple[0] for tuple in list_of_tuples)).lstrip(string.punctuation).rstrip(string.punctuation).strip()\n",
        "        combined_pos='*'.join(str(tuple[1]) for tuple in list_of_tuples)\n",
        "        combined_tuple=(combined_str,combined_pos,list_of_tuples[0][2],list_of_tuples[0][3],list_of_tuples[0][4],list_of_tuples[0][5],list_of_tuples[0][6])\n",
        "        return combined_tuple\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def all_capitalized(self,candidate):\n",
        "        strip_op=candidate\n",
        "        strip_op=(((strip_op.lstrip(string.punctuation)).rstrip(string.punctuation)).strip())\n",
        "        strip_op=(strip_op.lstrip('“‘’”')).rstrip('“‘’”')\n",
        "        strip_op= self.rreplace(self.rreplace(self.rreplace(strip_op,\"'s\",\"\",1),\"’s\",\"\",1),\"’s\",\"\",1)\n",
        "        prep_article_list=prep_list+article_list+self.phase2stopwordList\n",
        "        word_list=strip_op.split()\n",
        "        for i in range(len(word_list)):\n",
        "            word=word_list[i]\n",
        "            if((word[0].isupper())|(word[0].isdigit())):\n",
        "                continue\n",
        "            else:\n",
        "                if(word in prep_article_list):\n",
        "                    if (i!=0):\n",
        "                        continue\n",
        "                    else:\n",
        "                        return False\n",
        "                elif(word in conjoiner):\n",
        "                    continue\n",
        "                else:\n",
        "                    return False\n",
        "        return True\n",
        "\n",
        "\n",
        "    def check_feature_update(self, candidate_tuple,non_discriminative_flag):\n",
        "        #print(candidate_tuple)\n",
        "        if(non_discriminative_flag):\n",
        "            return 7\n",
        "        candidateText=candidate_tuple[0]\n",
        "        position=candidate_tuple[1]\n",
        "        word_list=candidateText.split()\n",
        "        if candidateText.islower():\n",
        "            return 6\n",
        "        elif candidateText.isupper():\n",
        "            return 5\n",
        "        elif (len(word_list)==1):\n",
        "            #start-of-sentence-check\n",
        "            if self.all_capitalized(candidateText):\n",
        "                if(int(position[0])==0):\n",
        "                    return 4\n",
        "                else:\n",
        "                    return 2\n",
        "            else:\n",
        "                return 3\n",
        "        else:\n",
        "            if(self.all_capitalized(candidateText)):\n",
        "                return 2\n",
        "            else:\n",
        "                return 3\n",
        "\n",
        "    def addEmbedding(self, candidate_tuple,contextual_embedding_vector):\n",
        "\n",
        "        candidateText=candidate_tuple[0]\n",
        "        normalized_candidate=self.normalize(candidateText)\n",
        "\n",
        "        if(normalized_candidate in self.candidateEmbedding_records.keys()):\n",
        "            curr_id = self.candidate_string_freq_dict[normalized_candidate]\n",
        "            self.candidateEmbedding_records[normalized_candidate][curr_id]=(contextual_embedding_vector,)\n",
        "            self.candidateEmbeddingPool[normalized_candidate].append(contextual_embedding_vector.tolist())\n",
        "        else:\n",
        "            curr_id = 0\n",
        "            self.candidateEmbedding_records[normalized_candidate]={curr_id:(contextual_embedding_vector,)}\n",
        "            self.candidateEmbeddingPool[normalized_candidate]=[contextual_embedding_vector.tolist()]\n",
        "        self.candidate_string_freq_dict[normalized_candidate]=curr_id+1\n",
        "        \n",
        "        return curr_id\n",
        "\n",
        "    def extract(self,tweetBaseInput,CTrie,phase2stopwordList,new_or_old):\n",
        "\n",
        "\n",
        "        if(self.counter==0):\n",
        "            #output_queue\n",
        "            self.candidate_string_freq_dict= {} #not mindful of clusters\n",
        "\n",
        "            self.CandidateBase_dict_alt={}\n",
        "            self.candidateEmbeddingDict={}\n",
        "\n",
        "            #new data structures for clustering\n",
        "            self.candidateEmbeddingPool={}\n",
        "            self.candidateEmbedding_records={} # {candidate:{mention_id: <contextual embedding,cluster_id>...},....} multi level dictionary\n",
        "\n",
        "            self.ambiguous_candidate_distanceDict_prev={}\n",
        "            self.partition_dict={}\n",
        "            self.good_candidates=[]\n",
        "            self.bad_candidates=[]\n",
        "            self.ambiguous_candidates=[]\n",
        "\n",
        "            self.aggregator_incomplete_tweets=pd.DataFrame([], columns=['index', 'entry_batch', 'tweetID', 'sentID', 'TweetSentence','phase1Candidates', '2nd Iteration Candidates', '2nd Iteration Candidates Unnormalized'])\n",
        "            self.just_converted_tweets=pd.DataFrame([], columns=['index', 'entry_batch', 'tweetID', 'sentID', 'TweetSentence','phase1Candidates', '2nd Iteration Candidates', '2nd Iteration Candidates Unnormalized'])\n",
        "            #self.data_frame_holder=pd.DataFrame([], columns=['index','entry_batch','tweetID', 'sentID', 'TweetSentence','phase1Candidates', '2nd Iteration Candidates'])\n",
        "            self.raw_tweets_for_others=pd.DataFrame([], columns=['index','entry_batch','tweetID', 'sentID', 'TweetSentence','phase1Candidates', '2nd Iteration Candidates', '2nd Iteration Candidates Unnormalized'])\n",
        "\n",
        "            self.accuracy_tuples_prev_batch=[]\n",
        "            self.accuracy_vals=[]\n",
        "            \n",
        "            #frequency_w_decay related information\n",
        "            self.ambiguous_candidates_reintroduction_dict={}\n",
        "\n",
        "            #### other systems\n",
        "            self.accuracy_vals_stanford=[]\n",
        "            self.accuracy_vals_opencalai=[]\n",
        "            self.accuracy_vals_ritter=[]\n",
        "            self.accuracy_vals_neuroner=[]\n",
        "\n",
        "            self.number_of_seen_tweets_per_batch=[]\n",
        "        self.phase2stopwordList=phase2stopwordList\n",
        "        self.number_of_seen_tweets_per_batch.append(len(tweetBaseInput))\n",
        "\n",
        "\n",
        "        #data_frame_holder=pd.DataFrame([], columns=['index','entry_batch','tweetID', 'sentID', 'hashtags', 'user', 'TweetSentence','phase1Candidates', '2nd Iteration Candidates', '2nd Iteration Candidates Unnormalized'])\n",
        "        phase1_holder_holder=[]\n",
        "        phase2_candidates_holder=[]\n",
        "        phase2_unnormalized_candidates_holder=[]\n",
        "        df_holder=[]\n",
        "\n",
        "\n",
        "        combined_list_here=([]+list(cachedStopWords)+chat_word_list+day_list+month_list+article_list+prep_list)\n",
        "        combined_list_filtered=list(filter(lambda word: word not in (prep_list+article_list+month_list+self.phase2stopwordList), combined_list_here))\n",
        "\n",
        "        self.entity_phrase_embedder.eval()\n",
        "        #--------------------------------------PHASE II---------------------------------------------------\n",
        "        for index, row in tweetBaseInput.iterrows():\n",
        "\n",
        "            #phase 1 candidates for one sentence\n",
        "            phase1_holder=[]\n",
        "\n",
        "            tweetText=str(row['TweetSentence'])\n",
        "            tweetWordList = row['tweetwordList']\n",
        "            sentID=str(row['sentID'])\n",
        "            tweetID=str(row['tweetID'])\n",
        "            phase1Candidates=str(row['phase1CandidatesWPositions'])\n",
        "            batch=int(row['entry_batch'])\n",
        "            contextual_embeddings_dict= {ind: embedding for ind, embedding in enumerate(row['contextual_embeddings'])}\n",
        "            \n",
        "            # print('====',tweetID,sentID)\n",
        "            # print('tweetWordList:',tweetWordList)\n",
        "            \n",
        "            non_discriminative_flag=False\n",
        "            phase1CandidatesList=[]\n",
        "\n",
        "            # print('phase1Candidates:',phase1Candidates)\n",
        "\n",
        "            if (phase1Candidates !='nan'):\n",
        "                phase1Raw=phase1Candidates.split(\"||\")\n",
        "                phase1Raw = list(filter(None, phase1Raw))\n",
        "\n",
        "\n",
        "                for entities_with_loc in phase1Raw:\n",
        "                    candidateData=entities_with_loc.split(\"::\")\n",
        "                    entity_to_store=candidateData[0]\n",
        "                    #print(entity_to_store)\n",
        "                    position=candidateData[1]\n",
        "                    #print(position)\n",
        "                    entityType=candidateData[2]\n",
        "                    phase1_holder.append((entity_to_store,entityType,position))\n",
        "                    phase1_holder.clear()\n",
        "                    phase1CandidatesList.append(entity_to_store.lower())\n",
        "\n",
        "                phase1_holder_holder.append(copy.deepcopy(phase1_holder))\n",
        "                \n",
        "\n",
        "            else:\n",
        "                non_discriminative_flag=True\n",
        "                phase1_holder_holder.append([])\n",
        "\n",
        "            \n",
        "            # tweetWordList=self.getWords(tweetText)\n",
        "            # tweetWordList= [(token,idx) for idx,token in enumerate(tweetWordList)]\n",
        "            \n",
        "            tweetWordList_stopWords=list(filter (lambda word: ((((word[0].strip()).strip(punct)).lower() in combined_list_filtered)|(word[0].strip() in punct)|(word[0].startswith('@'))|(word[0].startswith('#'))), tweetWordList))\n",
        "\n",
        "            # phase 2 candidate tuples without stopwords for a sentence\n",
        "            c=[(y[0],str(y[1]),tweetID,sentID,'ne',batch,time) for y  in tweetWordList if y not in tweetWordList_stopWords ]\n",
        "            #c=[(y[0],str(y[1])) for y  in tweetWordList if y not in tweetWordList_stopWords ]\n",
        "\n",
        "            \n",
        "            sequences=[]\n",
        "            for k, g in groupby(enumerate(c), lambda element: element[0]-int(element[1][1])):\n",
        "                sequences.append(list(map(itemgetter(1), g)))\n",
        "\n",
        "            # print('phaseII candidates:')\n",
        "            phase2_candidates=[]\n",
        "            phase2_candidates_unnormalized=[]\n",
        "            for sequence in sequences:\n",
        "                seq_candidate_list=self.get_Candidates(sequence, CTrie,False)\n",
        "                if(seq_candidate_list):\n",
        "                    for candidate_tuple in seq_candidate_list:\n",
        "\n",
        "                        # extract candidate token embeddings\n",
        "                        candidate_token_embeddings = torch.stack([contextual_embeddings_dict[int(position)] for position in candidate_tuple[1]])\n",
        "                        assert torch.isnan(candidate_token_embeddings).any() == False\n",
        "                        tensor_inter = torch.mean(candidate_token_embeddings,dim=0)\n",
        "                        assert torch.isnan(tensor_inter).any() == False\n",
        "                        tensor_inter_norm = torch.norm(tensor_inter, p=2,dim=0)\n",
        "                        \n",
        "                        if (not torch.is_nonzero(tensor_inter_norm)):\n",
        "                            print(candidate_tuple, 'adjustement needed')\n",
        "                            tensor_inter = torch.add(tensor_inter,1e-7)\n",
        "                            tensor_inter_norm = torch.norm(tensor_inter, p=2,dim=0)\n",
        "                        \n",
        "\n",
        "                        candidate_tokens_avg_embedding = tensor_inter/tensor_inter_norm\n",
        "                        assert torch.isnan(candidate_tokens_avg_embedding).any() == False\n",
        "\n",
        "                        # !! must unsqueeze at test time with embedder else batchnorm throws error\n",
        "                        candidate_tokens_avg_embedding = candidate_tokens_avg_embedding.unsqueeze(0)\n",
        "                        \n",
        "                        candidate_embedding = (self.entity_phrase_embedder.getEmbedding(candidate_tokens_avg_embedding)).squeeze(0)\n",
        "                        \n",
        "                        assert torch.isnan(candidate_embedding).any() == False\n",
        "\n",
        "                        # print(candidate_tuple,candidate_token_embeddings.shape)\n",
        "                        # print('candidate_embedding:',candidate_embedding.shape)\n",
        "\n",
        "                        #inserts into CandidatePool: pre-clustering\n",
        "                        # if not ((float(batch)<self.counter)&(candidate_tuple[-1]<self.counter)):\n",
        "                        mention_id = self.addEmbedding(candidate_tuple,candidate_embedding)\n",
        "                        # self.update_Candidatedict(candidate_tuple,non_discriminative_flag,candidate_embedding.tolist())\n",
        "\n",
        "                        phase2_candidates.append(self.normalize(candidate_tuple[0])+'||'+str(mention_id))\n",
        "                        phase2_candidates_unnormalized.append(candidate_tuple[0]+'||'+str(mention_id))\n",
        "\n",
        "            phase2_candidates_holder.append(phase2_candidates)\n",
        "            phase2_unnormalized_candidates_holder.append(phase2_candidates_unnormalized)\n",
        "\n",
        "            dict1 = {'entry_batch':batch, 'tweetID':tweetID, 'sentID':sentID, 'TweetSentence':tweetText, 'phase1Candidates':phase1CandidatesList,'2nd Iteration Candidates':phase2_candidates,'2nd Iteration Candidates Unnormalized':phase2_candidates_unnormalized}\n",
        "\n",
        "            df_holder.append(dict1)\n",
        "\n",
        "        # sanity check\n",
        "        for candidate in self.candidate_string_freq_dict.keys():\n",
        "            assert self.candidate_string_freq_dict[candidate] == len(self.candidateEmbedding_records[candidate])\n",
        "            assert self.candidate_string_freq_dict[candidate] == len(self.candidateEmbeddingPool[candidate])\n",
        "\n",
        "        return df_holder,phase2_candidates_holder,phase2_unnormalized_candidates_holder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQix93xPFfAf"
      },
      "source": [
        "## **Running the NER Globalizer engine**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufF8xR7ffYN2"
      },
      "outputs": [],
      "source": [
        "def calculate_f1_ner_engine(tweet_to_sentences_w_annotation, ner_arrays):\n",
        "    \n",
        "    entity_types = ['org','misc', 'loc', 'per']\n",
        "    confusion_matrices = {entity_type: {'TP': 0, 'TN': 0, 'FP': 0, 'FN': 0} for entity_type in entity_types}\n",
        "    scores = {entity_type: {'p': 0, 'r': 0, 'f1': 0} for entity_type in entity_types}\n",
        "\n",
        "    out_str = ''\n",
        "    mistyping_count = 0\n",
        "    total_mention_count = 0\n",
        "\n",
        "    annotation_dict={}\n",
        "    output_dict={}\n",
        "\n",
        "    for tweetID in tweet_to_sentences_w_annotation.keys():\n",
        "        unrecovered_annotated_mention_list=[]\n",
        "        annotated_mention_list=tweet_to_sentences_w_annotation[tweetID][1]\n",
        "        output_mentions_list=[]\n",
        "        true_positive_list=[]\n",
        "        idRange=tweet_to_sentences_w_annotation[tweetID][0]\n",
        "\n",
        "        for sentID in range(idRange[0],idRange[1]):\n",
        "            output_mentions_list+=ner_arrays[sentID]\n",
        "        output_mentions_list=[(elem[0],elem[1].lower()) for elem in output_mentions_list]\n",
        "        print(tweetID,annotated_mention_list,output_mentions_list)\n",
        "        out_str+=str(tweetID)+str(annotated_mention_list)+str(output_mentions_list)+'\\n'\n",
        "\n",
        "        total_mention_count+=len(annotated_mention_list)\n",
        "\n",
        "        for annotated_entity in annotated_mention_list:\n",
        "            try:\n",
        "                annotation_dict[annotated_entity]+=1\n",
        "            except KeyError:\n",
        "                annotation_dict[annotated_entity]=1\n",
        "\n",
        "        while(annotated_mention_list):\n",
        "            if(len(output_mentions_list)):\n",
        "                annotated_candidate= annotated_mention_list.pop()\n",
        "                if(annotated_candidate in output_mentions_list):\n",
        "                    output_mentions_list.pop(output_mentions_list.index(annotated_candidate))\n",
        "                    # tp_counter_inner+=1 # for emd\n",
        "                    true_positive_list.append(annotated_candidate)\n",
        "                    # #for ner\n",
        "                    # entity_type=annotated_candidate[1]\n",
        "                    # confusion_matrices[entity_type]['TP']+=1\n",
        "                else:\n",
        "                    unrecovered_annotated_mention_list.append(annotated_candidate)\n",
        "            else:\n",
        "                unrecovered_annotated_mention_list.extend(annotated_mention_list)\n",
        "                break\n",
        "        # unrecovered_annotated_mention_list_outer.extend(unrecovered_annotated_mention_list)\n",
        "\n",
        "        # fn_counter_inner=len(unrecovered_annotated_mention_list)\n",
        "        # fp_counter_inner=all_postitive_counter_inner - tp_counter_inner\n",
        "        # print(tp_counter_inner,fp_counter_inner,fn_counter_inner)\n",
        "\n",
        "        print('true positives:',true_positive_list)\n",
        "        print('false positives:',output_mentions_list)\n",
        "        print('false negatives:',unrecovered_annotated_mention_list)\n",
        "\n",
        "        out_str+= 'true positives:'+str(true_positive_list)+'\\n'\n",
        "        out_str+= 'false positives:'+str(output_mentions_list)+'\\n'\n",
        "        out_str+= 'false negatives:'+str(unrecovered_annotated_mention_list)+'\\n'\n",
        "\n",
        "        mistyped_candidates = []\n",
        "        false_positive_candidate_strings = [elem[0] for elem in output_mentions_list]\n",
        "\n",
        "        for mention_tup in true_positive_list:\n",
        "            output_dict[mention_tup] = True\n",
        "            entity_type=mention_tup[1]\n",
        "            if(mention_tup[0]):\n",
        "                confusion_matrices[entity_type]['TP']+=1\n",
        "\n",
        "        for mention_tup in unrecovered_annotated_mention_list:\n",
        "            entity_type=mention_tup[1]\n",
        "            if(mention_tup[0]):\n",
        "                confusion_matrices[entity_type]['FN']+=1\n",
        "\n",
        "        for mention_tup in output_mentions_list:\n",
        "            entity_type=mention_tup[1]\n",
        "            if(mention_tup[0]):\n",
        "                confusion_matrices[entity_type]['FP']+=1\n",
        "\n",
        "        while(unrecovered_annotated_mention_list):\n",
        "            if(false_positive_candidate_strings):\n",
        "                fn_candidate = unrecovered_annotated_mention_list.pop()\n",
        "                if(fn_candidate[0] in false_positive_candidate_strings):\n",
        "                    false_positive_candidate_strings.pop(false_positive_candidate_strings.index(fn_candidate[0]))\n",
        "                    mistyped_candidates.append(fn_candidate)\n",
        "            else:\n",
        "                break\n",
        "        print('mistypings:',mistyped_candidates)\n",
        "        out_str+= 'mistypings:'+str(mistyped_candidates)+'\\n'\n",
        "        mistyping_count+= len(mistyped_candidates)\n",
        "    \n",
        "    # file1 = open(\"btc.txt\", \"w\")\n",
        "    file1 = open(\"tweets_3K.txt\", \"w\")\n",
        "    file1.write(out_str)\n",
        "    file1.close()\n",
        "\n",
        "    freq_bucket = {} \n",
        "    for candidate in annotation_dict.keys():\n",
        "        candidate_freq = annotation_dict[candidate]\n",
        "        flag = False\n",
        "        if(candidate in output_dict):\n",
        "            flag = True\n",
        "        try:\n",
        "            old_tup = freq_bucket[candidate_freq]\n",
        "            if flag:\n",
        "                freq_bucket[candidate_freq] = (old_tup[0]+1,old_tup[1])\n",
        "            else:\n",
        "                freq_bucket[candidate_freq] = (old_tup[0],old_tup[1]+1)\n",
        "        except KeyError:\n",
        "            if flag:\n",
        "                freq_bucket[candidate_freq] = (1,0)\n",
        "            else:\n",
        "                freq_bucket[candidate_freq] = (0,1)\n",
        "    \n",
        "    x_axis=[]\n",
        "    y_axis =[]\n",
        "    cumulative_tp=0\n",
        "    cumulative_annotated=0\n",
        "    freq_bucket_sorted = {k : freq_bucket[k] for k in sorted(freq_bucket)}\n",
        "\n",
        "    maxKey = list(freq_bucket_sorted.keys())[-1]\n",
        "    print(freq_bucket_sorted.keys(),maxKey)\n",
        "\n",
        "    step=0\n",
        "    for key in range(maxKey):\n",
        "        try:\n",
        "            tup = freq_bucket_sorted[key]\n",
        "        except KeyError:\n",
        "            tup = (0,0)\n",
        "\n",
        "        # freq_recall= tup[0]/(tup[0]+tup[1])\n",
        "\n",
        "        if(step==5):\n",
        "            if((cumulative_tp==0)&(cumulative_annotated==0)):\n",
        "                freq_recall= y_axis[-1]\n",
        "            else:\n",
        "                freq_recall= cumulative_tp/cumulative_annotated\n",
        "            # print(key, freq_recall)\n",
        "            x_axis.append(key)\n",
        "            y_axis.append(freq_recall)\n",
        "            step=0\n",
        "            cumulative_tp=0\n",
        "            cumulative_annotated=0\n",
        "\n",
        "\n",
        "        cumulative_tp+=tup[0]\n",
        "        cumulative_annotated+=(tup[0]+tup[1])\n",
        "        # freq_recall= cumulative_tp/cumulative_annotated\n",
        "        step+=1\n",
        "\n",
        "    print(x_axis)\n",
        "    print(y_axis)\n",
        "\n",
        "    # print20=20\n",
        "    for ind, elem in enumerate(x_axis):\n",
        "        # if(print20>0):\n",
        "        print(x_axis[ind],':',y_axis[ind])\n",
        "\n",
        "    print('========Entity Mention Detection========')\n",
        "    print('Total mentions:',str(total_mention_count))\n",
        "    print('Mistyped mentions:',str(mistyping_count))\n",
        "    for entity_type in entity_types:\n",
        "        print(entity_type.upper())\n",
        "        try:\n",
        "            precision = confusion_matrices[entity_type]['TP']/(confusion_matrices[entity_type]['TP']+confusion_matrices[entity_type]['FP'])\n",
        "        except ZeroDivisionError:\n",
        "            precision = 0\n",
        "        try:\n",
        "            recall = confusion_matrices[entity_type]['TP']/(confusion_matrices[entity_type]['TP']+confusion_matrices[entity_type]['FN'])\n",
        "        except ZeroDivisionError:\n",
        "            recall = 0\n",
        "        try:\n",
        "            f_measure = 2*precision*recall/(precision+recall)\n",
        "        except ZeroDivisionError:\n",
        "            f_measure = 0\n",
        "\n",
        "        scores[entity_type]['p'] = precision\n",
        "        scores[entity_type]['r'] = recall\n",
        "        scores[entity_type]['f1'] = f_measure\n",
        "\n",
        "        print('true positives: ',confusion_matrices[entity_type]['TP'])\n",
        "        print('false positives: ',confusion_matrices[entity_type]['FP'])\n",
        "        print('false negatives: ',confusion_matrices[entity_type]['FN'])\n",
        "\n",
        "        print('precision: ',precision)\n",
        "        print('recall: ',recall)\n",
        "        print('f_measure: ',f_measure)\n",
        "\n",
        "        print('------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCdNPuGhrrah"
      },
      "outputs": [],
      "source": [
        "# tweets_unpartitoned=pd.read_csv('data/tweets_3k_annotated.csv',sep =',',keep_default_na=False)\n",
        "\n",
        "# tweets_unpartitoned=pd.read_csv('data/tweets_6k_annotated.csv',sep =',',keep_default_na=False)\n",
        "\n",
        "# tweets_unpartitoned=pd.read_csv('data/venezuela.csv',sep =',',keep_default_na=False)\n",
        "\n",
        "# tweets_unpartitoned=pd.read_csv('data/covid_2K.csv',sep =',',keep_default_na=False)\n",
        "\n",
        "# tweets_unpartitoned=pd.read_csv('data/broad_twitter_corpus.csv',sep =',',keep_default_na=False)\n",
        "\n",
        "# tweets_unpartitoned=pd.read_csv('data/billdeblasio.csv',sep =',',keep_default_na=False)\n",
        "# tweets_unpartitoned=pd.read_csv('data/roevwade.csv',sep =',',keep_default_na=False)\n",
        "# tweets_unpartitoned=pd.read_csv('data/pikapika.csv',sep =',',keep_default_na=False)\n",
        "# tweets_unpartitoned=pd.read_csv('data/ripcity.csv',sep =',',keep_default_na=False)\n",
        "# tweets_unpartitoned=pd.read_csv('data/billnye.csv',sep =',',keep_default_na=False)\n",
        "\n",
        "# tweets_unpartitoned=pd.read_csv('data/wnut17test_ner.csv',sep =',',keep_default_na=False)\n",
        "tweets_unpartitoned=pd.read_csv('data/btctest_ner.csv',sep =',',keep_default_na=False)\n",
        "# tweets_unpartitoned=pd.read_csv('data/venezuela_ner.csv',sep =',',keep_default_na=False)\n",
        "# tweets_unpartitoned=pd.read_csv('data/covid_2K_ner.csv',sep =',',keep_default_na=False)\n",
        "# tweets_unpartitoned=pd.read_csv('data/tweets_3k_annotated_ner.csv',sep =',',keep_default_na=False)\n",
        "\n",
        "# tweets_unpartitoned=pd.read_csv('data/roevwade_ner.csv',sep =',',keep_default_na=False)\n",
        "# tweets_unpartitoned=pd.read_csv('data/billnye_ner.csv',sep =',',keep_default_na=False)\n",
        "# tweets_unpartitoned=pd.read_csv('data/pikapika_ner.csv',sep =',',keep_default_na=False)\n",
        "# tweets_unpartitoned=pd.read_csv('data/billdeblasio_ner.csv',sep =',',keep_default_na=False)\n",
        "# tweets_unpartitoned=pd.read_csv('data/ripcity_ner.csv',sep =',',keep_default_na=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0U9BbL2FhYd"
      },
      "outputs": [],
      "source": [
        "#tokenizer here is the BERT model's tokenizer\n",
        "local_NER_Module= LocalNERModule(sentence_tokenizer, tokenizer, alt_model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAsb7l-0Fly9"
      },
      "outputs": [],
      "source": [
        "# global_NER_Module = GlobalNERModule(entityPhraseEmbedder, device,'wnut17')\n",
        "\n",
        "global_NER_Module = GlobalNERModule(entityPhraseEmbedder, device,'btc')\n",
        "\n",
        "# global_NER_Module = GlobalNERModule(entityPhraseEmbedder, device,'tweets_3k_annotated')\n",
        "\n",
        "# global_NER_Module = GlobalNERModule(entityPhraseEmbedder, device,'tweets_6k_annotated')\n",
        "\n",
        "# global_NER_Module = GlobalNERModule(entityPhraseEmbedder, device,'venezuela')\n",
        "\n",
        "# global_NER_Module = GlobalNERModule(entityPhraseEmbedder, device,'covid_2K')\n",
        "\n",
        "# global_NER_Module = GlobalNERModule(entityPhraseEmbedder, device,'billdeblasio')\n",
        "# global_NER_Module = GlobalNERModule(entityPhraseEmbedder, device,'ripcity')\n",
        "# global_NER_Module = GlobalNERModule(entityPhraseEmbedder, device,'pikapika')\n",
        "# global_NER_Module = GlobalNERModule(entityPhraseEmbedder, device,'roevwade')\n",
        "# global_NER_Module = GlobalNERModule(entityPhraseEmbedder, device,'billnye')\n",
        "\n",
        "\n",
        "# global_NER_Module = GlobalNERModule(entityPhraseEmbedder, device,'classifier-train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwCB8GpCFqXU"
      },
      "outputs": [],
      "source": [
        "print('Tweets are in memory...')\n",
        "\n",
        "length=len(tweets_unpartitoned)\n",
        "batch_size=length\n",
        "print(length, batch_size)\n",
        "val=math.ceil(length/batch_size)-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7sD_5LtFxVk"
      },
      "outputs": [],
      "source": [
        "tweet_batch = tweets_unpartitoned\n",
        "print(len(tweet_batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5VfP7sdFzu8"
      },
      "outputs": [],
      "source": [
        "tweet_to_sentences_w_annotation={}\n",
        "# df_out_holder_Phase1=[]\n",
        "total_time=0\n",
        "reintroduction_threshold_dummy=0\n",
        "max_batch_value=112\n",
        "z_score=1\n",
        "\n",
        "# for g, tweet_batch in tweets_unpartitoned.groupby(np.arange(length) //batch_size):\n",
        "phaseI_timein=time.time()\n",
        "g=0\n",
        "tuple_of= local_NER_Module.extract(tweet_batch,g)\n",
        "phaseI_timeout=time.time()\n",
        "\n",
        "print('local emd time',(phaseI_timeout-phaseI_timein))\n",
        "\n",
        "tweet_base=tuple_of[0]\n",
        "contextual_embeddings=tuple_of[1]\n",
        "candidate_base=tuple_of[2]\n",
        "elapsedTime= tuple_of[4] - tuple_of[3]\n",
        "phase2stopwordList=tuple_of[5]\n",
        "# print('len of tweet_base = '  len(tweet_base))\n",
        "tweet_to_sentences_w_annotation=tuple_of[6]\n",
        "total_time+=elapsedTime\n",
        "print(elapsedTime,total_time)\n",
        "\n",
        "# df_out_holder_Phase1.append(tweet_base)\n",
        "\n",
        "print ('Produced', g)\n",
        "print(\"**********************************************************\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "am_WGnH5F21o"
      },
      "outputs": [],
      "source": [
        "# # #PHASE I CHECKING:\n",
        "# calculate_f1_ner_engine(tweet_to_sentences_w_annotation, local_NER_Module.phaseIpredictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RaNiMz3zzIA"
      },
      "outputs": [],
      "source": [
        "additional_list = ['dannysimpson 12','new zealand','latin america','east coast','west coast','chatteris- manea','lasa national congress', 'aust special forces',\n",
        "                   'adammacdougall 5','south korean','irish news','mv augusta brutale','myung ga','central asia','general motors','premier league','new zealand','west midlands','china town','celestine lake','maida vale','west africa','boeing 777','liztilley 84','liberal democrats','fort hood',\n",
        "                   'white house','waltengoo nar','new york','north america','south america','united states','olive garden','crystal palace' ,'abortion','gmail','fox news','physics','trump administration' ,'fisa warrant','global warming',\n",
        "                   'rogue one','labour party','fred hollows foundation','biddulph moor','lady mary downer','ac / dc','ac/dc','northern ontario','cape breton','atlantic canada','air canada','ontario tories','vancouver canucks','statistics canada','air canada','cloverhill prison','south sudan','coryjane 1080','hrjohn 44','dancohen 17','mt cook','president obama','southeast ukraine',\n",
        "                   'supreme court','south korea','north korea','costa rica','new orleans', 'badlands national park','covid 19','harry _ styles', 'punta cana', 'los angeles','united kingdom','coronavirus',\n",
        "                   'bbc news','bbc 1','bbc world','kuala lumpur','ffc','brfc','honey nutloops','australian open','blackberry messenger','hongkong','wakefield council','sir alex ferguson','russian bank','bank of ireland','kilkenny bridge','north galway','galway bay','northern ireland','tel aviv','sierra leone','evening standard']\n",
        "for candidateText in additional_list:\n",
        "    candidate_base.__setitem__(candidateText.split(),len(candidateText.split()),[],0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wI-xf3eKfXi",
        "outputId": "a4f0de2b-e9ec-4a8e-83c2-18dc7585d141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5699 candidates from phaseI\n",
            "['tosca', 'gateshead', 'shaw', 'blink 182', 'blink technologies inc', 'dorothy gale', 'return to oz', 'chargers', 'sherlock', 'coe', 'stamford', 'facebook', 'facebook timeline', 'wadey', 'salmon valley', 'j edgar', 'j leno sito', 'j lo', 'j whaley music', 'j j abrams', 'j cole', 'leo', 'leo messi', 'leo johnson', 'pride and prejudice', 'fulham', 'wenger', 'hobo', 'rob', 'rob ogleby', 'rob mcclelland', 'rob ford', 'otis', 'green', 'green goddess', 'kane', 'disneyworld', 'florida', 'daniel', 'daniel james evans', 'daniel jones', 'daniel cormier', 'daniel sturridge', 'daniel ellsberg', 'daniel morcombe', 'daniel radcliffe', 'daniel finkelstein', 'woolwich', 'oracle', 'mysql', 'perl', 'java', 'city', 'city centre', 'city garden apts', 'london', 'london college', 'london king cross', 'yorkshire', 'yorkshire police', 'yorkshire dales', 'doncaster', 'doncaster rovers', 'leeds', 'lamb of god', 'mancity', 'liverpool', 'liverpool city council', 'kuyt', 'aguero', 'louise', 'louise mensch', 'alan', 'alan b stard', 'alan turing', 'alan partridge', 'alan yentob', 'alan porter', 'alan kavanagh', 'alan mulally', 'alan pardew', 'twitter', 'east', 'east coast', 'hackney', 'hackney people', 'come dine', 'extra spicy', 'itv', 'lewes', 'enough', 'brenda lee', 'idiot abroad 1', 'rachid harkouk', 'qpr', 'sex and the city', 'sex the city', 'carrie', 'casey', 'air', 'air sonic armada', 'air force school', 'air canada', 'trip to the moon', 'bbc', 'bbc news', 'bbc 1', 'bbc world', 'newcastle', 'newcastle eagles rlfc', 'jakclark', 'utd', 'connect', 'everton', 'everton fc', 'dannysimpson', 'dannysimpson 12', 'battlefield', 'battlefield 3', 'philly', 'cheesesteaks', 'digitalkipper', 'one', 'one direction', 'one show', 'one thing', 'one last chance', 'spotify', 'dianeabbott', 'andrew', 'andrew stone', 'andrew dickson', 'andrew forrest', 'andrew stoner', 'andrew wiggins', 'andrew gilligan', 'nataliecooper', 'daisybruce', 'mark', 'mark wright', \"mark d'arcy\", 'mark lawrenson', 'mark rutte', 'mark zuckerberg', 'mark selby', 'mark lowe', 'mark dreyfus', 'mark twain', 'mark fields', 'markihenderson', 'nexxgendrue', 'snickers', 'catan', 'geno', 'mufc', 'manutd', 'georgedobell', 'perthcollegeuhi', 'perth', 'gene cohen', 'mature mind', 'warwickshire', 'jeanne d arc', 'culprate', 'gary oldman', 'gary numan', 'gary cahill', 'gary hart', 'lv', 'manchester', 'manchester met library', 'manchester united', 'manchester city', 'msmonica', 'munckinland', 'chefmarccollins', 'dragoons', 'jordan', 'jordan rhodes', 'leona lewis', 'beady eye', 'high', 'high flying birds', 'high street low lives', 'kitchen', 'cultofdomkeller', 'veritydouglas', 'dean street', 'pamflet', 'declan', 'declan rudd', 'dempsey', 'hunico', 'teddibiase', 'cole', 'josh', 'sharp', 'lambert', 'saintsfc', 'frank', 'frank kern', 'frank lowy', 'frank lampard', 'barcelona', 'take', 'drpeterthraft', 'happy', 'happy ending', 'janicehorton', 'issy miyake', 'dtodenver', 'fb', 'boris', 'boris johnson', 'sophietweddle', 'paul', 'paul scholes', 'paul parker', 'paul kelly', 'paul nurse', 'paul gautlier', 'paul grogan', 'paul ryan', 'paul mckenna', 'paul heyman', 'sir', 'sir alex ferguson', 'sir cliff richard', 'sir #alexferguson', 'ferguson', 'dave', 'dave hancock', 'united', 'united charities market', 'united states', 'united kingdom', 'vidic', 'pantilimon', 'ipod', 'david', 'david bowie', 'david westwood', 'david dimbleby', 'david dickinson', 'david heyman', 'david norris', 'david morrissey', 'david cameron', 'david miliband', 'david bebber', 'david harewood', 'david sexton', 'david sexton #intodarkness', 'david letterman', 'saracens', 'owen farrell', 'bath', 'ncis la', 'ericcolsen', 'pretty woman', 'pretty little liars', 'wild at heart', 'kirk', 'brighton', 'brighton centre', 'brighton detention centre', 'beyonce', 'sky', 'sky full of stars', 'sky news', 'alex', 'alex burrows', 'alex johnson', 'alex salmond', 'alex white', 'alex rodriguez', 'harry', 'harry potter', 'harry bun', 'harry rednap', 'harry _ styles', 'lma', 'god', 'god forgives', 'las', 'vegas', 'steelers', 'cosmo body', 'chiltern', 'moor park', 'naked', 'shaune_mj', 'henry', 'henry hitchings', 'henry kissinger', 'henry j kaiser', 'uk', 'uk north sea', 'duchess of cambridge', 'duchess of york', 'duchess kate', 'corrie', 'birmingham', 'birmingham city', 'colin doyle', 'colin blakemore', 'colin pillinger', 'bcfc', 'birminghamcity', 'blues', 'colindoyle', 'coppers', 'ilkeston', 'machine gun kelly', 'potters', 'bar', 'hertfordshire', 'shalanga', 'taiya soul', 'demzy', 'croatia', 'gillovny', 'bad', 'bad day', 'bad science', 'darwin', 'darwin deez', 'tw', 'louisebrealey', 'guardian', 'guardian us', 'youview', 'farah', 'lorna', 'xfactor', 'jason euell', 'jason mraz', 'jason sherlock', 'sony', 'bigbig', 'fourfourtwo', 'african', 'african cup of nations', 'african country', 'african union', 'wraxall', 'bristol', 'dexter', 'dexter filkins', 'willow', 'awkward george', 'truro', 'cornwall', 'palmerston road', 'southsea', 'kimberleybarber', 'austrian', 'tedbaker', 'pentagram', 'dominic lippa', 'university', 'university of the arts london', 'university of virginia', 'ireland', 'gemini', 'lanadelrey', 'eastenders', 'aragorn', 'frodo', 'lord', 'lord of the rings', 'lord of the rings lego', 'lord rennard', 'colwyn bay', 'colwyn bay civic society', 'olbasoil', 'youtube', 'primavera', 'scotland', 'scotland bill', 'scotland yard', 'glasgow', 'glasgow school of art', 'malton', 'phunkation', 'label', 'worx', 'mommie dearest', 'cray cray', 'blighty', 'christian', 'christian brothers', 'vaccines', 'ecco shoes uk', 'edmund burke', 'edmundburke', 'lucy beale', 'lucy in disguise', 'lucy meck', 'misskeverdeen', 'hunger games', 'neven maguire', 'desmond', 'levenson', 'julian', 'julian #assange', 'us', 'us marine', 'us army', 'nbc', 'nbc today show', 'imam alhussain', 'edinburgh', 'ruben', 'martinclaudon', 'ghettohikes', 'justin', 'justin bieber', 'justin beiber', 'justin trudeau', 'supra tk society', 'hmv', 'noah and the whale', 'tom', 'tom petty', 'tom wilkinson', 'tom 22howe', 'tom waterhouse', 'tom cruise', 'tom parker', 'deacon blue', 'emily osment', 'emily davison', 'friends', 'chiddybang', 'realchiddy', 'xaphoonjones', 'hitler', 'google', 'johnbattelle', 'shona', 'vaccine', 'dunn', 'bradleyjohnsonx', 'peter', 'peter hotez', 'peter van onselen', 'peter standen', 'peter gleeson', 'peter dutton', 'peter mackay', 'peter robinson', 'peter jackson', 'hangover 2', 'limitless', 'inspector norse', 'james_cyprus', 'dannyroca', 'clauds', 'zambian', 'raywilkins', 'mileycyrus', 'nufc', 'bring me the horizon', 'michelle', 'michelle williams', 'michelle knight', 'heath ledger', 'kingston', 'ben', 'ben howard', 'ben goldacre', 'ben arfa', 'ben bernanke', 'ben wizner', 'ben kingsley', 'mondoben', 'martin', 'martin luther king', \"martin o'neill\", 'martin parkinson', 'martin koughan', 'martin mcguinness', 'martin kaymer', 'zooey deschanel', 'lydia', 'lith', 'kinect', 'windows', 'heathrow airport', 'tchesshyre', 'djerba', 'tunisia', 'times', 'psn', 'pc', 'pc world', 'danwrexham', 'temple', 'temple run', 'temple run 2', 'enter the dragon', 'williams', 'lee', 'brooke', 'rupert', 'rupert murdoch', 'rupert everett', 'buzzfeed', 'cena', 'ryder', 'wwe', 'snooki', 'marcuscollinsuk', 'bruno', 'bruno mars', 'brazilians', 'wiz khalifa', 'smallville', 'super ladotelli', 'super trooper', 'super bass.now', 'super eagles', 'super soulers', 'library', 'ladotelli', 'chaos_theory', 'ed miliband', 'ed vaizey', 'ed robertson', 'ed moloney', 'ed conway', 'ed sheeran', 'pots', 'g-cloud', 'new', 'new zealand', 'new democrats', 'new york', 'new orleans', 'york', 'york times', 'york risk services group inc', 'kenny dalglish', 'kenny g', 'dougie', 'two', 'two times', 'door cinema club', 'metronomy', 'tribes', 'academy', 'ghostlondon', 'rfleeshman', 'sharondclarke', 'royal', 'royal sussex county hospital', 'royal philips', 'royal gallery', 'royal free hospital', 'royal air force', 'eastern', 'eastern rd', 'sopa', 'wikipedia', 'osx', 'salford', 'salford city council', 'timi', 'timi yuro', 'shameless', 'mozambique', 'maputo', 'verdademz', 'reading', 'talksport', 'vouchar', 'halamadrid', 'galaxy hot chocolate', 'galaxy nexus', 'galaxy mega', 'octane', 'iamchandizzy', 'til kingdom come', 'russianhcr', 'dj dubl', 'andymcmahon', 'valentina', 'widnes', 'bob', 'bob marley', 'bob woodward', 'bob geldof', 'mavado', 'messiah', 'durex', 'durex play', 'americanidol', 'dom', 'wilbatronus', 'peppa pig', 'caffè', 'nero', 'leontiaflynn', 'alexpryce', 'planetrockradio', 'philipsayce steamroller', 'drake', 'glee', 'msleamichele', 'voldemort', 'nicola', 'nicola adams', 'nicola sturgeon', 'real', 'real gypsies', 'real sociedad', 'real madrid', 'carolinelucas', 'blackadder', 'rihanna', 'mariakelly', 'king_jerwayne', 'edsheeran', 'ipswich', 'ipswich west', 'bluewatch mcfc', 'tyrone', 'christaylor', 'thekentwhitaker', 'stevorley', 'camden market', 'anouska_woods', 'westcountry', 'devon', 'aldgate', 'elena', 'portland', 'portland timbers', 'dorset', 'ashleypavittjb', 'enyapallett', 'laurenellishall', 'charlie', 'charlie rose', 'charlie sheen', 'jcole', 'renz', 'northallerton', 'lloytron bolero', 'fm alarm clock', 'broonaldinho', 'ian', 'ian malcolm', 'ian macfarlane', 'celine nano', 'lincoln', 'sam', 'sam smith', 'sam judd', 'sam bruynseels', 'sam c', 'deasy', 'gerrard', 'gareththomas', 'black', 'black sheep', 'black banner', 'black sea', 'golden sheep', 'liv', 'office', 'office for mac 2011', 'gingrich', 'romney', 'darlo', 'savedarlo', 'clare', 'dark brotherhood', 'dark knight rises', 'dark horse', 'elder', 'elder scrolls v skyrim', 'brian', 'brian cox', 'brian purcell', 'brian feeney', 'brian mcknight', 'brian williams', 'el', 'el guincho', 'pres', 'bertielwales', 'mommysumo', 'terry_oneill', 'djourou', 'john', 'john prescott', 'john hughes', 'john williams', 'john cusack', 'john mayer', 'john lennon', 'john butler', 'john cobb', 'john paul pietrus', 'john paul ii', 'john legend', 'john brown', 'john mcareavey', 'john key', 'john tamihere', 'john banks', 'john cornyn', 'john baird', 'john mckay', 'john van wisse', 'john winfield', 'john brooks', 'john kerry', 'mario', 'mario draghi', 'australia', 'central', 'central coast', 'central perk', 'central asia', 'isabelle', 'stephen', 'stephen lawrence', 'stephen harper', 'stephen roche', 'stephen sutton', 'stephen colbert', 'stephen a smith', 'frosty', 'ox', 'tedxcardiff', 'amazon', 'troy', 'troy grant', 'hsm', 'hsm 2', 'sue fortin', 'sue steward', 'star', 'star child', 'star trek', 'star trek into darkness', 'star wars episode vii', 'stephanie keyes', 'treysongz', 'smurfs village', 'converge', 'natmacfarlane', 'cher', 'cher lloyd', 'siri', 'evi', 'dance', 'witham', 'essex', 'earthakitt', 'fassbender', 'effy', 'marcus collins', 'white', 'white stripes', 'white house', 'seven nation army', 'devlin', 'o2 arena', 'skysportsnews', 'nataliesawyer', 'steve', 'steve jones', 'steve martin', 'towie', 'chicobalzaretti', 'julie', 'julie bishop', 'virgin', 'virgin school', 'media', 'death row dogs', 'death cab for cutie', 'obama', 'obama wh', 'lennyhirsch', 'way to harlem', 'i_gregoryporter', 'good', 'good will hunting', 'missmillco', 'senderos', 'philippe senderos', 'luwrufc', 'uclan', 'krakenrum', 'kanyewest', 'mamas papas trip buggy', 'apple', 'apple green', 'apple magic', 'apple store', 'apple itunes', 'apple iphone 4 white', 'mix', 'mcfc', 'de jong', 'ken', 'serenity hair spa', 'chris', 'chris brown', 'chris rock', 'chris foy', 'chris hartcher', 'chris huhne', 'chris nkulor', 'andy', 'andy murray', 'andy carroll', 'jesus', 'bradford', 'symantec', 'pcanywhere', 'sasaki', 'dave_ashworth', 'gordon ramsay', 'wales', 'lenovo', 'kind of wonderful', 'eventbrite', 'phish', 'mike', 'mike gordon', 'mike brown', 'mike tyson', 'mike savage', 'mike tindall', 'mike lee', 'nagini', 'gemmamiddleton', 'sasha_pearce', 'banf', 'man', 'man utd', 'man united', 'man city', 'dorchester', 'felicity huffman', 'pier', 'scart', 'alexandramusic', 'iphone', 'iphone 6', 'iphone 6 plus', 'iphone 4 16gb', 'butlins', 'ronaldo', 'old trafford', 'prince', 'prince of persia', 'prince william', 'prince harry', 'prince charles', 'albertines', 'lewisham way', 'typography', 'tietam brown', 'ji sung park', 'claremont', 'gas hall', 'gallery', 'sigma sd', 'spurs', 'savic', 'barufc', 'captain', 'captain morgan', 'captain america', 'orpington', 'randstad', 'randstad financial', 'victor valdes', 'victor ibarbo', 'robin fucking williams', 'robin hood', 'robin williams', 'robin thicke', 'nadal', 'djokovic', 'rafa', 'alexander', 'alexander payne', 'alexander khodakovsky', 'alexander salmond', 'george', 'george clooney', 'george river', 'george galloway', 'george harrison', 'george osborne', 'george w bush', 'george alexander louis', 'george h w bush', 'trent reznor', 'atticus ross', 'gwtdt', 'thomas zipp schwartze', 'thomas eisfeld', 'thomas duncan', 'thomas heatherwick', 'saatchi gallery', 'ginamaldina', 'angelasimmons', 'wolfgang munchau', 'jlm', 'delon armitage', 'england', 'england saxons', 'augusta brutale', 'hallam', 'billy sharp', 'billy elliot the musical', 'billy mandy', 'southampton', 'grimsby', 'santander', 'profhelenstorey', 'bethshak', 'nick', 'nick kershaw', 'shannon', 'shannon matthews', 'malia', 'abba', 'xbox', 'microsoft', 'jim', 'jim white', 'jim madden', 'jim day', 'jim frederick', 'jim middleton', 'jim gibney', 'jim gavin', 'skysports', 'morrison', 'charliekmartin', 'exeter', 'beeb', 'pienaar', 'defoe', 'kfc', 'words with friends', 'burnley', 'buxton', 'buxton fc', 'scott', 'scott maxfield', 'pitbull', 'trig', 'trey', 'trey songz', 'steven john franks', 'steven tyler', 'steven gerrard', 'steven spielberg', 'maidstone', 'ursula le guin', 'dispossessed', 'syston', 'jane', 'jane lewis', 'british', 'goat', 'metallica', 'battery', 'itunes', 'chum', 'mayans', 'brussel sprout', 'sara', 'cambridge', 'lesley garrett', 'sunderland', 'bethanne', 'alias s5', 'briantracy', 'ivy', 'ivy asare', 'joeycottle', 'syllables', 'kev', 'bergertron', 'kelly', 'kelly rowland', 'kelly brook', 'yuri_smith', 'west', 'west bromwich albion', 'west wing', 'west ham', 'west end', 'west coast', 'west midlands', 'west africa', 'brom', 'efc', 'evertonfc', 'commodore 64', 'enrique', 'merseyside', 'hull', 'hull city', 'bill', 'bill shorten', 'bill murray', 'bill belichick', 'rooney', 'cashtastic', 'loftus road', 'discovery', 'discovery channel', 'discovery park', 'liliput', 'simonryan', 'adamryan', 'pat fenlon', 'pat tillman', 'nigeria', 'flixster', 'jls', 'emma watson', 'emma hill', 'potter', 'alesha dixon', 'fifa', 'homerton', 'ghostbusters', 'lakedistrict', 'leslie uggams', 'scooby', 'scooby doo', 'doobie', 'doo', 'espn', 'lauren bircher', 'lauren bacall', 'jasontheladiesman', 'tfl', 'vodafone', 'charl_watkins', 'misscardiff', 'dando', 'london-london', 'nw-north', 'uefa', 'sw', 'van helsing', 'nottingham', 'nottingham railway station', 'emsd', 'ruddington', 'joão bidu', 'eu', \"wo n't give\", 'iplayer', 'liam', 'liam bradley', 'liam neeson', 'liam adams', 'liam o neill', 'liam fox', 'klein bottle', 'hacks', 'rubber dinghy rapids', 'kik', 'livelovea ap', 'sydney', 'richmond', 'va', 'mitt romney', 'rick santorum', 'rick perry', 'iowa', 'ric', 'jack mcvicar', 'jack niall', 'jack 0wright', 'jack hill', 'luton', 'cool runnings', 'boulder', 'boulder weekly', 'colorado', 'colorado rockies', 'usa', 'bt', 'bt infinity homehub', 'huawei', 'arran', 'abington', 'nevada', 'louis vuitton', 'louis spence', 'louis walsh', 'louis van gaal', 'louis tommo', 'absolute', 'radio', 'radio national', 'demba ba', 'st', 'st edmund college', 'james', 'james peters', 'james vincent mcmorrow', 'james corden', 'james bond', 'james franco', 'james risen', 'james merlino', 'james moore', 'james foley', 'james alexander gordon', 'james rodríguez', 'james johnson', 'brogandavies', 'tim', 'tim howards', 'tim howard', 'tim cleverley', 'tim leiweke', 'tim hortons', 'tim bradley', 'mags', 'catherine tate', 'catherine middleton', 'adele', 'youth in revolt', 'spalding', 'skegness', 'jiangsu', 'sebastien buemi', 'red', 'red river', 'red arrows', 'red rocks amphitheatre', 'red cross', 'bull', 'jaime alguersuari', 'kanye', 'kanye west', 'dallas', 'colombia', 'wakefield council', 'melwood', 'vancanucks', 'sedin', 'eddie', 'bear grylls', 'martin_freeman', 'jeremyjhardy', 'frankie', 'frankie cocozza', 'celebrity big brother', 'vogue', 'andywaterman', 'louisville', 'willy', 'valencia-sevilla', 'sonia', 'big', 'big brother', 'big bang theory', 'big tobacco', 'wiley', 'romeo', 'romeo dallaire', 'andy_carey', 'louisreeson', 'clappleby', 'jflorance', 'quagmire', 'kimkardashian', 'handxguns', 'ziavenier', 'oliver twist', 'oliver letwin mp', 'resident evil 4 hd', 'deadmau 5', 'zachwehner', 'weeknd', 'downton abbey', 'maccabbi', 'maccabbi kieyat', 'ironi amishav', 'khan', 'trianglerecords', 'sugababes 1.0', 'anuj bidve', 'japan', 'volks', 'delirious', 'martinsmithtv', 'gere', 'dalai lama', 'britain', 'redbridgelive', 'glentoran', 'ripbob', 'lostprophets', 'chaz', 'selena', 'zayn', 'yellow dress', 'urban', 'outfitters', 'odd future', 'bevis', 'swansea', 'nyc', 'stella', 'stella mccartney', 'sons of the desert', 'sons of wichita', 'laurel and hardy', 'foreign legion', 'lush tush', 'elton john', 'peckhamjohn', 'southend', 'suarez', 'westlife', 'zaynmalik', 'anthony evans', 'anthony kiedis', 'anthony horowitz', 'anthony weiner', 'hatton garden', 'giant haystacks', 'nicky', 'nicky romero', 'burger', 'king', 'king edwards', 'king of latenight', 'len goodman', 'strictly', 'belfast', 'y.rilah', 'abigail', 'abigail tarttelin', 'scottie_martin', 'tourchwood', 'horrors', 'florence', 'misty', 'sainsburrys', 'toy story 3', 'tumblr', 'midlands', 'onigiri', 'hairspray', 'zac efron', 'link', 'clickbank', 'jay', 'jay z', 'jay electronica', 'max', 'yello', 'amazingphil', 'jones', 'jones new york sport shorts', 'waynerooney', 'lamp', 'joey barton', 'joey elias', 'paris', 'paris hilton', 'pegasus bridge', 'jay-z', 'europe', 'ba', 'fudge', 'bridesmaids', 'coldplay', 'visa', 'amy_nicola', 'nottm forest', 'leicester', 'leicester city', 'pearson', 'tunchev', 'beastie boys', 'anna angels', 'anna henderson', 'german', 'rebecca', 'rebecca ferguson', 'robbie keane', 'robbie williams', 'villa', 'whsmith', 'arndale', 'borgen', 'angel', 'smooth criminal', 'mtv', 'michael', 'michael jackson', 'michael niziolek', 'michael gove', 'michael schumacher', 'michael 5sos', 'michael clifford', 'michael jordan', 'garyjohnson', 'aaronpearse', 'hollyoaks', 'dennis', 'dennis the menace', 'dennis ross', 'bb', 'arsenal', 'kooks', 'natalie', 'natalie ambersley', 'x factor', 'x factor usa', 'family', 'family guy', 'brown', 'brown sugar', 'subway', 'mitchmyths', 'mitch', 'twilight saga', 'works', 'dudley', 'walsall', 'whatkatiewore', 'katie', 'howard webb', 'qualcomm mdm 9615', 'crystal palace', 'cardiff', 'cardiff city', 'macbraynes', 'kierenjacobsen', 'codecademy', 'js', 'loveyourbodyxtina', 'richard', 'richard ford', 'richard macdonald', 'richard flanagan', 'richard attenborough', 'richard rawson', 'pires', 'logitech g19', 'g15', 'night', 'night with the stars', 'night shift', 'pepper', 'tm103', 'ross', 'ross ashcroft', 'reds', 'betfair', 'andywebb', 'mallard_worksop', 'darren', 'lea', 'naya', 'guide', 'asia', 'ye', 'niallofficial', 'vampire diaries', 'vampire weekend', 'adambrook', 'better', 'adamlambert', 'nana', 'chrissy', 'chrissy sandow', 'olivia', 'kellyrenshaw', 'maljamea', 'brazil', 'newcastlejetsfc', 'gold', 'gold members', 'gold coast titans', 'greenwich', 'merco', 'south', 'south pole', 'south leitrim', 'south tipperary general hospital', 'south yorkshire police', 'south korean', 'south america', 'south sudan', 'south korea', 'general', 'general motors', 'motors', 'sixsigma', 'groezrock', 'prem', 'bolton', 'transcorp', 'lagos', 'kanban', 'jake_wood', 'medchart', 'casualty', 'meekmill', 'groundwork uk', 'cadburys', 'olympic', 'kirkby', 'james_gaskell', 'henrythomas', 'parliament', 'griffins', 'morning jacket', 'morning ireland', 'wordless chorus', 'mw2', 'killjoys', 'roman abramovich', 'archers', 'nokiagadgets n9 pr1', 'garageglasgow', 'dan', 'dan schneider', 'dan brown', 'milner', 'balotelli', 'adams', 'adobe', 'tennesse', 'path 2.0', 'carragher', 'benitez-ess', 'ghostyspoon', 'xemmasulway', 'infinity farnborough', 'johnson', 'johnson johnson', 'texas', 'texas health presbyterian hospital', 'shon', 'damianknowles', 'jonnolondon', 'best marigold hotel', 'judi dench', 'samir nasri', 'russia', 'mcdonalds', 'sufi inayat khan', 'tourist', 'dorothyfriedman', 'allanschoenberg', 'amazing atheist', 'amazing race canada', \"p'dice\", 'thewantedmusic', 'ellen', 'ellen show', 'ea', 'chelsea', 'chelsea pensioner', 'chelsea flower show', 'herts stags', 'sussex', 'seinfeld', 'calvin klein', 'calvin harris', 'deep impact', 'armageddon', 'genghis grill', 'katy fwy', 'katy perry', 'moroccan', 'mohammed', 'mohammed deif', 'china', 'china resources', 'china town', 'pixiesongs', 'kiss the stars', 'changed', 'paddy', 'paddy ashdown', 'paddy power', 'loughborough', 'thingsmorelikelythanteveztoqpr', 'moon', 'magic school bus', 'tank', 'adam smith', 'kant', 'mackintosh', 'kara_malinczak', 'lawrencepearce', 'itsreilly', 'alexgeorge', 'strathaven', 'scottish', 'scottish unemployed workers network', 'scottish nationalist party', 'darron gibson', 'dr_kev', 'long', 'eaton', 'chive', 'nth', 'teamcrunch', 'nicola_craig', 'fionablitz', 'i_jumelle', 'whoiskaty', 'yasminblitz', 'ellabtwjackson', 'nicol_bradley', 'danielgraves', 'darkermorgul', 'i-tunes', 'water for elephants', 'lola', 'jason_murphy', 'timlovejoy', 'pats', 'matt di angelo', 'matt taylor', 'matt cardle', 'matt baggott', 'matt frei', 'matt damon', 'natasha', 'million pound drop', 'tonipayne', 'orange', 'orange order', 'orange is the new black', 'mick_wilkinson', 'aus', 'danjenks', 'helprichardodwyer', 'iraq', 'jerry maguire', 'jerry jones', 'leighsteinberg', 'proactiv', 'alizafarsays', 'arriva', 'casper', 'avermedia', 'jaipur', 'gibson', 'jeff steling', 'stewart downing', 'stewart island', 'todmorden', 'lse', 'agatha christie', 'vale', 'stoke', 'djarum blacks', 'tgi fridays', 'nicolemx', 'er', 'supernatural', 'jared', 'jensen', 'mila kunis', 'uniteds', 'inbetweeners movie', 'cj', 'albert', 'albert einstein', 'albert reynolds', 'marilyn', 'marilyn monroe', 'bombay', 'tonicah', 'schwarzkopf professional', 'amy', 'amy winehouse', 'amy toensing', 'back', 'back to black', 'israel', 'baalim', 'cody', 'ramsey', 'peacocks', 'emo', 'imjameswesley', 'michaelowenfacts', 'knocks', 'doctor', 'juliec', 'pixie', 'pixie lott', 'pixietenenbaum', 'anderson', 'mars', 'mars bar', 'patriots', 'giants', 'steven_moffat', 'sanlam', 'cayman', 'alfa brera', 'swindon', 'swindon town', 'gillingham', 'luke', 'luke rooney', 'luke batty', 'luke hemmings', 'luke bryan', 'luke 5sos', 'anne frankly', 'anne atkins', 'meridian', 'toms', 'profbriancox', 'darlington', 'ballotelli', 'darlingtonfc', 'arry redknapp', 'iso 9001', 'marsden pedigree', 'wigan', 'myung ga', 'meadows estate', 'centre', 'josephyobo', 'leephillips', 'biscayne blvd', 'aventura', 'hester', 'hester residence', 'kingswinford', 'marcussingh', 'yoseob', 'salem', 'myspace', 'whatson 6music', 'afp', 'love and hip hop', 'love in the future', 'edenbridge', 'kent', 'kent brantly', 'costa', 'costa coffee', 'costa del crime', 'costa del tramore', 'costa rica', 'girl', 'girl model', 'mindless behavior', 'wael', 'ghonim', 'egypt', 'swallows and amazons', 'skins', 'rachel', 'rachel barnhart', 'said', 'taylor swift', 'coney island', 'greek', 'markwoodexplorer.com', 'union', 'union glacier', 'day', 'maine', 'sidney sheldon', 'amadeus', 'gad', 'nathan', 'francesmcveigh', 'mk', 'mk dons', 'forest', 'crew love', 'beckersher', 'cbs', 'mirandes', 'espanyol', 'official_flo', 'sia', 'annie', 'felix', 'felix magath', 'labour', 'labour party', 'mandelson', 'jimmy', 'jimmy martinez', 'jimmy choo', 'clarke', 'solihull', 'esc', 'ring', 'bargain hunt', 'quorn', 'boo ritson', 'eurozone', 'kingdoms of amalur', 'louisbly 96', 'harrisonwatt', 'nandos', 'haunted', 'arthur', 'arthur ransome', 'milne', 'winnie the pooh', 'emili sandé', 'dartford', 'dartford river crossing', 'blue', 'blue square premier', 'blue man', 'blue lions', 'blue mountains', 'direction', 'drive', 'ryan gosling', 'ryan leef', 'ryan miller', 'fenerbache', 'ios', 'android', 'android wear', 'face', 'tinsel', 'byronsmith', 'wetherby', 'thisisglos', 'theochouse', 'camra', 'carnage', 'martha marcy may marlene', 'surrey', 'ewell east', 'runescape', 'iker jimenez', 'notebook', 'vow', 'disney', 'disney pooh changing bags', 'roko', 'maddogs', 'charlies', 'wendyquent', 'saddam', 'cheltenham film club', 'veej_jay', 'paulchelt', 'jeremy kyle', 'jeremy lefroy', 'jeremy hunt', 'jessiej', 'staceyevo', 'cecil balmond', 'anish kapoor', 'lakshmi mittal', 'arcelormittal', 'hollywills', 'joeyessex', 'markwright', 'missjesswright', 'mcgiff', 'dunaway', 'lizwoodbridge', 'jeffery', 'paulgore', 'nhs', 'seth godin', 'seth rogen', 'chubby', 'helen hart', 'helen bamber', 'helen thomas', 'etta james', 'winehouse', 'n sync', 'nyx', 'liamcurranhair', 'theblackout', 'kerrang', 'cambridgeshire', 'chingford', 'argos', 'believe', 'susan', 'susan berson', 'american dad', 'american canyon', 'american hustle', 'romantica', 'gina kuschke', 'bluetack', 'hershey cookies creme', 'isabella__honey', 'altered beast', 'bc', 'metro', 'vancouver', 'vancouver canucks', 'vancouver canuck', 'kewford eagles north', 'firkins bakery', 'doug', 'doug ford', 'norwichcityfc', 'oakley', 'terry', 'holt', 'manu', 'manu ginobili', 'scum', 'garth', 'garth davis', 'garth brooks croke park', 'waitrose', 'copella', 'cherylcole', 'arctic monkeys', 'kindle', 'artist', 'frimpong', 'fame', 'kay panabaker', 'marc albrighton', 'marc ayrault', 'samurai jack', 'maomi', 'concordia', 'blackberry messenger', 'blackberry bold 9790', 'pranayoga', 'norseman', 'meg', 'meg and mog', 'nasri', 'arseshavin', 'rosiky', 'phil jones', 'phil rudd', 'phil spector', 'phil mickelson', 'warsi', 'hemo', 'aston', 'aston martin', 'ford', 'nissan micras', 'gareth', 'twitters', 'kingdom', 'gagavision', 'jernandes', 'thomson', 'deborah', 'leanne clark', 'rey', 'diana', 'diana spencer', 'diana nyad', 'iaea', 'norfolk', 'kyle 28walker', 'kyle falconer', 'oxbridge', 'keith chegwin', 'miley cyrus', 'nan', 'marcel', 'isaac', 'isaac newton', 'eden hazard', 'bama', 'napa', 'ct600', 'companies house', 'hulk hogan', 'loose women', 'danny wilson', 'adrianhendry', 'sea', 'sea and suspicious parents', 'macbook', 'macbook pro', 'mick', 'mick jagger', 'mick hannemann', 'belgrave ward', 'tutti frutti', 'tory', 'cameron', 'oreos', 'zagreb', 'level 42', 'northern', 'northern lights', 'northern gateway', 'northern ontario', 'northern ireland', 'samsung', 'samsung galaxy', 'samsung smartwatches', 'dutch', 'tigerwoods', 'lukedonald', 'mcilroyrory', 'abi dhabi', 'manc', 'adjustment bureau', 'specsavers', 'steve_worsley', 'londonwestend', 'debden', 'laurenconrad', 'mali cuba', 'afrocubism', 'ralph fiennes', 'cineworld', 'newport', 'coriolanus', 'beargrylls', 'floyd mayweather', 'chels', 'annabelle', 'withnail', 'lizziecundy', 'sbs', 'ausvsindia', 'ac', 'ac dc', 'ac milan', 'ac / dc', 'anastacia', 'aqua', 'bloodhound gang', 'celestine lake', 'tiny tower', 'mr_lee_fleming', 'foxes', 'nonabeez', 'hot corners', 'editors', 'munich', 'stobart', 'redbridge', 'viva', 'viva brother', 'viva forever', 'maggie', 'maggie smith', 'louiespence', 'fukushima', 'libya', 'zambia', 'dyer', 'hakuna mata', 'classico', 'dzeko', 'aki', 'u2', 'bono', 'barca', 'joannawise', 'weak willed', 'remains', 'fed', 'fed reserve', 'marianmjr', 'm62', 'croft interchange', 'birchwood', 'linux', 'imessage', 'x-plane 10', 'tesco', 'geminem 2503', 'kissed', 'alfie', 'bmw', 'bmw mini r58 3', 'ilovedust', 'dio', 'rainbow in the dark', 'viv campbell', 'needtobreathe', 'beautiful', 'peterborough', 'iranian', 'iran', 'islamabad', 'pakistan', 'avpm', 'andrewdaviespr', 'adecolborne', 'christchurch', 'joannesutton', 'b52s', 'chrismoylesshow', 'sarah', 'sarah teather', 'sarah burton', 'sarah palin', 'sportsdesk', 'tricycle cinema', 'cellar door', 'war', 'war horse', 'war of the vikings', 'benedict cumberbatch', 'dude', 'key 103', 'starboynathan', 'graham', 'graham phillips', 'middle', 'middle east', 'saudi', 'saudi prince', 'arabia', \"d'angelo\", 'stockholm', 'ghost protocol', 'ghost stories', 'oldhamchronicle', 'fabulous russella', 'alberto', 'milky', 'milky way', 'turkey', 'erdogan', 'janus', 'amy_smith', 'missdioroffic', 'roystonblythe', 'jamie', 'jamie sokalsky', 'jamie bryson', 'samuelgroche', 'thejamieroche', 'gabby', 'zoeey deschanel', 'roncharles', 'nbcc', 'briton', 'congo', 'maddie', 'maddie mccann', 'msn', 'courtz', 'explosion', 'eli paperboy', 'jaws 2', 'lil wayne', 'lil b', 'mirror', 'mega man', 'lisamaffiauk', 'romeolondon', 'lahore', 'policestory', 'manning', 'takapuna', 'evra', 'anfield', 'yahoo', 'ollyofficial', 'russell brand', 'russell kane', 'hindsight', 'berlin', 'germany', 'craig bellamy', 'craig wong', 'stevie gerrard gerrard', 'kendrick lamar', 'patrick stewart', 'chardonnay', 'bloomsbury', 'phelps', 'rachelpilley', 'der rosenkavalier', 'absent friends', 'bakbuk', 'hakupha', 'harhur', 'peroni', 'bizzle', 'pow 2011', 'donovan', 'murgh mangalore', 'hugh jackman', 'hugh van es', 'hugh grant', 'morrisonsoffers', 'morrisons', 'jayy', 'derek', 'derek malcolm', 'brewery', 'cora', 'jesshatchett', 'poundland', 'sabrinaghayour', 'chefbenhughes', 'cheftimanderson', 'gavinmccabe', 'warrior', 'jerusalem', 'irene', 'jaysavatar', 'jono', 'vw the dark side', 'get carter', 'get enough', 'layer cake', 'elizabethtown', 'dammyvenables', 'oloni', 'portsmouth', 'jose', 'jose mourinho', 'sevilla', 'chambo', 'sagna', 'walcott', 'wanted', 'glad you came', 'mw3', 'zara', 'zara phillips', 'jonny', 'mortal kombat', 'onaga', 'top gear', 'top of the lake', 'top of the rockies', 'fazer', 'spartacus', 'cage the elephant', 'kings of leon', 'smashing pumpkins', 'marisha_d', 'barnet', 'ucl', 'mit', 'arts council', 'sheffield', 'dundee', 'dundee utds', 'johnny russell', 'johnny carson', 'md', 'huffington', 'richieprice', 'tie fighter', 'rbs', 'velindre', 'antiques roadshow', 'shafri', 'telford', 'lightmoor road', 'a4169 queensway', 'icarly', 'eclipse', 'eclipse sql', 'coronation st', 'rangers', 'kris', 'kris boyd', 'mls', 'india', 'coralie', 'leannejane', 'lorenzomingus', 'crazy stupid love', 'tuanbonero', 'nik_sims', 'denny', 'wars', 'indycube', 'mitchellzoey', 'dale farm', 'meatloaf', 'bon', 'bon iver', 'calgary', 'troi', 'faketimo', 'isa', 'switzerland', 'charles', 'charles parker', 'timo', 'portugal', 'hmrc', 'queen', 'queen palaces', 'nhm_london', 'crusaders', 'owain brown', 'racecourse', 'thornton holmes', 'mitie', 'yorkshir', 'nicole scherzinger', 'paula abdul', 'paula patton', 'demi', 'wilmer', 'wrexham', 'hearts', 'jessica_bram', 'leisadouglas', 'aeropuerto de', 'tenerife', 'sur-reina sofía', 'reina sofía', 'granadilla', 'abona', 'dot cotton', 'borussia dortmund', 'edmunds', 'davidperry', 'barnsley', 'vaz te', 'minstrels', 'evan ensign', 'shrek', 'broadway', 'ave', 'q west end', 'welcome to manchester', 'veseli', 'eco', 'prague cemetery', 'william', 'william weaver', 'william hill', 'william pooley', 'william and kate', 'william ackman', 'william wilberforce', 'citeh', 'freddie ljungberg', 'freddie starr', 'attenborough', 'richardfortey', 'channel', 'succubus club', 'malaysia', 'malaysia airlines', 'malaysia airlines mh 17', 'malaysia airlines boeing 777 200', 'ukraine', 'poland', 'malaysian', 'malaysian airlines', 'malaysian airlines mh 17', 'russians', 'donetsk', 'donetsk region', 'mas', 'interfax', 'aljazeera', 'ukrainian', 'russian', 'russian soyuz', 'russian bank', 'bloombergtv', 'buk', 'grabovo', 'thai', 'thai airways', 'mh 17', 'mh 370', 'amsterdam', 'ifax', 'kuala', 'kuala lumpur', 'lumpur', 'allah', 'palestine', 'msia', 'astro awani', 'strelkov', 'igor', 'igor girkin', 'poroshenko', 'indian', 'ocean', 'raya', 'ukr armed forces', 'flightradar', 'malaysians', 'borodai', 'gazan', 'reuters', 'shaktarsk', 'lufthansa', 'reagan', 'kal 007', 'putin', 'snezhnoe', 'airway', 'archduke', 'franz ferdinand', 'shazana salleh', 'klm', 'secretary', 'secretary hagel', 'state', 'jen psaki', 'crimea', 'snizhne', 'najib', 'najib razak', 'sama', 'singapore', 'singapore airlines', 'dominique faget', 'intel', 'cnn', 'cnn international', 'indonesia', 'indonesia parliament', 'belgium', 'force one', 'minister', 'dato seri najib razak', 'spain', 'netherlands', 'netherlands embassy', 'kiev', 'iata', 'assad', 'mclaren', 'gaza', 'sabah', 'michelsidibe', 'docklands', 'australian', 'australian bureau of statistics', 'australian open', 'korean', 'korean peninsula', 'singaporeair', 'flight mh 17', 'sa', 'sa 11', 'airbus', 'kremlin', 'un', 'un security council', 'tony', 'tony abbott', 'tony harcup', 'tony gwynn', 'tony mayo', 'timmermans', 'potus', 'gazans', 'rozsypne', 'najibrazak', 'eindhoven', 'holland', 'senators', 'inabo', 'palau', 'chinese', 'chinese assoc', 'vic', 'vic park', 'vic dept of human services', 'vic police', 'vic labor', 'vic premier', 'vic greens', 'kevin', 'kevin sheedy', 'kevin constant', 'kevin mccarthy', 'therese', 'parlt', 'matt_levinson', 'alisoncroggon', 'dromana bowls', 'oz', 'coalition', 'adf', 'cats', 'amandarishworth', 'parl house', 'aussies', 'trimega', 'marius', 'abc', 'abc news', 'abc insiders', 'abc iview', 'katherine king', 'dutton', 'dermie', 'qatar', 'qatar heroes', 'qtcanberra', 'canberra', 'labor', 'labor party', 'mikecullen', 'eagleby learning college', 'cpa australia', 'asic', 'missionbeat', 'chrismogster', 'steven_noble', 'sharonbirdmp', 'garethjward', 'peter_gill', 'debspillane', 'david_ritter', 'greenpeace', 'murphymiranda', 'summersanne', 'melbourne', 'melbourne mcdonalds', 'jg', 'house', 'house of reps', 'house of lords', 'house republicans', 'rba', 'sean', 'sean brown', 'sean dunne', 'sean mcmeekin', 'graeme_bowman', 'lowy institute', 'eastwood fire brigade', 'landcare', 'forde', 'nrlknights', 'fran kelly', 'kangaroo island', 'margaret', 'margaret macmillan', 'maronite college of the holy family', 'newtonmark', 'treasury', 'nrl_bulldogs', 'shazam', 'wavepark group', 'wa', 'wa assoc for the blind', 'ariannahuff', 'bernard levin', 'tasmanian', 'nancy pelosi', 'nancy werlin', 'wendy_harmer', 'tas', 'tas health', 'julia christensen', 'colvinius', 'radionational', 'kitchener', 'kitchener way', 'abbott', 'yagoona', 'jasonclaremp', 'mdsimmonds', 'jimboykin', 'baton', 'rouge', 'council', 'lismore', 'ballina', 'clarence', 'tweed', 'nsw', 'nsw labor', 'nsw government', 'nsw blue mountains', 'nsw central coast', 'justine', 'justine mccarthy', 'janelle', 'rocky', 'stuart robert', 'stuart hall', 'stuart scott', 'adelaide', 'japanese', 'leon byner', 'tugun', 'rex', 'rudd', 'michelangeloruc', 'tonyzappia', 'sri', 'lanka', 'bernardkeane', 'palmer united party', 'jacqui lambie', 'oversharing express', 'heart', 'heart 107', 'feeney', 'christopher pyne', 'christopher kent', 'christopher musqua', 'thomas_drake', 'jesselynradack', 'nesa', 'washington', 'washington redskins', 'washington post', 'washington navy yard', 'dc', 'dc navy yard', 'barnaby joyce', 'marcuskelson', 'stevemolzer', 'hifi', 'arcane', 'medicare', 'mayorjd', 'casino saleyards', 'grafton', 'writerscentreau', 'fremantle press', 'iview', 'carlyhjackson', 'jon', 'jon faine', 'jon cornish', 'jon snow', 'jon stewart', 'kirby', 'c_pyne_mp', 'deborah_oneill', 'skynewsagenda', 'jasmin 1', 'gia hoi', 'mcewen', 'johnbutlertrio', 'redbank army camp', 'paulpisasale', 'syria', 'jordon', 'lebanon', 'aust', 'aust special forces', 'riot games', 'somerton', 'somerton slsc', 'victoria', 'victoria park', 'victoria school', 'victoria st', 'victoria street', 'instagram', 'cnbc', 'higgins', 'foxtel', 'gaffneypaul', 'raaf base', 'pearce', 'lisamillar', 'grong town', 'pac hydro', 'solar council', 'renewable energy', 'manus', 'reza barati', 'constitution', 'australians', 'hawaiin', 'villawood', 'waleed aly', 'tigers', 'mrgregtaylor', 'leannefaulkner', 'act', 'parliamentary library', 'lee_tennant', 'bankstown', 'advancement', 'tap', 'gc', 'murdoch', 'tasmania', 'collins', 'tasmanians', 'joe hockey', 'joe oliver', 'joe benett', 'joe biden', 'joe budden', 'nationals', 'hawkesbury', 'jacobgreber', 'townsville', 'nbn', 'opi', 'secrets', 'doc neeson', 'senator', 'senator bushby', 'senator gillibrand', 'neville', 'neville bonner', 'christine', 'christine milne', 'christine lagarde', 'mercury', 'liberal', 'liberal europe', 'liberal party', 'liberal democrats', 'post', 'anna_lisa', 'joe_hildebrand', 'freo', 'paterson', 'fremantle_fc', 'villers', 'bretonneux', 'herald', 'michaelwestbiz', 'sonycentreto', 'boston', 'boston college', 'boston marathon', 'colinhanks', 'mark_sheppard', 'remymichaels', 'marygracekirby', 'firefly', 'nlambert', 'carrie_preston', 'convent primary', 'nenagh', 'mrrobertmcgrath', 'corrwill', 'jarpad', 'jensenackles', 'mishacollins', 'alexshinta', 'bowie', 'jeffersonpenna', 'edmonton', 'centennial', 'centennial plaza', 'chinatown', 'howiemandel', 'geelong', 'running with the boys', 'astro_davids', 'image', 'dmitry lovetsky', 'neilsen', 'mrjoshcharles', 'game of thrones', 'ipad', 'ipad air 2', 'ipad mini 3', 'zac_posen', 'fijiwater', 'spacex', 'cnet', 'annapaquinfans', 'pixiep', 'myo armband', 'nathanfillion', 'rachelzoe', 'williamshatner firefly', 'redsox', 'vox', 'lisa_alot', 'rocket', 'rocket park', 'onexone', 'dinapugliese', 'zacefron', 'pnemcova', 'billclinton', 'illshawn', 'zetanai', 'jenniferelm', 'michelmartelly', 'wyclef', 'amandaziva', 'cgy', 'ericfrancis', 'roy thompson', 'roy hodgson', 'macklemore', 'gabselisa', 'rayelle', 'marnie', 'brownbagwine', 'rutina', 'rutina wesley', 'ray', 'ray jennings', 'midlandpolice', 'chi', 'richards', 'end', 'pads', 'helmets', 'bryan', 'bryan murray', 'bryan singer', 'murray clan', 'murray bridge', 'shawville', 'que', 'officialdfoster', 'maxineskillen', 'baublebar', 'janeygodley', 'ott', 'mansfieldlibr', 'drew buckley', 'santa', 'wonder woman', 'fernsehturm', 'mary', 'mary downer', 'mary beard', 'mary turner', 'mary barra', 'vsrovert', 'space oddity', 'dina', 'jorg_yvr', 'canada', 'askmrmickey', 'mickey', 'williamdevry', 'curtisdickson', 'iroquois nation', 'world', 'world field', 'tsn', 'imjeffraymond', 'candy crush', 'mattrpianoman', 'jtimberlake', 'olivier grunewald', 'anh co tran', 'amanda', 'joseph', 'joseph gordon levitt', 'tsnbobmckenzie', 'trayvon', 'trayvon martin', 'loupardi', 'lou', 'california', 'samsparro', 'park', 'park community council', 'astro_alex', 'astro_reid', 'askdrruth', 'jeff_daniels', 'mikemckenzie', 'walmart', 'walmart canada', 'steelweaver', 'danielmacsween', 'time', 'pandaisarose', 'canadian', 'canadian medical association', 'canadian press', 'beth', 'brad richards', 'brad jacob', 'thejimmichaels', 'matthews', 'dragon mk 2', 'jianghomeshi', 'oddity', 'denmark', 'vesa', 'anthony_graham', 'vinidiamandis', 'modelallianceny', 'niki m nray', 'danilo', 'lucia liu', 'harneymike', 'jstevens', 'shawnmckenziesn', 'ericjjohnson', 'dominos', 'markduplass', 'robertconradtv', 'ichadlowe', 'amandadecadenet', 'kelly_clarkson', 'barry', 'barry devlin', 'mykeynote', 'pharrell', 'pharrell williams', 'gust of wind', 'universalorl', 'jlo', 'jamosfoundation', 'piersmorgan', 'officialfoxes', 'carolinaxo', 'sportlobster', 'brad_attitude', 'bogota', 'luvalentino', 'philipandelman', 'robinroberts', 'jonnysinc', 'team usa', 'stevenlangton', 'christiesinc', 'wale', 'nia', 'gma', 'justincoit', 'iggy', 'iggy azalea', 'latin', 'latin america', 'america', 'pedro', 'tonikroos', 'luis suárez', 'luis suarez', 'dickycollins', 'karan mitchell', 'matthew', 'matthew church', 'matthew parris', 'matthew grey gubler', 'youngandhungry', 'abcfamily', 'carter', 'dashboutique', 'austin', 'austin swift', 'austin mahone #austinmahone', 'nv', 'vine', 'lukejwindsor', 'lenadunham', 'jk_rowling', 'mt', 'mt cook', 'yale', 'north', 'north bay', 'north east lincolnshire', 'north america', 'north korea', 'north galway', 'ussoccer', 'morgan', 'morgan freeman', 'morgan stanley', 'morgan schneiderlin', 'milan', 'kaká', 'napoli', 'ancona', 'genoa', 'jamielynnspears', 'nist', 'wedding', 'wedding ringer', 'mickwillow', 'ig', 'ashleytisdale', 'lana del rey', 'lana del ray', 'whitehouse', 'alejandrosanz', 'colbiecaillat', 'andygrammer', 'linnjones', 'drshefali', 'maxmutchnick', 'italy', 'finallymario', 'kevinspacey', 'kimmel', 'madrid', 'christie', 'harper', 'harper north', 'shaniatwain', 'messi', 'nicolehurst', 'bosnia', 'hercegovina', 'daveboll', 'ubersocial', 'kuwtk', 'ladygaga', 'johnlegend', 'jacquieleemusic', 'hilaryduff', 'centric', 'according', 'jasonsilva', 'target', 'target canada', 'reddit', 'christinagrimme', 'utube', 'management', 'toronto', 'toronto blue jay', 'toronto zoo', 'conner greene', 'santiago', 'trevorproject', 'haarlemmermeer', 'boys', 'harvey', 'jessica lowndes', 'jessica benko', 'jessica simpson', 'keynote', 'harryconnickjr', 'huxley', 'stuartcamp', 'arianagrande', 'radiodisney', 'hartluck', 'unistudios', 'mummy', 'jurassic park', 'cheynethomas', 'squidward', 'zeus gameover', 'montpellier', 'france', 'lance stephenson', 'eckharttolle', 'louis_tomlinson', 'versace', 'simon', 'simon robey', 'simon hoggart', 'sonny', 'syco', 'riff raff', 'kardashian kollection', 'saint', 'laurent', 'marco carola', 'ibiza', 'caesarspalace', 'sportscenter', 'sheritasberry', 'radiomiggy', 'bjork', 'human behaviour', 'drmayaangelou', 'amnesia ibiza', 'marcbartra', 'eleven madison park', 'davidburtka', 'pbs', 'sheryl sandberg', 'kissfmuk', 'benedetto demaio', 'journals', 'leelee', 'johnnewmanmusic', 'hacker', 'avaaz', 'wilson_daniella', 'cannes', 'jesseleonard', 'ohio', 'cote', 'ivoire', 'nickyhilton', 'mpn', 'mariana_gde', 'russellcrowe', 'honduras', 'eye of the tiger', 'vevo', 'lucybellnix', 'charades', 'halle berry', 'chriscolfer', 'mj', 'pepe', 'jimmyfallon', 'opelssl', 'tina', 'tina fontaine', 'devlinhuxtable', 'aprilbeck', 'aliciakeys', 'kendricklamar', 'barça', 'walrus', 'rose', 'rose bowl', 'sin city 2 a dame to kill', 'lakings', 'barbara zoo', 'barbara mcculkin', 'stevestoute', 'tanning of america', 'common', 'core', 'iheartradio', 'pg', 'taylorswift', 'lupita_nyongo', 'people magazine', 'laugh factory', 'live at the royal albert hall', 'jude', 'giroud', 'cfda', 'katniss', 'see fire', 'scotty', 'gloria-uss', 'reveal', 'detroit', 'detroit tigers', 'drdre', 'andre', 'andre russell', 'cicero', 'inyama', 'nigerians', 'snapchat', 'britneyspears', 'ubermenu', 'edsheeranplanet', 'jimcarrey', 'jermain', 'finland', 'maya angelou', 'connormcginty', 'eric', 'eric lauren', 'eric pickles', 'eric garner', 'eric cantor', 'eric holder', 'lady', 'lady mary downer', 'shak', 'johnhenryryan', 'robot', 'guillermo del toro', 'rio', 'rio tinto', 'rica', 'napier', 'cinderella', 'carlyraejepsen', 'janeiro', 'jacobschultz', 'jacob', 'hansrosling', 'jackson pollock', 'seanmoussavi', 'tyleroakley', 'ferrari world', 'rum house', 'molly ryan', 'juanes', 'paulo nutini', 'paulo stadium', 'austinmahone', 'orlando', 'georgelopez', 'erikalinn', 'kingrich_mh', 'alexaluria', 'joycebonelli', 'makeupbymario', 'uruguay', 'ericmcmanus', 'microsoftstore', 'buffalo', 'matuidi', 'woody', 'bertie ahern', 'alison lapper', 'drkeithredmond', 'irish', 'irish water', 'irish news', 'macdonaghroisin', 'adrianweckler', 'ciaraobrien', 'dublin', 'dublin west', 'dublin south west', 'dublin north central', 'eamon gilmore', 'irishtimes', 'audreycarville', 'mindfield', 'gaa', 'joebrolly', 'garymurphydcu', 'anmailleach', 'shane_martin', 'alanryan', 'aerlingus', 'dublinairport', 'ladfleg', 'paulmwatson', 'liamdelaneyecon', 'limerick', 'brennanmarjorie', 'ruth coppinger', 'gabrielle mcfadden', 'tipp south', 'easter rising', 'cag', 'nama', 'dublingaalive', 'laois', 'shellyindublin', 'niallharbison', 'foursquare', 'robkitchin', 'conallmaccoille', 'davyresearch', 'dana', 'mexico', 'maurice hayes', 'argentina', 'nz', 'lisbon treaty', 'initiative', 'brianjohnspencr', 'realeddiehobbs', 'keithdkennedy', 'declanharmon', 'kilkenny', 'kilkenny hills', 'kilkenny bridge', 'miguelgarcia', 'seanad', 'rivada', 'croke park', 'leinster', 'dubs', 'toyota', 'toyota sienna', 'il duce', 'draghi', 'norahcasey', 'rte', 'garryvoe', 'universities branch', 'ruairi quinn', 'ted', 'ted cruz', 'pira', 'joan_burton', 'donal ryan', 'joan burton', 'joan rivers', 'eamondelaney', 'varadkar', 'mikey', 'department', 'department of finance', 'department of health', 'dept of finance', 'noonan', 'sf', 'paulageraghty', 'edelmcginley', 'maynooth', 'maynooth university', 'richardwaghorne', 'sinn', 'sinn féin', 'sinn fein', 'johngilroyteam', 'margareteward', 'susanokeeffe', 'uzbekistan', 'phoenix', 'anise', 'inna', 'jillkerby', 'cormac_staunton', 'anglo irish treaty', 'polref_ireland', 'collateral damage', 'oconnellhugh', 'eamonryan', 'dublincityuni', 'walt kilroy', 'walt #disney world', 'robhoban', 'westminster', 'westminster council', 'nui', 'antrim', 'johnkav', 'irishwoman who shot mussolini', 'siobhan lynam', 'kieranshannon', 'ewanmackenna', 'dingle', 'fianna fail roscommon', 'ff', 'gerry adams', 'gerry brownlee', 'gerry goffin', 'michaelaw', 'eamongilmore', 'louisebyrnenews', 'dub', 'dubcitycouncil', 'bishop', 'dublinseagulls', 'daveyhannigan', 'brazilian', 'de_nva', 'ecr', 'alde', 'ecclestone', 'patten', 'paulrouseucd', 'cork', 'cork city', 'lkellyoconnor', 'drogheda', 'gerryadamssf', 'ni', 'helenorahilly', 'lcreighton', 'finegael', 'dáil', 'adriankavanagh', 'galway', 'galway east', 'galway bay', 'galway city', 'earth', 'hananrazek', 'maryeregan', 'lenaicvaudin', 'markobroin', 'fenian', 'claire', 'claire trevett', 'zealand', 'donna_cooney', 'taoiseach', 'ballyhea', 'monaghan', 'cavan', 'sendavidnorris', 'doiregaa', 'islamic', 'islamic state', 'islamic jihad', 'fine', 'fine gael', 'fox news', 'clones', 'saffrons', 'seanfionn', 'worker', 'party', 'johncreedon', 'dail', 'hogan', 'fortrum', 'mero', 'frankmcdonald', 'khodorkovskiy', 'lebedev', 'republic', 'fitzgeraldfrncs', 'armagh_gaa', 'ulster', 'ulster championship', 'ulstergaa', 'ie', 'alliance party offices', 'gael', 'chris_derry', 'garda', 'ananelson', 'jonnyfallon', 'kealanjflynn', 'noelwhelan', 'conorwilson', 'tuam', 'newyorkgaa', 'bodengaa', 'daithí mckay', 'féin', 'clifford jr', 'lorraine', 'johnobrennan', 'osvaldo ardiles', 'rory', 'rory broomfield', 'winston', 'richardhills', 'balmoral', 'mr_sam_brown', 'te radar', 'te apiti wind farm', 'artax', 'northcote', 'waitemata', 'rnz', 'ashburton', 'zealanders', 'paulhenryshow', 'vern', 'waikato', 'waikato university', 'mizjwilliams', 'taane', 'janfrodeno', 'lavamagazine', 'nymphomaniac', 'ii', 'jamesjrobertson', 'taupo', 'wendywings', 'coryjane', 'coryjane 1080', 'cory', 'pramcoll', 'manacoll', 'wellington', 'wellington city', 'trevor mallard', 'jeannemoos', 'bourkey', 'noel', 'lizziemarvelly', 'katyperry', 'hrjohn', 'hrjohn 44', 'harleypeters', 'goldman', 'sachs', 'istanbul', 'turkmenistan', 'wendy', 'andrealessi', 'a_smith', 'alexahotz', 'wendyl', 'dancohen', 'dancohen 17', 'amiens cathedral', 'amylmcdonald', 'cadbury #dreamfactory', 'brooke_hs', 'fault in our stars', 'fault in our stars movie', 'hamilton', 'fargo', 'davidclarke', 'realstevenadams', 'oamaru', 'opera house', 'natashautting', 'kingnivin', 'alexquilliam', 'googleglass', 'lake', 'lyndon', 'canterbury', 'cook', 'cateowen', 'mastodon', 'clintvsmith', 'cunliffe', 'ruminatornz', 'davidcunliffemp', 'jimmybarnes', 'castlecliff', 'wanganui hospital', 'willie', 'willie jackson', 'jt', 'waititi', 'gonzo_mcnulty', 'td', 'greens', 'wasim', 'les p', 'les mis', 'docherty', 'kendallforbes', 'hurricanes', 'queenofcobden', 'manawatu hills', 'jayson_bryant', 'ferg', 'grey', 'lynn park', 'ruataniwha', 'szechuan', 'cruel intentions', 'totl', 'logies', 'vincristine', 'trevormallard', 'tovaobrien', 'oecd', 'playa hotel', 'charlesdagnall', 'joshemett', 'umu', 'moonlight', 'mockanz', 'williamson_nz', 'hope and wire', 'kyleipryor', 'kaitaia', 'pukehinau flats', 'willis street', 'universe', 'jolenegolightly', 'chch', 'waiariki institute', 'rotorua', 'tec', 'aj', 'tay', 'gabbymonsta', 'thejamiebowen', 'jamesmoran', 'nzf', 'williamson', 'leigh cleveland', 'nelson', 'nelson distr', 'cheviot', 'hurunui district', 'shawnmoodie', 'conrad', 'jessie', 'chichen itza', 'devlinlive', 'cowan_jimmy', 'fred hollows foundation', 'sarahcowley', 'allblacks', 'eliota_sapolu', 'eliota', 'ozzie', 'four stars', 'movies', 'sanjeevpalar', 'yarraville', 'yarraville club', 'vinemantri', 'reno', 'georgemonbiot', 'ukip', 'ukip clacton', 'european', 'conwycbc', 'portheirias', 'maida vale', 'psv', 'dwp', 'modern slavery', 'meg_hilliermp', 'galas', 'liver ducks', 'rachelgoodchild', 'oliverkaytimes', 'ecuador', 'geoffshreeves', 'rwandan', 'norf', 'suff', 'ess', 'chloe', 'mepal', 'dannyhackett', 'universal credit', 'conservatives', 'billyfoulkes', 'thecourteeners', 'londoners', 'itvlondon', 'danfrancis', 'bonkersbexley', 'british-polish', 'mariusz haladyj', 'biddulph', 'biddulph moor', 'premier', 'premier league', 'yaya toure', 'stancollymore', 'queens hospital', 'cannock chase', 'aidan burley', 'bruce', 'bruce flegg', 'chester', 'aluko', 'freeman_george', 'arundel', 'charlieelphicke', 'pps', 'ids', 'iain', 'iain watters', 'easton', 'greenrobtelford', 'wimblington', 'chatteris', 'manea', 'hector bellerin', 'são', 'isis', 'lib', 'lib dem', 'lib dems', 'lib party', 'northbrook st', 'newbury', 'bnmth', 'gravity', 'strattondorset', 'goresbrook', 'fenland', 'didier deschamps', 'co-op', 'britannia house', 'dortmund', 'albion_crosby', 'gove', 'kategreensu', 'fear', 'khalsa hockey club', 'houseofcommons', 'thames', 'thames valley', 'dean_walmsley', 'seaswanlets', 'schalke', 'drogba', 'bridge', 'matthewdancona', 'coulson', 'damianastuart', 'unesco', 'mikearmiger', 'mc 5', 'tories', 'kate', 'kate humble', 'kate ellis', 'kate middleton', 'kate winslet', 'humble', 'nature', 'letwino', 'dr_airbrake', 'penkridge', 'osborne', 'osborne treasury', 'scottwilkins', 'samiwilkins', 'glogenuk', 'heddas', 'communitiesuk', 'spursofficial', 'fazio', 'stambouli', 'lloris', 'partizan belgrade', 'tottenham', 'tottenham tories', 'barnham', 'eastergate', 'arun', 'atalanta', 'betts', 'nato', 'monmouthshire', 'marshall', 'fabio', 'caulker', 'turner', 'gunnarsson', 'mutch', 'whittingham', 'daehli', 'bellamy', 'campbell', 'norwichjcp', 'bbcnorthampton', 'libdems', 'snp', 'anniesland', 'cathcart', 'shettleston', 'tahir_london', 'londonmidland', 'tescohednesford', 'kailashchandobe', 'ssp healthcare', 'sefton', 'angela merkel', 'regents park royal green jackets band', 'hyde park', 'farage', 'rodriguez', 'wolfsburg', 'coleman', 'baines', 'mirallas', 'toffees', 'hart', 'zabaleta', 'kompany demichelis', 'kolarov', 'garcia', 'silva', 'aloe', 'pizza cream soda', 'hammersmith', 'robshepherd', 'nigerian', 'juncker', 'lexingtonsteel', 'audrey', 'hazel', 'swynnerton', 'connie', 'dunkirk', 'asaleresident', 'stretford fire station', 'israeli', 'unite', 'cosyclubbristol', 'geoffreyjfowler', 'shinzo abe', 'guildhall', 'abeconomics', 'cllrmarkdobson', 'bournemouth', 'laurentmurphy', 'chrisfriaz', 'crossrail', 'dementiafriends', 'francis report', 'jimmurphymp', 'cristiano ronaldo', 'lochee', 'bournemouthrotary', 'hong', 'kong', 'mtr', 'gregclark', 'clwyd west', 'mp', 'ukparliament', 'morrisseyobe', 'mandy', 'hamiltons', 'michaelvaughan', 'ministry', 'd_smith', 'firstcc', 'rafal trzaskowski', 'goqueenspark', 'bbcradio', 'janegarvey', 'helengoodmanmp', 'ed_miliband', 'simonwierny', 'tottenhamtories', 'polish', 'gnev', 'gn', 'mignolet', 'skrtel', 'agger', 'flanagan', 'henderson', 'allen', 'allen daviau', 'allen iverson', 'sterling', 'sturridge', 'berks council', 'associated press', 'jasonrspencer', 'stylebook', 'colleen newvine', 'keithrastall', 'lizmackean', 'fliplingo', 'sirsteven', 'lakes', 'michelledean', 'albertocairo', 'hemisphere', 'koughan', 'paulmcnally', 'wanda', 'heathermcurtis', 'user', 'user vanessagezari', 'doleinstitute', 'book', 'michaelniziolek', 'ann', 'ann maguire', 'arbor news', 'mlive', 'ny', 'ca', 'mattjroper', 'richardkendall', 'marabrockakil', 'wilbertlcooper', 'jeff_licciard', 'zenoradio', 'nab', 'fcc', 'net', 'apme', 'imidwest', 'music', 'marx brothers', 'duck', 'pelican bay', 'vietnam', 'saigon', 'jesse', 'jesse ventura', 'navy seal', 'splc', 'ryderdavid', 'finnish', 'catherineanaya', 'uscannenberg', 'missouri', 'jayrjordan', 'timfusciardi', 'george_berridge', 'lisamjarvis', 'usc', 'gosparksc', 'national center', 'huffpo', 'kimfoxwosu', 'nicoleeshelman', 'allisonpearson', 'wonkblog', 'financial', 'jaspjackson', 'bergdahl', 'baquet', 'benjamin mullin', 'benjamin netanyahu', 'poynter', 'social', 'newspaper guild', 'wardsville', 'mo', 'marcsettle', 'sarahmarshall', 'ona', 'kimbui', 'evonnebenedict', 'ericcarvin', 'bjsheehan', 'publicis', 'omnicom', 'carroll', 'martinbelam', 'montreal', 'montreal city hall', 'petersburg', 'chrisvaccaro', 'tedd scripps leadership institute', 'hartford', 'geoffreyfowler', 'praddenkeefe', 'loaded gun', 'diane gray', 'bedesworld', 'prof', 'karol sikora', 'stuartforbes', 'stv', 'olaf palme', 'doj', 'mattburgess', 'andrewsduncan', 'ccasciano', 'ahcj', 'beltway', 'bloomberg', 'following the world', 'beverly spicer', 'westword', 'patty calhoun', 'cia', 'elilake', 'airbnb', 'margoandhow', 'amyzipkin', 'anniemdance', 'alanblaustein', 'men', 'carl bernstein', 'npr', 'dylanreeve', 'oil', 'ijnet', 'la__cuen', 'tel', 'tel aviv', 'aviv', 'boxer', 'feinsten', 'tmobile', 'africa', 'photoham', 'nasw', 'joannauk', 'yorker', 'ifjj', 'peteashton', 'gabekahn', 'columbia', 'tow center', 'knight', 'snowden', 'joseiswriting', 'border patrol', 'reedalbergotti', 'karenrussell', 'acluva', 'peta', 'warner', 'katebevan', 'samjamez', 'jerometaylor', 'pearswick', 'sargasso sea', 'gulf coast', 'chicago', 'scotthornsby', 'nathancphillips', 'professor', 'jan leach', 'srm university', 'chennai', 'cma', 'leather', 'hamptonu', 'warrington', 'jason_cobb', 'report', 'fbi', 'bolter', 'sjmc', 'fpc', 'koch brothers', 'danielschulman', 'taywiles', 'ashley highfield', 'ashley mcdonald', 'milwaukee', 'sharpener', 'ghana', 'ghanaparliament', 'starghana', 'ap', 'center', 'blacklands', 'mcnamara', 'hilton als', 'ruby', 'ruby dee', 'pulitzer', 'pulitzer center', 'widows', 'juliaduin', 'jimwaterson', 'billkeller', 'reeva', 'reeva steenkamp', 'fat chance', 'kobane', 'turkish', 'cfmeu', 'coles', 'gonzalo', 'bermuda', 'bahamas', 'ten', 'network', 'neil', 'neil patrick harris', 'wall', 'street', 'ferouz', 'pentagon', 'international', 'international space station', 'anu', 'don coulson', 'don valley west', 'caitlin forrest', 'oscar pistorius', 'oscar pistorious', 'oscar #pistorius', 'steenkamp', 'philippines', 'federal government', 'federal reserve', 'workcover', 'nepal', 'annapurna', 'korea', 'riverina', 'moranbah', 'kumi taguchi', 'asada', 'catholic church', 'police integrity commission', 'annajhenderson', 'arnhem', 'land', 'timminchin', 'roald dahl', 'matilda', 'brisbane', 'brisbane council', 'zia abdul haq', 'macquarie point', 'kesha', 'png', 'goulburn court', 'rosie', 'rosie batty', 'david_speers', 'domensin', 'jamesmassola', 'chriskkenny', 'aaron connelly', 'aaron hernandez', 'indonesian', 'indonesian parliament', 'jokowi', 'mathiascormann', 'medibank private', 'dantehanwannon', 'joko widodo', 'dan_bourchier', 'jpgaultier', 'davidleyonhjelm', 'alannah mactiernan', 'angustaylormp', 'tomwconnell', 'jean', 'jean mcconville', 'kieran_gilbert', 'idalia', 'brendan o connor', 'brendan eich', 'qld', 'jetstar', 'denpasar', 'kerry', 'kerry stokes', 'boy from nowhere', 'ash_gillon', 'victoriapolice', 'greg anderson', 'tyabb oval #lukebatty', 'coronial inquest', 'skybusiness', 'lasa', 'lasa national congress', 'staceylee', 'swanston st', 'ahronyoung', 'samdawson', 'queensland', 'iraqi', 'iraqi city', 'widodo', 'ninabstevens', 'jasonmorrisonau', 'peter_reith', 'barnaby_joyce', 'wallabies', 'ewen mckenzie', 'trinity college', 'joshua', 'joshua hardy', 'liztilley', 'liztilley 84', 'simolove', 'vanessa_trezise', 'cormann', 'shorten', 'cormannator', 'arnold the governator', 'jacktheinsider', 'ali__clarke', 'sharrimarkson', 'essendon afl', 'essendon fc', 'billshortenmp', 'ebola', 'tiger', 'sampcrosby', 'joint', 'committee', 'tonyabbottmhr', 'brookewylie', 'dicksonlauren', 'avoca beach', 'reservoir', 'agim kruezi', 'barack obama', 'kobani', 'jackie kelly', 'jackie stewart', 'libs', 'spanish', 'tadhgkennelly', 'adammacdougall', 'adammacdougall 5', 'braceyjames', 'news', 'news of the world', 'troygrant', 'nicholas_reece', 'hmas', 'hmas cerberus', 'cerberus', 'sen fierravanti', 'wells', 'senatordoug', 'cassandragoldie', 'scottmorrisonmp', 'mornington peninsula', 'coast titans', 'nrl', 'merlino', 'peterdutton_mp', 'plibersek', 'wagner', 'toowoomba', 'peaches', 'victorian', 'victorian powerball', 'denis napthine', 'denis coderre', 'iraqis', 'baghdad', 'baghdad embassy', 'canva', 'jarryd hayne', 'booker', 'csl', 'clive palmer', 'clive owen', 'westfield corporation', 'converse', 'skechers', 'chuck taylor', 'chuck hagel', 'chuck norris', 'qantas a 380', 'kim jong-un', 'kim williams', 'kim seung soo', 'states', 'territory', 'tahrir', 'blinky', 'furqan', 'narrow road to deep north', 'dewani', 'malcolm fraser', 'malcolm morrison', 'pravda', 'bishops', 'juliette lewis', 'juliette binoche', 'osage county', 'blacks', 'nt', 'nt labor', 'casuarina', 'rachael finch', 'pell', 'caesars', 'glen campbell', 'manhattan', 'manhattan transfer', 'mattyoung', 'dane cook', 'ebloa', 'philippine', 'uganda', 'senegal', 'ge', 'cambodia', 'cambodia khmer rouge', 'anz', 'malala', 'ibac', 'hk', 'barnett', 'kiwi', 'ridley scott', 'aussie', 'sharon strzelecki', 'skycity', 'ontario', 'ontario tories', 'ontario liberals', 'buddy macmaster', 'cape breton', 'hawaiian', 'prime', 'newfoundland', 'atlantic', 'atlantic canada', 'montague area', 'alward', 'transport canada', 'rcmp', 'keystone', 'mccain', 'durham', 'mountie', 'canucks', 'moore', 'bertuzzi', 'winnipeg', 'staples', 'cohon', 'cfl', 'albertans', 'ahs', 'energy east pipeline', 'ndp', 'quebec', 'quebec court of appeal', 'tuktoyaktuk', 'armstrong', 'brunswick', 'f word', 'mulcair', 'inuit', 'pam owen', 'mlse', 'blanc sablon', 'trudeau', 'mounties', 'labrador', 'maple leafs', 'sierra', 'sierra club', 'sierra leone', 'shakeil boothe', 'fontaine', 'hall', 'mount polley', 'cnsc', 'faron hall', 'cbc news network', 'savage', 'nhl', 'canada-wide', 'channing tatum', 'al', 'al pacino', 'halifax', 'evelyn dick', 'alberta', 'alberta pc', 'khurram sher', 'peace river', 'nutella', 'rona ambrose', 'python', 'yellowknife', 'cra', 'bell', 'bell media', 'liberals', 'goodridge street', 'eugenie bouchard', 'petra kvitova', 'wimbledon', 'milos raonic', 'roger federer', 'roger boyes', 'manitoba', 'wynne', 'bernardo', 'ufc', 'alexis', 'alexis davis', 'saskatchewan', 'lac', 'bouchard', 'halep', 'megantic', 'hortons', 'amber alert', 'porter airlines', 'prairies', 'gino odjick', 'cornet', 'westjet', 'jenniferweiner', 'fall', 'stampeders', 'raptors', 'habs', 'charlottetown', 'canuck', 'kathleen wynne', 'kathleen sebelius', 'killing', 'netflix', 'cleveland', 'cleveland cavaliers', 'supreme', 'supreme court', 'grand pride', 'grand lodge', 'optimus prime', 'transformers', 'gg', 'normandy', 'juno beach', 'steve_rennie', 'joanne buth', 'senate', 'clement gascon', 'commons', 'speaker', 'ottawa', 'fantino', 'mackay', 'chiefs', 'first nations', 'pmo', 'thornhill', 'mcguinty', 'timhudak', 'hudak', 'kathleen_wynne', 'andreahorwath', 'cpontario', 'allisonjones_cp', 'andrea horwath', 'niagara west', 'glanbrook', 'progressive conservatives', 'jennifer reynolds', 'purdy crawford', 'bay', 'bay street', 'statistics', 'statistics canada', 'aircanada', 'athabasca', 'petrochina', 'dover', 'laurenkrugel', 'cineplexmovies', 'timhortons', 'heatherpayne', 'lindanguyento', 'mackayneville', 'secusmart', 'sap', 'ibm', 'bank', 'bank of canada', 'bank of ireland', 'bank of england', 'bank of japan', 'richardloat', 'barrick', 'barrick gold corp', 'onex corp', 'viewer choice', 'maurinor', 'jenreynolds', 'fitch ratings', 'davidpaddon', 'rossmarowits', 'c series', 'michaeloliveira', 'globe', 'globe and mail', 'iptv', 'regina', 'saskatoon', 'mail', 'cdn', 'transcontinental', 'volkswagen', 'cibc', 'corporate', 'sobeys', 'indigo', 'heather reisman', 'hat', 'snapsaves', 'groupon', 'hudson', 'wind mobile', 'wind waker', 'amaya gaming', 'halifax-based', 'dhx media', 'lululemon', 'lululemon athletica', 'chip wilson', 'mikesavagehfx', 'french', 'french indycar', 'simonpagenaud', 'saks', 'lordandtaylor', 'thehudsonsbayco', 'canadiantire', 'italia', 'coppibelfast', 'breidge gadd', 'ira', 'giro', 'co', 'semtex', 'nicholas roche', 'newton emerson', 'baggott', 'sas', 'loughgall', 'derry', 'derry gaa', 'strabane', 'psni', 'psni cc', 'maggot', 'discoverni', 'rev gibson', 'church', 'allison morris', 'allison argent', 'stormont', 'ballymurphy', 'villiers', 'alves', 'fionnuala oconnor', 'pistorius', 'heaney', 'hanlon', 'pan celtic', 'celtic', 'mora', 'casement', 'casement park', 'pope', 'pope francis', 'swilly', 'buncrana', 'cormac mcanallen', 'uvf', 'magheberry', 'lisburn', 'rsf', 'mcguinness', 'fein', 'la', 'la dearg', 'iarnród éireann', 'nbru', 'balkan', 'home', 'home office', 'theresa may', 'tipperary', 'pinergy', 'louth', 'nicaragua', 'greece', 'mosul', 'iceland', 'wicklow', 'maureen o hara', 'southeast', 'southeast ukraine', 'defence forces', 'syrian', 'syrian golan heights', 'seamus heaney', 'boi', 'suzuki', 'sudan', 'wexford', 'wexford park', 'cloverhill prison', 'baker mckenzie', 'castlerea', 'meath', 'hollande', 'egyptian', 'organisation', 'luxor', 'minsk', 'bus', 'sligo', 'harris', 'abadi', 'jimboireland', 'johndelx', 'newry', 'paulohanlon', 'horn head', 'sheephaven bay', 'donegal', 'denver', 'liamdutton', 'ballywatticock', 'dillon', 'roscommon', 'oak', 'oak park', 'carlow', 'met', 'met eireann', 'met office', 'holywood', 'county', 'ballinamore', 'leitrim', 'kellysarahw', 'blarney', 'mallow', 'rathduff', 'ginapotter', 'sandymount strand', 'greystones riviera', 'malahide', 'headford', 'rochestown', 'edwinmac', 'kilkennyweather', 'bantry bay', 'killary fjord', 'foyle', 'caseys', 'emmet_kennedy', 'eireogcork', 'corks', 'baltimore', 'pierce higgins', 'jackiehogan', 'kilmallock', 'nickkimcb', 'nikki', 'oola', 'meteireann', 'corkharbourwx', 'magilligan', 'magilligan strand', 'adress church', 'kesh', 'mayo', 'mayo clinic', 'moorbrook lodge', 'slieve anierin', 'irelandwalking', 'castlecomer', 'mtcomerford', 'munster', 'grange co', 'dunluce castle', 'knockananna', 'ballyjamesduff', 'ilovenorthcoast', 'weathercee', 'photosofdublin', 'lovindublin', 'olddublintown', 'dun', 'dun laoghaire harbour', 'causeway coast', 'leary', 'inis mor', 'mccarthy', 'menlough county', 'banbridge', 'kilkee', 'cian_mccormack', 'neoguri', 'nasa', 'deric_hartigan', 'dollroberts', 'youghal beach', 'ballygowan', 'clglaois', 'mark_kavanagh', 'kildare', 'galtymore', 'terenure', 'alistair darling', 'petro poroshenko', 'fort', 'fort hood', 'virginia', 'mikaeel kular', 'sergei lavrov', 'manuel valls', 'gandhi', 'raf', 'leone', 'natanz', 'bardarbunga volcano', 'san', 'san antonio spurs', 'san diego state', 'francisco', 'francisco bay area', 'sacramento', 'icelandic', 'kurdish region', 'cliff richard', 'kirkuk', 'tilbury docks', 'south-east', 'shia', 'sunni mosque', 'diyala', 'diyala province', 'diayala province', 'hamas', 'luhansk', 'guinea', 'atlanta', 'liberia', 'thailand', 'prayuth chan-ocha', 'austria', 'londonderry', 'downing st', 'palestinian', 'ascoli', 'eritrea', 'kashmir', 'somerset', 'ilminster', 'avon', 'beersheba', 'borneo', 'cairo', 'imran khan', 'sabrina moss', 'raytheon', 'kingston-upon', 'duke', 'duke of edinburgh', 'duke of cambridge', 'buckingham palace', 'wembley stadium', 'ons', 'hmp grampian jail', 'ftse', 'court', 'pfizer', 'astrazeneca', 'pascal soriot', 'claudia lawrence', 'wayne rooney', 'conchita wurst', 'copenhagen', 'taliban', 'rolf harris', 'english channel', 'beagle 2 mars', 'skull cracker', 'wheatley', 'tower hamlets', 'crown prosecution service', 'douglas carswell', 'carswell', 'panda', 'hillsborough', 'folkestone', 'easyjet', 'rotherham', 'shaun wright', 'aldi', 'revolting rhymes', 'omaha', 'cops', 'cancer', 'arizona', 'banksy', 'jasper johns', 'jasper national park', 'ryanair', 'nigel farage', 'palestinians', 'jhon jairo velasquez', 'pablo escobar', 'dewsbury', 'thanet', 'valladolid', 'pooley', 'zürich', 'rebekah brooks', 'norwich', 'salmond', 'uae', 'libyan', 'corp', 'darling', 'harriet harman', 'mi 6', 'watford', 'theindynews', 'porrahudson', 'drantbradley', 'lambethnut', 'gavhollander', 'owenjones', 'anguscarruthers', 'rgmcdermott', 'benmoretti', 'ian_fraser', 'geofflambert', 'drewbarclay', 'londongreenfair', 'theodorosbalbou', 'queenchristina', 'stephenhignell', 'fiona_richmond', 'msalverston', 'missjay', 'jamaledwards', 'laurengayejones', 'malwill', 'tafkabrianmoore', 'neilcowleytrio', 'clairekeuls', 'independent', 'pippa', 'pippa middleton', 'debenhams', 'princess beatrice', 'princess margaret', 'princess vacations', 'karl lagerfeld', 'grazia', 'frock', 'earl spencer', 'shepherd neame ale', 'ascot', 'knights of the order of the garter', 'windsor', 'epsom', 'vanity fair', 'miranda', 'miranda hart', 'philip treacy', 'blake', 'pilates', 'duncan bannatyne', 'seychelles', 'accessories', 'mitford', 'pa', 'pa kasumu', 'barbican', 'florian', 'florian paulmier', 'stephen_millard', 'cable', 'abu qatada', 'abu khatallah', 'miliband', 'rogerboyes', 'nelsoncardoz', 'florianp', 'calais', 'barclays', 'qaeda', 'carol midgley', 'driver', 'married the waiter', 'alice', 'delhi', 'scope', 'breaking', 'golan heights', 'jamielaing_uk', 'zadie smith', 'malorie blackman', 'niamh cusack', 'wicked', 'lily cole', 'warwick davis', 'kathylette', 'simonmasonsays', 'richardjgodwin', 'britpop', 'nineties', 'devil wears prada', 'lweisberger', 'jackandraka', 'charlotteedwa', 'beltrew', 'jonathan', 'jasgardner', 'tamara ecclestone', 'rosamundurwin', 'comedian', 'evening', 'evening standard', 'standard', 'standard procedure dubstep', 'mulberry', 'carney', 'nickcurtis', 'josé mourinho', 'joshneicho', 'mayfair', 'joshiherrmann', 'loulou', 'beyoncé', 'j-lo', 'chime for change', 'middletons', 'clooney', 'cruise', 'mumsnet', 'newsnight', 'justine_roberts', 'jkatielaw', 'rohan silva', 'amolrajan', 'clarebalding', 'chimerica', 'almeidatheatre', 'vicstewart', 'taj hargey', 'allan cubitt', 'gillian anderson', 'maxfrith', 'klassmyleene', 'des mcdonald', 'jonprynn', 'sigrid rausing', 'judy craymer', 'grown woman', 'susannahbutter', 'blumenfeld studio', 'somersethouse', 'londoner', 'germans', 'gosling', 'scot young', 'tomjharper', 'behind the candelabra', 'royaloperahouse', 'mrjamesashton', 'remy blumenfeld', 'erwin', 'grace kelly', 'milligan', 'jontyhurwitz', 'wonga', 'sol campbel', 'orleans', 'rothschild', 'goldsmith', 'downhills', 'tracy morgan', 'tracy martin', 'nas', 'kenyan', 'bulgarian', 'varna', 'carole king', 'presbyterian church', 'centers for disease control', 'rep', 'juan', 'carlos', 'felipe vi', 'los angeles', 'los angeles dodgers', 'clayton kershaw', 'shelly sterling', 'donald', 'donald sterling', 'south-central', 'dakota', 'vice', 'biden', 'nuri al maliki', 'oklahoma', 'native americans', 'baiji', 'carolina', 'carolina dmv', 'georgia', 'benghazi', 'clinton', 'hillary clinton', 'ahmed abu khatallah', 'ahmed abu khattalah', 'hillaryclinton', 'tehran', 'nebraska', 'sewol', 'guo jian', 'clint dempsey', 'jozy altidore', 'defense', 'defense department', 'baseball', 'army', 'bowe bergdahl', 'tiananmen square', 'cctv', 'kenya', 'coastal town', 'town', 'mpeketoni', 'nba', 'miami heat', 'tal', 'afar', 'senjohnmccain', 'jaycarney', 'janay rice', 'mcdonald', 'dallascowboys', 'scarlett o hara', 'depot', 'hsbc', 'jetblue', 'baltic', 'novartis', 'gsk', 'glaxosmithkline', 'valeant pharmaceuticals', 'botox', 'allergan', 'meb keflezighi', 'rita jeptoo', 'rubin', 'hurricane', 'hurricane carter', 'newmont mining', 'gabriel garcía márquez', 'fda', 'lavrov', 'song lin', 'stanley', 'geneva', 'weibo', 'gox', 'tokyo', 'credit', 'suisse', 'swiss', 'berlusconi', 'nsa', 'titan aerospace', 'citigroup', 'kansas', 'afghan', 'slavyansk', 'journal', 'manny pacquiao', 'sylvia mathews burwell', 'health and human services', 'p morgan', 'vaio pcs', 'nasdaq', 'dow', 'average', 'sac capital', 'gop', 'late show', 'dimon', 'gm', 'nhtsa', 'moscow', 'connecticut', 'kentucky', 'pharma', 'ranbaxy laboratories', 'wisconsin', 'uconn', 'justice', 'justice dept', 'formula', 'mideast', 'bouygues', 'vivendi', 'sfr', 'ims health', 'fonterra', 'mozilla', 'ecb', 'hood', 'hood rampage', 'chilean coast', 'bangkok', 'representatives', 'afghanistan', 'pavlo klimkin', 'janet yellen', 'yellen', 'megan twohey', 'shaneferro', 'imf', 'madeleine', 'madeleine albright', 'hungary', 'wilson', 'a_scottberg', 'sirharryevans', 'kaiser', 'thomsonreuters', 'lg', 'cantor', 'barra', 'valukas', 'rasmussen', 'komorowski', 'nike', 'healthkit', 'edwininla', 'chrissyfarr', 'aapl', 'sloan gibson', 'shinseki', 'barackobama', 'capitol', 'westgate mall', 'ariel castro', 'nidal hasan', 'hosni mubarak', 'bradley manning', 'bradley haines', 'whitey bulger', 'edward snowden', 'stevenportnoy', 'middleton', 'asiana airlines', 'congress', 'naacp', 'yasiel puig', 'enu', 'kerradontcare', 'southgate', 'carlson', 'gi', 'roseline_hair', 'coach daddy', 'misskatieprice', 'benhannington', 'dwydesigns', 'rentaro', 'calum', 'calum hood', 'ashton', 'ashton irwin', 'ashton 5sos', 'jeromepiggy', 'justinbieber', 'camelotwines', 'catalina_nunez', 'elvis presley', 'imara', 'millsbrett', 'fisherman savior', 'ddlovato', 'pewdiepie', 'mae', 'aa', 'atl', 'adtr', 'attila', 'bmth', 'om', 'nigga', 'glishy', 'masspike miles', 'cullen', 'danpatrick', 'codysimpson', 'homs', 'lexi_bailey', 'mercedes benz', 'planet of the apes', 'hummels', 'cuadrado', 'vidal', 'khedira', 'xiumin', 'hyung', 'luhan', 'marriott_cayman', 'cl', 'jinmark', 'real_liam_payne', 'varnum st', 'landover hills', 'panasonic', 'chappell', 'stevestfler', 'noaheiden', 'jovonne_mariah', 'malik', 'jenoconnell', 'wef', 'smash bros', 'pooh', 'bu', 'ozeri pronto digital multifunction kitchen', 'food scale', 'pron', 'enhamtrust', 'keatonstromberg', 'vatican', 'kymellis', 'lindfield', 'nashgrier', 'camerondallas', 'skype', 'dating the gangster', 'priscilla', 'limpopo', 'saps', 'honolulu', 'sehun', 'gimpo', 'brionyjeaan', 'jacobwhitesides', 'corralejo', 'terio', 'lyssadoe', 'catalans', 'rishamae', 'patrickgjackson', 'lou_manati', 'bangi', 'jamesmolock', 'amymartin', 'shirley valentine', 'theresadrianne', 'raj', 'gab', 'daveviena', 'niall', 'maxjoseph', 'nokia', 'nokia lumia 1020', 'jacked up halloween', 'zadrogas', 'amberrnickkolee', 'johndelfsound', 'western', 'western germany', 'extra-terrestrial', 'acacia brinley', 'alabama', 'sec', 'natalia', 'boa', 'scootermcgavin', 'rake', 'tarynlynn', 'googleplay', 'taemin', 'dereknichols', 'hawks', 'bianconeri', 'rubymariereyna', 'natecaldwell', 'jibo', 'annabel', 'spencer_jones', 'sabrinasoria', 'mitchell_bodden', 'patton', 'ugg australia men rockville ii motorcycle', 'casual', 'boot', 'crocs', 'wellingtons', 'babaoba', 'ibadan', 'nema', 'louisianavenue', 'vanilla islands', 'arabian', 'dubai', 'marie hoareau', 'ftisland', 'fla', 'lexibraicovich', 'gwynnharris', 'lex', 'iron', 'kimyixing', 'jongin', 'chanyeol', 'anc', 'rik', 'chiefkeef', 'chief', 'sosa', 'perezhilton', 'samui', 'halpacino', 'paulmcgrath', 'gladis', 'ridgeway arms', 'mahmoud bastard abbas', 'quisling', 'league', 'fitz and the tantrums', 'ashtondruwhaley', 'cassidywalden', 'jaden', 'kin', 'jindo', 'rail', 'bhoyeddie', 'annabellebtw', 'titanbet', 'jamesemerywhite', 'alexhirsch', 'soos', 'lohanthony', 'fairy godmother', 'zoesaadia', 'aztec', 'jennettemccurdy', 'joebudden', 'greenpeaceuk', 'appa', 'eduardjohn', 'derekirvine', 'pinehurst', 'claudiaolsberg', 'chrome', 'youngstown', 'themattespinosa', 'cornish', 'itsmrsmoran', 'jenniferbeals', 'pattie', 'hannahbolt', 'austinfordyoung', 'jeffweey', 'vamps', 'danii_azucena', 'rahm', 'tancia', 'rome', 'garethbale', 'realmadrid', 'dominiqueemonte', 'faze', 'demyliano', 'michaelsvcks', 'bruna', 'neymar', 'shabaab', 'kenyans', 'somalia', 'sarcelles', 'oxford', 'bethany', 'civitimarti', 'kai', 'aurora', 'shannons', 'schoolboy bbq', 'sant andreu hotels', 'simonharris', 'joshsmith', 'bella', 'himymcraig', 'nascar', 'sprint', 'sprint network', 'hovel', 'karlie redd', 'bianca del rio', 'sasha digiulian', 'mafia', 'sunggyu', 'sharks', 'niallftsbrad', 'hill', 'liamhaylett', 'boothwilliam', 'shifa hospital', 'khalid al batish', 'mitchgrassi', 'monaco', 'andreaonairmtl', 'abdelaziz', 'mitri', 'davelackie', 'dior addict fluid stick', 'ryanmiller', 'wny', 'rochester', 'plants vs zombies', 'drop bomb', 'bomb', 'kevburbano', 'sergio', 'lexinicole', 'cinemark', 'dumb and dumber', 'alex_godinez', 'eastridge', 'jasonkuznicki', 'gbpchf', 'boe', 'alicia keys', 'nini', 'alfredoflores', 'stefkojohoe', 'whiskey stones', 'djtayjames', 'charlesbivona', 'bush', 'jasmine_hutton', 'holgate', 'holgate academy', 'boehner', 'i_m_justinbiebe', 'thecosby', 'michigan', 'kobe', 'ant barton', 'h_poulter', 'brit', 'big_jason', 'kwanhatalo', 'ashleykelleher', 'skinny', 'fiber', 'mikeandmike', 'bubba', 'harry_styles', 'delaware', 'hancock fabrics', 'jindal', 'varanasi', 'chadcollins', 'brandonacosta', 'jhabea', 'sashaalexander', 'davidullsperger', 'nickkopecky', 'basman district court', 'levon hayrapetyan', 'abra', 'helsinki', 'manaus', 'manaus stadium', 'bound 2', 'baekhyun', 'keyauntejones', 'wreck this journal', 'southern', 'oceans', 'michaelmigs', 'melody of love', 'kang in duk', 'gwak hee sung', 'da som', 'wonderland', 'tunein', 'minseok', 'robert hemmings', 'jazmine sullivan', 'caribou_coffee', 'wfc', 'jpm', 'ronnie lovejoy', 'bombshellbetti', 'mrsjellysantos', 'homedepot', 'wizards', 'julius erving', 'moses malone', 'dikembe mutombo', 'david_myers', 'drbrucebaird', 'sayulita', 'vera wang', 'topkapi palace', 'russellcosta', 'dave_sciarra', 'rog', 'arena', 'hampshire', 'gavin bottoms', 'clash of clans', 'jorge', 'adrian', 'universidade federal', 'tocantins', 'uft', 'palmas', 'pardew', 'davidmeyler', 'stephengrootes', 'bryneven', 'multiply', 'heffrondrive', 'comedy central', 'verizon wireless', 'harrison high school', 'westendhousebgc', 'yongguk', 'adrianna', 'philips avent scf 281/02 microwave', 'philips avent scf 281/02 microwave steriliser', 'nialls', 'daniellarosita', 'wyoming', 'katherinedines', 'kaylie', 'shaun_moore', 'briana', 'moonlightlouis', 'mansell', 'jubilee hotel', 'letterston', 'chelmsford', 'gerard gardens', 'spyrokush', 'kerleys', 'firefox 29', 'm_kunza', 'yume co grimsby', 'willauerprosky', 'richmondkickers', 'marylandmsoccer', 'indianaal', 'kugluktuk hs', 'rapper', 'godson', 'nac', 'manishpaul', 'beingsalmankhan', 'stevieboylan', 'houston', 'mickeastcoast', 'leeh_horan', 'natgotti', 'ugandan', 'wilfried moons', 'khalish', 'hum sitaray', 'kdotson', 'mike_stelzner', 'linkedin', 'johnnemopr', 'juliaroberts', 'venezuela', 'paigearooney', 'schooley', 'rue bourbon', 'officialtamera', 'mannypacquiao', 'ernie', 'markallensen', 'noldirahman', 'stephenpiment', 'isacelliot', 'ludacris', 'ashutosh', 'oitnb', 'osama', 'nujaifi', 'maliki', 'janeklee', 'kohl', 'stuartscott', 'iggyazalea', 'enner valencia', 'hammers', 'brucekasanoff', 'kelly_louise', 'burnsemily', 'chad_martinn', 'taco bell', 'liberty', 'junhyung', 'beast showtime', 'barryoberholzer', 'balhatn', 'saksow', 'silvakhaos', 'kaylnn', 'geoffhampton', 'clippers', 'plott', 'patricia plott', 'lisacim', 'corporation', 'cottonpet', 'ippolita models', 'glamazon', 'lindy', 'logan', 'gutter notes', 'jessicalakey', 'jess', 'prypto', 'stephi', 'krystalradz', 'skylar', 'sc', 'hodor', 'scarborough', 'elkington', 'brianmfloyd', 'ashleynickels', 'kalin', 'gta', 'kid karate', 'becky', 'linwood', 'liz crowe', 'leeper', 'mig', 'bigjohnterry', 'eileen', 'ryanbutcher', 'ijamesmacdonald', 'reganstevely', 'georgiomartini', 'wwmd', 'manmohan singh', 'christ', 'jake', 'howon', 'kingslandrd', 'jeniferhampton', 'dylandrut', 'shanataulbee', 'nollywood', 'stephenson', 'caroline forbes', 'originals', 'johnl', 'danielrichards', 'samford', 'tt', 'joshdevinedrums', 'harrold', 'hanging lake', 'sprouting rock', 'glenwood springs', 'mildred gaddis', 'chelseafc', 'erikdavis', 'frozen', 'deveengabrail', 'dani_sanchez', 'mrjamessmith', 'ward', 'deneenborelli', 'epunk', 'sweden', 'meyler', 'lucanchan', 'clarets', 'derby', 'lightning', 'fany', 'catwalk', 'fortress investment group', 'mathews', 'tour de chesapeake', 'shenzhen', 'onedirection', 'edith', 'floydmayweather', 'niel', 'samudra hindia', 'laws of the jungle', 'erikcamacho', 'drjoannefarrow', 'skakeller', 'jaredstone', 'msleasalonga', 'ella', 'boko haram', 'geelani', 'darienflorez', 'ottawapolice', 'gazspellman', 'mikeaveli', 'reginald', 'erase', 'gabriele_corno', 'hanny setiawan', 'dyslexus', 'agustina', 'keely_frey', 'care fund', 'whitehall', 'jamiebhernandez', 'assenal', 'minecraft', 'jd', 'olympus', 'olympus 128 mb smartmedia cardby', 'endiamoore', 'court_taylor', 'chanceanderson', 'eldontimo', 'staplescenter', 'asa', 'inquirer', 'bom', 'ricky lambert', 'momo_morgann', 'bbcnewsmagazine', 'mirandacosgrove miranda', 'cincinnati', 'juliasamantha', 'alien planets', 'gaynes', 'brina', 'th', 'liljimmyj', 'gtownporirua', 'whitireiacampus', 'strip', 'cicibussey', 'ecuadorian embassy', 'w shannon', 'medical park hastanesi', 'waynemeisel', 'mighty morphine power rangers', 'peninsular', 'jar of hearts', 'christina perri', 'marti_sara', 'maligne lake', 'bray', 'idekselena', 'ambala', 'cassese', 'gabipluchino', 'bronnleyengland', 'richie acevedo', 'k-solo', 'josefherrero', 'goes', 'lydiamartin', 'belarus', 'mikecain', 'hunter', 'vespaeternity', 'xboxone', 'donald_taulbee', 'andygood', 'horicon', 'dannymcfly', 'tommcfly', 'fifth harmony', 'vma', 'lee_bow', 'kdtrey', 'snsd', 'arifrahimi', 'undercliff ave', 'bruckner interchange', 'lamarstevens', 'caryangeline', 'pete', 'liamlew', 'bloor', 'marisa', 'willey street', 'ph', 'cagliari', 'jonnyknowles', 'bundy', 'ruland psr 16', 'yubylopez', 'sheriffzurlo', 'lenilen', 'iamcecesca', 'ray_mcrobbie', 'amiee', 'blacwood', 'mrtonyknucklez', 'bigmizzie', 'nsheia', 'yuri', 'elizabethjanee', 'fireflies', 'lowestoft lions', 'petticoat lane', 'uber', 'zipcar', 'kermit', 'chatteris- manea', 'mv augusta brutale', 'boeing 777', 'waltengoo nar', 'olive garden', 'abortion', 'gmail', 'physics', 'trump administration', 'fisa warrant', 'global warming', 'rogue one', 'ac/dc', 'president obama', 'badlands national park', 'covid 19', 'punta cana', 'coronavirus', 'ffc', 'brfc', 'honey nutloops', 'hongkong']\n"
          ]
        }
      ],
      "source": [
        "phaseI_candidates = candidate_base.displayTrie(\"\",[])\n",
        "print(str(len(phaseI_candidates))+' candidates from phaseI')\n",
        "print(phaseI_candidates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwzJoGq6F7fy"
      },
      "outputs": [],
      "source": [
        "phaseII_timein=time.time()\n",
        "global_ner_predictions = global_NER_Module.executor(max_batch_value,tweet_base,candidate_base,phase2stopwordList,z_score,reintroduction_threshold_dummy,tweet_batch)\n",
        "phaseII_timeout=time.time()\n",
        "\n",
        "print('global emd time',(phaseII_timeout-phaseII_timein))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMJgl1zFEhBq"
      },
      "outputs": [],
      "source": [
        "calculate_f1_ner_engine(tweet_to_sentences_w_annotation, global_ner_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8D38z3wO5Ia"
      },
      "source": [
        "## **Other stuff**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BhnnK9WO3uW"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import cdist\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
        "from pathlib import Path\n",
        "import torchvision\n",
        "import urllib.request\n",
        "import os\n",
        "import ssl\n",
        "import zipfile\n",
        "import platform\n",
        "import ctypes\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Dip related stuff\n",
        "\"\"\"\n",
        "\n",
        "C_DIP_FILE = None\n",
        "\n",
        "\n",
        "def dip_test(X, is_data_sorted=False, debug=False):\n",
        "    n_points = X.shape[0]\n",
        "    data_dip = dip(X, just_dip=True, is_data_sorted=is_data_sorted, debug=debug)\n",
        "    pval = dip_pval(data_dip, n_points)\n",
        "    return data_dip, pval\n",
        "\n",
        "\n",
        "def dip(X, just_dip=False, is_data_sorted=False, debug=False):\n",
        "    assert X.ndim == 1, \"Data must be 1-dimensional for the dip-test. Your shape:{0}\".format(X.shape)\n",
        "    N = len(X)\n",
        "    if not is_data_sorted:\n",
        "        X = np.sort(X)\n",
        "    if N < 4 or X[0] == X[-1]:\n",
        "        d = 0.0\n",
        "        return d if just_dip else (d, None, None)\n",
        "    # Prepare data to match C data types\n",
        "    if C_DIP_FILE is None:\n",
        "        load_c_dip_file()\n",
        "    X = np.asarray(X, dtype=np.float64)\n",
        "    X_c = X.ctypes.data_as(ctypes.POINTER(ctypes.c_double))\n",
        "    N_c = np.array([N]).ctypes.data_as(ctypes.POINTER(ctypes.c_int))\n",
        "    dip_value = np.zeros(1, dtype=np.float).ctypes.data_as(ctypes.POINTER(ctypes.c_double))\n",
        "    low_high = np.zeros(4).ctypes.data_as(ctypes.POINTER(ctypes.c_int))\n",
        "    modal_triangle = np.zeros(3).ctypes.data_as(ctypes.POINTER(ctypes.c_int))\n",
        "    gcm = np.zeros(N).ctypes.data_as(ctypes.POINTER(ctypes.c_int))\n",
        "    lcm = np.zeros(N).ctypes.data_as(ctypes.POINTER(ctypes.c_int))\n",
        "    mn = np.zeros(N).ctypes.data_as(ctypes.POINTER(ctypes.c_int))\n",
        "    mj = np.zeros(N).ctypes.data_as(ctypes.POINTER(ctypes.c_int))\n",
        "    debug_c = np.array([1 if debug else 0]).ctypes.data_as(ctypes.POINTER(ctypes.c_int))\n",
        "    # Execute C dip test\n",
        "    _ = C_DIP_FILE.diptst(X_c, N_c, dip_value, low_high, modal_triangle, gcm, lcm, mn, mj, debug_c)\n",
        "    dip_value = dip_value[0]\n",
        "    if just_dip:\n",
        "        return dip_value\n",
        "    else:\n",
        "        low_high = (low_high[0], low_high[1], low_high[2], low_high[3])\n",
        "        modal_triangle = (modal_triangle[0], modal_triangle[1], modal_triangle[2])\n",
        "        return dip_value, low_high, modal_triangle\n",
        "\n",
        "\n",
        "def load_c_dip_file():\n",
        "    global C_DIP_FILE\n",
        "    files_path = os.path.dirname(__file__)\n",
        "    # if platform.system() == \"Windows\":\n",
        "    #     dip_compiled = files_path + \"/dip.dll\"\n",
        "    # else:\n",
        "    dip_compiled = files_path + \"/dip.so\"\n",
        "    if os.path.isfile(dip_compiled):\n",
        "        # load c file\n",
        "        try:\n",
        "            C_DIP_FILE = ctypes.CDLL(dip_compiled)\n",
        "            C_DIP_FILE.diptst.restype = None\n",
        "            C_DIP_FILE.diptst.argtypes = [ctypes.POINTER(ctypes.c_double),\n",
        "                                          ctypes.POINTER(ctypes.c_int),\n",
        "                                          ctypes.POINTER(ctypes.c_double),\n",
        "                                          ctypes.POINTER(ctypes.c_int),\n",
        "                                          ctypes.POINTER(ctypes.c_int),\n",
        "                                          ctypes.POINTER(ctypes.c_int),\n",
        "                                          ctypes.POINTER(ctypes.c_int),\n",
        "                                          ctypes.POINTER(ctypes.c_int),\n",
        "                                          ctypes.POINTER(ctypes.c_int),\n",
        "                                          ctypes.POINTER(ctypes.c_int)]\n",
        "        except Exception as e:\n",
        "            print(\"[WARNING] Error while loading the C compiled dip file.\")\n",
        "            raise e\n",
        "    else:\n",
        "        raise Exception(\"C compiled dip file can not be found.\\n\"\n",
        "                        \"On Windows execute: gcc -fPIC -shared -std=c99 -o dip.dll dip.c\\n\"\n",
        "                        \"On Linux execute: gcc -fPIC -shared -o dip.so dip.c\")\n",
        "\n",
        "\n",
        "def dip_pval(data_dip, n_points):\n",
        "    N, SIG, CV = _dip_table_values()\n",
        "    i1 = N.searchsorted(n_points, side='left')\n",
        "    i0 = i1 - 1\n",
        "    # if n falls outside the range of tabulated sample sizes, use the\n",
        "    # critical values for the nearest tabulated n (i.e. treat them as\n",
        "    # 'asymptotic')\n",
        "    i0 = max(0, i0)\n",
        "    i1 = min(N.shape[0] - 1, i1)\n",
        "    # interpolate on sqrt(n)\n",
        "    n0, n1 = N[[i0, i1]]\n",
        "    fn = float(n_points - n0) / (n1 - n0)\n",
        "    y0 = np.sqrt(n0) * CV[i0]\n",
        "    y1 = np.sqrt(n1) * CV[i1]\n",
        "    sD = np.sqrt(n_points) * data_dip\n",
        "    pval = 1. - np.interp(sD, y0 + fn * (y1 - y0), SIG)\n",
        "    return pval\n",
        "\n",
        "\n",
        "def _dip_table_values():\n",
        "    N = np.array([4, 5, 6, 7, 8, 9, 10, 15, 20,\n",
        "                  30, 50, 100, 200, 500, 1000, 2000, 5000, 10000,\n",
        "                  20000, 40000, 72000])\n",
        "    SIG = np.array([0., 0.01, 0.02, 0.05, 0.1, 0.2,\n",
        "                    0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
        "                    0.9, 0.95, 0.98, 0.99, 0.995, 0.998,\n",
        "                    0.999, 0.9995, 0.9998, 0.9999, 0.99995, 0.99998,\n",
        "                    0.99999, 1.])\n",
        "    # [len(N), len(SIG)] table of critical values\n",
        "    CV = np.array([[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.132559548782689,\n",
        "                    0.157497369040235, 0.187401878807559, 0.20726978858736, 0.223755804629222, 0.231796258864192,\n",
        "                    0.237263743826779, 0.241992892688593, 0.244369839049632, 0.245966625504691, 0.247439597233262,\n",
        "                    0.248230659656638, 0.248754269146416, 0.249302039974259, 0.249459652323225, 0.24974836247845],\n",
        "                   [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.108720593576329, 0.121563798026414, 0.134318918697053,\n",
        "                    0.147298798976252, 0.161085025702604, 0.176811998476076, 0.186391796027944, 0.19361253363045,\n",
        "                    0.196509139798845, 0.198159967287576, 0.199244279362433, 0.199617527406166, 0.199800941499028,\n",
        "                    0.199917081834271, 0.199959029093075, 0.199978395376082, 0.199993151405815, 0.199995525025673,\n",
        "                    0.199999835639211],\n",
        "                   [0.0833333333333333, 0.0833333333333333, 0.0833333333333333, 0.0833333333333333,\n",
        "                    0.0833333333333333, 0.0924514470941933, 0.103913431059949, 0.113885220640212, 0.123071187137781,\n",
        "                    0.13186973390253, 0.140564796497941, 0.14941924112913, 0.159137064572627, 0.164769608513302,\n",
        "                    0.179176547392782, 0.191862827995563, 0.202101971042968, 0.213015781111186, 0.219518627282415,\n",
        "                    0.224339047394446, 0.229449332154241, 0.232714530449602, 0.236548128358969, 0.2390887911995,\n",
        "                    0.240103566436295, 0.244672883617768],\n",
        "                   [0.0714285714285714, 0.0714285714285714, 0.0714285714285714, 0.0725717816250742,\n",
        "                    0.0817315478539489, 0.09405901819225269, 0.103244490800871, 0.110964599995697,\n",
        "                    0.117807846504335, 0.124216086833531, 0.130409013968317, 0.136639642123068, 0.144240669035124,\n",
        "                    0.159903395678336, 0.175196553271223, 0.184118659121501, 0.191014396174306, 0.198216795232182,\n",
        "                    0.202341010748261, 0.205377566346832, 0.208306562526874, 0.209866047852379, 0.210967576933451,\n",
        "                    0.212233348558702, 0.212661038312506, 0.21353618608817],\n",
        "                   [0.0625, 0.0625, 0.06569119945032829, 0.07386511360717619, 0.0820045917762512,\n",
        "                    0.0922700601131892, 0.09967371895993631, 0.105733531802737, 0.111035129847705,\n",
        "                    0.115920055749988, 0.120561479262465, 0.125558759034845, 0.141841067033899, 0.153978303998561,\n",
        "                    0.16597856724751, 0.172988528276759, 0.179010413496374, 0.186504388711178, 0.19448404115794,\n",
        "                    0.200864297005026, 0.208849997050229, 0.212556040406219, 0.217149174137299, 0.221700076404503,\n",
        "                    0.225000835357532, 0.233772919687683],\n",
        "                   [0.0555555555555556, 0.0613018090298924, 0.0658615858179315, 0.0732651142535317,\n",
        "                    0.0803941629593475, 0.0890432420913848, 0.0950811420297928, 0.09993808978110461,\n",
        "                    0.104153560075868, 0.108007802361932, 0.112512617124951, 0.122915033480817, 0.136412639387084,\n",
        "                    0.146603784954019, 0.157084065653166, 0.164164643657217, 0.172821674582338, 0.182555283567818,\n",
        "                    0.188658833121906, 0.194089120768246, 0.19915700809389, 0.202881598436558, 0.205979795735129,\n",
        "                    0.21054115498898, 0.21180033095039, 0.215379914317625],\n",
        "                   [0.05, 0.0610132555623269, 0.0651627333214016, 0.0718321619656165, 0.077966212182459,\n",
        "                    0.08528353598345639, 0.09032041737070989, 0.0943334983745117, 0.0977817630384725,\n",
        "                    0.102180866696628, 0.109960948142951, 0.118844767211587, 0.130462149644819, 0.139611395137099,\n",
        "                    0.150961728882481, 0.159684158858235, 0.16719524735674, 0.175419540856082, 0.180611195797351,\n",
        "                    0.185286416050396, 0.191203083905044, 0.195805159339184, 0.20029398089673, 0.205651089646219,\n",
        "                    0.209682048785853, 0.221530282182963],\n",
        "                   [0.0341378172277919, 0.0546284208048975, 0.0572191260231815, 0.0610087367689692,\n",
        "                    0.06426571373304441, 0.06922341079895911, 0.0745462114365167, 0.07920308789817621,\n",
        "                    0.083621033469191, 0.08811984822029049, 0.093124666680253, 0.0996694393390689,\n",
        "                    0.110087496900906, 0.118760769203664, 0.128890475210055, 0.13598356863636, 0.142452483681277,\n",
        "                    0.150172816530742, 0.155456133696328, 0.160896499106958, 0.166979407946248, 0.17111793515551,\n",
        "                    0.175900505704432, 0.181856676013166, 0.185743454151004, 0.192240563330562],\n",
        "                   [0.033718563622065, 0.0474333740698401, 0.0490891387627092, 0.052719998201553,\n",
        "                    0.0567795509056742, 0.0620134674468181, 0.06601638720690479, 0.06965060750664009,\n",
        "                    0.07334377405927139, 0.07764606628802539, 0.0824558407118372, 0.08834462700173699,\n",
        "                    0.09723460181229029, 0.105130218270636, 0.114309704281253, 0.120624043335821, 0.126552378036739,\n",
        "                    0.13360135382395, 0.138569903791767, 0.14336916123968, 0.148940116394883, 0.152832538183622,\n",
        "                    0.156010163618971, 0.161319225839345, 0.165568255916749, 0.175834459522789],\n",
        "                   [0.0262674485075642, 0.0395871890405749, 0.0414574606741673, 0.0444462614069956,\n",
        "                    0.0473998525042686, 0.0516677370374349, 0.0551037519001622, 0.058265005347493,\n",
        "                    0.0614510857304343, 0.0649164408053978, 0.0689178762425442, 0.0739249074078291,\n",
        "                    0.08147913793901269, 0.0881689143126666, 0.0960564383013644, 0.101478558893837,\n",
        "                    0.10650487144103, 0.112724636524262, 0.117164140184417, 0.121425859908987, 0.126733051889401,\n",
        "                    0.131198578897542, 0.133691739483444, 0.137831637950694, 0.141557509624351, 0.163833046059817],\n",
        "                   [0.0218544781364545, 0.0314400501999916, 0.0329008160470834, 0.0353023819040016,\n",
        "                    0.0377279973102482, 0.0410699984399582, 0.0437704598622665, 0.0462925642671299,\n",
        "                    0.048851155289608, 0.0516145897865757, 0.0548121932066019, 0.0588230482851366,\n",
        "                    0.06491363240467669, 0.0702737877191269, 0.07670958860791791, 0.0811998415355918,\n",
        "                    0.0852854646662134, 0.09048478274902939, 0.0940930106666244, 0.0974904344916743,\n",
        "                    0.102284204283997, 0.104680624334611, 0.107496694235039, 0.11140887547015, 0.113536607717411,\n",
        "                    0.117886716865312],\n",
        "                   [0.0164852597438403, 0.022831985803043, 0.0238917486442849, 0.0256559537977579,\n",
        "                    0.0273987414570948, 0.0298109370830153, 0.0317771496530253, 0.0336073821590387,\n",
        "                    0.0354621760592113, 0.0374805844550272, 0.0398046179116599, 0.0427283846799166,\n",
        "                    0.047152783315718, 0.0511279442868827, 0.0558022052195208, 0.059024132304226,\n",
        "                    0.0620425065165146, 0.06580160114660991, 0.0684479731118028, 0.0709169443994193,\n",
        "                    0.0741183486081263, 0.0762579402903838, 0.0785735967934979, 0.08134583568891331,\n",
        "                    0.0832963013755522, 0.09267804230967371],\n",
        "                   [0.0111236388849688, 0.0165017735429825, 0.0172594157992489, 0.0185259426032926,\n",
        "                    0.0197917612637521, 0.0215233745778454, 0.0229259769870428, 0.024243848341112,\n",
        "                    0.025584358256487, 0.0270252129816288, 0.0286920262150517, 0.0308006766341406,\n",
        "                    0.0339967814293504, 0.0368418413878307, 0.0402729850316397, 0.0426864799777448,\n",
        "                    0.044958959158761, 0.0477643873749449, 0.0497198001867437, 0.0516114611801451,\n",
        "                    0.0540543978864652, 0.0558704526182638, 0.0573877056330228, 0.0593365901653878,\n",
        "                    0.0607646310473911, 0.0705309107882395],\n",
        "                   [0.00755488597576196, 0.0106403461127515, 0.0111255573208294, 0.0119353655328931,\n",
        "                    0.0127411306411808, 0.0138524542751814, 0.0147536004288476, 0.0155963185751048,\n",
        "                    0.0164519238025286, 0.017383057902553, 0.0184503949887735, 0.0198162679782071,\n",
        "                    0.0218781313182203, 0.0237294742633411, 0.025919578977657, 0.0274518022761997,\n",
        "                    0.0288986369564301, 0.0306813505050163, 0.0320170996823189, 0.0332452747332959,\n",
        "                    0.0348335698576168, 0.0359832389317461, 0.0369051995840645, 0.0387221159256424,\n",
        "                    0.03993025905765, 0.0431448163617178],\n",
        "                   [0.00541658127872122, 0.00760286745300187, 0.007949878346447991, 0.008521651834359399,\n",
        "                    0.00909775605533253, 0.009889245210140779, 0.0105309297090482, 0.0111322726797384,\n",
        "                    0.0117439009052552, 0.012405033293814, 0.0131684179320803, 0.0141377942603047,\n",
        "                    0.0156148055023058, 0.0169343970067564, 0.018513067368104, 0.0196080260483234,\n",
        "                    0.0206489568587364, 0.0219285176765082, 0.0228689168972669, 0.023738710122235,\n",
        "                    0.0248334158891432, 0.0256126573433596, 0.0265491336936829, 0.027578430100536, 0.0284430733108,\n",
        "                    0.0313640941982108],\n",
        "                   [0.00390439997450557, 0.00541664181796583, 0.00566171386252323, 0.00607120971135229,\n",
        "                    0.0064762535755248, 0.00703573098590029, 0.00749421254589299, 0.007920878896017331,\n",
        "                    0.008355737247680061, 0.00882439333812351, 0.00936785820717061, 0.01005604603884,\n",
        "                    0.0111019116837591, 0.0120380990328341, 0.0131721010552576, 0.0139655122281969,\n",
        "                    0.0146889122204488, 0.0156076779647454, 0.0162685615996248, 0.0168874937789415,\n",
        "                    0.0176505093388153, 0.0181944265400504, 0.0186226037818523, 0.0193001796565433,\n",
        "                    0.0196241518040617, 0.0213081254074584],\n",
        "                   [0.00245657785440433, 0.00344809282233326, 0.00360473943713036, 0.00386326548010849,\n",
        "                    0.00412089506752692, 0.00447640050137479, 0.00476555693102276, 0.00503704029750072,\n",
        "                    0.00531239247408213, 0.00560929919359959, 0.00595352728377949, 0.00639092280563517,\n",
        "                    0.00705566126234625, 0.0076506368153935, 0.00836821687047215, 0.008863578928549141,\n",
        "                    0.00934162787186159, 0.009932186363240289, 0.0103498795291629, 0.0107780907076862,\n",
        "                    0.0113184316868283, 0.0117329446468571, 0.0119995948968375, 0.0124410052027886,\n",
        "                    0.0129467396733128, 0.014396063834027],\n",
        "                   [0.00174954269199566, 0.00244595133885302, 0.00255710802275612, 0.00273990955227265,\n",
        "                    0.0029225480567908, 0.00317374638422465, 0.00338072258533527, 0.00357243876535982,\n",
        "                    0.00376734715752209, 0.00397885007249132, 0.00422430013176233, 0.00453437508148542,\n",
        "                    0.00500178808402368, 0.00542372242836395, 0.00592656681022859, 0.00628034732880374,\n",
        "                    0.00661030641550873, 0.00702254699967648, 0.00731822628156458, 0.0076065423418208,\n",
        "                    0.00795640367207482, 0.008227052458435399, 0.00852240989786251, 0.00892863905540303,\n",
        "                    0.009138539330002131, 0.009522345795667729],\n",
        "                   [0.00119458814106091, 0.00173435346896287, 0.00181194434584681, 0.00194259470485893,\n",
        "                    0.00207173719623868, 0.00224993202086955, 0.00239520831473419, 0.00253036792824665,\n",
        "                    0.00266863168718114, 0.0028181999035216, 0.00299137548142077, 0.00321024899920135,\n",
        "                    0.00354362220314155, 0.00384330190244679, 0.00420258799378253, 0.00445774902155711,\n",
        "                    0.00469461513212743, 0.00499416069129168, 0.00520917757743218, 0.00540396235924372,\n",
        "                    0.00564540201704594, 0.00580460792299214, 0.00599774739593151, 0.00633099254378114,\n",
        "                    0.00656987109386762, 0.00685829448046227],\n",
        "                   [0.000852415648011777, 0.00122883479310665, 0.00128469304457018, 0.00137617650525553,\n",
        "                    0.00146751502006323, 0.00159376453672466, 0.00169668445506151, 0.00179253418337906,\n",
        "                    0.00189061261635977, 0.00199645471886179, 0.00211929748381704, 0.00227457698703581,\n",
        "                    0.00250999080890397, 0.00272375073486223, 0.00298072958568387, 0.00315942194040388,\n",
        "                    0.0033273652798148, 0.00353988965698579, 0.00369400045486625, 0.00383345715372182,\n",
        "                    0.00400793469634696, 0.00414892737222885, 0.0042839159079761, 0.00441870104432879,\n",
        "                    0.00450818604569179, 0.00513477467565583],\n",
        "                   [0.000644400053256997, 0.000916872204484283, 0.000957932946765532, 0.00102641863872347,\n",
        "                    0.00109495154218002, 0.00118904090369415, 0.00126575197699874, 0.00133750966361506,\n",
        "                    0.00141049709228472, 0.00148936709298802, 0.00158027541945626, 0.00169651643860074,\n",
        "                    0.00187306184725826, 0.00203178401610555, 0.00222356097506054, 0.00235782814777627,\n",
        "                    0.00248343580127067, 0.00264210826339498, 0.0027524322157581, 0.0028608570740143,\n",
        "                    0.00298695044508003, 0.00309340092038059, 0.00319932767198801, 0.00332688234611187,\n",
        "                    0.00339316094477355, 0.00376331697005859]])\n",
        "    return N, SIG, CV\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Autoencoder stuff\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def detect_device():\n",
        "    \"\"\"Automatically detects if you have a cuda enabled GPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "    return device\n",
        "\n",
        "\n",
        "def encode_batchwise(dataloader, model, device):\n",
        "    \"\"\" Utility function for embedding the whole data set in a mini-batch fashion\n",
        "    \"\"\"\n",
        "    embeddings = []\n",
        "    for batch in dataloader:\n",
        "        batch_data = batch.to(device)\n",
        "        embeddings.append(model.encode(batch_data).detach().cpu())\n",
        "    return torch.cat(embeddings, dim=0).numpy()\n",
        "\n",
        "\n",
        "def get_trained_autoencoder(trainloader, learning_rate, n_epochs, device, optimizer_class, loss_fn,\n",
        "                            input_dim, embedding_size, autoencoder_class):\n",
        "    if embedding_size > input_dim:\n",
        "        print(\n",
        "            \"WARNING: embedding_size is larger than the dimensionality of the input dataset. Setting embedding_size to\",\n",
        "            input_dim)\n",
        "        embedding_size = input_dim\n",
        "    # Pretrain Autoencoder\n",
        "    autoencoder = autoencoder_class(input_dim=input_dim, embedding_size=embedding_size).to(device)\n",
        "    optimizer = optimizer_class(autoencoder.parameters(), lr=learning_rate)\n",
        "    autoencoder.start_training(trainloader, n_epochs, device, optimizer, loss_fn)\n",
        "    return autoencoder\n",
        "\n",
        "\n",
        "def squared_euclidean_distance(centers, embedded, weights=None):\n",
        "    ta = centers.unsqueeze(0)\n",
        "    tb = embedded.unsqueeze(1)\n",
        "    squared_diffs = (ta - tb)\n",
        "    if weights is not None:\n",
        "        weights_unsqueezed = weights.unsqueeze(0).unsqueeze(1)\n",
        "        squared_diffs = squared_diffs * weights_unsqueezed\n",
        "    squared_diffs = squared_diffs.pow(2).sum(2)  # .mean(2) # TODO Evaluate this change\n",
        "    return squared_diffs\n",
        "\n",
        "\n",
        "def int_to_one_hot(label_tensor, n_labels):\n",
        "    onehot = torch.zeros([label_tensor.shape[0], n_labels], dtype=torch.float, device=label_tensor.device)\n",
        "    onehot.scatter_(1, label_tensor.unsqueeze(1).long(), 1.0)\n",
        "    return onehot\n",
        "\n",
        "\"\"\"\n",
        "DipDECK stuff\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def _dip_deck(X, n_clusters_start, dip_merge_threshold, cluster_loss_weight, n_clusters_max, n_clusters_min, batch_size,\n",
        "              learning_rate, pretrain_epochs, dedc_epochs, optimizer_class, loss_fn, autoencoder, embedding_size,\n",
        "              max_cluster_size_diff_factor, debug):\n",
        "    if n_clusters_max < n_clusters_min:\n",
        "        raise Exception(\"n_clusters_max can not be smaller than n_clusters_min\")\n",
        "    if n_clusters_min <= 0:\n",
        "        raise Exception(\"n_clusters_min must be greater than zero\")\n",
        "    if n_clusters_start < n_clusters_min:\n",
        "        raise Exception(\"n_clusters can not be smaller than n_clusters_min\")\n",
        "    device = detect_device()\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(*(torch.from_numpy(X).float(), torch.arange(0, X.shape[0]))),\n",
        "        batch_size=batch_size,\n",
        "        # sample random mini-batches from the data\n",
        "        shuffle=True,\n",
        "        drop_last=False)\n",
        "    \n",
        "    # create a Dataloader to test the autoencoder in mini-batch fashion (Important for validation)\n",
        "    testloader = torch.utils.data.DataLoader(torch.from_numpy(X).float(),\n",
        "                                             batch_size=batch_size,\n",
        "                                             # Note that we deactivate the shuffling\n",
        "                                             shuffle=False,\n",
        "                                             drop_last=False)\n",
        "    if autoencoder is None:\n",
        "        autoencoder = get_trained_autoencoder(trainloader, learning_rate, pretrain_epochs, device,\n",
        "                                              optimizer_class, loss_fn, X.shape[1], embedding_size,\n",
        "                                              _DipDECK_Autoencoder)\n",
        "        \n",
        "    # Execute kmeans in embedded space - initial clustering\n",
        "    embedded_data = encode_batchwise(testloader, autoencoder, device)\n",
        "    kmeans = KMeans(n_clusters=n_clusters_start)\n",
        "    kmeans.fit(embedded_data)\n",
        "    init_centers = kmeans.cluster_centers_\n",
        "    cluster_labels_cpu = kmeans.labels_\n",
        "\n",
        "    # Get nearest points to optimal centers\n",
        "    centers_cpu, embedded_centers_cpu = _get_nearest_points_to_optimal_centers(X, init_centers, embedded_data)\n",
        "    # Initial dip values\n",
        "    dip_matrix_cpu = _get_dip_matrix(embedded_data, embedded_centers_cpu, cluster_labels_cpu, n_clusters_start,\n",
        "                                     max_cluster_size_diff_factor)\n",
        "    \n",
        "    # Reduce learning_rate from pretraining by a magnitude of 10\n",
        "    dedc_learning_rate = learning_rate * 0.1\n",
        "    optimizer = optimizer_class(autoencoder.parameters(), lr=dedc_learning_rate)\n",
        "    # Start training\n",
        "    cluster_labels_cpu, n_clusters_current, centers_cpu, autoencoder = _dip_deck_training(X, n_clusters_start,\n",
        "                                                                                          dip_merge_threshold,\n",
        "                                                                                          cluster_loss_weight,\n",
        "                                                                                          centers_cpu,\n",
        "                                                                                          cluster_labels_cpu,\n",
        "                                                                                          dip_matrix_cpu,\n",
        "                                                                                          n_clusters_max,\n",
        "                                                                                          n_clusters_min, dedc_epochs,\n",
        "                                                                                          optimizer, loss_fn,\n",
        "                                                                                          autoencoder,\n",
        "                                                                                          device, trainloader,\n",
        "                                                                                          testloader,\n",
        "                                                                                          max_cluster_size_diff_factor,\n",
        "                                                                                          debug)\n",
        "    # Return results\n",
        "    return cluster_labels_cpu, n_clusters_current, centers_cpu, autoencoder\n",
        "\n",
        "\n",
        "def _dip_deck_training(X, n_clusters_current, dip_merge_threshold, cluster_loss_weight, centers_cpu, cluster_labels_cpu,\n",
        "                       dip_matrix_cpu, n_clusters_max, n_clusters_min, dedc_epochs, optimizer, loss_fn, autoencoder,\n",
        "                       device, trainloader, testloader, max_cluster_size_diff_factor, debug):\n",
        "    i = 0\n",
        "    while i < dedc_epochs:\n",
        "        cluster_labels_torch = torch.from_numpy(cluster_labels_cpu).long().to(device)\n",
        "        centers_torch = torch.from_numpy(centers_cpu).float().to(device)\n",
        "        dip_matrix_torch = torch.from_numpy(dip_matrix_cpu).float().to(device)\n",
        "\n",
        "        # Get dip costs matrix\n",
        "        dip_matrix_eye = dip_matrix_torch + torch.eye(n_clusters_current, device=device)\n",
        "        dip_matrix_final = dip_matrix_eye / dip_matrix_eye.sum(1).reshape((-1, 1))\n",
        "\n",
        "        # Iterate over batches\n",
        "        for batch, ids in trainloader:\n",
        "            batch_data = batch.to(device)\n",
        "            embedded = autoencoder.encode(batch_data)\n",
        "            reconstruction = autoencoder.decode(embedded)\n",
        "            embedded_centers_torch = autoencoder.encode(centers_torch)\n",
        "\n",
        "            # Reconstruction Loss\n",
        "            ae_loss = loss_fn(reconstruction, batch_data)\n",
        "            # Get distances between points and centers. Get nearest center\n",
        "            squared_diffs = squared_euclidean_distance(embedded_centers_torch, embedded)\n",
        "\n",
        "            # Update labels? Pause is needed, so cluster labels can adjust to the new structure\n",
        "            if i != 0:\n",
        "                # Update labels\n",
        "                current_labels = squared_diffs.argmin(1)\n",
        "                # cluster_labels_torch[ids] = current_labels\n",
        "            else:\n",
        "                current_labels = cluster_labels_torch[ids]\n",
        "            onehot_labels = int_to_one_hot(current_labels, n_clusters_current).float()\n",
        "            cluster_relationships = torch.matmul(onehot_labels, dip_matrix_final)\n",
        "            escaped_diffs = cluster_relationships * squared_diffs\n",
        "\n",
        "            # Normalize loss by cluster distances\n",
        "            squared_center_diffs = squared_euclidean_distance(embedded_centers_torch, embedded_centers_torch)\n",
        "\n",
        "            # Ignore zero values (diagonal)\n",
        "            mask = torch.where(squared_center_diffs != 0)\n",
        "            masked_center_diffs = squared_center_diffs[mask[0], mask[1]]\n",
        "            sqrt_masked_center_diffs = masked_center_diffs.sqrt()\n",
        "            masked_center_diffs_std = sqrt_masked_center_diffs.std() if len(sqrt_masked_center_diffs) > 2 else 0\n",
        "\n",
        "            # Loss function\n",
        "            cluster_loss = escaped_diffs.sum(1).mean() * (1 + masked_center_diffs_std) / sqrt_masked_center_diffs.mean()\n",
        "            cluster_loss *= cluster_loss_weight\n",
        "            loss = ae_loss + cluster_loss\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        # cluster_labels_cpu = cluster_labels_torch.detach().cpu().numpy()\n",
        "        # Update centers\n",
        "        embedded_data = encode_batchwise(testloader, autoencoder, device)\n",
        "        embedded_centers_cpu = autoencoder.encode(centers_torch).detach().cpu().numpy()\n",
        "        cluster_labels_cpu = np.argmin(cdist(embedded_centers_cpu, embedded_data), axis=0)\n",
        "        optimal_centers = np.array([np.mean(embedded_data[cluster_labels_cpu == cluster_id], axis=0) for cluster_id in\n",
        "                                    range(n_clusters_current)])\n",
        "        centers_cpu, embedded_centers_cpu = _get_nearest_points_to_optimal_centers(X, optimal_centers, embedded_data)\n",
        "        \n",
        "        # Update Dips\n",
        "        dip_matrix_cpu = _get_dip_matrix(embedded_data, embedded_centers_cpu, cluster_labels_cpu, n_clusters_current,\n",
        "                                         max_cluster_size_diff_factor)\n",
        "\n",
        "        if debug:\n",
        "            print(\n",
        "                \"Iteration {0}  (n_clusters = {4}) - reconstruction loss: {1} / cluster loss: {2} / total loss: {3}\".format(\n",
        "                    i, ae_loss.item(), cluster_loss.item(), loss.item(), n_clusters_current))\n",
        "            print(\"max dip\", np.max(dip_matrix_cpu), \" at \",\n",
        "                  np.unravel_index(np.argmax(dip_matrix_cpu, axis=None), dip_matrix_cpu.shape))\n",
        "        # i is increased here. Else next iteration will start with i = 1 instead of 0 after a merge\n",
        "        i += 1\n",
        "        # Start merging procedure\n",
        "        dip_argmax = np.unravel_index(np.argmax(dip_matrix_cpu, axis=None), dip_matrix_cpu.shape)\n",
        "        # Is merge possible?\n",
        "        if i != 0:\n",
        "            while dip_matrix_cpu[dip_argmax] >= dip_merge_threshold and n_clusters_current > n_clusters_min:\n",
        "                if debug:\n",
        "                    print(\"Start merging in iteration {0}.\\nMerging clusters {1} with dip value {2}.\".format(i,\n",
        "                                                                                                             dip_argmax,\n",
        "                                                                                                             dip_matrix_cpu[\n",
        "                                                                                                                 dip_argmax]))\n",
        "                # Reset iteration and reduce number of cluster\n",
        "                i = 0\n",
        "                n_clusters_current -= 1\n",
        "                cluster_labels_cpu, centers_cpu, embedded_centers_cpu, dip_matrix_cpu = \\\n",
        "                    _merge_by_dip_value(X, embedded_data, cluster_labels_cpu, dip_argmax, n_clusters_current,\n",
        "                                        centers_cpu,\n",
        "                                        embedded_centers_cpu, max_cluster_size_diff_factor)\n",
        "                dip_argmax = np.unravel_index(np.argmax(dip_matrix_cpu, axis=None), dip_matrix_cpu.shape)\n",
        "        if n_clusters_current == 1:\n",
        "            if debug:\n",
        "                print(\"Only one cluster left\")\n",
        "            break\n",
        "    return cluster_labels_cpu, n_clusters_current, centers_cpu, autoencoder\n",
        "\n",
        "\n",
        "def _merge_by_dip_value(X, embedded_data, cluster_labels_cpu, dip_argmax, n_clusters_current, centers_cpu,\n",
        "                        embedded_centers_cpu, max_cluster_size_diff_factor):\n",
        "    # Get points in clusters\n",
        "    points_in_center_1 = len(cluster_labels_cpu[cluster_labels_cpu == dip_argmax[0]])\n",
        "    points_in_center_2 = len(cluster_labels_cpu[cluster_labels_cpu == dip_argmax[1]])\n",
        "    # update labels\n",
        "    for j, l in enumerate(cluster_labels_cpu):\n",
        "        if l == dip_argmax[0] or l == dip_argmax[1]:\n",
        "            cluster_labels_cpu[j] = n_clusters_current - 1\n",
        "        elif l < dip_argmax[0] and l < dip_argmax[1]:\n",
        "            cluster_labels_cpu[j] = l\n",
        "        elif l > dip_argmax[0] and l > dip_argmax[1]:\n",
        "            cluster_labels_cpu[j] = l - 2\n",
        "        else:\n",
        "            cluster_labels_cpu[j] = l - 1\n",
        "    # Find new center position\n",
        "    optimal_new_center = (embedded_centers_cpu[dip_argmax[0]] * points_in_center_1 +\n",
        "                          embedded_centers_cpu[dip_argmax[1]] * points_in_center_2) / (\n",
        "                                 points_in_center_1 + points_in_center_2)\n",
        "    new_center_cpu, new_embedded_center_cpu = _get_nearest_points_to_optimal_centers(X, [optimal_new_center],\n",
        "                                                                                     embedded_data)\n",
        "    # Remove the two old centers and add the new one\n",
        "    centers_cpu_tmp = np.delete(centers_cpu, dip_argmax, axis=0)\n",
        "    centers_cpu = np.append(centers_cpu_tmp, new_center_cpu, axis=0)\n",
        "    embedded_centers_cpu_tmp = np.delete(embedded_centers_cpu, dip_argmax, axis=0)\n",
        "    embedded_centers_cpu = np.append(embedded_centers_cpu_tmp, new_embedded_center_cpu, axis=0)\n",
        "    # Update dip values\n",
        "    dip_matrix_cpu = _get_dip_matrix(embedded_data, embedded_centers_cpu, cluster_labels_cpu,\n",
        "                                     n_clusters_current, max_cluster_size_diff_factor)\n",
        "    return cluster_labels_cpu, centers_cpu, embedded_centers_cpu, dip_matrix_cpu\n",
        "\n",
        "\n",
        "def _get_nearest_points_to_optimal_centers(X, optimal_centers, embedded_data):\n",
        "    best_center_points = np.argmin(cdist(optimal_centers, embedded_data), axis=1)\n",
        "    centers_cpu = X[best_center_points, :]\n",
        "    embedded_centers_cpu = embedded_data[best_center_points, :]\n",
        "    return centers_cpu, embedded_centers_cpu\n",
        "\n",
        "\n",
        "def _get_nearest_points(points_in_larger_cluster, center, size_smaller_cluster, max_cluster_size_diff_factor,\n",
        "                        min_sample_size):\n",
        "    distances = cdist(points_in_larger_cluster, [center])\n",
        "    nearest_points = np.argsort(distances, axis=0)\n",
        "    # Check if more points should be taken because the other cluster is too small\n",
        "    sample_size = size_smaller_cluster * max_cluster_size_diff_factor\n",
        "    if size_smaller_cluster + sample_size < min_sample_size:\n",
        "        sample_size = min(min_sample_size - size_smaller_cluster, len(points_in_larger_cluster))\n",
        "    subset_all_points = points_in_larger_cluster[nearest_points[:sample_size, 0]]\n",
        "    return subset_all_points\n",
        "\n",
        "\n",
        "def _get_dip_matrix(data, dip_centers, dip_labels, n_clusters, max_cluster_size_diff_factor=2, min_sample_size=100):\n",
        "    dip_matrix = np.zeros((n_clusters, n_clusters))\n",
        "    # Loop over all combinations of centers\n",
        "    for i in range(0, n_clusters - 1):\n",
        "        for j in range(i + 1, n_clusters):\n",
        "            center_diff = dip_centers[i] - dip_centers[j]\n",
        "            points_in_i = data[dip_labels == i]\n",
        "            points_in_j = data[dip_labels == j]\n",
        "            points_in_i_or_j = np.append(points_in_i, points_in_j, axis=0)\n",
        "            proj_points = np.dot(points_in_i_or_j, center_diff)\n",
        "            _, dip_p_value = dip_test(proj_points)\n",
        "            # Check if clusters sizes differ heavily\n",
        "            if points_in_i.shape[0] > points_in_j.shape[0] * max_cluster_size_diff_factor or \\\n",
        "                    points_in_j.shape[0] > points_in_i.shape[0] * max_cluster_size_diff_factor:\n",
        "                if points_in_i.shape[0] > points_in_j.shape[0] * max_cluster_size_diff_factor:\n",
        "                    points_in_i = _get_nearest_points(points_in_i, dip_centers[j], points_in_j.shape[0],\n",
        "                                                      max_cluster_size_diff_factor, min_sample_size)\n",
        "                elif points_in_j.shape[0] > points_in_i.shape[0] * max_cluster_size_diff_factor:\n",
        "                    points_in_j = _get_nearest_points(points_in_j, dip_centers[i], points_in_i.shape[0],\n",
        "                                                      max_cluster_size_diff_factor, min_sample_size)\n",
        "                points_in_i_or_j = np.append(points_in_i, points_in_j, axis=0)\n",
        "                proj_points = np.dot(points_in_i_or_j, center_diff)\n",
        "                _, dip_p_value_2 = dip_test(proj_points)\n",
        "                dip_p_value = min(dip_p_value, dip_p_value_2)\n",
        "            # Add pval to dip matrix\n",
        "            dip_matrix[i][j] = dip_p_value\n",
        "            dip_matrix[j][i] = dip_p_value\n",
        "    return dip_matrix\n",
        "\n",
        "\n",
        "class _DipDECK_Autoencoder(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim: int, embedding_size: int):\n",
        "        super(_DipDECK_Autoencoder, self).__init__()\n",
        "\n",
        "        # make a sequential list of all operations you want to apply for encoding a data point\n",
        "        self.encoder = torch.nn.Sequential(\n",
        "            # Linear layer (just a matrix multiplication)\n",
        "            torch.nn.Linear(input_dim, 500),\n",
        "            # apply an elementwise non-linear function\n",
        "            torch.nn.LeakyReLU(inplace=True),\n",
        "            torch.nn.Linear(500, 500),\n",
        "            torch.nn.LeakyReLU(inplace=True),\n",
        "            torch.nn.Linear(500, 2000),\n",
        "            torch.nn.LeakyReLU(inplace=True),\n",
        "            torch.nn.Linear(2000, embedding_size))\n",
        "\n",
        "        # make a sequential list of all operations you want to apply for decoding a data point\n",
        "        # In our case this is a symmetric version of the encoder\n",
        "        self.decoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(embedding_size, 2000),\n",
        "            torch.nn.LeakyReLU(inplace=True),\n",
        "            torch.nn.Linear(2000, 500),\n",
        "            torch.nn.LeakyReLU(inplace=True),\n",
        "            torch.nn.Linear(500, 500),\n",
        "            torch.nn.LeakyReLU(inplace=True),\n",
        "            torch.nn.Linear(500, input_dim),\n",
        "        )\n",
        "\n",
        "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: input data point, can also be a mini-batch of points\n",
        "\n",
        "        Returns:\n",
        "            embedded: the embedded data point with dimensionality embedding_size\n",
        "        \"\"\"\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, embedded: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            embedded: embedded data point, can also be a mini-batch of embedded points\n",
        "\n",
        "        Returns:\n",
        "            reconstruction: returns the reconstruction of a data point\n",
        "        \"\"\"\n",
        "        return self.decoder(embedded)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\" Applies both encode and decode function.\n",
        "        The forward function is automatically called if we call self(x).\n",
        "        Args:\n",
        "            x: input data point, can also be a mini-batch of embedded points\n",
        "\n",
        "        Returns:\n",
        "            reconstruction: returns the reconstruction of a data point\n",
        "        \"\"\"\n",
        "        embedded = self.encode(x)\n",
        "        reconstruction = self.decode(embedded)\n",
        "        return reconstruction\n",
        "\n",
        "    def start_training(self, trainloader, n_epochs, device, optimizer, loss_fn):\n",
        "        for _ in range(n_epochs):\n",
        "            for batch, _ in trainloader:\n",
        "                # load batch on device\n",
        "                batch_data = batch.to(device)\n",
        "                reconstruction = self.forward(batch_data)\n",
        "                loss = loss_fn(reconstruction, batch_data)\n",
        "                # reset gradients from last iteration\n",
        "                optimizer.zero_grad()\n",
        "                # calculate gradients and reset the computation graph\n",
        "                loss.backward()\n",
        "                # update the internal params (weights, etc.)\n",
        "                optimizer.step()\n",
        "\n",
        "\n",
        "class DipDECK():\n",
        "\n",
        "    def __init__(self, n_clusters_start=35, dip_merge_threshold=0.9, cluster_loss_weight=1, n_clusters_max=np.inf,\n",
        "                 n_clusters_min=1, batch_size=256, learning_rate=1e-3, pretrain_epochs=100, dedc_epochs=50,\n",
        "                 optimizer_class=torch.optim.Adam, loss_fn=torch.nn.MSELoss(), autoencoder=None, embedding_size=5,\n",
        "                 max_cluster_size_diff_factor=2, debug=False):\n",
        "        self.n_clusters_start = n_clusters_start\n",
        "        self.dip_merge_threshold = dip_merge_threshold\n",
        "        self.cluster_loss_weight = cluster_loss_weight\n",
        "        self.n_clusters_max = n_clusters_max\n",
        "        self.n_clusters_min = n_clusters_min\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.pretrain_epochs = pretrain_epochs\n",
        "        self.dedc_epochs = dedc_epochs\n",
        "        self.optimizer_class = optimizer_class\n",
        "        self.loss_fn = loss_fn\n",
        "        self.autoencoder = autoencoder\n",
        "        self.embedding_size = embedding_size\n",
        "        self.max_cluster_size_diff_factor = max_cluster_size_diff_factor\n",
        "        self.debug = debug\n",
        "\n",
        "    def fit(self, X):\n",
        "        labels, n_clusters, centers, autoencoder = _dip_deck(X, self.n_clusters_start, self.dip_merge_threshold,\n",
        "                                                             self.cluster_loss_weight, self.n_clusters_max,\n",
        "                                                             self.n_clusters_min, self.batch_size, self.learning_rate,\n",
        "                                                             self.pretrain_epochs, self.dedc_epochs,\n",
        "                                                             self.optimizer_class,\n",
        "                                                             self.loss_fn, self.autoencoder, self.embedding_size,\n",
        "                                                             self.max_cluster_size_diff_factor, self.debug)\n",
        "        self.labels_ = labels\n",
        "        self.n_clusters_ = n_clusters\n",
        "        self.cluster_centers_ = centers\n",
        "        self.autoencoder = autoencoder\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Data loader\n",
        "\"\"\"\n",
        "\n",
        "def _get_download_dir():\n",
        "    downloads_path = str(Path.home() / \"Downloads/dipDECK_data\")\n",
        "    if not os.path.isdir(downloads_path):\n",
        "        os.makedirs(downloads_path)\n",
        "    return downloads_path\n",
        "\n",
        "def _download_file(download_path, filename):\n",
        "    ssl._create_default_https_context = ssl._create_unverified_context\n",
        "    urllib.request.urlretrieve(download_path, filename)\n",
        "    ssl._create_default_https_context = ssl._create_default_https_context\n",
        "\n",
        "\n",
        "def _load_data_file(filename, download_path, delimiter=\",\", last_column_are_labels=True):\n",
        "    if not os.path.isfile(filename):\n",
        "        _download_file(download_path, filename)\n",
        "    datafile = np.genfromtxt(filename, delimiter=delimiter)\n",
        "    if last_column_are_labels:\n",
        "        data = datafile[:, :-1]\n",
        "        labels = datafile[:, -1]\n",
        "    else:\n",
        "        data = datafile[:, 1:]\n",
        "        labels = datafile[:, 0]\n",
        "    return data, labels\n",
        "\n",
        "def _load_torch_image_data(data_source, add_testdata):\n",
        "    # Get data from source\n",
        "    ssl._create_default_https_context = ssl._create_unverified_context\n",
        "    dataset = data_source(root=_get_download_dir(), train=True, download=True)\n",
        "    data = dataset.data\n",
        "    labels = dataset.targets\n",
        "    if add_testdata:\n",
        "        testset = data_source(root=_get_download_dir(), train=False, download=True)\n",
        "        data = torch.cat([data, testset.data], dim=0)\n",
        "        labels = torch.cat([labels, testset.targets], dim=0)\n",
        "    ssl._create_default_https_context = ssl._create_default_https_context\n",
        "    # Flatten shape\n",
        "    if data.dim() == 3:\n",
        "        data = data.reshape(-1, data.shape[1] * data.shape[2])\n",
        "    else:\n",
        "        data = data.reshape(-1, data.shape[1] * data.shape[2] * data.shape[3])\n",
        "    # Move data to CPU\n",
        "    data_cpu = data.detach().cpu().numpy()\n",
        "    labels_cpu = labels.detach().cpu().numpy()\n",
        "    return data_cpu, labels_cpu\n",
        "\n",
        "def _image_z_transformation(data):\n",
        "    return (data - np.mean(data)) / np.std(data)\n",
        "\n",
        "\n",
        "def load_usps(add_testdata=True, normalize=True):\n",
        "    dataset = torchvision.datasets.USPS(root=_get_download_dir(), train=True, download=True)\n",
        "    data = dataset.data\n",
        "    labels = dataset.targets\n",
        "    if add_testdata:\n",
        "        test_dataset = torchvision.datasets.USPS(root=_get_download_dir(), train=False, download=True)\n",
        "        data = np.r_[data, test_dataset.data]\n",
        "        labels = np.r_[labels, test_dataset.targets]\n",
        "    data = data.reshape(-1, 256)\n",
        "    if normalize:\n",
        "        data = _image_z_transformation(data)\n",
        "    return data, labels\n",
        "\n",
        "def load_optdigits(add_testdata=True, normalize=True):\n",
        "    filename = _get_download_dir() + \"/optdigits.tra\"\n",
        "    data, labels = _load_data_file(filename,\n",
        "                                   \"https://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tra\")\n",
        "    if add_testdata:\n",
        "        filename = _get_download_dir() + \"/optdigits.tes\"\n",
        "        test_data, test_labels = _load_data_file(filename,\n",
        "                                                 \"https://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tes\")\n",
        "        data = np.r_[data, test_data]\n",
        "        labels = np.r_[labels, test_labels]\n",
        "    if normalize:\n",
        "        data = _image_z_transformation(data)\n",
        "    return data, labels\n",
        "\"\"\"\n",
        "Start DipDECK\n",
        "\"\"\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # === Choose data set ===\n",
        "    # data, labels = load_usps()\n",
        "    # data, labels = load_mnist()\n",
        "    # data, labels = load_fmnist()\n",
        "    # data, labels = load_kmnist()\n",
        "    data, labels = load_optdigits()\n",
        "    # data, labels = load_pendigits()\n",
        "    # data, labels = load_letterrecognition()\n",
        "    # GTSRB can be downloaded at https://benchmark.ini.rub.de/gtsrb_news.html\n",
        "\n",
        "    # === Create DipDECK object ===\n",
        "    dipdeck = DipDECK()\n",
        "    dipdeck.fit(data)\n",
        "\n",
        "    # === Print results ===\n",
        "    print(\"K:\", dipdeck.n_clusters_)\n",
        "    print(\"NMI:\", nmi(labels, dipdeck.labels_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZkJ9wBwUYZJ"
      },
      "source": [
        "## **External Run of BERTweet -- NOT REQD TO RUN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPfpoUgLDJKo"
      },
      "outputs": [],
      "source": [
        "from emoji import demojize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIw-KqtkJxCL"
      },
      "outputs": [],
      "source": [
        "# tweets_unpartitoned=pd.read_csv(\"/Users/satadisha/Documents/GitHub/TwiCSv2/data/tweets_3k_annotated.csv\",sep =',',keep_default_na=False)\n",
        "# testset, tokenizedtestset, tweet_to_sentences_w_annotation = preprocess('tweets_3k_annotated.csv')\n",
        "\n",
        "# testset, tokenizedtestset, tweet_to_sentences_w_annotation = preprocess('venezuela.csv')\n",
        "\n",
        "# testset, tokenizedtestset, tweet_to_sentences_w_annotation = preprocess('billdeblasio.csv')\n",
        "# testset, tokenizedtestset, tweet_to_sentences_w_annotation = preprocess('pikapika.csv')\n",
        "# testset, tokenizedtestset, tweet_to_sentences_w_annotation = preprocess('ripcity.csv')\n",
        "# testset, tokenizedtestset, tweet_to_sentences_w_annotation = preprocess('billnye.csv')\n",
        "# testset, tokenizedtestset, tweet_to_sentences_w_annotation = preprocess('roevwade.csv')\n",
        "\n",
        "# testset, tokenizedtestset, tweet_to_sentences_w_annotation = preprocess('wnut17test.csv')\n",
        "\n",
        "# testset, tokenizedtestset, tweet_to_sentences_w_annotation = preprocess('broad_twitter_corpus.csv')\n",
        "\n",
        "\n",
        "# testset, tokenizedtestset, tweet_to_sentences_w_annotation = preprocess('wnut17test_ner.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcBypu5tJ1T-",
        "outputId": "88a6dbab-96b9-4133-9ade-4683b84cd3c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1864\n",
            "['& gt ; * The soldier was killed when another avalanche hit an army barracks in the northern area of Sonmarg , said a military spokesman .', '& gt ; * Police last week evacuated 80 villagers from Waltengoo Nar where dozens were killed after a series of avalanches hit the area in 2005 in the south of the territory .', '& gt ; * The army on Thursday recovered the bodies of ten of its men who were killed in an avalanche the previous day .', '& gt ; * The four civilians killed included two children of a family whose house was hit by a separate avalanche , also on Wednesday , a police spokesman said .', 'The bodies of the soldiers were recovered after the concerted efforts of the Avalanche Rescue Teams ( ART ) , which is equipped to work in inhospitable terrain and weather conditions .']\n"
          ]
        }
      ],
      "source": [
        "# tokenized_datasets = testset.map(tokenize_and_align_labels)\n",
        "print(len(testset))\n",
        "print(testset[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmVMgIiEKABu",
        "outputId": "34642b51-63b6-4429-8b42-9c6a13d98e6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Set device\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdEQEXmmDQWw"
      },
      "outputs": [],
      "source": [
        "def normalizeToken(token):\n",
        "    lowercased_token = token.lower()\n",
        "    if token.startswith(\"@\"):\n",
        "        return \"@USER\"\n",
        "    elif lowercased_token.startswith(\"http\") or lowercased_token.startswith(\"www\"):\n",
        "        return \"HTTPURL\"\n",
        "    elif len(token) == 1:\n",
        "        return demojize(token)\n",
        "    else:\n",
        "        if token == \"’\":\n",
        "            return \"'\"\n",
        "        elif token == \"…\":\n",
        "            return \"...\"\n",
        "        else:\n",
        "            return token\n",
        "\n",
        "def normalizeTweet(tweet):\n",
        "    tokens = tweetTokenizer.tokenize(tweet.replace(\"’\", \"'\").replace(\"…\", \"...\"))\n",
        "    normTweet = \" \".join([normalizeToken(token) for token in tokens])\n",
        "\n",
        "    normTweet = normTweet.replace(\"cannot \", \"can not \").replace(\"n't \", \" n't \").replace(\"n 't \", \" n't \").replace(\"ca n't\", \"can't\").replace(\"ai n't\", \"ain't\")\n",
        "    normTweet = normTweet.replace(\"'m \", \" 'm \").replace(\"'re \", \" 're \").replace(\"'s \", \" 's \").replace(\"'ll \", \" 'll \").replace(\"'d \", \" 'd \").replace(\"'ve \", \" 've \")\n",
        "    normTweet = normTweet.replace(\" p . m .\", \"  p.m.\") .replace(\" p . m \", \" p.m \").replace(\" a . m .\", \" a.m.\").replace(\" a . m \", \" a.m \")\n",
        "\n",
        "    normTweet = re.sub(r\",([0-9]{2,4}) , ([0-9]{2,4})\", r\",\\1,\\2\", normTweet)\n",
        "    normTweet = re.sub(r\"([0-9]{1,3}) / ([0-9]{2,4})\", r\"\\1/\\2\", normTweet)\n",
        "    normTweet = re.sub(r\"([0-9]{1,3})- ([0-9]{2,4})\", r\"\\1-\\2\", normTweet)\n",
        "    \n",
        "    return normTweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YypE-PAbKCiq",
        "outputId": "afc8dfa4-a115-4f77-b2f6-6dd75814b5d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 5 0 0 5 0 5 5 5 5 0 0 0 0 0 0 0]\n",
            "13\n",
            "dict_keys(['&', 'gt', ';', '*', 'The', 'soldier', 'was', 'killed', 'when', 'another', 'avalanche', 'hit', 'an', 'army', 'barracks', 'in', 'the', 'northern', 'area', 'of', 'Sonmarg', ',', 'said', 'a', 'military', 'spokesman', '.'])\n",
            "tensor([[    0,    55,  8083,   208,   110,    47, 10998,    38,  1294,    64,\n",
            "           347, 36791, 25313,   512,    74,  3466,  2149, 18549,    16,     6,\n",
            "          7322,  1149,    15,  7725,  2350,   714,     7,   193,    11,  2492,\n",
            "         34196,     4,     2]])\n",
            "tensor([[    0,    55,  8083,   208,   110,    47, 10998,    38,  1294,    64,\n",
            "           347, 36791, 25313,   512,    74,  3466,  2149, 18549,    16,     6,\n",
            "          7322,  1149,    15,  7725,  2350,   714,     7,   193,    11,  2492,\n",
            "         34196,     4,     2]], device='cuda:0')\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'B-LOC', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "===============\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 5 5 5 6 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0]\n",
            "13\n",
            "dict_keys(['&', 'gt', ';', '*', 'Police', 'last', 'week', 'evacuated', '80', 'villagers', 'from', 'Waltengoo', 'Nar', 'where', 'dozens', 'were', 'killed', 'after', 'a', 'series', 'of', 'avalanches', 'hit', 'the', 'area', 'in', '2005', 'south', 'territory', '.'])\n",
            "tensor([[    0,    55,  8083,   208,   110,  2282,   175,   223, 32138,  1785,\n",
            "         47942,    53,  5047,  4744, 15258,   450,  1348,   209, 19116,   147,\n",
            "          1294,   177,    11,  1049,    15, 36791,   725,  3652,   512,     6,\n",
            "          1149,    16,  3414,    16,     6,  2729,    15,     6, 10909,     4,\n",
            "             2]])\n",
            "tensor([[    0,    55,  8083,   208,   110,  2282,   175,   223, 32138,  1785,\n",
            "         47942,    53,  5047,  4744, 15258,   450,  1348,   209, 19116,   147,\n",
            "          1294,   177,    11,  1049,    15, 36791,   725,  3652,   512,     6,\n",
            "          1149,    16,  3414,    16,     6,  2729,    15,     6, 10909,     4,\n",
            "             2]], device='cuda:0')\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "===============\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "13\n",
            "dict_keys(['&', 'gt', ';', '*', 'The', 'army', 'on', 'Thursday', 'recovered', 'the', 'bodies', 'of', 'ten', 'its', 'men', 'who', 'were', 'killed', 'in', 'an', 'avalanche', 'previous', 'day', '.'])\n",
            "tensor([[    0,    55,  8083,   208,   110,    47,  3466,    24,  1638, 14595,\n",
            "             6,  5644,    15,  2540,    15,   139,   656,    87,   147,  1294,\n",
            "            16,    74, 36791, 25313,     6,  4006,    93,     4,     2]])\n",
            "tensor([[    0,    55,  8083,   208,   110,    47,  3466,    24,  1638, 14595,\n",
            "             6,  5644,    15,  2540,    15,   139,   656,    87,   147,  1294,\n",
            "            16,    74, 36791, 25313,     6,  4006,    93,     4,     2]],\n",
            "       device='cuda:0')\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "===============\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "13\n",
            "dict_keys(['&', 'gt', ';', '*', 'The', 'four', 'civilians', 'killed', 'included', 'two', 'children', 'of', 'a', 'family', 'whose', 'house', 'was', 'hit', 'by', 'separate', 'avalanche', ',', 'also', 'on', 'Wednesday', 'police', 'spokesman', 'said', '.'])\n",
            "tensor([[    0,    55,  8083,   208,   110,    47,  1362, 17260,  1294,  3280,\n",
            "           255,   994,    15,    11,   383,  3430,   364,    38,   512,    61,\n",
            "            11,  5628, 36791, 25313,     7,   237,    24,  1895,     7,    11,\n",
            "          1415, 34196,   193,     4,     2]])\n",
            "tensor([[    0,    55,  8083,   208,   110,    47,  1362, 17260,  1294,  3280,\n",
            "           255,   994,    15,    11,   383,  3430,   364,    38,   512,    61,\n",
            "            11,  5628, 36791, 25313,     7,   237,    24,  1895,     7,    11,\n",
            "          1415, 34196,   193,     4,     2]], device='cuda:0')\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "===============\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 4 4 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "13\n",
            "dict_keys(['The', 'bodies', 'of', 'the', 'soldiers', 'were', 'recovered', 'after', 'concerted', 'efforts', 'Avalanche', 'Rescue', 'Teams', '(', 'ART', ')', ',', 'which', 'is', 'equipped', 'to', 'work', 'in', 'inhospitable', 'terrain', 'and', 'weather', 'conditions', '.'])\n",
            "tensor([[    0,    47,  5644,    15,     6,  6819,   147, 14595,   177,     6,\n",
            "         28782,  1535,  5785,    15,     6, 50852, 14663, 15706,    57, 13927,\n",
            "            60,     7,   248,    17, 18510,     9,   157,    16,   520, 62262,\n",
            "           503, 37222,    13,  1155,  5430,     4,     2]])\n",
            "tensor([[    0,    47,  5644,    15,     6,  6819,   147, 14595,   177,     6,\n",
            "         28782,  1535,  5785,    15,     6, 50852, 14663, 15706,    57, 13927,\n",
            "            60,     7,   248,    17, 18510,     9,   157,    16,   520, 62262,\n",
            "           503, 37222,    13,  1155,  5430,     4,     2]], device='cuda:0')\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "===============\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 7 7 8\n",
            " 8 0 0 0]\n",
            "13\n",
            "dict_keys(['&', 'gt', ';', '*', 'Arrangements', 'are', 'in', 'place', 'to', 'carry', 'the', 'mortal', 'remains', 'of', 'martyrs', 'their', 'native', 'places', 'immediately', 'after', 'weather', 'becomes', 'clear', ',', 'Defence', 'Spokesman', 'Colonel', 'Rajesh', 'Kalia', 'said', '.'])\n",
            "tensor([[    0,    55,  8083,   208,   110,  1517, 36647, 11363,    41,    16,\n",
            "           430,     9,  3071,     6, 27093,  5237,    15,     6, 33248,  7372,\n",
            "             9,   130,  7468,  2128,  3714,   177,  1155,  3655,  1673,     7,\n",
            "         20231, 55976,   171, 22514, 12824,  7440,   368, 13077,   193,     4,\n",
            "             2]])\n",
            "tensor([[    0,    55,  8083,   208,   110,  1517, 36647, 11363,    41,    16,\n",
            "           430,     9,  3071,     6, 27093,  5237,    15,     6, 33248,  7372,\n",
            "             9,   130,  7468,  2128,  3714,   177,  1155,  3655,  1673,     7,\n",
            "         20231, 55976,   171, 22514, 12824,  7440,   368, 13077,   193,     4,\n",
            "             2]], device='cuda:0')\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'B-PER', 'I-PER', 'O', 'O']\n",
            "===============\n",
            "1864 1864\n"
          ]
        }
      ],
      "source": [
        "tweetTokenizer = TweetTokenizer()\n",
        "predictions=[]\n",
        "tokenized_sentences=[]\n",
        "count=0\n",
        "with torch.no_grad():\n",
        "    for test_record in testset:\n",
        "        # print(test_record)\n",
        "        # test_record=test_record.lower()\n",
        "        # print(test_record)\n",
        "        sentence = normalizeTweet(test_record)\n",
        "        # tweetWordList=self.getWords(sentence)\n",
        "        tweetWordList = sentence.split()\n",
        "\n",
        "        tokenized_input=tokenizer(sentence)\n",
        "        initial_input_ids = torch.tensor([tokenizer.encode(sentence)])\n",
        "        initial_input_ids = initial_input_ids[:,:128]\n",
        "        token_dict = {x : tokenizer.encode(x, add_special_tokens=False) for x in sentence.split()}\n",
        "        input_ids = initial_input_ids.to(device)\n",
        "        tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
        "        \n",
        "        # output = model(input_ids)\n",
        "\n",
        "        output = alt_model(input_ids)\n",
        "        \n",
        "        \n",
        "        prediction = (torch.argmax(output.logits, axis=2))\n",
        "        prediction = prediction.cpu().numpy().reshape(-1)\n",
        "        if(count<=5):\n",
        "            print(prediction)\n",
        "        # prediction_labels=[label_list[l].split('-')[0] for l in prediction]\n",
        "        prediction_labels=[label_list[l] for l in prediction]\n",
        "        prediction_labels=collate_token_labels(tweetWordList, token_dict, prediction_labels[1:-1])\n",
        "        predictions.append(prediction_labels)\n",
        "        tokenized_sentences.append(tweetWordList)\n",
        "        assert (len(prediction_labels)==len(tweetWordList))\n",
        "\n",
        "        if(count<=5):\n",
        "            print(len(output.hidden_states))\n",
        "            print(token_dict.keys())\n",
        "            print(initial_input_ids)\n",
        "            print(input_ids)\n",
        "            print(prediction_labels)\n",
        "            print('===============')\n",
        "        count+=1\n",
        "\n",
        "print(len(predictions),len(tokenized_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R01RAjRUKGnb",
        "outputId": "22562278-d3ff-4d1f-bd09-4435bc3828be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['&', 'gt', ';', '*', 'The', 'soldier', 'was', 'killed', 'when', 'another', 'avalanche', 'hit', 'an', 'army', 'barracks', 'in', 'the', 'northern', 'area', 'of', 'Sonmarg', ',', 'said', 'a', 'military', 'spokesman', '.'], ['&', 'gt', ';', '*', 'Police', 'last', 'week', 'evacuated', '80', 'villagers', 'from', 'Waltengoo', 'Nar', 'where', 'dozens', 'were', 'killed', 'after', 'a', 'series', 'of', 'avalanches', 'hit', 'the', 'area', 'in', '2005', 'in', 'the', 'south', 'of', 'the', 'territory', '.'], ['&', 'gt', ';', '*', 'The', 'army', 'on', 'Thursday', 'recovered', 'the', 'bodies', 'of', 'ten', 'of', 'its', 'men', 'who', 'were', 'killed', 'in', 'an', 'avalanche', 'the', 'previous', 'day', '.'], ['&', 'gt', ';', '*', 'The', 'four', 'civilians', 'killed', 'included', 'two', 'children', 'of', 'a', 'family', 'whose', 'house', 'was', 'hit', 'by', 'a', 'separate', 'avalanche', ',', 'also', 'on', 'Wednesday', ',', 'a', 'police', 'spokesman', 'said', '.'], ['The', 'bodies', 'of', 'the', 'soldiers', 'were', 'recovered', 'after', 'the', 'concerted', 'efforts', 'of', 'the', 'Avalanche', 'Rescue', 'Teams', '(', 'ART', ')', ',', 'which', 'is', 'equipped', 'to', 'work', 'in', 'inhospitable', 'terrain', 'and', 'weather', 'conditions', '.']]\n",
            "[['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'B-LOC', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n"
          ]
        }
      ],
      "source": [
        "print(tokenized_sentences[:5])\n",
        "print(predictions[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhY1gFCqKKci"
      },
      "outputs": [],
      "source": [
        "# calculate_f1(tweet_to_sentences_w_annotation, tokenized_sentences, predictions)\n",
        "calculate_f1_ner(tweet_to_sentences_w_annotation, tokenized_sentences, predictions)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "TZKMubBHEgZM",
        "usDw-ReUiklS",
        "bhnAJCnbjKIm",
        "M5qm2iIc8zzq",
        "UDEYZT668rNp",
        "mK4fkrxjLQZj",
        "47Do-RR4nsYt",
        "Mmj4tewsyPCv",
        "i6a02VCgGRl9",
        "ZQix93xPFfAf",
        "s8D38z3wO5Ia",
        "yZkJ9wBwUYZJ"
      ],
      "machine_shape": "hm",
      "name": "BERTweet-Collective-NER.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b1dc79a62aa4482bb258bbb610fe8801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75551b8dfb724224a1c01ca18a468dbd",
              "IPY_MODEL_e3faa268eb6c4ccca59b3088aaec4ab9",
              "IPY_MODEL_32bd522a15c34ae8822a610e2605da76"
            ],
            "layout": "IPY_MODEL_db66b7c836a6468194a7bad1dbfb4e52"
          }
        },
        "75551b8dfb724224a1c01ca18a468dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d4e228b9b8745eebbb2cc7388c46041",
            "placeholder": "​",
            "style": "IPY_MODEL_90097e15f993452ea7d428823eef398b",
            "value": "Downloading builder script: "
          }
        },
        "e3faa268eb6c4ccca59b3088aaec4ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd8f266dc9074c7aa2d0b60a717d1107",
            "max": 2543,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21ede9873eb044e6a1bf0759770f25d4",
            "value": 2543
          }
        },
        "32bd522a15c34ae8822a610e2605da76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dff7e1c834b4296a82ae4b181f72a07",
            "placeholder": "​",
            "style": "IPY_MODEL_80abe1a5fcfd428ab05f89b3467fac45",
            "value": " 7.46k/? [00:00&lt;00:00, 252kB/s]"
          }
        },
        "db66b7c836a6468194a7bad1dbfb4e52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d4e228b9b8745eebbb2cc7388c46041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90097e15f993452ea7d428823eef398b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd8f266dc9074c7aa2d0b60a717d1107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21ede9873eb044e6a1bf0759770f25d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5dff7e1c834b4296a82ae4b181f72a07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80abe1a5fcfd428ab05f89b3467fac45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f594642877e94e0c8424f67183cd393e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c4973cc228741279270e90a9a200fe4",
              "IPY_MODEL_f60b055cced64c0c889c277c612a8ef5",
              "IPY_MODEL_92152896c9ba41f6a4d2066ca54f4df7"
            ],
            "layout": "IPY_MODEL_2c95d44de52b41289afc44a904c7dc9a"
          }
        },
        "4c4973cc228741279270e90a9a200fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdc1bde71f0c4164b49560f78b789c59",
            "placeholder": "​",
            "style": "IPY_MODEL_6d729dc7617a44658e9fc71a16c2bbf9",
            "value": "Downloading metadata: "
          }
        },
        "f60b055cced64c0c889c277c612a8ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee8681564a50431dbb2eecafc815a9c7",
            "max": 1656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_304e3fb6d8cd46b2beef916d7ec358c9",
            "value": 1656
          }
        },
        "92152896c9ba41f6a4d2066ca54f4df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c92d53a9d14f43b5b426988ad4226402",
            "placeholder": "​",
            "style": "IPY_MODEL_5b6073439d3e44369c1afa80b86a12a8",
            "value": " 4.28k/? [00:00&lt;00:00, 155kB/s]"
          }
        },
        "2c95d44de52b41289afc44a904c7dc9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdc1bde71f0c4164b49560f78b789c59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d729dc7617a44658e9fc71a16c2bbf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee8681564a50431dbb2eecafc815a9c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "304e3fb6d8cd46b2beef916d7ec358c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c92d53a9d14f43b5b426988ad4226402": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b6073439d3e44369c1afa80b86a12a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3487d34848214cf8bbd86159f0c4e44e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_682cf09564b84076ac88e3bf83468b43",
              "IPY_MODEL_877b2dfec2224785b0362fb20e2bacdd",
              "IPY_MODEL_36e78d6c798f4780b105ff2feed7fa70"
            ],
            "layout": "IPY_MODEL_be0f742d1c88420ba704816164d26c91"
          }
        },
        "682cf09564b84076ac88e3bf83468b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07f3bfd67fb9420dbd75e4dd5881c988",
            "placeholder": "​",
            "style": "IPY_MODEL_a12795fcb64d4d9f9e716c0f1c19a69d",
            "value": "Downloading data files: 100%"
          }
        },
        "877b2dfec2224785b0362fb20e2bacdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a460fdfc13445b0a15ee2c27478ae17",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb7607908ab345828676cbe3b1b59878",
            "value": 3
          }
        },
        "36e78d6c798f4780b105ff2feed7fa70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c8363a885884e66ba1bd02ed0490d75",
            "placeholder": "​",
            "style": "IPY_MODEL_5c943f3a65f644e18e8b935a1af92293",
            "value": " 3/3 [00:01&lt;00:00,  1.94it/s]"
          }
        },
        "be0f742d1c88420ba704816164d26c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f3bfd67fb9420dbd75e4dd5881c988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a12795fcb64d4d9f9e716c0f1c19a69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a460fdfc13445b0a15ee2c27478ae17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb7607908ab345828676cbe3b1b59878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c8363a885884e66ba1bd02ed0490d75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c943f3a65f644e18e8b935a1af92293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11118b22ecef44acb95651080ed57889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0bfaf01db444496fa1846d573d69544b",
              "IPY_MODEL_9a3f2552057b434cae80ab5c9f54fd03",
              "IPY_MODEL_b860f904f8f24c0fb17ea57cd8b65b93"
            ],
            "layout": "IPY_MODEL_90b1f53888bb4d2ca9b77c5e6bc15c91"
          }
        },
        "0bfaf01db444496fa1846d573d69544b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7eb5e662063e4b4abf9c2b24bfb2ebdd",
            "placeholder": "​",
            "style": "IPY_MODEL_99582dfa47804bbc828fc6deeb8f2e2b",
            "value": "Downloading data: "
          }
        },
        "9a3f2552057b434cae80ab5c9f54fd03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdb8075f3d704dba990554ba0a3edd26",
            "max": 185319,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d64b301362224593bd5dec17f2941dc9",
            "value": 185319
          }
        },
        "b860f904f8f24c0fb17ea57cd8b65b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1534f65fe72c4d46acc6d36fb24fef8b",
            "placeholder": "​",
            "style": "IPY_MODEL_5114996707fc44cf9668e4041f8fa23f",
            "value": " 494k/? [00:00&lt;00:00, 9.22MB/s]"
          }
        },
        "90b1f53888bb4d2ca9b77c5e6bc15c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eb5e662063e4b4abf9c2b24bfb2ebdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99582dfa47804bbc828fc6deeb8f2e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdb8075f3d704dba990554ba0a3edd26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d64b301362224593bd5dec17f2941dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1534f65fe72c4d46acc6d36fb24fef8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5114996707fc44cf9668e4041f8fa23f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6402077d1b214d6b93af404593317be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dca18745ecf7403283b9270311bfab81",
              "IPY_MODEL_1f2e17ac40764137bf76a9ac05f588a3",
              "IPY_MODEL_a6f7afc495b0453bbdfe98ed7c9308fc"
            ],
            "layout": "IPY_MODEL_67a7649512d44261951ad4ceabd67fd9"
          }
        },
        "dca18745ecf7403283b9270311bfab81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_016dc1a71b8c49679a08b8c760938d1d",
            "placeholder": "​",
            "style": "IPY_MODEL_438ea8398f8544cbbc2e06815857245b",
            "value": "Downloading data: "
          }
        },
        "1f2e17ac40764137bf76a9ac05f588a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcc4728d9aa041a8803797182027eb8a",
            "max": 39129,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd1860a1309a49159f4528b845e39a90",
            "value": 39129
          }
        },
        "a6f7afc495b0453bbdfe98ed7c9308fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f7acf72e38d48ae86217d835c406746",
            "placeholder": "​",
            "style": "IPY_MODEL_017a638533ce4a9c9c90654a45970864",
            "value": " 115k/? [00:00&lt;00:00, 3.17MB/s]"
          }
        },
        "67a7649512d44261951ad4ceabd67fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "016dc1a71b8c49679a08b8c760938d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "438ea8398f8544cbbc2e06815857245b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcc4728d9aa041a8803797182027eb8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd1860a1309a49159f4528b845e39a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f7acf72e38d48ae86217d835c406746": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "017a638533ce4a9c9c90654a45970864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12e1acc660f4486d9ca030e0f8b4965f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb71e3aa19714a5faee990bbf5c36c78",
              "IPY_MODEL_758f0079ec8d42988a39901623852455",
              "IPY_MODEL_516af4dab11c49848cb37c3b87d3804e"
            ],
            "layout": "IPY_MODEL_21a9f8259807499ca01cfbbb423fb7c2"
          }
        },
        "cb71e3aa19714a5faee990bbf5c36c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bede4a6edbb4d53b0695c57dc8ee624",
            "placeholder": "​",
            "style": "IPY_MODEL_34add080a81b41f1918a06f7bf8ae80d",
            "value": "Downloading data: "
          }
        },
        "758f0079ec8d42988a39901623852455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24dcd3f5a6754179b056afd81741776e",
            "max": 66855,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a355142d418d4102b3f0db1c737318b7",
            "value": 66855
          }
        },
        "516af4dab11c49848cb37c3b87d3804e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c21bec3a8d3d404da07db6a48ad2306b",
            "placeholder": "​",
            "style": "IPY_MODEL_2cd342354af24677898d237f628214a6",
            "value": " 192k/? [00:00&lt;00:00, 5.20MB/s]"
          }
        },
        "21a9f8259807499ca01cfbbb423fb7c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bede4a6edbb4d53b0695c57dc8ee624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34add080a81b41f1918a06f7bf8ae80d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24dcd3f5a6754179b056afd81741776e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a355142d418d4102b3f0db1c737318b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c21bec3a8d3d404da07db6a48ad2306b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cd342354af24677898d237f628214a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0da11c0181a419a863cf86df151b130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_341ebdce16b942d2bd62e848d7928ad6",
              "IPY_MODEL_d6fd0eaadd4a4fbfab2fc7518a8d703f",
              "IPY_MODEL_60474ab9f1f94a1ea1bb149e6d9cb1e5"
            ],
            "layout": "IPY_MODEL_cfffe63f35054281b63372950bd28402"
          }
        },
        "341ebdce16b942d2bd62e848d7928ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a14a041b6d1f4642894754b1656477e8",
            "placeholder": "​",
            "style": "IPY_MODEL_ab525bd932fc4abdabf8f7438acff1a9",
            "value": "Extracting data files: 100%"
          }
        },
        "d6fd0eaadd4a4fbfab2fc7518a8d703f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fda688506364321bdea7203cecf8ca2",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33adeeed0e12464db6ddb6b9e424bcf2",
            "value": 3
          }
        },
        "60474ab9f1f94a1ea1bb149e6d9cb1e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dc306ede0b747cab4908cfceb3e93e3",
            "placeholder": "​",
            "style": "IPY_MODEL_0aff12944bc4477fbd1c8e50a55d2ca5",
            "value": " 3/3 [00:00&lt;00:00, 86.25it/s]"
          }
        },
        "cfffe63f35054281b63372950bd28402": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a14a041b6d1f4642894754b1656477e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab525bd932fc4abdabf8f7438acff1a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fda688506364321bdea7203cecf8ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33adeeed0e12464db6ddb6b9e424bcf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9dc306ede0b747cab4908cfceb3e93e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aff12944bc4477fbd1c8e50a55d2ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ae92aaf38054c5686254b54db2b9358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_983991292c114144bb00e7652ee26d27",
              "IPY_MODEL_1d630bed2e9242b1b4c6af977f1d0d40",
              "IPY_MODEL_67905dcd3dde4153b083ff740c720631"
            ],
            "layout": "IPY_MODEL_64b6cf52ffbe46559ffd5e2b0f13f505"
          }
        },
        "983991292c114144bb00e7652ee26d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dda3391cadf54674b11f5b55413e8a64",
            "placeholder": "​",
            "style": "IPY_MODEL_47f04fb929644df49aa2d7a9cf4d8b29",
            "value": "Generating train split:  94%"
          }
        },
        "1d630bed2e9242b1b4c6af977f1d0d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4744990b4dff49e682eb8fec87d3c913",
            "max": 3394,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78dfd3449d4044c8876e1db237fbcaea",
            "value": 3394
          }
        },
        "67905dcd3dde4153b083ff740c720631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42c68f1abc3f4f649405235fc2f09b81",
            "placeholder": "​",
            "style": "IPY_MODEL_39b51ca1f7f3474d959af284ed1d3b7a",
            "value": " 3186/3394 [00:00&lt;00:00, 6798.90 examples/s]"
          }
        },
        "64b6cf52ffbe46559ffd5e2b0f13f505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dda3391cadf54674b11f5b55413e8a64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47f04fb929644df49aa2d7a9cf4d8b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4744990b4dff49e682eb8fec87d3c913": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78dfd3449d4044c8876e1db237fbcaea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42c68f1abc3f4f649405235fc2f09b81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39b51ca1f7f3474d959af284ed1d3b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e034861130ee4d318039554952aed21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b9970ad33ed455a9468ca2be2d7d51e",
              "IPY_MODEL_7e67a319203a4820aec374761c32279e",
              "IPY_MODEL_911ec2b356f94117af483ff6f16aff38"
            ],
            "layout": "IPY_MODEL_efb99f2c061f4692b0dd98e83cc4869e"
          }
        },
        "6b9970ad33ed455a9468ca2be2d7d51e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02f629323214444cb105883b56ba6dce",
            "placeholder": "​",
            "style": "IPY_MODEL_5587442219ad4173a1067c2bb68f011c",
            "value": "Generating validation split:  53%"
          }
        },
        "7e67a319203a4820aec374761c32279e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14df70a7b046465ab74998bfa20b44c2",
            "max": 1009,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_684ee0417cba480f81529058ba2fa209",
            "value": 1009
          }
        },
        "911ec2b356f94117af483ff6f16aff38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0decd33fc65b4992be382ea9b9b04022",
            "placeholder": "​",
            "style": "IPY_MODEL_ced851cbf22b4ad0a22800ba6059fb78",
            "value": " 537/1009 [00:00&lt;00:00, 5367.32 examples/s]"
          }
        },
        "efb99f2c061f4692b0dd98e83cc4869e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02f629323214444cb105883b56ba6dce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5587442219ad4173a1067c2bb68f011c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14df70a7b046465ab74998bfa20b44c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "684ee0417cba480f81529058ba2fa209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0decd33fc65b4992be382ea9b9b04022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ced851cbf22b4ad0a22800ba6059fb78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75835fca11ba455b85f78dd28876a8e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f63dfd4ee0934560a3796fbf8accf1c6",
              "IPY_MODEL_fd47174d492d49a6bc17b211a6650bb7",
              "IPY_MODEL_7e7ee8ba4b2c42d0b157cbf5890e9a29"
            ],
            "layout": "IPY_MODEL_03a50289cf6e4e42af01454d78bf415d"
          }
        },
        "f63dfd4ee0934560a3796fbf8accf1c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0de2fbb52c940b6937945e098d0469e",
            "placeholder": "​",
            "style": "IPY_MODEL_636636f5b0ab4a47bbef54d9875d31df",
            "value": "Generating test split:  91%"
          }
        },
        "fd47174d492d49a6bc17b211a6650bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4866c09cd447474fa5f4ecebd12d30e4",
            "max": 1287,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05bc48434e634f64bec3bcc23e37862b",
            "value": 1287
          }
        },
        "7e7ee8ba4b2c42d0b157cbf5890e9a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afd610ff06e340059b7bf8c21b64ef5a",
            "placeholder": "​",
            "style": "IPY_MODEL_39ee43655bcf44389350a1ae07d0f165",
            "value": " 1165/1287 [00:00&lt;00:00, 5968.31 examples/s]"
          }
        },
        "03a50289cf6e4e42af01454d78bf415d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0de2fbb52c940b6937945e098d0469e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "636636f5b0ab4a47bbef54d9875d31df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4866c09cd447474fa5f4ecebd12d30e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05bc48434e634f64bec3bcc23e37862b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afd610ff06e340059b7bf8c21b64ef5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39ee43655bcf44389350a1ae07d0f165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a7861554e624405b7f5db21dd38cccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87fbe3da467f43488c2394ee6c37b5d5",
              "IPY_MODEL_857aecde3da14be5b4af41808c74483c",
              "IPY_MODEL_9bb7095aaabc431da3960e1051ea6018"
            ],
            "layout": "IPY_MODEL_57c062d610ae4521b25f5eca7ac1ce07"
          }
        },
        "87fbe3da467f43488c2394ee6c37b5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf8bbd7fa3224ec39a4093bac8594c87",
            "placeholder": "​",
            "style": "IPY_MODEL_1ab7a9bc3e53418bbcfad8d80e7942cc",
            "value": "100%"
          }
        },
        "857aecde3da14be5b4af41808c74483c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_879076ff6d184ad19d700189cbf3c222",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79a6045891cd4797a06f77ff1ee9200a",
            "value": 3
          }
        },
        "9bb7095aaabc431da3960e1051ea6018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77c0c07ce21a4e11836d3d36dca794e8",
            "placeholder": "​",
            "style": "IPY_MODEL_6ff9dd7daaae4901a544605011df5fa1",
            "value": " 3/3 [00:00&lt;00:00, 79.04it/s]"
          }
        },
        "57c062d610ae4521b25f5eca7ac1ce07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf8bbd7fa3224ec39a4093bac8594c87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ab7a9bc3e53418bbcfad8d80e7942cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "879076ff6d184ad19d700189cbf3c222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79a6045891cd4797a06f77ff1ee9200a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77c0c07ce21a4e11836d3d36dca794e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff9dd7daaae4901a544605011df5fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c55b682db6794c2ba68ffde709a2ae49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e10f5ab75f024e57b7057d7172865a41",
              "IPY_MODEL_e9e4844f0345464591cac1676511ae8a",
              "IPY_MODEL_ab73c596820e4189846ad824f51db0e7"
            ],
            "layout": "IPY_MODEL_0db4a224496a4f9bba8f7b537c1da0e9"
          }
        },
        "e10f5ab75f024e57b7057d7172865a41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e3f8d971715479c9db649966522e3b9",
            "placeholder": "​",
            "style": "IPY_MODEL_fcb8b669e6e646df8c2b60410b4089ca",
            "value": "100%"
          }
        },
        "e9e4844f0345464591cac1676511ae8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aec35f6fadb04dc9bf05a9cf2e79d756",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7174a5d08404d64b56467596b08f189",
            "value": 3
          }
        },
        "ab73c596820e4189846ad824f51db0e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3628a3ff8624bbe894c76baa547a011",
            "placeholder": "​",
            "style": "IPY_MODEL_dbe2a15f7e644090bb9a0be73fcba41a",
            "value": " 3/3 [00:00&lt;00:00, 78.09it/s]"
          }
        },
        "0db4a224496a4f9bba8f7b537c1da0e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e3f8d971715479c9db649966522e3b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcb8b669e6e646df8c2b60410b4089ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aec35f6fadb04dc9bf05a9cf2e79d756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7174a5d08404d64b56467596b08f189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3628a3ff8624bbe894c76baa547a011": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbe2a15f7e644090bb9a0be73fcba41a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "001a47f6a44f4f4781b792c29f510d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdfc07901bd04641bf98d73a951d9714",
              "IPY_MODEL_5e19564359dc4c29a0d36d448a55ae8e",
              "IPY_MODEL_2ee3a5b3a6744fbf8679e0ad285d3b4d"
            ],
            "layout": "IPY_MODEL_dc854083c65449b8b948be940a55bf4a"
          }
        },
        "bdfc07901bd04641bf98d73a951d9714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a7209429f0f4d3ca57b090dafc5a07f",
            "placeholder": "​",
            "style": "IPY_MODEL_f42be22a4c8844d18cbeeb967f921be4",
            "value": "Downloading: 100%"
          }
        },
        "5e19564359dc4c29a0d36d448a55ae8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bd42e413aa140388db8198725274c12",
            "max": 558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5436b51e3784addb57194608dff4961",
            "value": 558
          }
        },
        "2ee3a5b3a6744fbf8679e0ad285d3b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d195df342704c738ace65708401ad45",
            "placeholder": "​",
            "style": "IPY_MODEL_6dcba632ec6a44b5a29525e407ff63a6",
            "value": " 558/558 [00:00&lt;00:00, 23.1kB/s]"
          }
        },
        "dc854083c65449b8b948be940a55bf4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a7209429f0f4d3ca57b090dafc5a07f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f42be22a4c8844d18cbeeb967f921be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bd42e413aa140388db8198725274c12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5436b51e3784addb57194608dff4961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d195df342704c738ace65708401ad45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dcba632ec6a44b5a29525e407ff63a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac0e8aa8bc444c1ca9c10a20af732e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5560accc267c432096cee013ea4cbb73",
              "IPY_MODEL_6dce300f9032420cab5f14ca67515f73",
              "IPY_MODEL_a58a373671104e1f899d7f1aa4d9f145"
            ],
            "layout": "IPY_MODEL_32d4baca23d9443599ed1b53edd247b0"
          }
        },
        "5560accc267c432096cee013ea4cbb73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f448e4bfa7145dd92a78c9877226403",
            "placeholder": "​",
            "style": "IPY_MODEL_34618d5166be4e1b973a756ec633217b",
            "value": "Downloading: 100%"
          }
        },
        "6dce300f9032420cab5f14ca67515f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_156e05ab87374e98abd19229fcae0025",
            "max": 843438,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f83be78a5f814fd393d237e12a85f6a6",
            "value": 843438
          }
        },
        "a58a373671104e1f899d7f1aa4d9f145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2b1953ed7a34c4eaaccde5630b1ef73",
            "placeholder": "​",
            "style": "IPY_MODEL_e23a9dfec8014e999a07c7a669bd0655",
            "value": " 824k/824k [00:01&lt;00:00, 1.24MB/s]"
          }
        },
        "32d4baca23d9443599ed1b53edd247b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f448e4bfa7145dd92a78c9877226403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34618d5166be4e1b973a756ec633217b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "156e05ab87374e98abd19229fcae0025": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f83be78a5f814fd393d237e12a85f6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2b1953ed7a34c4eaaccde5630b1ef73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e23a9dfec8014e999a07c7a669bd0655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a016bea695644ef39f99eebd27c586c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59d8d3aee55d4b03964cfc0346be9dc8",
              "IPY_MODEL_b860b0c2195c4ac093b9fb9b364ca3b9",
              "IPY_MODEL_aef6b6efb0944dc580da07bab67fb7ce"
            ],
            "layout": "IPY_MODEL_9b2b7f29d6ba47c4944cf7e46920622d"
          }
        },
        "59d8d3aee55d4b03964cfc0346be9dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7e4cff77eb74dada3042a61321f1c50",
            "placeholder": "​",
            "style": "IPY_MODEL_01ad3c8ff3a849289bd6e272c63da9fe",
            "value": "Downloading: 100%"
          }
        },
        "b860b0c2195c4ac093b9fb9b364ca3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21539e4e9a8e4e4c93bcfcd6ed6694b7",
            "max": 1078931,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62e53537522148b6919c54ca87da8f2f",
            "value": 1078931
          }
        },
        "aef6b6efb0944dc580da07bab67fb7ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30e7ce61472a47b794a30b5feb7d9654",
            "placeholder": "​",
            "style": "IPY_MODEL_317885226f9d402e932cdf4b8b05fd2a",
            "value": " 1.03M/1.03M [00:00&lt;00:00, 1.31MB/s]"
          }
        },
        "9b2b7f29d6ba47c4944cf7e46920622d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7e4cff77eb74dada3042a61321f1c50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01ad3c8ff3a849289bd6e272c63da9fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21539e4e9a8e4e4c93bcfcd6ed6694b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62e53537522148b6919c54ca87da8f2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30e7ce61472a47b794a30b5feb7d9654": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "317885226f9d402e932cdf4b8b05fd2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2aba4ab958146b08209e8477172c4f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7db12347aef44a20ac873519e5b9e271",
              "IPY_MODEL_e7b2e6a804fb4980a082e47bbbca5ef2",
              "IPY_MODEL_6a138311557946509ce7a899dd0184c7"
            ],
            "layout": "IPY_MODEL_dde1fb9123094acaacf319367e9f8f36"
          }
        },
        "7db12347aef44a20ac873519e5b9e271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13c8b391e2504051ad4e9ae56fe5fea7",
            "placeholder": "​",
            "style": "IPY_MODEL_6d75cbd13a404381aa4c331440aab769",
            "value": "100%"
          }
        },
        "e7b2e6a804fb4980a082e47bbbca5ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeaca672735f4408b7af772bf2eec94a",
            "max": 3394,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5c4bfd36e634319bc0b8df3a21fb690",
            "value": 3394
          }
        },
        "6a138311557946509ce7a899dd0184c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f48697ac141742e9979ad4401c8307a7",
            "placeholder": "​",
            "style": "IPY_MODEL_051ff8fc9f33434c9ce21b438faf2dc5",
            "value": " 3394/3394 [00:09&lt;00:00, 405.68ex/s]"
          }
        },
        "dde1fb9123094acaacf319367e9f8f36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13c8b391e2504051ad4e9ae56fe5fea7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d75cbd13a404381aa4c331440aab769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aeaca672735f4408b7af772bf2eec94a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5c4bfd36e634319bc0b8df3a21fb690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f48697ac141742e9979ad4401c8307a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "051ff8fc9f33434c9ce21b438faf2dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70afe0c654ff4325a3c26301419eab13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8b333f021c44369964215231feafdf0",
              "IPY_MODEL_501f1fbb3ba442ee957ac0959ad9f3c9",
              "IPY_MODEL_e4dac02df09344c9a3a7f6009841c5ca"
            ],
            "layout": "IPY_MODEL_7db6534be7fe4381adad2a3959674cf0"
          }
        },
        "c8b333f021c44369964215231feafdf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a6d01a888114fb7acf8ce29e4ca1300",
            "placeholder": "​",
            "style": "IPY_MODEL_b4fc7614208c4a8291a3a556796209a1",
            "value": "100%"
          }
        },
        "501f1fbb3ba442ee957ac0959ad9f3c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d51ae2c200344478c8b69192cb20e52",
            "max": 1009,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1800f59450f14bf18ff3408613cc3fc4",
            "value": 1009
          }
        },
        "e4dac02df09344c9a3a7f6009841c5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5aba16676355445d94d85402ee01b30c",
            "placeholder": "​",
            "style": "IPY_MODEL_66f5936b02e9485f9339201109a03d52",
            "value": " 1009/1009 [00:02&lt;00:00, 456.84ex/s]"
          }
        },
        "7db6534be7fe4381adad2a3959674cf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a6d01a888114fb7acf8ce29e4ca1300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4fc7614208c4a8291a3a556796209a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d51ae2c200344478c8b69192cb20e52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1800f59450f14bf18ff3408613cc3fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5aba16676355445d94d85402ee01b30c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66f5936b02e9485f9339201109a03d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb3a8918d26745a4b06a52888cebaf3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63f90a215ac4483e9885f6595f39b8fd",
              "IPY_MODEL_3b13c49be3b946debe6ba1f05cdbe6bc",
              "IPY_MODEL_743bc0e178d1440f8ebf559178f26739"
            ],
            "layout": "IPY_MODEL_9a1370d962954032a86366b037e2b7dd"
          }
        },
        "63f90a215ac4483e9885f6595f39b8fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7002d3142d54435b9fcddf6112815143",
            "placeholder": "​",
            "style": "IPY_MODEL_5a5bcf77d77a487db478b3ba3ff88dec",
            "value": "100%"
          }
        },
        "3b13c49be3b946debe6ba1f05cdbe6bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcf98d2121544e8d8cf82d755c5cfa86",
            "max": 1287,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5bdb0de0fb9477f994e436c0e0176be",
            "value": 1287
          }
        },
        "743bc0e178d1440f8ebf559178f26739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eba193d7ffb41c48d8e2b016d9d1c77",
            "placeholder": "​",
            "style": "IPY_MODEL_e5d0bb6789bf4219b3d4de3cabfad0b5",
            "value": " 1287/1287 [00:03&lt;00:00, 402.31ex/s]"
          }
        },
        "9a1370d962954032a86366b037e2b7dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7002d3142d54435b9fcddf6112815143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a5bcf77d77a487db478b3ba3ff88dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcf98d2121544e8d8cf82d755c5cfa86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5bdb0de0fb9477f994e436c0e0176be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9eba193d7ffb41c48d8e2b016d9d1c77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5d0bb6789bf4219b3d4de3cabfad0b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "751993f2713947bd9fc5609ade3a715e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95cdababeab948a1971fd47a128a3d72",
              "IPY_MODEL_c1ebe461a96b4c2091187dc38034d868",
              "IPY_MODEL_9b1b48a6fcd24c37b70b58600e6d2bdf"
            ],
            "layout": "IPY_MODEL_a6ee188762704779a0eafbe7375ca131"
          }
        },
        "95cdababeab948a1971fd47a128a3d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d34f53bdb8d14e27bba0994550d2b55b",
            "placeholder": "​",
            "style": "IPY_MODEL_41f38cf56e8642faac3fff2b33285a91",
            "value": "Downloading builder script: "
          }
        },
        "c1ebe461a96b4c2091187dc38034d868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be334e62079342a79621dc1a16b909c2",
            "max": 2472,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17f809e03fb04dcc92dc24b452f00323",
            "value": 2472
          }
        },
        "9b1b48a6fcd24c37b70b58600e6d2bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aea79f74e784e05b8c5834f18cd44da",
            "placeholder": "​",
            "style": "IPY_MODEL_e685a34d99af42db8e8185195807b0e9",
            "value": " 6.33k/? [00:00&lt;00:00, 177kB/s]"
          }
        },
        "a6ee188762704779a0eafbe7375ca131": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d34f53bdb8d14e27bba0994550d2b55b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41f38cf56e8642faac3fff2b33285a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be334e62079342a79621dc1a16b909c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17f809e03fb04dcc92dc24b452f00323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2aea79f74e784e05b8c5834f18cd44da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e685a34d99af42db8e8185195807b0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7f9192387ed47e5938c1db413f50db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28cc23a1d218414c826871979888e30c",
              "IPY_MODEL_47331b4f621e4e0ca3c667aa9cb16e67",
              "IPY_MODEL_0efca1f12bdb4a7697a2cb4549b0b787"
            ],
            "layout": "IPY_MODEL_c41cdcf9ddce42e1860300b96c7300cb"
          }
        },
        "28cc23a1d218414c826871979888e30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c450dacebed414f89c36e49341dcf58",
            "placeholder": "​",
            "style": "IPY_MODEL_597e2fcf39824fd791dac9c038b01f93",
            "value": "Downloading: 100%"
          }
        },
        "47331b4f621e4e0ca3c667aa9cb16e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c9d32087b1f4ba18b5d8563ea968a52",
            "max": 542529064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8646b1a071d4e1983c38bc8545f2809",
            "value": 542529064
          }
        },
        "0efca1f12bdb4a7697a2cb4549b0b787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17859754b95b4b23869d9d525cfcf6be",
            "placeholder": "​",
            "style": "IPY_MODEL_aa8a6edf3df44000a29f0b2eda246ee8",
            "value": " 517M/517M [00:10&lt;00:00, 52.9MB/s]"
          }
        },
        "c41cdcf9ddce42e1860300b96c7300cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c450dacebed414f89c36e49341dcf58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "597e2fcf39824fd791dac9c038b01f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c9d32087b1f4ba18b5d8563ea968a52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8646b1a071d4e1983c38bc8545f2809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17859754b95b4b23869d9d525cfcf6be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa8a6edf3df44000a29f0b2eda246ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}